{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import sys\n",
    "sys.path.append('../')    \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, average_precision_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "from scipy.stats import randint\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cricket_matches(df):\n",
    "    df = df.sort_values(['Match Date', 'Ground'])\n",
    "\n",
    "    teams_a = df.iloc[::2].reset_index(drop=True)  # Even rows\n",
    "    teams_b = df.iloc[1::2].reset_index(drop=True)  # Odd rows\n",
    "    \n",
    "    renamed_cols_a = {\n",
    "        'Winner': 'Winner', \n",
    "        'Match Date': 'Match Date',\n",
    "        'Ground': 'Ground',\n",
    "        'Team': 'Team_A',\n",
    "        'Opposition': 'Team_B',\n",
    "        'RR_rolling': 'Team_A_RR_rolling',\n",
    "        'batting_average_rolling': 'Team_A_batting_average_rolling',\n",
    "        'BP_rolling': 'Team_A_BP_rolling',\n",
    "        'SR_rolling': 'Team_A_SR_rolling',\n",
    "        'bowling_average_rolling': 'Team_A_bowling_average_rolling',\n",
    "        'ER_rolling': 'Team_A_ER_rolling',\n",
    "        'balls_per_wicket_rolling': 'Team_A_balls_per_wicket_rolling'\n",
    "    }\n",
    "    \n",
    "    renamed_cols_b = {\n",
    "        'Team': 'Team_B_actual',  \n",
    "        'Opposition': 'Team_A_actual', \n",
    "        'RR_rolling': 'Team_B_RR_rolling',\n",
    "        'batting_average_rolling': 'Team_B_batting_average_rolling',\n",
    "        'BP_rolling': 'Team_B_BP_rolling',\n",
    "        'SR_rolling': 'Team_B_SR_rolling',\n",
    "        'bowling_average_rolling': 'Team_B_bowling_average_rolling',\n",
    "        'ER_rolling': 'Team_B_ER_rolling',\n",
    "        'balls_per_wicket_rolling': 'Team_B_balls_per_wicket_rolling'\n",
    "    }\n",
    "\n",
    "    teams_a = teams_a.rename(columns=renamed_cols_a)\n",
    "    teams_b = teams_b.rename(columns=renamed_cols_b)\n",
    "    \n",
    "    teams_b = teams_b[[col for col in renamed_cols_b.values()]]\n",
    "    \n",
    "    merged_df = pd.concat([teams_a, teams_b], axis=1)\n",
    "    \n",
    "    merged_df = merged_df.drop(['Team_B_actual', 'Team_A_actual'], axis=1)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/matches_rolling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Opposition</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Ground</th>\n",
       "      <th>Match Date</th>\n",
       "      <th>Scorecard</th>\n",
       "      <th>RR</th>\n",
       "      <th>batting_average</th>\n",
       "      <th>BP</th>\n",
       "      <th>SR</th>\n",
       "      <th>...</th>\n",
       "      <th>day_code</th>\n",
       "      <th>opp_code</th>\n",
       "      <th>target</th>\n",
       "      <th>RR_rolling</th>\n",
       "      <th>batting_average_rolling</th>\n",
       "      <th>BP_rolling</th>\n",
       "      <th>SR_rolling</th>\n",
       "      <th>bowling_average_rolling</th>\n",
       "      <th>ER_rolling</th>\n",
       "      <th>balls_per_wicket_rolling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Dehradun</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>Test # 2351</td>\n",
       "      <td>3.010403</td>\n",
       "      <td>38.583333</td>\n",
       "      <td>0.604752</td>\n",
       "      <td>50.173385</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.216995</td>\n",
       "      <td>11.157895</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>53.616591</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>4.535885</td>\n",
       "      <td>69.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Chattogram</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>Test # 2361</td>\n",
       "      <td>2.906808</td>\n",
       "      <td>31.684211</td>\n",
       "      <td>0.495017</td>\n",
       "      <td>48.446805</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.086084</td>\n",
       "      <td>28.536612</td>\n",
       "      <td>0.625129</td>\n",
       "      <td>51.434730</td>\n",
       "      <td>33.867747</td>\n",
       "      <td>3.566780</td>\n",
       "      <td>54.606409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>Lucknow</td>\n",
       "      <td>2019-11-27</td>\n",
       "      <td>Test # 2370</td>\n",
       "      <td>2.755835</td>\n",
       "      <td>16.157895</td>\n",
       "      <td>0.534202</td>\n",
       "      <td>45.930580</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.001292</td>\n",
       "      <td>30.025332</td>\n",
       "      <td>0.563590</td>\n",
       "      <td>50.021530</td>\n",
       "      <td>26.788449</td>\n",
       "      <td>3.235241</td>\n",
       "      <td>47.494635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>Test # 2413</td>\n",
       "      <td>2.881907</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>0.548872</td>\n",
       "      <td>48.031780</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.913343</td>\n",
       "      <td>25.056542</td>\n",
       "      <td>0.553060</td>\n",
       "      <td>48.555717</td>\n",
       "      <td>27.287702</td>\n",
       "      <td>3.317095</td>\n",
       "      <td>47.968870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>Test # 2415</td>\n",
       "      <td>3.501340</td>\n",
       "      <td>93.285714</td>\n",
       "      <td>0.428790</td>\n",
       "      <td>58.355675</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.898444</td>\n",
       "      <td>19.484742</td>\n",
       "      <td>0.551075</td>\n",
       "      <td>48.307407</td>\n",
       "      <td>27.009171</td>\n",
       "      <td>3.427728</td>\n",
       "      <td>46.618700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team   Opposition       Winner      Ground Match Date  \\\n",
       "591   Afghanistan      Ireland  Afghanistan    Dehradun 2019-03-15   \n",
       "1185  Afghanistan   Bangladesh  Afghanistan  Chattogram 2019-09-05   \n",
       "572   Afghanistan  West Indies  West Indies     Lucknow 2019-11-27   \n",
       "52    Afghanistan     Zimbabwe     Zimbabwe   Abu Dhabi 2021-03-02   \n",
       "50    Afghanistan     Zimbabwe  Afghanistan   Abu Dhabi 2021-03-10   \n",
       "\n",
       "        Scorecard        RR  batting_average        BP         SR  ...  \\\n",
       "591   Test # 2351  3.010403        38.583333  0.604752  50.173385  ...   \n",
       "1185  Test # 2361  2.906808        31.684211  0.495017  48.446805  ...   \n",
       "572   Test # 2370  2.755835        16.157895  0.534202  45.930580  ...   \n",
       "52    Test # 2413  2.881907        13.300000  0.548872  48.031780  ...   \n",
       "50    Test # 2415  3.501340        93.285714  0.428790  58.355675  ...   \n",
       "\n",
       "      day_code  opp_code  target  RR_rolling  batting_average_rolling  \\\n",
       "591          4         5       1    3.216995                11.157895   \n",
       "1185         3         2       1    3.086084                28.536612   \n",
       "572          2        10      -1    3.001292                30.025332   \n",
       "52           1        11      -1    2.913343                25.056542   \n",
       "50           2        11       1    2.898444                19.484742   \n",
       "\n",
       "      BP_rolling  SR_rolling  bowling_average_rolling  ER_rolling  \\\n",
       "591     0.660377   53.616591                52.666667    4.535885   \n",
       "1185    0.625129   51.434730                33.867747    3.566780   \n",
       "572     0.563590   50.021530                26.788449    3.235241   \n",
       "52      0.553060   48.555717                27.287702    3.317095   \n",
       "50      0.551075   48.307407                27.009171    3.427728   \n",
       "\n",
       "      balls_per_wicket_rolling  \n",
       "591                  69.666667  \n",
       "1185                 54.606409  \n",
       "572                  47.494635  \n",
       "52                   47.968870  \n",
       "50                   46.618700  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_cricket_matches(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_A</th>\n",
       "      <th>Team_B</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Ground</th>\n",
       "      <th>Match Date</th>\n",
       "      <th>day_code</th>\n",
       "      <th>target</th>\n",
       "      <th>Team_A_RR_rolling</th>\n",
       "      <th>Team_A_batting_average_rolling</th>\n",
       "      <th>Team_A_BP_rolling</th>\n",
       "      <th>...</th>\n",
       "      <th>Team_A_bowling_average_rolling</th>\n",
       "      <th>Team_A_ER_rolling</th>\n",
       "      <th>Team_A_balls_per_wicket_rolling</th>\n",
       "      <th>Team_B_RR_rolling</th>\n",
       "      <th>Team_B_batting_average_rolling</th>\n",
       "      <th>Team_B_BP_rolling</th>\n",
       "      <th>Team_B_SR_rolling</th>\n",
       "      <th>Team_B_bowling_average_rolling</th>\n",
       "      <th>Team_B_ER_rolling</th>\n",
       "      <th>Team_B_balls_per_wicket_rolling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>England</td>\n",
       "      <td>drawn</td>\n",
       "      <td>North Sound</td>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.039106</td>\n",
       "      <td>28.631579</td>\n",
       "      <td>0.522059</td>\n",
       "      <td>...</td>\n",
       "      <td>60.555556</td>\n",
       "      <td>3.410513</td>\n",
       "      <td>106.533333</td>\n",
       "      <td>3.727088</td>\n",
       "      <td>45.750000</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>62.118126</td>\n",
       "      <td>40.312500</td>\n",
       "      <td>2.660891</td>\n",
       "      <td>90.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>England</td>\n",
       "      <td>England</td>\n",
       "      <td>St George's</td>\n",
       "      <td>2015-04-21</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.830963</td>\n",
       "      <td>35.059928</td>\n",
       "      <td>0.528264</td>\n",
       "      <td>...</td>\n",
       "      <td>52.407629</td>\n",
       "      <td>3.584733</td>\n",
       "      <td>88.436682</td>\n",
       "      <td>3.503236</td>\n",
       "      <td>60.995997</td>\n",
       "      <td>0.485829</td>\n",
       "      <td>58.387265</td>\n",
       "      <td>36.069948</td>\n",
       "      <td>2.731188</td>\n",
       "      <td>79.528170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>England</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>Bridgetown</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.819991</td>\n",
       "      <td>33.924740</td>\n",
       "      <td>0.524637</td>\n",
       "      <td>...</td>\n",
       "      <td>60.868975</td>\n",
       "      <td>3.476495</td>\n",
       "      <td>106.535227</td>\n",
       "      <td>3.464844</td>\n",
       "      <td>55.437500</td>\n",
       "      <td>0.478016</td>\n",
       "      <td>57.747396</td>\n",
       "      <td>62.800000</td>\n",
       "      <td>3.729216</td>\n",
       "      <td>101.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>Mirpur</td>\n",
       "      <td>2015-05-06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.729216</td>\n",
       "      <td>62.800000</td>\n",
       "      <td>0.426752</td>\n",
       "      <td>...</td>\n",
       "      <td>55.437500</td>\n",
       "      <td>3.464844</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>3.245982</td>\n",
       "      <td>47.074694</td>\n",
       "      <td>0.506726</td>\n",
       "      <td>54.099701</td>\n",
       "      <td>32.491955</td>\n",
       "      <td>2.967049</td>\n",
       "      <td>67.708111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>England</td>\n",
       "      <td>England</td>\n",
       "      <td>Lord's</td>\n",
       "      <td>2015-05-21</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.280493</td>\n",
       "      <td>49.666667</td>\n",
       "      <td>0.389262</td>\n",
       "      <td>...</td>\n",
       "      <td>29.052632</td>\n",
       "      <td>3.163324</td>\n",
       "      <td>55.105263</td>\n",
       "      <td>3.384855</td>\n",
       "      <td>46.102029</td>\n",
       "      <td>0.517168</td>\n",
       "      <td>56.414249</td>\n",
       "      <td>33.708354</td>\n",
       "      <td>3.169700</td>\n",
       "      <td>65.577706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team_A      Team_B       Winner       Ground Match Date  day_code  \\\n",
       "0  West Indies     England        drawn  North Sound 2015-04-13         0   \n",
       "1  West Indies     England      England  St George's 2015-04-21         1   \n",
       "2  West Indies     England  West Indies   Bridgetown 2015-05-01         4   \n",
       "3     Pakistan  Bangladesh     Pakistan       Mirpur 2015-05-06         2   \n",
       "4  New Zealand     England      England       Lord's 2015-05-21         3   \n",
       "\n",
       "   target  Team_A_RR_rolling  Team_A_batting_average_rolling  \\\n",
       "0       0           3.039106                       28.631579   \n",
       "1      -1           2.830963                       35.059928   \n",
       "2       1           2.819991                       33.924740   \n",
       "3       1           3.729216                       62.800000   \n",
       "4      -1           3.280493                       49.666667   \n",
       "\n",
       "   Team_A_BP_rolling  ...  Team_A_bowling_average_rolling  Team_A_ER_rolling  \\\n",
       "0           0.522059  ...                       60.555556           3.410513   \n",
       "1           0.528264  ...                       52.407629           3.584733   \n",
       "2           0.524637  ...                       60.868975           3.476495   \n",
       "3           0.426752  ...                       55.437500           3.464844   \n",
       "4           0.389262  ...                       29.052632           3.163324   \n",
       "\n",
       "   Team_A_balls_per_wicket_rolling  Team_B_RR_rolling  \\\n",
       "0                       106.533333           3.727088   \n",
       "1                        88.436682           3.503236   \n",
       "2                       106.535227           3.464844   \n",
       "3                        96.000000           3.245982   \n",
       "4                        55.105263           3.384855   \n",
       "\n",
       "   Team_B_batting_average_rolling  Team_B_BP_rolling  Team_B_SR_rolling  \\\n",
       "0                       45.750000           0.508197          62.118126   \n",
       "1                       60.995997           0.485829          58.387265   \n",
       "2                       55.437500           0.478016          57.747396   \n",
       "3                       47.074694           0.506726          54.099701   \n",
       "4                       46.102029           0.517168          56.414249   \n",
       "\n",
       "   Team_B_bowling_average_rolling  Team_B_ER_rolling  \\\n",
       "0                       40.312500           2.660891   \n",
       "1                       36.069948           2.731188   \n",
       "2                       62.800000           3.729216   \n",
       "3                       32.491955           2.967049   \n",
       "4                       33.708354           3.169700   \n",
       "\n",
       "   Team_B_balls_per_wicket_rolling  \n",
       "0                        90.900000  \n",
       "1                        79.528170  \n",
       "2                       101.040000  \n",
       "3                        67.708111  \n",
       "4                        65.577706  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=['Scorecard', 'RR',\n",
    "       'batting_average', 'BP', 'SR', 'bowling_average', 'ER',\n",
    "       'balls_per_wicket', 'opp_code' , 'ground_code', 'target'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = (data['Winner'] == data['Team_A']).astype(int)\n",
    "train_df = data[data['Match Date'] <= '2021-01-01']\n",
    "test_df = data[data['Match Date'] > '2021-01-01']\n",
    "train_df = train_df.drop(columns='Match Date')\n",
    "test_df = test_df.drop(columns='Match Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(df, target_col='Winner', cv_splits=5):\n",
    "    param_grid = {\n",
    "        'num_trees': [100, 200, 300],\n",
    "        'max_depth': [20, 30, -1],\n",
    "        'min_examples': [5, 10, 20],\n",
    "        'bootstrap_size_ratio': [1.0, 0.8]\n",
    "    }\n",
    "\n",
    "    param_combinations = [dict(zip(param_grid.keys(), v)) \n",
    "                    for v in itertools.product(*param_grid.values())]\n",
    "    \n",
    "    tuning_results = []\n",
    "\n",
    "    df = df.dropna()\n",
    "    exclude_cols = [target_col, 'Match Date', 'Ground', 'Team_A', 'Team_B']\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    feature_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "    \n",
    "    X = df.drop(columns=['target'])\n",
    "    \n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for params in param_combinations:\n",
    "        print(f\"\\nTesting parameters: {params}\")\n",
    "        fold_metrics = {'precision': [], 'avg_precision': []}\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            df_train, df_val = df.iloc[train_idx], df.iloc[val_idx]\n",
    "\n",
    "            train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "                df_train, label='target', task=tfdf.keras.Task.CLASSIFICATION\n",
    "            )\n",
    "            val_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "                df_val, label='target', task=tfdf.keras.Task.CLASSIFICATION\n",
    "            )\n",
    "            \n",
    "            model = tfdf.keras.RandomForestModel(\n",
    "                num_trees=params['num_trees'],\n",
    "                max_depth=params['max_depth'],\n",
    "                min_examples=params['min_examples'],\n",
    "                bootstrap_size_ratio=params['bootstrap_size_ratio'],\n",
    "                task=tfdf.keras.Task.CLASSIFICATION\n",
    "            )\n",
    "            \n",
    "            model.fit(train_ds, verboes=0)\n",
    "            \n",
    "            y_pred_proba = model.predict(val_ds)\n",
    "            y_pred_binary = (y_pred_proba > 0.5).astype(int)\n",
    "            \n",
    "            fold_metrics['precision'].append(precision_score(df_val['target'], y_pred_binary))\n",
    "            fold_metrics['avg_precision'].append(average_precision_score(df_val['target'], y_pred_proba))\n",
    "        \n",
    "        tuning_results.append({\n",
    "            **params,\n",
    "            'mean_precision': np.mean(fold_metrics['precision']),\n",
    "            'std_precision': np.std(fold_metrics['precision']),\n",
    "            'mean_avg_precision': np.mean(fold_metrics['avg_precision']),\n",
    "            'std_avg_precision': np.std(fold_metrics['avg_precision'])\n",
    "        })\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(tuning_results)\n",
    "    \n",
    "    # Get best parameters based on average precision\n",
    "    best_params = results_df.loc[results_df['mean_avg_precision'].idxmax()]\n",
    "    \n",
    "    return best_params, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 20, 'min_examples': 5, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7rq105rf as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:01.598148. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.019452\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729625066.729032 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625066.729051 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625066.729056 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625066.729278 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625066.729282 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625066.729325 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625066.729336 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625066.729341 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625066.729346 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625066.729374 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625066.729395 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625066.729527 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625066.729691 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7rq105rf/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625066.729796 6784310 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625066.729908 6784310 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625066.730416 6784322 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.55814 logloss:15.9263\n",
      "I0000 00:00:1729625066.730646 6784324 random_forest.cc:812] Training of tree  11/100 (tree index:8) done accuracy:0.70339 logloss:4.31404\n",
      "I0000 00:00:1729625066.730930 6784325 random_forest.cc:812] Training of tree  21/100 (tree index:24) done accuracy:0.708333 logloss:1.3862\n",
      "I0000 00:00:1729625066.731148 6784325 random_forest.cc:812] Training of tree  32/100 (tree index:32) done accuracy:0.725 logloss:0.848473\n",
      "I0000 00:00:1729625066.731391 6784323 random_forest.cc:812] Training of tree  42/100 (tree index:35) done accuracy:0.741667 logloss:0.547436\n",
      "I0000 00:00:1729625066.731551 6784326 random_forest.cc:812] Training of tree  52/100 (tree index:52) done accuracy:0.733333 logloss:0.549734\n",
      "I0000 00:00:1729625066.731742 6784327 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.758333 logloss:0.528999\n",
      "I0000 00:00:1729625066.731932 6784324 random_forest.cc:812] Training of tree  72/100 (tree index:71) done accuracy:0.758333 logloss:0.530853\n",
      "I0000 00:00:1729625066.732124 6784321 random_forest.cc:812] Training of tree  82/100 (tree index:82) done accuracy:0.733333 logloss:0.522988\n",
      "I0000 00:00:1729625066.732344 6784327 random_forest.cc:812] Training of tree  92/100 (tree index:95) done accuracy:0.725 logloss:0.524086\n",
      "I0000 00:00:1729625066.732675 6784325 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.758333 logloss:0.522872\n",
      "I0000 00:00:1729625066.732777 6784310 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.522872\n",
      "I0000 00:00:1729625066.733193 6784310 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7rq105rf with prefix b6dd6291aa5e4253\n",
      "I0000 00:00:1729625066.735172 6784310 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625066.736324 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.522872\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  15\n",
      "2  14  48\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:26.742398: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7rq105rf/model/ with prefix b6dd6291aa5e4253\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729625066.745350 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2188 node(s), and 19 input feature(s).\n",
      "I0000 00:00:1729625066.745380 6784195 abstract_model.cc:1323] Engine \"RandomForestOptPred\" built\n",
      "2024-10-22 20:24:26.745387: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpoir446vz as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.133961. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016776\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625067.301314 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625067.301323 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625067.301329 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625067.301398 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625067.301402 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625067.301449 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.301459 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.301465 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.301470 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.301499 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625067.301516 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625067.301650 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625067.301677 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpoir446vz/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625067.301743 6784380 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625067.301879 6784380 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625067.302363 6784390 random_forest.cc:812] Training of tree  1/100 (tree index:4) done accuracy:0.729167 logloss:9.76182\n",
      "I0000 00:00:1729625067.302590 6784396 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.672269 logloss:4.03093\n",
      "I0000 00:00:1729625067.302775 6784391 random_forest.cc:812] Training of tree  21/100 (tree index:19) done accuracy:0.716667 logloss:0.821922\n",
      "I0000 00:00:1729625067.302982 6784396 random_forest.cc:812] Training of tree  31/100 (tree index:32) done accuracy:0.758333 logloss:0.788058\n",
      "I0000 00:00:1729625067.303145 6784393 random_forest.cc:812] Training of tree  41/100 (tree index:41) done accuracy:0.733333 logloss:0.518671\n",
      "I0000 00:00:1729625067.303359 6784390 random_forest.cc:812] Training of tree  51/100 (tree index:36) done accuracy:0.741667 logloss:0.509184\n",
      "I0000 00:00:1729625067.303579 6784394 random_forest.cc:812] Training of tree  61/100 (tree index:59) done accuracy:0.741667 logloss:0.517732\n",
      "I0000 00:00:1729625067.303804 6784394 random_forest.cc:812] Training of tree  71/100 (tree index:70) done accuracy:0.733333 logloss:0.514675\n",
      "I0000 00:00:1729625067.304004 6784390 random_forest.cc:812] Training of tree  81/100 (tree index:80) done accuracy:0.741667 logloss:0.500752\n",
      "I0000 00:00:1729625067.304309 6784396 random_forest.cc:812] Training of tree  91/100 (tree index:92) done accuracy:0.775 logloss:0.490298\n",
      "I0000 00:00:1729625067.304473 6784395 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.766667 logloss:0.490591\n",
      "I0000 00:00:1729625067.304500 6784380 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.490591\n",
      "I0000 00:00:1729625067.304778 6784380 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpoir446vz with prefix 2f0d8638680e4499\n",
      "I0000 00:00:1729625067.307481 6784380 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625067.308160 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.490591\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  13  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:27.313426: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpoir446vz/model/ with prefix 2f0d8638680e4499\n",
      "I0000 00:00:1729625067.316404 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2252 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:27.316418: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpko06gazu as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.139817. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015473\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625067.595840 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625067.595852 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625067.595856 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625067.595918 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625067.595922 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625067.595966 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.595978 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.595984 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.595990 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.596017 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625067.596035 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625067.596178 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625067.596208 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpko06gazu/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625067.596268 6784450 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625067.596373 6784450 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625067.596834 6784459 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.697674 logloss:10.8969\n",
      "I0000 00:00:1729625067.597000 6784463 random_forest.cc:812] Training of tree  12/100 (tree index:11) done accuracy:0.722689 logloss:2.78325\n",
      "I0000 00:00:1729625067.597237 6784465 random_forest.cc:812] Training of tree  23/100 (tree index:23) done accuracy:0.7 logloss:0.57094\n",
      "I0000 00:00:1729625067.597459 6784465 random_forest.cc:812] Training of tree  34/100 (tree index:33) done accuracy:0.683333 logloss:0.580726\n",
      "I0000 00:00:1729625067.597665 6784465 random_forest.cc:812] Training of tree  44/100 (tree index:45) done accuracy:0.733333 logloss:0.564169\n",
      "I0000 00:00:1729625067.597861 6784462 random_forest.cc:812] Training of tree  55/100 (tree index:54) done accuracy:0.716667 logloss:0.555252\n",
      "I0000 00:00:1729625067.598087 6784459 random_forest.cc:812] Training of tree  65/100 (tree index:64) done accuracy:0.75 logloss:0.543012\n",
      "I0000 00:00:1729625067.598284 6784459 random_forest.cc:812] Training of tree  76/100 (tree index:77) done accuracy:0.733333 logloss:0.54805\n",
      "I0000 00:00:1729625067.598501 6784462 random_forest.cc:812] Training of tree  86/100 (tree index:86) done accuracy:0.741667 logloss:0.543914\n",
      "I0000 00:00:1729625067.598703 6784460 random_forest.cc:812] Training of tree  96/100 (tree index:96) done accuracy:0.733333 logloss:0.532932\n",
      "I0000 00:00:1729625067.598724 6784463 random_forest.cc:812] Training of tree  100/100 (tree index:90) done accuracy:0.741667 logloss:0.533083\n",
      "I0000 00:00:1729625067.598797 6784450 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.533083\n",
      "I0000 00:00:1729625067.599087 6784450 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpko06gazu with prefix d6f8c023742b473b\n",
      "I0000 00:00:1729625067.600742 6784450 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625067.601339 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.533083\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  16\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:27.606385: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpko06gazu/model/ with prefix d6f8c023742b473b\n",
      "I0000 00:00:1729625067.609622 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2286 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:27.609639: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x3021b0900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x3021b0900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x300eb9300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x300eb9300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgewox1e9 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.130831. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625067.875143 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625067.875157 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625067.875161 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625067.875230 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625067.875235 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625067.875284 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.875294 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.875300 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.875305 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625067.875335 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625067.875354 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625067.875515 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625067.875540 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgewox1e9/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625067.875587 6784536 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625067.875690 6784536 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625067.876098 6784549 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625067.876340 6784547 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.747899 logloss:2.71579\n",
      "I0000 00:00:1729625067.876571 6784547 random_forest.cc:812] Training of tree  21/100 (tree index:22) done accuracy:0.816667 logloss:0.423215\n",
      "I0000 00:00:1729625067.876748 6784549 random_forest.cc:812] Training of tree  31/100 (tree index:32) done accuracy:0.825 logloss:0.410281\n",
      "I0000 00:00:1729625067.876905 6784550 random_forest.cc:812] Training of tree  41/100 (tree index:40) done accuracy:0.791667 logloss:0.426923\n",
      "I0000 00:00:1729625067.877094 6784551 random_forest.cc:812] Training of tree  51/100 (tree index:42) done accuracy:0.791667 logloss:0.428632\n",
      "I0000 00:00:1729625067.877277 6784545 random_forest.cc:812] Training of tree  61/100 (tree index:63) done accuracy:0.783333 logloss:0.428894\n",
      "I0000 00:00:1729625067.877427 6784552 random_forest.cc:812] Training of tree  71/100 (tree index:71) done accuracy:0.775 logloss:0.443608\n",
      "I0000 00:00:1729625067.877618 6784552 random_forest.cc:812] Training of tree  82/100 (tree index:81) done accuracy:0.808333 logloss:0.451004\n",
      "I0000 00:00:1729625067.877853 6784551 random_forest.cc:812] Training of tree  93/100 (tree index:95) done accuracy:0.791667 logloss:0.45355\n",
      "I0000 00:00:1729625067.878060 6784545 random_forest.cc:812] Training of tree  100/100 (tree index:92) done accuracy:0.808333 logloss:0.449186\n",
      "I0000 00:00:1729625067.878095 6784536 random_forest.cc:892] Final OOB metrics: accuracy:0.808333 logloss:0.449186\n",
      "I0000 00:00:1729625067.878356 6784536 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgewox1e9 with prefix 494209a3a25f401b\n",
      "I0000 00:00:1729625067.880021 6784536 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625067.880682 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.808333  CI95[W][0.739526 0.865316]\n",
      "LogLoss: : 0.449186\n",
      "ErrorRate: : 0.191667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  13\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.014721\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 20:24:27.885260: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgewox1e9/model/ with prefix 494209a3a25f401b\n",
      "I0000 00:00:1729625067.888093 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2090 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:27.888110: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0w4tk_x0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x1761e5a80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function CoreModel._consumes_training_examples_until_eof at 0x1761e5a80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.134649. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018730\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625068.157670 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625068.157682 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625068.157687 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625068.157752 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625068.157757 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625068.157801 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.157810 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.157816 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.157821 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.157849 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625068.157866 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625068.158001 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625068.158024 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0w4tk_x0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625068.158167 6784603 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625068.158282 6784603 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625068.158807 6784612 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625068.159090 6784613 random_forest.cc:812] Training of tree  12/100 (tree index:13) done accuracy:0.686441 logloss:4.62755\n",
      "I0000 00:00:1729625068.159324 6784614 random_forest.cc:812] Training of tree  22/100 (tree index:22) done accuracy:0.741667 logloss:1.93982\n",
      "I0000 00:00:1729625068.159568 6784618 random_forest.cc:812] Training of tree  32/100 (tree index:32) done accuracy:0.758333 logloss:1.07282\n",
      "I0000 00:00:1729625068.159793 6784613 random_forest.cc:812] Training of tree  42/100 (tree index:43) done accuracy:0.766667 logloss:0.777998\n",
      "I0000 00:00:1729625068.160086 6784616 random_forest.cc:812] Training of tree  52/100 (tree index:52) done accuracy:0.775 logloss:0.486335\n",
      "I0000 00:00:1729625068.160510 6784614 random_forest.cc:812] Training of tree  62/100 (tree index:56) done accuracy:0.791667 logloss:0.485155\n",
      "I0000 00:00:1729625068.160921 6784612 random_forest.cc:812] Training of tree  72/100 (tree index:68) done accuracy:0.8 logloss:0.481168\n",
      "I0000 00:00:1729625068.161202 6784612 random_forest.cc:812] Training of tree  82/100 (tree index:84) done accuracy:0.775 logloss:0.474526\n",
      "I0000 00:00:1729625068.161501 6784615 random_forest.cc:812] Training of tree  94/100 (tree index:93) done accuracy:0.783333 logloss:0.472895\n",
      "I0000 00:00:1729625068.161860 6784617 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.783333 logloss:0.475094\n",
      "I0000 00:00:1729625068.161883 6784603 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.475094\n",
      "I0000 00:00:1729625068.162215 6784603 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0w4tk_x0 with prefix 635e2554987f4d90\n",
      "I0000 00:00:1729625068.163834 6784603 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625068.164591 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.475094\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  44  11\n",
      "2  15  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:28.171006: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0w4tk_x0/model/ with prefix 635e2554987f4d90\n",
      "I0000 00:00:1729625068.174486 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2184 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:28.174519: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x300ec5580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x300ec5580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 20, 'min_examples': 5, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_6tlddng as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x1761e5a80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x1761e5a80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:00.132038. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625068.452156 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625068.452165 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625068.452170 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625068.452232 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625068.452236 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625068.452291 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.452305 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.452311 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.452317 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.452346 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625068.452375 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625068.452512 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625068.452534 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_6tlddng/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625068.452574 6784675 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625068.452670 6784675 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625068.453105 6784691 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625068.453226 6784687 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.65 logloss:3.70013\n",
      "I0000 00:00:1729625068.453411 6784688 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.716667 logloss:0.794953\n",
      "I0000 00:00:1729625068.453664 6784689 random_forest.cc:812] Training of tree  31/100 (tree index:32) done accuracy:0.691667 logloss:0.516666\n",
      "I0000 00:00:1729625068.453810 6784685 random_forest.cc:812] Training of tree  41/100 (tree index:40) done accuracy:0.691667 logloss:0.575317\n",
      "I0000 00:00:1729625068.454038 6784688 random_forest.cc:812] Training of tree  51/100 (tree index:50) done accuracy:0.691667 logloss:0.560397\n",
      "I0000 00:00:1729625068.454315 6784688 random_forest.cc:812] Training of tree  61/100 (tree index:57) done accuracy:0.708333 logloss:0.543255\n",
      "I0000 00:00:1729625068.454532 6784686 random_forest.cc:812] Training of tree  71/100 (tree index:70) done accuracy:0.716667 logloss:0.546156\n",
      "I0000 00:00:1729625068.454717 6784685 random_forest.cc:812] Training of tree  81/100 (tree index:83) done accuracy:0.725 logloss:0.540762\n",
      "I0000 00:00:1729625068.454872 6784687 random_forest.cc:812] Training of tree  92/100 (tree index:85) done accuracy:0.7 logloss:0.539217\n",
      "I0000 00:00:1729625068.455031 6784685 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.716667 logloss:0.538451\n",
      "I0000 00:00:1729625068.455071 6784675 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.538451\n",
      "I0000 00:00:1729625068.455328 6784675 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_6tlddng with prefix 0069c18668a54a43\n",
      "I0000 00:00:1729625068.456900 6784675 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625068.457483 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.538451\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.014987\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 20:24:28.462897: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_6tlddng/model/ with prefix 0069c18668a54a43\n",
      "I0000 00:00:1729625068.465503 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1896 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:28.465521: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x300e398a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x300e398a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3xwv0qla as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.130504. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625068.771054 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625068.771064 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625068.771068 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625068.771135 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625068.771140 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625068.771186 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.771197 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.771202 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.771207 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625068.771235 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625068.771272 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625068.771414 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625068.771440 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3xwv0qla/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625068.771494 6784745 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625068.771598 6784745 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625068.772055 6784755 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.510638 logloss:17.6384\n",
      "I0000 00:00:1729625068.772221 6784761 random_forest.cc:812] Training of tree  12/100 (tree index:12) done accuracy:0.697479 logloss:3.72666\n",
      "I0000 00:00:1729625068.772426 6784761 random_forest.cc:812] Training of tree  22/100 (tree index:22) done accuracy:0.683333 logloss:1.45291\n",
      "I0000 00:00:1729625068.772619 6784755 random_forest.cc:812] Training of tree  32/100 (tree index:31) done accuracy:0.691667 logloss:0.596491\n",
      "I0000 00:00:1729625068.772790 6784754 random_forest.cc:812] Training of tree  42/100 (tree index:41) done accuracy:0.7 logloss:0.583066\n",
      "I0000 00:00:1729625068.772925 6784756 random_forest.cc:812] Training of tree  53/100 (tree index:52) done accuracy:0.733333 logloss:0.559588\n",
      "I0000 00:00:1729625068.773121 6784758 random_forest.cc:812] Training of tree  63/100 (tree index:62) done accuracy:0.733333 logloss:0.564675\n",
      "I0000 00:00:1729625068.773295 6784757 random_forest.cc:812] Training of tree  74/100 (tree index:74) done accuracy:0.708333 logloss:0.572658\n",
      "I0000 00:00:1729625068.773488 6784761 random_forest.cc:812] Training of tree  84/100 (tree index:82) done accuracy:0.741667 logloss:0.564917\n",
      "I0000 00:00:1729625068.773737 6784755 random_forest.cc:812] Training of tree  95/100 (tree index:88) done accuracy:0.716667 logloss:0.555949\n",
      "I0000 00:00:1729625068.773843 6784755 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.733333 logloss:0.55753\n",
      "I0000 00:00:1729625068.773880 6784745 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.55753\n",
      "I0000 00:00:1729625068.774153 6784745 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3xwv0qla with prefix 8621ae853f244a21\n",
      "I0000 00:00:1729625068.775848 6784745 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625068.776504 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.55753\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  16\n",
      "2  16  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:28.781501: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3xwv0qla/model/ with prefix 8621ae853f244a21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.014811\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625068.784262 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1930 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:28.784280: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpiiffnmig as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.131916. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014600\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625069.048498 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625069.048510 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625069.048515 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625069.048578 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625069.048583 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625069.048628 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.048637 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.048642 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.048647 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.048674 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625069.048691 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625069.048830 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625069.048853 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpiiffnmig/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625069.048905 6784815 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625069.048997 6784815 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625069.049461 6784831 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.660377 logloss:12.2412\n",
      "I0000 00:00:1729625069.049616 6784831 random_forest.cc:812] Training of tree  12/100 (tree index:8) done accuracy:0.672269 logloss:5.18372\n",
      "I0000 00:00:1729625069.049801 6784829 random_forest.cc:812] Training of tree  22/100 (tree index:21) done accuracy:0.675 logloss:1.73957\n",
      "I0000 00:00:1729625069.049998 6784824 random_forest.cc:812] Training of tree  34/100 (tree index:33) done accuracy:0.683333 logloss:0.594772\n",
      "I0000 00:00:1729625069.050204 6784827 random_forest.cc:812] Training of tree  45/100 (tree index:41) done accuracy:0.691667 logloss:0.5855\n",
      "I0000 00:00:1729625069.050410 6784830 random_forest.cc:812] Training of tree  55/100 (tree index:56) done accuracy:0.741667 logloss:0.555837\n",
      "I0000 00:00:1729625069.050551 6784831 random_forest.cc:812] Training of tree  65/100 (tree index:65) done accuracy:0.791667 logloss:0.542908\n",
      "I0000 00:00:1729625069.050701 6784830 random_forest.cc:812] Training of tree  75/100 (tree index:74) done accuracy:0.783333 logloss:0.542977\n",
      "I0000 00:00:1729625069.050879 6784825 random_forest.cc:812] Training of tree  85/100 (tree index:84) done accuracy:0.758333 logloss:0.539423\n",
      "I0000 00:00:1729625069.051038 6784829 random_forest.cc:812] Training of tree  95/100 (tree index:94) done accuracy:0.8 logloss:0.534041\n",
      "I0000 00:00:1729625069.051160 6784829 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.791667 logloss:0.53188\n",
      "I0000 00:00:1729625069.051186 6784815 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.53188\n",
      "I0000 00:00:1729625069.051426 6784815 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpiiffnmig with prefix d7b29c4c6af44d40\n",
      "I0000 00:00:1729625069.053171 6784815 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625069.053799 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.53188\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  13\n",
      "2  12  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:29.058348: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpiiffnmig/model/ with prefix d7b29c4c6af44d40\n",
      "I0000 00:00:1729625069.061221 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1970 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:29.061245: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbgny9av2 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.135678. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014056\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625069.437779 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625069.437788 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625069.437793 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625069.437863 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625069.437869 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625069.437918 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.437928 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.437934 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.437940 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.437969 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625069.437987 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625069.438153 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625069.438174 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbgny9av2/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625069.438227 6784889 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625069.438324 6784889 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625069.438778 6784904 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.509434 logloss:17.6818\n",
      "I0000 00:00:1729625069.438904 6784898 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.65812 logloss:4.36269\n",
      "I0000 00:00:1729625069.439144 6784901 random_forest.cc:812] Training of tree  21/100 (tree index:19) done accuracy:0.75 logloss:1.64876\n",
      "I0000 00:00:1729625069.439364 6784903 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.766667 logloss:1.0395\n",
      "I0000 00:00:1729625069.439572 6784905 random_forest.cc:812] Training of tree  42/100 (tree index:40) done accuracy:0.766667 logloss:0.475966\n",
      "I0000 00:00:1729625069.439760 6784904 random_forest.cc:812] Training of tree  52/100 (tree index:50) done accuracy:0.758333 logloss:0.493257\n",
      "I0000 00:00:1729625069.439865 6784901 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.758333 logloss:0.489715\n",
      "I0000 00:00:1729625069.440015 6784904 random_forest.cc:812] Training of tree  72/100 (tree index:72) done accuracy:0.766667 logloss:0.486306\n",
      "I0000 00:00:1729625069.440256 6784905 random_forest.cc:812] Training of tree  84/100 (tree index:76) done accuracy:0.775 logloss:0.48131\n",
      "I0000 00:00:1729625069.440412 6784900 random_forest.cc:812] Training of tree  94/100 (tree index:91) done accuracy:0.775 logloss:0.477391\n",
      "I0000 00:00:1729625069.440549 6784898 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.775 logloss:0.475327\n",
      "I0000 00:00:1729625069.440654 6784889 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.475327\n",
      "I0000 00:00:1729625069.440916 6784889 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbgny9av2 with prefix da8080ea30c04ecf\n",
      "I0000 00:00:1729625069.442423 6784889 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625069.443058 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.475327\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  13\n",
      "2  14  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:29.447674: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbgny9av2/model/ with prefix da8080ea30c04ecf\n",
      "I0000 00:00:1729625069.450191 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1776 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:29.450206: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxzunz7wh as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.134179. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015026\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625069.718240 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625069.718259 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625069.718263 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625069.718330 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625069.718336 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625069.718381 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.718420 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.718428 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.718461 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.718554 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625069.718576 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625069.718847 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625069.718877 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxzunz7wh/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625069.718925 6784958 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625069.719087 6784958 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625069.719638 6784967 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.641509 logloss:12.9213\n",
      "I0000 00:00:1729625069.719851 6784971 random_forest.cc:812] Training of tree  11/100 (tree index:7) done accuracy:0.75 logloss:1.5806\n",
      "I0000 00:00:1729625069.719993 6784971 random_forest.cc:812] Training of tree  21/100 (tree index:18) done accuracy:0.741667 logloss:0.738915\n",
      "I0000 00:00:1729625069.720203 6784971 random_forest.cc:812] Training of tree  31/100 (tree index:33) done accuracy:0.725 logloss:0.743414\n",
      "I0000 00:00:1729625069.720367 6784968 random_forest.cc:812] Training of tree  42/100 (tree index:41) done accuracy:0.783333 logloss:0.743532\n",
      "I0000 00:00:1729625069.720621 6784972 random_forest.cc:812] Training of tree  52/100 (tree index:52) done accuracy:0.775 logloss:0.472109\n",
      "I0000 00:00:1729625069.720762 6784967 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.766667 logloss:0.473236\n",
      "I0000 00:00:1729625069.721011 6784971 random_forest.cc:812] Training of tree  72/100 (tree index:71) done accuracy:0.766667 logloss:0.474468\n",
      "I0000 00:00:1729625069.721157 6784971 random_forest.cc:812] Training of tree  82/100 (tree index:79) done accuracy:0.783333 logloss:0.468411\n",
      "I0000 00:00:1729625069.721352 6784968 random_forest.cc:812] Training of tree  93/100 (tree index:92) done accuracy:0.791667 logloss:0.453877\n",
      "I0000 00:00:1729625069.721460 6784972 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.783333 logloss:0.461742\n",
      "I0000 00:00:1729625069.721537 6784958 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.461742\n",
      "I0000 00:00:1729625069.721777 6784958 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxzunz7wh with prefix 7873259b14ca4eaa\n",
      "I0000 00:00:1729625069.723168 6784958 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625069.723786 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.461742\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  13\n",
      "2  13  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:29.728931: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxzunz7wh/model/ with prefix 7873259b14ca4eaa\n",
      "I0000 00:00:1729625069.731443 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1826 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:29.731459: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 20, 'min_examples': 10, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps8aoz39p as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.132584. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013377\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625069.998120 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625069.998129 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625069.998134 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625069.998195 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625069.998200 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625069.998243 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.998257 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.998263 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.998268 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625069.998294 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625069.998313 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625069.998464 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625069.998487 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps8aoz39p/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625069.998538 6785027 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625069.998621 6785027 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625069.999047 6785042 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625069.999234 6785042 random_forest.cc:812] Training of tree  12/100 (tree index:12) done accuracy:0.677966 logloss:4.58827\n",
      "I0000 00:00:1729625069.999365 6785041 random_forest.cc:812] Training of tree  22/100 (tree index:21) done accuracy:0.75 logloss:1.70408\n",
      "I0000 00:00:1729625069.999529 6785043 random_forest.cc:812] Training of tree  32/100 (tree index:31) done accuracy:0.766667 logloss:1.10766\n",
      "I0000 00:00:1729625069.999663 6785041 random_forest.cc:812] Training of tree  42/100 (tree index:40) done accuracy:0.775 logloss:0.828473\n",
      "I0000 00:00:1729625069.999823 6785043 random_forest.cc:812] Training of tree  52/100 (tree index:52) done accuracy:0.758333 logloss:0.811951\n",
      "I0000 00:00:1729625069.999975 6785042 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.758333 logloss:0.795447\n",
      "I0000 00:00:1729625070.000126 6785043 random_forest.cc:812] Training of tree  72/100 (tree index:71) done accuracy:0.725 logloss:0.807199\n",
      "I0000 00:00:1729625070.000321 6785038 random_forest.cc:812] Training of tree  82/100 (tree index:82) done accuracy:0.725 logloss:0.815109\n",
      "I0000 00:00:1729625070.000499 6785040 random_forest.cc:812] Training of tree  92/100 (tree index:91) done accuracy:0.708333 logloss:0.815505\n",
      "I0000 00:00:1729625070.000650 6785037 random_forest.cc:812] Training of tree  100/100 (tree index:97) done accuracy:0.708333 logloss:0.542033\n",
      "I0000 00:00:1729625070.000684 6785027 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.542033\n",
      "I0000 00:00:1729625070.000881 6785027 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps8aoz39p with prefix e2accf5583ee4c10\n",
      "I0000 00:00:1729625070.002195 6785027 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625070.002828 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.542033\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  20\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:30.007697: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps8aoz39p/model/ with prefix e2accf5583ee4c10\n",
      "I0000 00:00:1729625070.009781 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1502 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:30.009797: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyj_m_vu7 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.134606. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013629\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625070.319774 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625070.319787 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625070.319791 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625070.319865 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625070.319870 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625070.319924 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.319938 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.319944 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.319950 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.319977 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625070.320002 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625070.320172 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625070.320199 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyj_m_vu7/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625070.320254 6785097 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625070.320347 6785097 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625070.320779 6785107 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.772727 logloss:8.19174\n",
      "I0000 00:00:1729625070.320930 6785106 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.697479 logloss:5.45262\n",
      "I0000 00:00:1729625070.321131 6785107 random_forest.cc:812] Training of tree  21/100 (tree index:15) done accuracy:0.758333 logloss:1.38234\n",
      "I0000 00:00:1729625070.321337 6785110 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.75 logloss:1.07938\n",
      "I0000 00:00:1729625070.321490 6785109 random_forest.cc:812] Training of tree  41/100 (tree index:41) done accuracy:0.766667 logloss:0.795927\n",
      "I0000 00:00:1729625070.321644 6785112 random_forest.cc:812] Training of tree  51/100 (tree index:52) done accuracy:0.775 logloss:0.533127\n",
      "I0000 00:00:1729625070.321808 6785109 random_forest.cc:812] Training of tree  61/100 (tree index:60) done accuracy:0.783333 logloss:0.53666\n",
      "I0000 00:00:1729625070.321965 6785112 random_forest.cc:812] Training of tree  71/100 (tree index:69) done accuracy:0.775 logloss:0.535683\n",
      "I0000 00:00:1729625070.322109 6785107 random_forest.cc:812] Training of tree  81/100 (tree index:79) done accuracy:0.775 logloss:0.535353\n",
      "I0000 00:00:1729625070.322403 6785111 random_forest.cc:812] Training of tree  93/100 (tree index:92) done accuracy:0.766667 logloss:0.523909\n",
      "I0000 00:00:1729625070.322556 6785106 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.775 logloss:0.522878\n",
      "I0000 00:00:1729625070.322613 6785097 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.522878\n",
      "I0000 00:00:1729625070.322866 6785097 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyj_m_vu7 with prefix 13b3cceeeb6b48fe\n",
      "I0000 00:00:1729625070.324531 6785097 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625070.325152 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.522878\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  13  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:30.329688: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyj_m_vu7/model/ with prefix 13b3cceeeb6b48fe\n",
      "I0000 00:00:1729625070.331830 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1548 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:30.331847: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5pe5tiwx as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.133760. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014112\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625070.597030 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625070.597039 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625070.597044 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625070.597112 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625070.597117 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625070.597162 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.597172 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.597177 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.597183 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.597211 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625070.597230 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625070.597366 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625070.597392 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5pe5tiwx/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625070.597451 6785167 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625070.597544 6785167 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625070.597984 6785179 random_forest.cc:812] Training of tree  1/100 (tree index:2) done accuracy:0.682927 logloss:11.4285\n",
      "I0000 00:00:1729625070.598112 6785176 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.731092 logloss:2.46132\n",
      "I0000 00:00:1729625070.598310 6785177 random_forest.cc:812] Training of tree  21/100 (tree index:22) done accuracy:0.683333 logloss:1.12332\n",
      "I0000 00:00:1729625070.598501 6785178 random_forest.cc:812] Training of tree  31/100 (tree index:31) done accuracy:0.7 logloss:0.589885\n",
      "I0000 00:00:1729625070.598637 6785180 random_forest.cc:812] Training of tree  41/100 (tree index:39) done accuracy:0.716667 logloss:0.58715\n",
      "I0000 00:00:1729625070.598810 6785183 random_forest.cc:812] Training of tree  51/100 (tree index:48) done accuracy:0.666667 logloss:0.585947\n",
      "I0000 00:00:1729625070.598983 6785178 random_forest.cc:812] Training of tree  61/100 (tree index:61) done accuracy:0.683333 logloss:0.583071\n",
      "I0000 00:00:1729625070.599254 6785178 random_forest.cc:812] Training of tree  71/100 (tree index:71) done accuracy:0.716667 logloss:0.590285\n",
      "I0000 00:00:1729625070.599382 6785183 random_forest.cc:812] Training of tree  81/100 (tree index:80) done accuracy:0.725 logloss:0.594505\n",
      "I0000 00:00:1729625070.599538 6785177 random_forest.cc:812] Training of tree  91/100 (tree index:91) done accuracy:0.733333 logloss:0.590132\n",
      "I0000 00:00:1729625070.599661 6785182 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.733333 logloss:0.583556\n",
      "I0000 00:00:1729625070.599707 6785167 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.583556\n",
      "I0000 00:00:1729625070.599921 6785167 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5pe5tiwx with prefix dea26305f5e84675\n",
      "I0000 00:00:1729625070.601745 6785167 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625070.602436 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.583556\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  15\n",
      "2  17  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:30.607216: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5pe5tiwx/model/ with prefix dea26305f5e84675\n",
      "I0000 00:00:1729625070.609430 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1544 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:30.609453: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjm8w9800 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.133352. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013474\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625070.875335 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625070.875345 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625070.875349 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625070.875411 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625070.875415 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625070.875461 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.875470 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.875475 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.875480 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625070.875509 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625070.875527 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625070.875663 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625070.875687 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjm8w9800/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625070.875744 6785236 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625070.875833 6785236 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625070.876285 6785245 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.674419 logloss:11.7351\n",
      "I0000 00:00:1729625070.876435 6785252 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.731092 logloss:1.95599\n",
      "I0000 00:00:1729625070.876585 6785245 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.741667 logloss:1.09995\n",
      "I0000 00:00:1729625070.876761 6785245 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.75 logloss:0.768006\n",
      "I0000 00:00:1729625070.876926 6785252 random_forest.cc:812] Training of tree  42/100 (tree index:36) done accuracy:0.733333 logloss:0.771312\n",
      "I0000 00:00:1729625070.877113 6785248 random_forest.cc:812] Training of tree  52/100 (tree index:50) done accuracy:0.741667 logloss:0.495793\n",
      "I0000 00:00:1729625070.877245 6785247 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.758333 logloss:0.492421\n",
      "I0000 00:00:1729625070.877413 6785250 random_forest.cc:812] Training of tree  72/100 (tree index:71) done accuracy:0.766667 logloss:0.490206\n",
      "I0000 00:00:1729625070.877633 6785251 random_forest.cc:812] Training of tree  82/100 (tree index:82) done accuracy:0.775 logloss:0.49122\n",
      "I0000 00:00:1729625070.877787 6785248 random_forest.cc:812] Training of tree  92/100 (tree index:91) done accuracy:0.766667 logloss:0.480611\n",
      "I0000 00:00:1729625070.877947 6785250 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.783333 logloss:0.475724\n",
      "I0000 00:00:1729625070.878004 6785236 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.475724\n",
      "I0000 00:00:1729625070.878251 6785236 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjm8w9800 with prefix 0eb971649bbc422f\n",
      "I0000 00:00:1729625070.879495 6785236 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625070.880141 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.475724\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  16\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:30.885145: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjm8w9800/model/ with prefix 0eb971649bbc422f\n",
      "I0000 00:00:1729625070.887182 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1442 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:30.887197: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpur1_fizk as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.174055. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013430\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625071.191189 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625071.191199 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625071.191204 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625071.191264 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625071.191268 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625071.191312 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.191326 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.191331 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.191337 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.191365 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625071.191382 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625071.191514 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625071.191538 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpur1_fizk/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625071.191589 6785305 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625071.191671 6785305 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625071.192165 6785321 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625071.192425 6785316 random_forest.cc:812] Training of tree  11/100 (tree index:9) done accuracy:0.747899 logloss:3.03497\n",
      "I0000 00:00:1729625071.192583 6785317 random_forest.cc:812] Training of tree  22/100 (tree index:22) done accuracy:0.716667 logloss:1.3725\n",
      "I0000 00:00:1729625071.192768 6785317 random_forest.cc:812] Training of tree  32/100 (tree index:35) done accuracy:0.75 logloss:0.801196\n",
      "I0000 00:00:1729625071.192899 6785315 random_forest.cc:812] Training of tree  42/100 (tree index:41) done accuracy:0.75 logloss:0.793585\n",
      "I0000 00:00:1729625071.193080 6785316 random_forest.cc:812] Training of tree  52/100 (tree index:53) done accuracy:0.775 logloss:0.480167\n",
      "I0000 00:00:1729625071.193231 6785320 random_forest.cc:812] Training of tree  62/100 (tree index:63) done accuracy:0.783333 logloss:0.48789\n",
      "I0000 00:00:1729625071.193391 6785321 random_forest.cc:812] Training of tree  73/100 (tree index:72) done accuracy:0.775 logloss:0.489045\n",
      "I0000 00:00:1729625071.193555 6785315 random_forest.cc:812] Training of tree  83/100 (tree index:83) done accuracy:0.758333 logloss:0.50142\n",
      "I0000 00:00:1729625071.193699 6785319 random_forest.cc:812] Training of tree  93/100 (tree index:91) done accuracy:0.766667 logloss:0.495524\n",
      "I0000 00:00:1729625071.193804 6785320 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.766667 logloss:0.491437\n",
      "I0000 00:00:1729625071.193842 6785305 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.491437\n",
      "I0000 00:00:1729625071.194045 6785305 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpur1_fizk with prefix 157143a80a1c4731\n",
      "I0000 00:00:1729625071.195543 6785305 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625071.196102 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.491437\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:31.200823: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpur1_fizk/model/ with prefix 157143a80a1c4731\n",
      "I0000 00:00:1729625071.202878 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1514 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:31.202898: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 20, 'min_examples': 10, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmph7tsyyif as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.137050. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013403\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625071.480486 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625071.480499 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625071.480503 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625071.480569 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625071.480573 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625071.480622 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.480632 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.480637 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.480642 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.480671 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625071.480690 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625071.480827 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625071.480851 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmph7tsyyif/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625071.480902 6785373 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625071.481005 6785373 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625071.481499 6785382 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625071.481612 6785382 random_forest.cc:812] Training of tree  11/100 (tree index:8) done accuracy:0.680672 logloss:4.00563\n",
      "I0000 00:00:1729625071.481831 6785388 random_forest.cc:812] Training of tree  22/100 (tree index:23) done accuracy:0.741667 logloss:1.37628\n",
      "I0000 00:00:1729625071.481978 6785386 random_forest.cc:812] Training of tree  33/100 (tree index:31) done accuracy:0.783333 logloss:1.12577\n",
      "I0000 00:00:1729625071.482169 6785387 random_forest.cc:812] Training of tree  43/100 (tree index:42) done accuracy:0.75 logloss:0.843405\n",
      "I0000 00:00:1729625071.482312 6785387 random_forest.cc:812] Training of tree  55/100 (tree index:55) done accuracy:0.75 logloss:0.554577\n",
      "I0000 00:00:1729625071.482585 6785389 random_forest.cc:812] Training of tree  65/100 (tree index:63) done accuracy:0.716667 logloss:0.548289\n",
      "I0000 00:00:1729625071.482783 6785386 random_forest.cc:812] Training of tree  75/100 (tree index:77) done accuracy:0.666667 logloss:0.558094\n",
      "I0000 00:00:1729625071.482959 6785388 random_forest.cc:812] Training of tree  85/100 (tree index:83) done accuracy:0.708333 logloss:0.546545\n",
      "I0000 00:00:1729625071.483118 6785388 random_forest.cc:812] Training of tree  95/100 (tree index:95) done accuracy:0.7 logloss:0.551857\n",
      "I0000 00:00:1729625071.483206 6785383 random_forest.cc:812] Training of tree  100/100 (tree index:96) done accuracy:0.7 logloss:0.556474\n",
      "I0000 00:00:1729625071.483251 6785373 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.556474\n",
      "I0000 00:00:1729625071.483450 6785373 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmph7tsyyif with prefix 0e2d9371e98747ef\n",
      "I0000 00:00:1729625071.484778 6785373 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625071.485439 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.556474\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  16\n",
      "2  20  42\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:31.490504: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmph7tsyyif/model/ with prefix 0e2d9371e98747ef\n",
      "I0000 00:00:1729625071.492398 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1250 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:24:31.492416: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp04ipw526 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.137727. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012370\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625071.769957 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625071.769967 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625071.769972 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625071.770033 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625071.770037 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625071.770082 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.770092 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.770098 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.770103 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625071.770130 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625071.770147 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625071.770296 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625071.770323 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp04ipw526/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625071.770374 6785455 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625071.770478 6785455 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625071.770915 6785466 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625071.771058 6785467 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.689076 logloss:2.25492\n",
      "I0000 00:00:1729625071.771191 6785468 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.741667 logloss:1.13456\n",
      "I0000 00:00:1729625071.771337 6785467 random_forest.cc:812] Training of tree  31/100 (tree index:29) done accuracy:0.7 logloss:0.861898\n",
      "I0000 00:00:1729625071.771461 6785468 random_forest.cc:812] Training of tree  41/100 (tree index:41) done accuracy:0.725 logloss:0.575116\n",
      "I0000 00:00:1729625071.771596 6785471 random_forest.cc:812] Training of tree  51/100 (tree index:51) done accuracy:0.733333 logloss:0.580892\n",
      "I0000 00:00:1729625071.771799 6785467 random_forest.cc:812] Training of tree  61/100 (tree index:61) done accuracy:0.716667 logloss:0.572662\n",
      "I0000 00:00:1729625071.771939 6785471 random_forest.cc:812] Training of tree  71/100 (tree index:70) done accuracy:0.733333 logloss:0.575065\n",
      "I0000 00:00:1729625071.772084 6785466 random_forest.cc:812] Training of tree  81/100 (tree index:79) done accuracy:0.741667 logloss:0.571413\n",
      "I0000 00:00:1729625071.772198 6785464 random_forest.cc:812] Training of tree  91/100 (tree index:90) done accuracy:0.733333 logloss:0.572584\n",
      "I0000 00:00:1729625071.772317 6785465 random_forest.cc:812] Training of tree  100/100 (tree index:97) done accuracy:0.75 logloss:0.554476\n",
      "I0000 00:00:1729625071.772355 6785455 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.554476\n",
      "I0000 00:00:1729625071.772533 6785455 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp04ipw526 with prefix 6b8b3d4402aa45b5\n",
      "I0000 00:00:1729625071.773915 6785455 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625071.774554 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.554476\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  16  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:31.778966: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp04ipw526/model/ with prefix 6b8b3d4402aa45b5\n",
      "I0000 00:00:1729625071.780759 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1276 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:31.780778: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpcoqe8_s7 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.132805. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013285\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625072.044647 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625072.044663 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625072.044667 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625072.044730 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625072.044736 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625072.044776 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.044786 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.044791 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.044796 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.044822 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625072.044840 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625072.044966 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625072.044989 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpcoqe8_s7/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625072.045031 6785526 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625072.045197 6785526 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625072.045688 6785537 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625072.045868 6785539 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.666667 logloss:2.56529\n",
      "I0000 00:00:1729625072.046072 6785541 random_forest.cc:812] Training of tree  22/100 (tree index:22) done accuracy:0.641667 logloss:1.21474\n",
      "I0000 00:00:1729625072.046255 6785535 random_forest.cc:812] Training of tree  32/100 (tree index:31) done accuracy:0.675 logloss:0.875179\n",
      "I0000 00:00:1729625072.046405 6785542 random_forest.cc:812] Training of tree  44/100 (tree index:42) done accuracy:0.716667 logloss:0.591403\n",
      "I0000 00:00:1729625072.046620 6785536 random_forest.cc:812] Training of tree  54/100 (tree index:53) done accuracy:0.691667 logloss:0.590283\n",
      "I0000 00:00:1729625072.046820 6785536 random_forest.cc:812] Training of tree  64/100 (tree index:63) done accuracy:0.7 logloss:0.584167\n",
      "I0000 00:00:1729625072.046971 6785542 random_forest.cc:812] Training of tree  74/100 (tree index:75) done accuracy:0.7 logloss:0.58098\n",
      "I0000 00:00:1729625072.047101 6785538 random_forest.cc:812] Training of tree  84/100 (tree index:82) done accuracy:0.683333 logloss:0.568806\n",
      "I0000 00:00:1729625072.047287 6785540 random_forest.cc:812] Training of tree  95/100 (tree index:94) done accuracy:0.708333 logloss:0.56021\n",
      "I0000 00:00:1729625072.047407 6785540 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.683333 logloss:0.563739\n",
      "I0000 00:00:1729625072.047433 6785526 random_forest.cc:892] Final OOB metrics: accuracy:0.683333 logloss:0.563739\n",
      "I0000 00:00:1729625072.047615 6785526 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpcoqe8_s7 with prefix 94d619ba2e7245f7\n",
      "I0000 00:00:1729625072.048979 6785526 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625072.049666 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.683333  CI95[W][0.60641 0.75331]\n",
      "LogLoss: : 0.563739\n",
      "ErrorRate: : 0.316667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  33  21\n",
      "2  17  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:32.054662: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpcoqe8_s7/model/ with prefix 94d619ba2e7245f7\n",
      "I0000 00:00:1729625072.056403 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1292 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:32.056416: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3bap8kxj as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.132414. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012278\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625072.362846 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625072.362856 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625072.362860 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625072.362928 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625072.362933 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625072.362979 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.362989 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.362995 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.363000 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.363027 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625072.363046 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625072.363211 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625072.363235 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3bap8kxj/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625072.363296 6785595 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625072.363377 6785595 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625072.363860 6785611 random_forest.cc:812] Training of tree  1/100 (tree index:2) done accuracy:0.632653 logloss:13.2405\n",
      "I0000 00:00:1729625072.363964 6785606 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.697479 logloss:3.4173\n",
      "I0000 00:00:1729625072.364184 6785607 random_forest.cc:812] Training of tree  22/100 (tree index:21) done accuracy:0.7 logloss:1.38452\n",
      "I0000 00:00:1729625072.364438 6785608 random_forest.cc:812] Training of tree  32/100 (tree index:29) done accuracy:0.741667 logloss:0.802345\n",
      "I0000 00:00:1729625072.364599 6785608 random_forest.cc:812] Training of tree  42/100 (tree index:45) done accuracy:0.758333 logloss:0.525774\n",
      "I0000 00:00:1729625072.364733 6785604 random_forest.cc:812] Training of tree  52/100 (tree index:42) done accuracy:0.783333 logloss:0.51852\n",
      "I0000 00:00:1729625072.364925 6785606 random_forest.cc:812] Training of tree  63/100 (tree index:62) done accuracy:0.75 logloss:0.518166\n",
      "I0000 00:00:1729625072.365145 6785608 random_forest.cc:812] Training of tree  75/100 (tree index:72) done accuracy:0.758333 logloss:0.517632\n",
      "I0000 00:00:1729625072.365300 6785608 random_forest.cc:812] Training of tree  85/100 (tree index:86) done accuracy:0.75 logloss:0.523518\n",
      "I0000 00:00:1729625072.365403 6785607 random_forest.cc:812] Training of tree  95/100 (tree index:95) done accuracy:0.758333 logloss:0.515964\n",
      "I0000 00:00:1729625072.365523 6785605 random_forest.cc:812] Training of tree  100/100 (tree index:96) done accuracy:0.783333 logloss:0.516345\n",
      "I0000 00:00:1729625072.365579 6785595 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.516345\n",
      "I0000 00:00:1729625072.365752 6785595 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3bap8kxj with prefix 964da057ace54e7a\n",
      "I0000 00:00:1729625072.367033 6785595 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625072.367610 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.516345\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:32.371936: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3bap8kxj/model/ with prefix 964da057ace54e7a\n",
      "I0000 00:00:1729625072.373639 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1218 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:32.373654: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp56d6g4qw as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.136504. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014461\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625072.641089 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625072.641098 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625072.641103 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625072.641166 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625072.641172 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625072.641215 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.641225 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.641231 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.641236 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.641264 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625072.641283 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625072.641431 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625072.641456 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp56d6g4qw/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625072.641509 6785662 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625072.641617 6785662 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625072.642073 6785674 random_forest.cc:812] Training of tree  1/100 (tree index:4) done accuracy:0.839286 logloss:5.79273\n",
      "I0000 00:00:1729625072.642259 6785673 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.680672 logloss:2.23858\n",
      "I0000 00:00:1729625072.642458 6785672 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.691667 logloss:0.82172\n",
      "I0000 00:00:1729625072.642616 6785673 random_forest.cc:812] Training of tree  31/100 (tree index:29) done accuracy:0.741667 logloss:0.496308\n",
      "I0000 00:00:1729625072.642811 6785671 random_forest.cc:812] Training of tree  41/100 (tree index:43) done accuracy:0.741667 logloss:0.509929\n",
      "I0000 00:00:1729625072.642938 6785678 random_forest.cc:812] Training of tree  51/100 (tree index:41) done accuracy:0.766667 logloss:0.511307\n",
      "I0000 00:00:1729625072.643091 6785676 random_forest.cc:812] Training of tree  62/100 (tree index:46) done accuracy:0.766667 logloss:0.511369\n",
      "I0000 00:00:1729625072.643235 6785672 random_forest.cc:812] Training of tree  72/100 (tree index:71) done accuracy:0.75 logloss:0.527735\n",
      "I0000 00:00:1729625072.643408 6785677 random_forest.cc:812] Training of tree  83/100 (tree index:82) done accuracy:0.758333 logloss:0.524316\n",
      "I0000 00:00:1729625072.643545 6785677 random_forest.cc:812] Training of tree  93/100 (tree index:94) done accuracy:0.783333 logloss:0.518509\n",
      "I0000 00:00:1729625072.643658 6785675 random_forest.cc:812] Training of tree  100/100 (tree index:97) done accuracy:0.775 logloss:0.518928\n",
      "I0000 00:00:1729625072.643699 6785662 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.518928\n",
      "I0000 00:00:1729625072.643870 6785662 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp56d6g4qw with prefix b19ef3e3af3a44b4\n",
      "I0000 00:00:1729625072.646564 6785662 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625072.647169 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.518928\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  16\n",
      "2  11  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:32.652144: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp56d6g4qw/model/ with prefix b19ef3e3af3a44b4\n",
      "I0000 00:00:1729625072.653937 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1226 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:32.653959: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 20, 'min_examples': 20, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg8vsuk3c as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.134589. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011752\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625072.919539 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625072.919551 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625072.919559 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625072.919621 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625072.919626 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625072.919671 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.919682 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.919687 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.919692 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625072.919720 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625072.919736 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625072.919870 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625072.919925 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg8vsuk3c/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625072.919988 6785734 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625072.920101 6785734 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625072.920598 6785750 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.454545 logloss:19.6602\n",
      "I0000 00:00:1729625072.920750 6785749 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.697479 logloss:4.27091\n",
      "I0000 00:00:1729625072.920912 6785743 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.758333 logloss:2.24616\n",
      "I0000 00:00:1729625072.921035 6785748 random_forest.cc:812] Training of tree  32/100 (tree index:31) done accuracy:0.758333 logloss:1.38412\n",
      "I0000 00:00:1729625072.921153 6785749 random_forest.cc:812] Training of tree  42/100 (tree index:42) done accuracy:0.733333 logloss:1.40989\n",
      "I0000 00:00:1729625072.921316 6785750 random_forest.cc:812] Training of tree  52/100 (tree index:41) done accuracy:0.708333 logloss:1.14085\n",
      "I0000 00:00:1729625072.921424 6785749 random_forest.cc:812] Training of tree  63/100 (tree index:61) done accuracy:0.708333 logloss:0.84275\n",
      "I0000 00:00:1729625072.921553 6785745 random_forest.cc:812] Training of tree  73/100 (tree index:74) done accuracy:0.708333 logloss:0.837855\n",
      "I0000 00:00:1729625072.921697 6785743 random_forest.cc:812] Training of tree  83/100 (tree index:83) done accuracy:0.708333 logloss:0.851697\n",
      "I0000 00:00:1729625072.921797 6785748 random_forest.cc:812] Training of tree  93/100 (tree index:92) done accuracy:0.716667 logloss:0.845532\n",
      "I0000 00:00:1729625072.921941 6785747 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.7 logloss:0.578909\n",
      "I0000 00:00:1729625072.921978 6785734 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.578909\n",
      "I0000 00:00:1729625072.922105 6785734 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg8vsuk3c with prefix 8f9727773bf64b7c\n",
      "I0000 00:00:1729625072.923214 6785734 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625072.923801 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.578909\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  16\n",
      "2  20  42\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:32.928707: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg8vsuk3c/model/ with prefix 8f9727773bf64b7c\n",
      "I0000 00:00:1729625072.929930 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 832 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:32.929945: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpul_9q5s1 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.132881. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011283\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625073.237914 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625073.237926 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625073.237931 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625073.237993 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625073.237996 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625073.238043 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.238057 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.238062 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.238068 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.238095 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625073.238112 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625073.238249 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625073.238274 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpul_9q5s1/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625073.238324 6785803 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625073.238431 6785803 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625073.238848 6785816 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.675 logloss:11.7142\n",
      "I0000 00:00:1729625073.239005 6785819 random_forest.cc:812] Training of tree  11/100 (tree index:13) done accuracy:0.655462 logloss:4.91822\n",
      "I0000 00:00:1729625073.239113 6785814 random_forest.cc:812] Training of tree  21/100 (tree index:19) done accuracy:0.658333 logloss:2.04523\n",
      "I0000 00:00:1729625073.239243 6785819 random_forest.cc:812] Training of tree  31/100 (tree index:32) done accuracy:0.675 logloss:1.45651\n",
      "I0000 00:00:1729625073.239431 6785815 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.708333 logloss:0.625936\n",
      "I0000 00:00:1729625073.239605 6785814 random_forest.cc:812] Training of tree  52/100 (tree index:52) done accuracy:0.691667 logloss:0.612112\n",
      "I0000 00:00:1729625073.239804 6785815 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.7 logloss:0.623271\n",
      "I0000 00:00:1729625073.239980 6785814 random_forest.cc:812] Training of tree  72/100 (tree index:72) done accuracy:0.733333 logloss:0.613919\n",
      "I0000 00:00:1729625073.240078 6785817 random_forest.cc:812] Training of tree  82/100 (tree index:81) done accuracy:0.741667 logloss:0.607899\n",
      "I0000 00:00:1729625073.240197 6785814 random_forest.cc:812] Training of tree  93/100 (tree index:93) done accuracy:0.741667 logloss:0.603343\n",
      "I0000 00:00:1729625073.240326 6785816 random_forest.cc:812] Training of tree  100/100 (tree index:96) done accuracy:0.75 logloss:0.586752\n",
      "I0000 00:00:1729625073.240359 6785803 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.586752\n",
      "I0000 00:00:1729625073.240470 6785803 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpul_9q5s1 with prefix 1b60c10ed5ec4978\n",
      "I0000 00:00:1729625073.241667 6785803 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625073.242287 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.586752\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  34  19\n",
      "2  11  56\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:33.246482: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpul_9q5s1/model/ with prefix 1b60c10ed5ec4978\n",
      "I0000 00:00:1729625073.247700 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 814 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:33.247713: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq22sj3z9 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.136094. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011285\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625073.513887 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625073.513896 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625073.513900 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625073.513961 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625073.513965 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625073.514011 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.514021 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.514026 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.514031 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.514058 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625073.514076 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625073.514211 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625073.514232 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq22sj3z9/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625073.514284 6785871 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625073.514384 6785871 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625073.514831 6785887 random_forest.cc:812] Training of tree  1/100 (tree index:2) done accuracy:0.658537 logloss:12.3076\n",
      "I0000 00:00:1729625073.514966 6785880 random_forest.cc:812] Training of tree  11/100 (tree index:12) done accuracy:0.606838 logloss:3.84611\n",
      "I0000 00:00:1729625073.515094 6785887 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.641667 logloss:1.15262\n",
      "I0000 00:00:1729625073.515205 6785882 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.708333 logloss:0.884682\n",
      "I0000 00:00:1729625073.515353 6785881 random_forest.cc:812] Training of tree  42/100 (tree index:42) done accuracy:0.708333 logloss:0.597804\n",
      "I0000 00:00:1729625073.515511 6785881 random_forest.cc:812] Training of tree  54/100 (tree index:53) done accuracy:0.7 logloss:0.602513\n",
      "I0000 00:00:1729625073.515684 6785881 random_forest.cc:812] Training of tree  65/100 (tree index:66) done accuracy:0.691667 logloss:0.604155\n",
      "I0000 00:00:1729625073.515825 6785884 random_forest.cc:812] Training of tree  75/100 (tree index:77) done accuracy:0.733333 logloss:0.603072\n",
      "I0000 00:00:1729625073.515924 6785881 random_forest.cc:812] Training of tree  85/100 (tree index:85) done accuracy:0.716667 logloss:0.604989\n",
      "I0000 00:00:1729625073.516058 6785881 random_forest.cc:812] Training of tree  95/100 (tree index:96) done accuracy:0.733333 logloss:0.590722\n",
      "I0000 00:00:1729625073.516111 6785886 random_forest.cc:812] Training of tree  100/100 (tree index:97) done accuracy:0.733333 logloss:0.578525\n",
      "I0000 00:00:1729625073.516187 6785871 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.578525\n",
      "I0000 00:00:1729625073.516316 6785871 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq22sj3z9 with prefix 76056ae7f1a449b2\n",
      "I0000 00:00:1729625073.517683 6785871 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625073.518291 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.578525\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  18\n",
      "2  14  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:33.522594: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq22sj3z9/model/ with prefix 76056ae7f1a449b2\n",
      "I0000 00:00:1729625073.523756 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 810 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:33.523770: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7o0efd_8 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.134606. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012079\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625073.826387 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625073.826396 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625073.826400 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625073.826462 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625073.826466 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625073.826512 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.826521 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.826527 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.826532 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625073.826559 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625073.826580 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625073.826714 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625073.826738 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7o0efd_8/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625073.826810 6785940 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625073.826911 6785940 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625073.827413 6785951 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625073.827614 6785954 random_forest.cc:812] Training of tree  15/100 (tree index:14) done accuracy:0.7 logloss:3.35861\n",
      "I0000 00:00:1729625073.827776 6785956 random_forest.cc:812] Training of tree  25/100 (tree index:25) done accuracy:0.741667 logloss:1.64631\n",
      "I0000 00:00:1729625073.827952 6785955 random_forest.cc:812] Training of tree  36/100 (tree index:34) done accuracy:0.758333 logloss:1.08685\n",
      "I0000 00:00:1729625073.828095 6785951 random_forest.cc:812] Training of tree  46/100 (tree index:45) done accuracy:0.741667 logloss:0.530714\n",
      "I0000 00:00:1729625073.828299 6785950 random_forest.cc:812] Training of tree  56/100 (tree index:55) done accuracy:0.708333 logloss:0.533792\n",
      "I0000 00:00:1729625073.828443 6785952 random_forest.cc:812] Training of tree  66/100 (tree index:66) done accuracy:0.758333 logloss:0.523936\n",
      "I0000 00:00:1729625073.828556 6785956 random_forest.cc:812] Training of tree  76/100 (tree index:75) done accuracy:0.741667 logloss:0.513629\n",
      "I0000 00:00:1729625073.828676 6785954 random_forest.cc:812] Training of tree  86/100 (tree index:87) done accuracy:0.758333 logloss:0.512706\n",
      "I0000 00:00:1729625073.828824 6785951 random_forest.cc:812] Training of tree  98/100 (tree index:97) done accuracy:0.75 logloss:0.51323\n",
      "I0000 00:00:1729625073.828875 6785956 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.758333 logloss:0.511259\n",
      "I0000 00:00:1729625073.828992 6785940 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.511259\n",
      "I0000 00:00:1729625073.829126 6785940 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7o0efd_8 with prefix 3ee117eafc58410e\n",
      "I0000 00:00:1729625073.831124 6785940 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625073.831743 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.511259\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  16\n",
      "2  13  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:33.835823: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7o0efd_8/model/ with prefix 3ee117eafc58410e\n",
      "I0000 00:00:1729625073.837048 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 792 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:33.837063: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyoadehnl as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.135415. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011039\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625074.105050 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625074.105063 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625074.105067 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625074.105129 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625074.105133 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625074.105177 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.105187 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.105192 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.105197 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.105224 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625074.105242 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625074.105377 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625074.105399 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyoadehnl/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625074.105450 6786007 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625074.105545 6786007 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625074.106053 6786023 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625074.106211 6786021 random_forest.cc:812] Training of tree  11/100 (tree index:5) done accuracy:0.747899 logloss:3.62413\n",
      "I0000 00:00:1729625074.106324 6786022 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.675 logloss:2.28636\n",
      "I0000 00:00:1729625074.106531 6786019 random_forest.cc:812] Training of tree  31/100 (tree index:31) done accuracy:0.725 logloss:0.869728\n",
      "I0000 00:00:1729625074.106686 6786017 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.725 logloss:0.856502\n",
      "I0000 00:00:1729625074.106839 6786020 random_forest.cc:812] Training of tree  52/100 (tree index:53) done accuracy:0.725 logloss:0.858356\n",
      "I0000 00:00:1729625074.107007 6786016 random_forest.cc:812] Training of tree  62/100 (tree index:62) done accuracy:0.75 logloss:0.838308\n",
      "I0000 00:00:1729625074.107149 6786022 random_forest.cc:812] Training of tree  72/100 (tree index:72) done accuracy:0.733333 logloss:0.839622\n",
      "I0000 00:00:1729625074.107266 6786016 random_forest.cc:812] Training of tree  82/100 (tree index:82) done accuracy:0.741667 logloss:0.839378\n",
      "I0000 00:00:1729625074.107409 6786023 random_forest.cc:812] Training of tree  93/100 (tree index:95) done accuracy:0.725 logloss:0.838449\n",
      "I0000 00:00:1729625074.107518 6786023 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.741667 logloss:0.835822\n",
      "I0000 00:00:1729625074.107535 6786007 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.835822\n",
      "I0000 00:00:1729625074.107660 6786007 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyoadehnl with prefix 385d29da09964e21\n",
      "I0000 00:00:1729625074.108802 6786007 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625074.109429 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.835822\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  17\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:34.113618: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyoadehnl/model/ with prefix 385d29da09964e21\n",
      "I0000 00:00:1729625074.114764 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 796 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:34.114777: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 20, 'min_examples': 20, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmplzff1547 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.133261. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011333\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625074.421741 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625074.421752 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625074.421756 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625074.421819 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625074.421825 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625074.421867 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.421877 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.421883 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.421888 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.421914 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625074.421931 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625074.422066 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625074.422088 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmplzff1547/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625074.422131 6786075 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625074.422296 6786075 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625074.422859 6786085 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.531915 logloss:16.8715\n",
      "I0000 00:00:1729625074.422957 6786089 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.691667 logloss:4.85607\n",
      "I0000 00:00:1729625074.423076 6786085 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.666667 logloss:1.45481\n",
      "I0000 00:00:1729625074.423167 6786088 random_forest.cc:812] Training of tree  31/100 (tree index:31) done accuracy:0.675 logloss:0.879019\n",
      "I0000 00:00:1729625074.423280 6786090 random_forest.cc:812] Training of tree  41/100 (tree index:40) done accuracy:0.7 logloss:0.612901\n",
      "I0000 00:00:1729625074.423395 6786091 random_forest.cc:812] Training of tree  51/100 (tree index:50) done accuracy:0.691667 logloss:0.59405\n",
      "I0000 00:00:1729625074.423521 6786085 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.708333 logloss:0.581635\n",
      "I0000 00:00:1729625074.423624 6786084 random_forest.cc:812] Training of tree  72/100 (tree index:71) done accuracy:0.675 logloss:0.585385\n",
      "I0000 00:00:1729625074.423729 6786087 random_forest.cc:812] Training of tree  82/100 (tree index:82) done accuracy:0.691667 logloss:0.583388\n",
      "I0000 00:00:1729625074.423844 6786085 random_forest.cc:812] Training of tree  92/100 (tree index:93) done accuracy:0.683333 logloss:0.584073\n",
      "I0000 00:00:1729625074.423980 6786085 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.683333 logloss:0.589066\n",
      "I0000 00:00:1729625074.424051 6786075 random_forest.cc:892] Final OOB metrics: accuracy:0.683333 logloss:0.589066\n",
      "I0000 00:00:1729625074.424204 6786075 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmplzff1547 with prefix fe208bd619d44a23\n",
      "I0000 00:00:1729625074.425270 6786075 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625074.425963 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.683333  CI95[W][0.60641 0.75331]\n",
      "LogLoss: : 0.589066\n",
      "ErrorRate: : 0.316667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  21\n",
      "2  17  45\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:34.430610: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmplzff1547/model/ with prefix fe208bd619d44a23\n",
      "I0000 00:00:1729625074.431653 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 658 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:34.431668: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp69i9qhfv as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.135531. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011478\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625074.697258 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625074.697268 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625074.697273 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625074.697338 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625074.697342 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625074.697387 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.697398 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.697405 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.697411 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625074.697439 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625074.697456 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625074.697595 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625074.697641 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp69i9qhfv/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625074.697708 6786142 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625074.697850 6786142 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625074.698255 6786158 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625074.698382 6786154 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.618644 logloss:4.96611\n",
      "I0000 00:00:1729625074.698511 6786154 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.691667 logloss:1.45825\n",
      "I0000 00:00:1729625074.698668 6786156 random_forest.cc:812] Training of tree  31/100 (tree index:34) done accuracy:0.75 logloss:0.864256\n",
      "I0000 00:00:1729625074.698803 6786156 random_forest.cc:812] Training of tree  41/100 (tree index:40) done accuracy:0.716667 logloss:0.87496\n",
      "I0000 00:00:1729625074.699000 6786156 random_forest.cc:812] Training of tree  51/100 (tree index:51) done accuracy:0.733333 logloss:0.616855\n",
      "I0000 00:00:1729625074.699183 6786157 random_forest.cc:812] Training of tree  61/100 (tree index:60) done accuracy:0.733333 logloss:0.597649\n",
      "I0000 00:00:1729625074.699338 6786151 random_forest.cc:812] Training of tree  71/100 (tree index:70) done accuracy:0.725 logloss:0.603503\n",
      "I0000 00:00:1729625074.699511 6786151 random_forest.cc:812] Training of tree  81/100 (tree index:81) done accuracy:0.708333 logloss:0.605097\n",
      "I0000 00:00:1729625074.699675 6786151 random_forest.cc:812] Training of tree  92/100 (tree index:93) done accuracy:0.716667 logloss:0.61866\n",
      "I0000 00:00:1729625074.699823 6786151 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.733333 logloss:0.612301\n",
      "I0000 00:00:1729625074.699927 6786142 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.612301\n",
      "I0000 00:00:1729625074.700086 6786142 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp69i9qhfv with prefix d4be7eda2d5e4737\n",
      "I0000 00:00:1729625074.701411 6786142 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625074.702074 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.612301\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  33  20\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:34.706320: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp69i9qhfv/model/ with prefix d4be7eda2d5e4737\n",
      "I0000 00:00:1729625074.707316 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 660 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:24:34.707329: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgfrrsvf3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.293892. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011274\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpl4yti6y7 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625075.173736 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625075.173747 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625075.173755 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625075.173828 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625075.173833 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625075.173881 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.173892 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.173898 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.173903 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.173933 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625075.173953 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625075.174112 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625075.174138 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgfrrsvf3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625075.174186 6786210 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625075.174290 6786210 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625075.174786 6786221 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.45283 logloss:19.722\n",
      "I0000 00:00:1729625075.174952 6786220 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.633333 logloss:1.73967\n",
      "I0000 00:00:1729625075.175074 6786220 random_forest.cc:812] Training of tree  22/100 (tree index:21) done accuracy:0.616667 logloss:0.903382\n",
      "I0000 00:00:1729625075.175231 6786225 random_forest.cc:812] Training of tree  33/100 (tree index:33) done accuracy:0.7 logloss:0.577013\n",
      "I0000 00:00:1729625075.175403 6786222 random_forest.cc:812] Training of tree  45/100 (tree index:44) done accuracy:0.691667 logloss:0.591219\n",
      "I0000 00:00:1729625075.175569 6786226 random_forest.cc:812] Training of tree  56/100 (tree index:56) done accuracy:0.675 logloss:0.610737\n",
      "I0000 00:00:1729625075.175724 6786219 random_forest.cc:812] Training of tree  69/100 (tree index:67) done accuracy:0.7 logloss:0.612176\n",
      "I0000 00:00:1729625075.175945 6786221 random_forest.cc:812] Training of tree  80/100 (tree index:79) done accuracy:0.7 logloss:0.604361\n",
      "I0000 00:00:1729625075.176066 6786222 random_forest.cc:812] Training of tree  90/100 (tree index:87) done accuracy:0.708333 logloss:0.610276\n",
      "I0000 00:00:1729625075.176247 6786221 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.7 logloss:0.606111\n",
      "I0000 00:00:1729625075.176303 6786210 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.606111\n",
      "I0000 00:00:1729625075.176424 6786210 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgfrrsvf3 with prefix c9b54bac70734bae\n",
      "I0000 00:00:1729625075.177536 6786210 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625075.178185 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.606111\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  33  21\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:35.182459: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgfrrsvf3/model/ with prefix c9b54bac70734bae\n",
      "I0000 00:00:1729625075.183470 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 638 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:24:35.183485: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.138604. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011948\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjvqm_mn7 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625075.459331 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625075.459342 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625075.459349 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625075.459413 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625075.459418 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625075.459459 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.459469 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.459474 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.459480 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.459507 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625075.459525 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625075.459653 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625075.459674 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpl4yti6y7/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625075.459735 6786278 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625075.459832 6786278 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625075.460367 6786294 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625075.460495 6786294 random_forest.cc:812] Training of tree  14/100 (tree index:13) done accuracy:0.630252 logloss:2.93779\n",
      "I0000 00:00:1729625075.460672 6786289 random_forest.cc:812] Training of tree  27/100 (tree index:26) done accuracy:0.7 logloss:1.45428\n",
      "I0000 00:00:1729625075.460819 6786290 random_forest.cc:812] Training of tree  37/100 (tree index:36) done accuracy:0.75 logloss:0.575387\n",
      "I0000 00:00:1729625075.460954 6786291 random_forest.cc:812] Training of tree  47/100 (tree index:47) done accuracy:0.741667 logloss:0.580093\n",
      "I0000 00:00:1729625075.461074 6786294 random_forest.cc:812] Training of tree  57/100 (tree index:58) done accuracy:0.733333 logloss:0.57189\n",
      "I0000 00:00:1729625075.461177 6786287 random_forest.cc:812] Training of tree  67/100 (tree index:66) done accuracy:0.725 logloss:0.571963\n",
      "I0000 00:00:1729625075.461362 6786287 random_forest.cc:812] Training of tree  77/100 (tree index:78) done accuracy:0.716667 logloss:0.56904\n",
      "I0000 00:00:1729625075.461476 6786287 random_forest.cc:812] Training of tree  87/100 (tree index:86) done accuracy:0.708333 logloss:0.568952\n",
      "I0000 00:00:1729625075.461610 6786291 random_forest.cc:812] Training of tree  97/100 (tree index:96) done accuracy:0.75 logloss:0.557081\n",
      "I0000 00:00:1729625075.461701 6786287 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.741667 logloss:0.558289\n",
      "I0000 00:00:1729625075.461750 6786278 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.558289\n",
      "I0000 00:00:1729625075.461871 6786278 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpl4yti6y7 with prefix f91fb9c66ac64c6c\n",
      "I0000 00:00:1729625075.463042 6786278 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625075.463764 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.558289\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  20\n",
      "2  11  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:35.468479: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpl4yti6y7/model/ with prefix f91fb9c66ac64c6c\n",
      "I0000 00:00:1729625075.469768 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 654 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:35.469784: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.177450. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.010727\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 30, 'min_examples': 5, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq8c02g4k as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625075.778426 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625075.778437 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625075.778441 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625075.778507 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625075.778512 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625075.778556 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.778566 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.778571 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.778576 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625075.778604 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625075.778620 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625075.778756 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625075.778777 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjvqm_mn7/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625075.778826 6786348 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625075.778919 6786348 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625075.779365 6786362 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625075.779464 6786364 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.596639 logloss:5.23949\n",
      "I0000 00:00:1729625075.779651 6786358 random_forest.cc:812] Training of tree  21/100 (tree index:17) done accuracy:0.708333 logloss:1.15985\n",
      "I0000 00:00:1729625075.779750 6786362 random_forest.cc:812] Training of tree  31/100 (tree index:31) done accuracy:0.741667 logloss:1.13642\n",
      "I0000 00:00:1729625075.779890 6786359 random_forest.cc:812] Training of tree  42/100 (tree index:41) done accuracy:0.708333 logloss:0.866719\n",
      "I0000 00:00:1729625075.780047 6786363 random_forest.cc:812] Training of tree  52/100 (tree index:50) done accuracy:0.683333 logloss:0.597917\n",
      "I0000 00:00:1729625075.780146 6786358 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.691667 logloss:0.586785\n",
      "I0000 00:00:1729625075.780250 6786361 random_forest.cc:812] Training of tree  72/100 (tree index:71) done accuracy:0.691667 logloss:0.590643\n",
      "I0000 00:00:1729625075.780394 6786357 random_forest.cc:812] Training of tree  83/100 (tree index:82) done accuracy:0.708333 logloss:0.582096\n",
      "I0000 00:00:1729625075.780529 6786361 random_forest.cc:812] Training of tree  93/100 (tree index:93) done accuracy:0.716667 logloss:0.579246\n",
      "I0000 00:00:1729625075.780622 6786364 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.7 logloss:0.581723\n",
      "I0000 00:00:1729625075.780645 6786348 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.581723\n",
      "I0000 00:00:1729625075.780762 6786348 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjvqm_mn7 with prefix 089fc95b87f24021\n",
      "I0000 00:00:1729625075.782103 6786348 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625075.782629 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.581723\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  35  20\n",
      "2  16  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:35.786738: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjvqm_mn7/model/ with prefix 089fc95b87f24021\n",
      "I0000 00:00:1729625075.787702 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 638 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:35.787721: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.136429. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014735\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphae94p3m as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625076.057488 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625076.057500 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625076.057508 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625076.057571 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625076.057576 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625076.057624 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.057633 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.057638 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.057643 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.057670 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625076.057688 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625076.057826 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625076.057851 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq8c02g4k/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625076.057909 6786417 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625076.058060 6786417 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625076.058615 6786432 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.55814 logloss:15.9263\n",
      "I0000 00:00:1729625076.058795 6786433 random_forest.cc:812] Training of tree  11/100 (tree index:12) done accuracy:0.731092 logloss:3.41992\n",
      "I0000 00:00:1729625076.059027 6786431 random_forest.cc:812] Training of tree  21/100 (tree index:15) done accuracy:0.708333 logloss:1.40632\n",
      "I0000 00:00:1729625076.059228 6786428 random_forest.cc:812] Training of tree  31/100 (tree index:33) done accuracy:0.708333 logloss:0.868921\n",
      "I0000 00:00:1729625076.059401 6786432 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.741667 logloss:0.833789\n",
      "I0000 00:00:1729625076.059599 6786426 random_forest.cc:812] Training of tree  51/100 (tree index:53) done accuracy:0.733333 logloss:0.541968\n",
      "I0000 00:00:1729625076.059789 6786429 random_forest.cc:812] Training of tree  61/100 (tree index:62) done accuracy:0.75 logloss:0.528915\n",
      "I0000 00:00:1729625076.059973 6786432 random_forest.cc:812] Training of tree  71/100 (tree index:71) done accuracy:0.75 logloss:0.52865\n",
      "I0000 00:00:1729625076.060170 6786432 random_forest.cc:812] Training of tree  81/100 (tree index:84) done accuracy:0.741667 logloss:0.531366\n",
      "I0000 00:00:1729625076.060311 6786429 random_forest.cc:812] Training of tree  91/100 (tree index:89) done accuracy:0.741667 logloss:0.52092\n",
      "I0000 00:00:1729625076.060467 6786432 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.758333 logloss:0.522245\n",
      "I0000 00:00:1729625076.060518 6786417 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.522245\n",
      "I0000 00:00:1729625076.060795 6786417 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq8c02g4k with prefix 70ea447390a94e65\n",
      "I0000 00:00:1729625076.062395 6786417 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625076.062952 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.522245\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  15\n",
      "2  14  48\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:36.067735: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq8c02g4k/model/ with prefix 70ea447390a94e65\n",
      "I0000 00:00:1729625076.070561 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2188 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:36.070581: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.139842. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015273\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp67bkoavq as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625076.346654 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625076.346665 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625076.346671 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625076.346734 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625076.346739 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625076.346784 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.346794 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.346799 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.346804 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.346861 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625076.346886 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625076.347031 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625076.347060 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphae94p3m/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625076.347125 6786485 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625076.347214 6786485 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625076.347677 6786495 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625076.347863 6786494 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.672269 logloss:4.86635\n",
      "I0000 00:00:1729625076.348024 6786497 random_forest.cc:812] Training of tree  21/100 (tree index:19) done accuracy:0.716667 logloss:0.825991\n",
      "I0000 00:00:1729625076.348219 6786497 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.75 logloss:0.783055\n",
      "I0000 00:00:1729625076.348430 6786500 random_forest.cc:812] Training of tree  41/100 (tree index:43) done accuracy:0.741667 logloss:0.798482\n",
      "I0000 00:00:1729625076.348609 6786498 random_forest.cc:812] Training of tree  51/100 (tree index:52) done accuracy:0.741667 logloss:0.51764\n",
      "I0000 00:00:1729625076.348820 6786500 random_forest.cc:812] Training of tree  61/100 (tree index:61) done accuracy:0.725 logloss:0.518001\n",
      "I0000 00:00:1729625076.348999 6786496 random_forest.cc:812] Training of tree  71/100 (tree index:70) done accuracy:0.733333 logloss:0.512746\n",
      "I0000 00:00:1729625076.349147 6786499 random_forest.cc:812] Training of tree  81/100 (tree index:81) done accuracy:0.758333 logloss:0.499573\n",
      "I0000 00:00:1729625076.349356 6786498 random_forest.cc:812] Training of tree  92/100 (tree index:91) done accuracy:0.766667 logloss:0.4992\n",
      "I0000 00:00:1729625076.349485 6786497 random_forest.cc:812] Training of tree  100/100 (tree index:95) done accuracy:0.766667 logloss:0.491281\n",
      "I0000 00:00:1729625076.349540 6786485 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.491281\n",
      "I0000 00:00:1729625076.349825 6786485 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphae94p3m with prefix 810d3e506c1640e7\n",
      "I0000 00:00:1729625076.351581 6786485 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625076.352148 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.491281\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  13  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:36.357220: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphae94p3m/model/ with prefix 810d3e506c1640e7\n",
      "I0000 00:00:1729625076.360224 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2252 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:36.360238: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.134710. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015402\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9y2vrc8f as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625076.666040 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625076.666049 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625076.666056 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625076.666253 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625076.666257 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625076.666303 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.666314 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.666320 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.666326 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.666353 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625076.666372 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625076.666512 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625076.666536 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp67bkoavq/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625076.666588 6786553 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625076.666686 6786553 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625076.667153 6786567 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.697674 logloss:10.8969\n",
      "I0000 00:00:1729625076.667343 6786562 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.697479 logloss:3.08883\n",
      "I0000 00:00:1729625076.667509 6786566 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.708333 logloss:1.11655\n",
      "I0000 00:00:1729625076.667708 6786562 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.691667 logloss:0.574449\n",
      "I0000 00:00:1729625076.667892 6786565 random_forest.cc:812] Training of tree  41/100 (tree index:40) done accuracy:0.725 logloss:0.56291\n",
      "I0000 00:00:1729625076.668073 6786566 random_forest.cc:812] Training of tree  51/100 (tree index:51) done accuracy:0.725 logloss:0.55487\n",
      "I0000 00:00:1729625076.668293 6786568 random_forest.cc:812] Training of tree  62/100 (tree index:62) done accuracy:0.733333 logloss:0.548817\n",
      "I0000 00:00:1729625076.668511 6786563 random_forest.cc:812] Training of tree  72/100 (tree index:70) done accuracy:0.716667 logloss:0.548584\n",
      "I0000 00:00:1729625076.668672 6786565 random_forest.cc:812] Training of tree  82/100 (tree index:82) done accuracy:0.741667 logloss:0.537183\n",
      "I0000 00:00:1729625076.668850 6786569 random_forest.cc:812] Training of tree  92/100 (tree index:92) done accuracy:0.733333 logloss:0.542631\n",
      "I0000 00:00:1729625076.669017 6786563 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.733333 logloss:0.534692\n",
      "I0000 00:00:1729625076.669059 6786553 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.534692\n",
      "I0000 00:00:1729625076.669362 6786553 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp67bkoavq with prefix 727d8830abe649f6\n",
      "I0000 00:00:1729625076.671042 6786553 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625076.671717 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.534692\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:36.676478: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp67bkoavq/model/ with prefix 727d8830abe649f6\n",
      "I0000 00:00:1729625076.679587 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2286 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:36.679606: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.134065. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015197\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpry9_m1g_ as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625076.948058 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625076.948067 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625076.948076 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625076.948138 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625076.948142 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625076.948197 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.948209 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.948214 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.948219 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625076.948246 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625076.948267 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625076.948400 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625076.948424 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9y2vrc8f/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625076.948483 6786642 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625076.948591 6786642 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625076.949054 6786651 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625076.949203 6786657 random_forest.cc:812] Training of tree  11/100 (tree index:12) done accuracy:0.739496 logloss:1.8677\n",
      "I0000 00:00:1729625076.949376 6786654 random_forest.cc:812] Training of tree  21/100 (tree index:13) done accuracy:0.833333 logloss:0.42028\n",
      "I0000 00:00:1729625076.949591 6786658 random_forest.cc:812] Training of tree  31/100 (tree index:34) done accuracy:0.808333 logloss:0.42271\n",
      "I0000 00:00:1729625076.949777 6786651 random_forest.cc:812] Training of tree  42/100 (tree index:40) done accuracy:0.791667 logloss:0.427799\n",
      "I0000 00:00:1729625076.949956 6786658 random_forest.cc:812] Training of tree  52/100 (tree index:50) done accuracy:0.791667 logloss:0.432492\n",
      "I0000 00:00:1729625076.950161 6786657 random_forest.cc:812] Training of tree  62/100 (tree index:64) done accuracy:0.783333 logloss:0.435995\n",
      "I0000 00:00:1729625076.950298 6786658 random_forest.cc:812] Training of tree  73/100 (tree index:72) done accuracy:0.783333 logloss:0.441395\n",
      "I0000 00:00:1729625076.950485 6786653 random_forest.cc:812] Training of tree  83/100 (tree index:83) done accuracy:0.8 logloss:0.452603\n",
      "I0000 00:00:1729625076.950642 6786655 random_forest.cc:812] Training of tree  93/100 (tree index:92) done accuracy:0.8 logloss:0.448792\n",
      "I0000 00:00:1729625076.950786 6786657 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.808333 logloss:0.449186\n",
      "I0000 00:00:1729625076.950836 6786642 random_forest.cc:892] Final OOB metrics: accuracy:0.808333 logloss:0.449186\n",
      "I0000 00:00:1729625076.951126 6786642 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9y2vrc8f with prefix 68fa2aef8f42424e\n",
      "I0000 00:00:1729625076.952975 6786642 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625076.953548 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.808333  CI95[W][0.739526 0.865316]\n",
      "LogLoss: : 0.449186\n",
      "ErrorRate: : 0.191667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  13\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:36.958637: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9y2vrc8f/model/ with prefix 68fa2aef8f42424e\n",
      "I0000 00:00:1729625076.961399 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2090 node(s), and 19 input feature(s).\n",
      "I0000 00:00:1729625076.961410 6784195 abstract_model.cc:1323] Engine \"RandomForestOptPred\" built\n",
      "2024-10-22 20:24:36.961415: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.137058. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014265\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 30, 'min_examples': 5, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf13p14zi as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625077.273979 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625077.273992 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625077.273996 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625077.274057 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625077.274063 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625077.274106 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.274116 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.274121 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.274126 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.274152 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625077.274169 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625077.274301 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625077.274326 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpry9_m1g_/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625077.274373 6786712 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625077.274490 6786712 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625077.275001 6786728 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625077.275188 6786725 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.705882 logloss:4.56415\n",
      "I0000 00:00:1729625077.275381 6786727 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.733333 logloss:1.93507\n",
      "I0000 00:00:1729625077.275539 6786726 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.758333 logloss:1.08033\n",
      "I0000 00:00:1729625077.275702 6786728 random_forest.cc:812] Training of tree  41/100 (tree index:36) done accuracy:0.766667 logloss:0.780084\n",
      "I0000 00:00:1729625077.275875 6786721 random_forest.cc:812] Training of tree  51/100 (tree index:43) done accuracy:0.783333 logloss:0.481942\n",
      "I0000 00:00:1729625077.276050 6786723 random_forest.cc:812] Training of tree  61/100 (tree index:62) done accuracy:0.783333 logloss:0.487535\n",
      "I0000 00:00:1729625077.276206 6786725 random_forest.cc:812] Training of tree  71/100 (tree index:70) done accuracy:0.791667 logloss:0.483215\n",
      "I0000 00:00:1729625077.276369 6786723 random_forest.cc:812] Training of tree  81/100 (tree index:82) done accuracy:0.775 logloss:0.4789\n",
      "I0000 00:00:1729625077.276537 6786725 random_forest.cc:812] Training of tree  92/100 (tree index:93) done accuracy:0.783333 logloss:0.478839\n",
      "I0000 00:00:1729625077.276710 6786721 random_forest.cc:812] Training of tree  100/100 (tree index:94) done accuracy:0.783333 logloss:0.475094\n",
      "I0000 00:00:1729625077.276754 6786712 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.475094\n",
      "I0000 00:00:1729625077.277016 6786712 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpry9_m1g_ with prefix 9b61448ea49347ff\n",
      "I0000 00:00:1729625077.278666 6786712 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625077.279194 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.475094\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  44  11\n",
      "2  15  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:37.283831: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpry9_m1g_/model/ with prefix 9b61448ea49347ff\n",
      "I0000 00:00:1729625077.286614 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2184 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:37.286631: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.136851. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014966\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9x6h_tce as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625077.556267 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625077.556279 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625077.556282 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625077.556343 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625077.556349 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625077.556392 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.556401 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.556407 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.556412 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.556438 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625077.556455 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625077.556580 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625077.556602 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf13p14zi/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625077.556657 6786783 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625077.556774 6786783 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625077.557277 6786799 random_forest.cc:812] Training of tree  1/100 (tree index:4) done accuracy:0.642857 logloss:12.8727\n",
      "I0000 00:00:1729625077.557428 6786795 random_forest.cc:812] Training of tree  11/100 (tree index:0) done accuracy:0.677966 logloss:1.99144\n",
      "I0000 00:00:1729625077.557655 6786797 random_forest.cc:812] Training of tree  22/100 (tree index:16) done accuracy:0.716667 logloss:0.822399\n",
      "I0000 00:00:1729625077.557953 6786799 random_forest.cc:812] Training of tree  32/100 (tree index:29) done accuracy:0.708333 logloss:0.526816\n",
      "I0000 00:00:1729625077.558097 6786795 random_forest.cc:812] Training of tree  42/100 (tree index:41) done accuracy:0.691667 logloss:0.573964\n",
      "I0000 00:00:1729625077.558286 6786795 random_forest.cc:812] Training of tree  52/100 (tree index:53) done accuracy:0.675 logloss:0.569507\n",
      "I0000 00:00:1729625077.558507 6786794 random_forest.cc:812] Training of tree  62/100 (tree index:65) done accuracy:0.675 logloss:0.552955\n",
      "I0000 00:00:1729625077.558887 6786793 random_forest.cc:812] Training of tree  72/100 (tree index:66) done accuracy:0.7 logloss:0.554573\n",
      "I0000 00:00:1729625077.559044 6786792 random_forest.cc:812] Training of tree  82/100 (tree index:81) done accuracy:0.708333 logloss:0.539546\n",
      "I0000 00:00:1729625077.559313 6786799 random_forest.cc:812] Training of tree  94/100 (tree index:94) done accuracy:0.708333 logloss:0.541329\n",
      "I0000 00:00:1729625077.559420 6786799 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.716667 logloss:0.538451\n",
      "I0000 00:00:1729625077.559443 6786783 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.538451\n",
      "I0000 00:00:1729625077.559707 6786783 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf13p14zi with prefix 2324dc2c48534af9\n",
      "I0000 00:00:1729625077.561304 6786783 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625077.562101 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.538451\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:37.566947: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf13p14zi/model/ with prefix 2324dc2c48534af9\n",
      "I0000 00:00:1729625077.569548 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1896 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:37.569566: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.131946. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013992\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzii_aewn as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625077.876377 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625077.876390 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625077.876394 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625077.876456 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625077.876462 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625077.876508 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.876518 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.876523 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.876528 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625077.876555 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625077.876572 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625077.876707 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625077.876728 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9x6h_tce/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625077.876783 6786854 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625077.876869 6786854 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625077.877325 6786864 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.773585 logloss:8.16083\n",
      "I0000 00:00:1729625077.877474 6786870 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.663866 logloss:4.63876\n",
      "I0000 00:00:1729625077.877688 6786863 random_forest.cc:812] Training of tree  21/100 (tree index:22) done accuracy:0.691667 logloss:1.18252\n",
      "I0000 00:00:1729625077.877870 6786867 random_forest.cc:812] Training of tree  34/100 (tree index:34) done accuracy:0.716667 logloss:0.569492\n",
      "I0000 00:00:1729625077.878128 6786868 random_forest.cc:812] Training of tree  45/100 (tree index:40) done accuracy:0.7 logloss:0.573961\n",
      "I0000 00:00:1729625077.878335 6786865 random_forest.cc:812] Training of tree  55/100 (tree index:55) done accuracy:0.741667 logloss:0.559956\n",
      "I0000 00:00:1729625077.878510 6786868 random_forest.cc:812] Training of tree  65/100 (tree index:64) done accuracy:0.741667 logloss:0.560879\n",
      "I0000 00:00:1729625077.878723 6786863 random_forest.cc:812] Training of tree  75/100 (tree index:75) done accuracy:0.716667 logloss:0.566648\n",
      "I0000 00:00:1729625077.878874 6786869 random_forest.cc:812] Training of tree  85/100 (tree index:85) done accuracy:0.725 logloss:0.565982\n",
      "I0000 00:00:1729625077.879018 6786864 random_forest.cc:812] Training of tree  95/100 (tree index:94) done accuracy:0.725 logloss:0.556041\n",
      "I0000 00:00:1729625077.879148 6786870 random_forest.cc:812] Training of tree  100/100 (tree index:96) done accuracy:0.733333 logloss:0.55753\n",
      "I0000 00:00:1729625077.879186 6786854 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.55753\n",
      "I0000 00:00:1729625077.879433 6786854 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9x6h_tce with prefix 9b1680517e414a76\n",
      "I0000 00:00:1729625077.881065 6786854 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625077.881617 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.55753\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  16\n",
      "2  16  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:37.886022: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9x6h_tce/model/ with prefix 9b1680517e414a76\n",
      "I0000 00:00:1729625077.888616 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1930 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:37.888632: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.139333. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015778\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxcbuetur as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625078.168436 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625078.168447 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625078.168451 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625078.168511 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625078.168516 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625078.168558 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.168570 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.168575 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.168580 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.168608 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625078.168625 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625078.168782 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625078.168807 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzii_aewn/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625078.168874 6786921 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625078.168976 6786921 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625078.169475 6786934 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.660377 logloss:12.2412\n",
      "I0000 00:00:1729625078.169718 6786931 random_forest.cc:812] Training of tree  12/100 (tree index:12) done accuracy:0.689076 logloss:4.06041\n",
      "I0000 00:00:1729625078.169995 6786935 random_forest.cc:812] Training of tree  23/100 (tree index:25) done accuracy:0.666667 logloss:1.16794\n",
      "I0000 00:00:1729625078.170266 6786932 random_forest.cc:812] Training of tree  33/100 (tree index:31) done accuracy:0.716667 logloss:0.565151\n",
      "I0000 00:00:1729625078.170465 6786933 random_forest.cc:812] Training of tree  44/100 (tree index:44) done accuracy:0.733333 logloss:0.554094\n",
      "I0000 00:00:1729625078.170642 6786931 random_forest.cc:812] Training of tree  54/100 (tree index:53) done accuracy:0.741667 logloss:0.558098\n",
      "I0000 00:00:1729625078.170782 6786935 random_forest.cc:812] Training of tree  64/100 (tree index:63) done accuracy:0.775 logloss:0.547784\n",
      "I0000 00:00:1729625078.170989 6786935 random_forest.cc:812] Training of tree  74/100 (tree index:74) done accuracy:0.783333 logloss:0.541692\n",
      "I0000 00:00:1729625078.171175 6786935 random_forest.cc:812] Training of tree  85/100 (tree index:85) done accuracy:0.75 logloss:0.535895\n",
      "I0000 00:00:1729625078.171315 6786934 random_forest.cc:812] Training of tree  95/100 (tree index:92) done accuracy:0.8 logloss:0.531469\n",
      "I0000 00:00:1729625078.171417 6786932 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.791667 logloss:0.53188\n",
      "I0000 00:00:1729625078.171469 6786921 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.53188\n",
      "I0000 00:00:1729625078.171778 6786921 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzii_aewn with prefix efd9ea8b975a428f\n",
      "I0000 00:00:1729625078.173399 6786921 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625078.174175 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.53188\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  13\n",
      "2  12  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:38.179460: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzii_aewn/model/ with prefix efd9ea8b975a428f\n",
      "I0000 00:00:1729625078.182242 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1970 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:38.182264: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.185979. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014580\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptub2d5rr as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625078.505988 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625078.505998 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625078.506007 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625078.506070 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625078.506074 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625078.506118 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.506127 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.506133 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.506138 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.506167 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625078.506184 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625078.506330 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625078.506355 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxcbuetur/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625078.506414 6786989 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625078.506521 6786989 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625078.506960 6786998 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625078.507123 6787004 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.694915 logloss:3.72599\n",
      "I0000 00:00:1729625078.507283 6787005 random_forest.cc:812] Training of tree  22/100 (tree index:21) done accuracy:0.766667 logloss:1.33207\n",
      "I0000 00:00:1729625078.507449 6787005 random_forest.cc:812] Training of tree  32/100 (tree index:33) done accuracy:0.766667 logloss:1.04645\n",
      "I0000 00:00:1729625078.507627 6786999 random_forest.cc:812] Training of tree  42/100 (tree index:42) done accuracy:0.766667 logloss:0.487975\n",
      "I0000 00:00:1729625078.507778 6787004 random_forest.cc:812] Training of tree  53/100 (tree index:49) done accuracy:0.758333 logloss:0.492579\n",
      "I0000 00:00:1729625078.507940 6786998 random_forest.cc:812] Training of tree  63/100 (tree index:61) done accuracy:0.766667 logloss:0.481083\n",
      "I0000 00:00:1729625078.508092 6787003 random_forest.cc:812] Training of tree  73/100 (tree index:72) done accuracy:0.758333 logloss:0.480694\n",
      "I0000 00:00:1729625078.508257 6787005 random_forest.cc:812] Training of tree  83/100 (tree index:82) done accuracy:0.775 logloss:0.483723\n",
      "I0000 00:00:1729625078.508404 6787001 random_forest.cc:812] Training of tree  95/100 (tree index:94) done accuracy:0.766667 logloss:0.472218\n",
      "I0000 00:00:1729625078.508472 6787000 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.783333 logloss:0.473639\n",
      "I0000 00:00:1729625078.508543 6786989 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.473639\n",
      "I0000 00:00:1729625078.508786 6786989 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxcbuetur with prefix b51b2488fe8a4c93\n",
      "I0000 00:00:1729625078.510368 6786989 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625078.510979 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.473639\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  13\n",
      "2  13  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:38.516112: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxcbuetur/model/ with prefix b51b2488fe8a4c93\n",
      "I0000 00:00:1729625078.518613 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1776 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:38.518631: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.140843. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013966\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 30, 'min_examples': 10, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr_c_pwab as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625078.797773 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625078.797789 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625078.797794 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625078.797858 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625078.797863 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625078.797918 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.797932 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.797938 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.797945 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625078.797973 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625078.797998 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625078.798134 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625078.798158 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptub2d5rr/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625078.798215 6787058 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625078.798307 6787058 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625078.798731 6787067 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.641509 logloss:12.9213\n",
      "I0000 00:00:1729625078.798868 6787068 random_forest.cc:812] Training of tree  11/100 (tree index:12) done accuracy:0.722689 logloss:2.81074\n",
      "I0000 00:00:1729625078.799065 6787070 random_forest.cc:812] Training of tree  22/100 (tree index:18) done accuracy:0.733333 logloss:0.737578\n",
      "I0000 00:00:1729625078.799215 6787073 random_forest.cc:812] Training of tree  32/100 (tree index:29) done accuracy:0.766667 logloss:0.727391\n",
      "I0000 00:00:1729625078.799355 6787074 random_forest.cc:812] Training of tree  42/100 (tree index:41) done accuracy:0.783333 logloss:0.461788\n",
      "I0000 00:00:1729625078.799549 6787068 random_forest.cc:812] Training of tree  52/100 (tree index:52) done accuracy:0.775 logloss:0.454333\n",
      "I0000 00:00:1729625078.799689 6787067 random_forest.cc:812] Training of tree  63/100 (tree index:62) done accuracy:0.775 logloss:0.465334\n",
      "I0000 00:00:1729625078.799854 6787068 random_forest.cc:812] Training of tree  73/100 (tree index:72) done accuracy:0.775 logloss:0.472421\n",
      "I0000 00:00:1729625078.799984 6787070 random_forest.cc:812] Training of tree  83/100 (tree index:83) done accuracy:0.775 logloss:0.463869\n",
      "I0000 00:00:1729625078.800154 6787068 random_forest.cc:812] Training of tree  94/100 (tree index:91) done accuracy:0.783333 logloss:0.45197\n",
      "I0000 00:00:1729625078.800290 6787068 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.775 logloss:0.46055\n",
      "I0000 00:00:1729625078.800332 6787058 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.46055\n",
      "I0000 00:00:1729625078.800557 6787058 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptub2d5rr with prefix 3d87eed54868441e\n",
      "I0000 00:00:1729625078.801933 6787058 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625078.802649 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.46055\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  13\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:38.807147: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptub2d5rr/model/ with prefix 3d87eed54868441e\n",
      "I0000 00:00:1729625078.809727 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1826 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:38.809747: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.135541. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013175\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpb58xng8f as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625079.085976 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625079.085989 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625079.085994 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625079.086055 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625079.086059 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625079.086105 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.086115 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.086120 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.086125 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.086152 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625079.086169 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625079.086307 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625079.086330 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr_c_pwab/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625079.086391 6787127 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625079.086497 6787127 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625079.087032 6787137 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.590909 logloss:14.7451\n",
      "I0000 00:00:1729625079.087242 6787136 random_forest.cc:812] Training of tree  11/100 (tree index:12) done accuracy:0.697479 logloss:4.59117\n",
      "I0000 00:00:1729625079.087370 6787143 random_forest.cc:812] Training of tree  22/100 (tree index:21) done accuracy:0.708333 logloss:2.29342\n",
      "I0000 00:00:1729625079.087567 6787140 random_forest.cc:812] Training of tree  32/100 (tree index:28) done accuracy:0.775 logloss:1.10351\n",
      "I0000 00:00:1729625079.087728 6787142 random_forest.cc:812] Training of tree  42/100 (tree index:43) done accuracy:0.766667 logloss:0.829304\n",
      "I0000 00:00:1729625079.087862 6787138 random_forest.cc:812] Training of tree  52/100 (tree index:51) done accuracy:0.758333 logloss:0.821108\n",
      "I0000 00:00:1729625079.088080 6787139 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.741667 logloss:0.796064\n",
      "I0000 00:00:1729625079.088228 6787141 random_forest.cc:812] Training of tree  72/100 (tree index:72) done accuracy:0.733333 logloss:0.801383\n",
      "I0000 00:00:1729625079.088380 6787139 random_forest.cc:812] Training of tree  82/100 (tree index:81) done accuracy:0.725 logloss:0.808083\n",
      "I0000 00:00:1729625079.088598 6787137 random_forest.cc:812] Training of tree  93/100 (tree index:92) done accuracy:0.708333 logloss:0.811097\n",
      "I0000 00:00:1729625079.088765 6787139 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.708333 logloss:0.542033\n",
      "I0000 00:00:1729625079.088801 6787127 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.542033\n",
      "I0000 00:00:1729625079.089005 6787127 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr_c_pwab with prefix 92eda15abfa64d0e\n",
      "I0000 00:00:1729625079.090324 6787127 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625079.090896 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.542033\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  20\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:39.095327: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr_c_pwab/model/ with prefix 92eda15abfa64d0e\n",
      "I0000 00:00:1729625079.097444 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1502 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:39.097460: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.134101. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012982\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzp00j11z as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625079.416713 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625079.416727 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625079.416730 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625079.416790 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625079.416797 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625079.416838 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.416847 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.416852 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.416857 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.416884 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625079.416902 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625079.417030 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625079.417055 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpb58xng8f/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625079.417115 6787197 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625079.417213 6787197 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625079.417708 6787213 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.772727 logloss:8.19174\n",
      "I0000 00:00:1729625079.417857 6787212 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.697479 logloss:4.86184\n",
      "I0000 00:00:1729625079.418034 6787210 random_forest.cc:812] Training of tree  21/100 (tree index:22) done accuracy:0.775 logloss:1.09095\n",
      "I0000 00:00:1729625079.418158 6787213 random_forest.cc:812] Training of tree  31/100 (tree index:29) done accuracy:0.758333 logloss:1.07114\n",
      "I0000 00:00:1729625079.418321 6787209 random_forest.cc:812] Training of tree  42/100 (tree index:42) done accuracy:0.766667 logloss:0.514086\n",
      "I0000 00:00:1729625079.418502 6787212 random_forest.cc:812] Training of tree  53/100 (tree index:51) done accuracy:0.741667 logloss:0.546881\n",
      "I0000 00:00:1729625079.418687 6787209 random_forest.cc:812] Training of tree  63/100 (tree index:62) done accuracy:0.8 logloss:0.538895\n",
      "I0000 00:00:1729625079.418843 6787210 random_forest.cc:812] Training of tree  73/100 (tree index:71) done accuracy:0.783333 logloss:0.536036\n",
      "I0000 00:00:1729625079.419052 6787209 random_forest.cc:812] Training of tree  83/100 (tree index:75) done accuracy:0.766667 logloss:0.530931\n",
      "I0000 00:00:1729625079.419182 6787212 random_forest.cc:812] Training of tree  93/100 (tree index:94) done accuracy:0.758333 logloss:0.532658\n",
      "I0000 00:00:1729625079.419330 6787211 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.775 logloss:0.522878\n",
      "I0000 00:00:1729625079.419387 6787197 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.522878\n",
      "I0000 00:00:1729625079.419601 6787197 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpb58xng8f with prefix 155158d8317a47ba\n",
      "I0000 00:00:1729625079.421078 6787197 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625079.421587 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.522878\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  13  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:39.426042: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpb58xng8f/model/ with prefix 155158d8317a47ba\n",
      "I0000 00:00:1729625079.428182 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1548 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:39.428201: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.133378. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013116\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp37jvazt0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625079.693079 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625079.693093 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625079.693097 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625079.693160 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625079.693163 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625079.693206 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.693217 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.693222 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.693227 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625079.693254 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625079.693272 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625079.693405 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625079.693428 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzp00j11z/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625079.693489 6787268 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625079.693675 6787268 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625079.694129 6787283 random_forest.cc:812] Training of tree  1/100 (tree index:2) done accuracy:0.682927 logloss:11.4285\n",
      "I0000 00:00:1729625079.694314 6787283 random_forest.cc:812] Training of tree  11/100 (tree index:8) done accuracy:0.689076 logloss:1.91993\n",
      "I0000 00:00:1729625079.694440 6787278 random_forest.cc:812] Training of tree  21/100 (tree index:19) done accuracy:0.708333 logloss:0.835389\n",
      "I0000 00:00:1729625079.694609 6787283 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.7 logloss:0.583202\n",
      "I0000 00:00:1729625079.694781 6787284 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.666667 logloss:0.594099\n",
      "I0000 00:00:1729625079.694984 6787279 random_forest.cc:812] Training of tree  54/100 (tree index:49) done accuracy:0.65 logloss:0.596269\n",
      "I0000 00:00:1729625079.695191 6787279 random_forest.cc:812] Training of tree  64/100 (tree index:64) done accuracy:0.691667 logloss:0.590499\n",
      "I0000 00:00:1729625079.695346 6787277 random_forest.cc:812] Training of tree  74/100 (tree index:73) done accuracy:0.683333 logloss:0.59999\n",
      "I0000 00:00:1729625079.695493 6787278 random_forest.cc:812] Training of tree  84/100 (tree index:84) done accuracy:0.716667 logloss:0.592969\n",
      "I0000 00:00:1729625079.695674 6787278 random_forest.cc:812] Training of tree  94/100 (tree index:96) done accuracy:0.708333 logloss:0.584032\n",
      "I0000 00:00:1729625079.695755 6787283 random_forest.cc:812] Training of tree  100/100 (tree index:92) done accuracy:0.733333 logloss:0.578733\n",
      "I0000 00:00:1729625079.695782 6787268 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.578733\n",
      "I0000 00:00:1729625079.695987 6787268 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzp00j11z with prefix a2a34c2c30134afc\n",
      "I0000 00:00:1729625079.697425 6787268 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625079.698049 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.578733\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  15\n",
      "2  17  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:39.702542: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzp00j11z/model/ with prefix a2a34c2c30134afc\n",
      "I0000 00:00:1729625079.704697 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1544 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:39.704713: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.188755. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013522\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_u0t4mq4 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625080.029602 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625080.029612 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625080.029616 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625080.029677 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625080.029682 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625080.029724 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.029737 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.029743 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.029747 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.029774 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625080.029789 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625080.029915 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625080.029940 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp37jvazt0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625080.029989 6787351 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625080.030092 6787351 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625080.030598 6787365 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.674419 logloss:11.7351\n",
      "I0000 00:00:1729625080.030816 6787364 random_forest.cc:812] Training of tree  14/100 (tree index:13) done accuracy:0.686441 logloss:2.2625\n",
      "I0000 00:00:1729625080.031098 6787360 random_forest.cc:812] Training of tree  25/100 (tree index:20) done accuracy:0.758333 logloss:0.77929\n",
      "I0000 00:00:1729625080.031301 6787367 random_forest.cc:812] Training of tree  35/100 (tree index:36) done accuracy:0.741667 logloss:0.762195\n",
      "I0000 00:00:1729625080.031489 6787367 random_forest.cc:812] Training of tree  45/100 (tree index:45) done accuracy:0.741667 logloss:0.494184\n",
      "I0000 00:00:1729625080.031644 6787366 random_forest.cc:812] Training of tree  55/100 (tree index:55) done accuracy:0.741667 logloss:0.494295\n",
      "I0000 00:00:1729625080.031782 6787364 random_forest.cc:812] Training of tree  65/100 (tree index:63) done accuracy:0.758333 logloss:0.495566\n",
      "I0000 00:00:1729625080.031944 6787367 random_forest.cc:812] Training of tree  75/100 (tree index:78) done accuracy:0.766667 logloss:0.493155\n",
      "I0000 00:00:1729625080.032073 6787364 random_forest.cc:812] Training of tree  85/100 (tree index:84) done accuracy:0.783333 logloss:0.485725\n",
      "I0000 00:00:1729625080.032295 6787365 random_forest.cc:812] Training of tree  95/100 (tree index:96) done accuracy:0.775 logloss:0.475523\n",
      "I0000 00:00:1729625080.032390 6787366 random_forest.cc:812] Training of tree  100/100 (tree index:95) done accuracy:0.783333 logloss:0.475724\n",
      "I0000 00:00:1729625080.032429 6787351 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.475724\n",
      "I0000 00:00:1729625080.032627 6787351 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp37jvazt0 with prefix efce1d4955684f4b\n",
      "I0000 00:00:1729625080.033966 6787351 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625080.034727 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.475724\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  16\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:40.039488: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp37jvazt0/model/ with prefix efce1d4955684f4b\n",
      "I0000 00:00:1729625080.041491 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1442 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:40.041509: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.135026. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014018\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 30, 'min_examples': 10, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgucdrysa as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625080.315902 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625080.315911 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625080.315915 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625080.315978 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625080.315984 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625080.316025 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.316034 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.316039 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.316045 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.316071 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625080.316089 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625080.316221 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625080.316250 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_u0t4mq4/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625080.316294 6787421 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625080.316397 6787421 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625080.316894 6787434 random_forest.cc:812] Training of tree  1/100 (tree index:2) done accuracy:0.780488 logloss:7.91202\n",
      "I0000 00:00:1729625080.317089 6787437 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.773109 logloss:2.74265\n",
      "I0000 00:00:1729625080.317237 6787431 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.716667 logloss:1.38217\n",
      "I0000 00:00:1729625080.317392 6787435 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.75 logloss:0.785781\n",
      "I0000 00:00:1729625080.317522 6787430 random_forest.cc:812] Training of tree  41/100 (tree index:22) done accuracy:0.75 logloss:0.790881\n",
      "I0000 00:00:1729625080.317735 6787431 random_forest.cc:812] Training of tree  52/100 (tree index:47) done accuracy:0.758333 logloss:0.485813\n",
      "I0000 00:00:1729625080.317888 6787432 random_forest.cc:812] Training of tree  62/100 (tree index:62) done accuracy:0.783333 logloss:0.488525\n",
      "I0000 00:00:1729625080.318050 6787435 random_forest.cc:812] Training of tree  72/100 (tree index:73) done accuracy:0.775 logloss:0.491734\n",
      "I0000 00:00:1729625080.318254 6787433 random_forest.cc:812] Training of tree  82/100 (tree index:81) done accuracy:0.758333 logloss:0.492161\n",
      "I0000 00:00:1729625080.318403 6787434 random_forest.cc:812] Training of tree  92/100 (tree index:92) done accuracy:0.766667 logloss:0.490207\n",
      "I0000 00:00:1729625080.318525 6787435 random_forest.cc:812] Training of tree  100/100 (tree index:97) done accuracy:0.766667 logloss:0.491437\n",
      "I0000 00:00:1729625080.318566 6787421 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.491437\n",
      "I0000 00:00:1729625080.318788 6787421 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_u0t4mq4 with prefix 30bcafb25e2f404c\n",
      "I0000 00:00:1729625080.320636 6787421 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625080.321340 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.491437\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:40.326338: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_u0t4mq4/model/ with prefix 30bcafb25e2f404c\n",
      "I0000 00:00:1729625080.328372 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1514 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:40.328385: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.138595. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014289\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw5muh9gt as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625080.656345 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625080.656358 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625080.656364 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625080.656428 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625080.656433 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625080.656477 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.656486 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.656492 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.656497 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.656524 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625080.656541 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625080.656746 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625080.656783 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgucdrysa/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625080.656840 6787490 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625080.656972 6787490 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625080.657505 6787499 random_forest.cc:812] Training of tree  1/100 (tree index:4) done accuracy:0.767857 logloss:8.36728\n",
      "I0000 00:00:1729625080.657689 6787501 random_forest.cc:812] Training of tree  11/100 (tree index:2) done accuracy:0.708333 logloss:3.10294\n",
      "I0000 00:00:1729625080.657986 6787504 random_forest.cc:812] Training of tree  21/100 (tree index:19) done accuracy:0.691667 logloss:1.41781\n",
      "I0000 00:00:1729625080.658193 6787502 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.783333 logloss:1.3883\n",
      "I0000 00:00:1729625080.658422 6787503 random_forest.cc:812] Training of tree  41/100 (tree index:40) done accuracy:0.766667 logloss:1.13434\n",
      "I0000 00:00:1729625080.658610 6787505 random_forest.cc:812] Training of tree  51/100 (tree index:38) done accuracy:0.733333 logloss:0.567663\n",
      "I0000 00:00:1729625080.658796 6787499 random_forest.cc:812] Training of tree  61/100 (tree index:63) done accuracy:0.708333 logloss:0.553351\n",
      "I0000 00:00:1729625080.659050 6787501 random_forest.cc:812] Training of tree  71/100 (tree index:68) done accuracy:0.7 logloss:0.551975\n",
      "I0000 00:00:1729625080.659307 6787506 random_forest.cc:812] Training of tree  83/100 (tree index:77) done accuracy:0.7 logloss:0.549585\n",
      "I0000 00:00:1729625080.659570 6787501 random_forest.cc:812] Training of tree  93/100 (tree index:88) done accuracy:0.708333 logloss:0.549033\n",
      "I0000 00:00:1729625080.659720 6787506 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.7 logloss:0.556535\n",
      "I0000 00:00:1729625080.659778 6787490 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.556535\n",
      "I0000 00:00:1729625080.659967 6787490 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgucdrysa with prefix 77d20aa7e4eb48d2\n",
      "I0000 00:00:1729625080.661300 6787490 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625080.662110 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.556535\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  16\n",
      "2  20  42\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:40.667015: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgucdrysa/model/ with prefix 77d20aa7e4eb48d2\n",
      "I0000 00:00:1729625080.668820 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1250 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:24:40.668843: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.136931. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012823\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpziqkynx5 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625080.948133 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625080.948149 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625080.948153 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625080.948217 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625080.948226 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625080.948271 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.948281 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.948287 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.948292 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625080.948318 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625080.948336 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625080.948468 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625080.948492 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw5muh9gt/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625080.948551 6787558 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625080.948662 6787558 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625080.949127 6787569 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625080.949268 6787572 random_forest.cc:812] Training of tree  12/100 (tree index:11) done accuracy:0.689076 logloss:2.25492\n",
      "I0000 00:00:1729625080.949490 6787573 random_forest.cc:812] Training of tree  24/100 (tree index:24) done accuracy:0.716667 logloss:1.14475\n",
      "I0000 00:00:1729625080.949707 6787572 random_forest.cc:812] Training of tree  35/100 (tree index:35) done accuracy:0.733333 logloss:0.584919\n",
      "I0000 00:00:1729625080.949885 6787570 random_forest.cc:812] Training of tree  45/100 (tree index:45) done accuracy:0.733333 logloss:0.570242\n",
      "I0000 00:00:1729625080.950036 6787574 random_forest.cc:812] Training of tree  55/100 (tree index:53) done accuracy:0.716667 logloss:0.575637\n",
      "I0000 00:00:1729625080.950190 6787569 random_forest.cc:812] Training of tree  65/100 (tree index:66) done accuracy:0.733333 logloss:0.576358\n",
      "I0000 00:00:1729625080.950330 6787572 random_forest.cc:812] Training of tree  75/100 (tree index:76) done accuracy:0.741667 logloss:0.575479\n",
      "I0000 00:00:1729625080.950464 6787569 random_forest.cc:812] Training of tree  87/100 (tree index:87) done accuracy:0.741667 logloss:0.565678\n",
      "I0000 00:00:1729625080.950648 6787572 random_forest.cc:812] Training of tree  97/100 (tree index:99) done accuracy:0.741667 logloss:0.557501\n",
      "I0000 00:00:1729625080.950691 6787570 random_forest.cc:812] Training of tree  100/100 (tree index:95) done accuracy:0.741667 logloss:0.557301\n",
      "I0000 00:00:1729625080.950759 6787558 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.557301\n",
      "I0000 00:00:1729625080.950944 6787558 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw5muh9gt with prefix 9e9fb7fe8a3b45c7\n",
      "I0000 00:00:1729625080.952470 6787558 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625080.952990 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.557301\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  16  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:40.957343: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw5muh9gt/model/ with prefix 9e9fb7fe8a3b45c7\n",
      "I0000 00:00:1729625080.959104 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1276 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:40.959118: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.184543. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013238\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpagzgrwm1 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625081.284081 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625081.284095 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625081.284101 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625081.284193 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625081.284201 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625081.284246 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625081.284256 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625081.284262 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625081.284267 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625081.284297 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625081.284316 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625081.284449 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625081.284475 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpziqkynx5/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625081.284538 6787626 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625081.284627 6787626 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625081.285156 6787635 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.595745 logloss:14.5708\n",
      "I0000 00:00:1729625081.285332 6787635 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.675 logloss:2.87664\n",
      "I0000 00:00:1729625081.285491 6787636 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.633333 logloss:1.49484\n",
      "I0000 00:00:1729625081.285674 6787637 random_forest.cc:812] Training of tree  31/100 (tree index:33) done accuracy:0.675 logloss:0.891351\n",
      "I0000 00:00:1729625081.285864 6787638 random_forest.cc:812] Training of tree  42/100 (tree index:43) done accuracy:0.733333 logloss:0.585488\n",
      "I0000 00:00:1729625081.286029 6787639 random_forest.cc:812] Training of tree  52/100 (tree index:54) done accuracy:0.7 logloss:0.596877\n",
      "I0000 00:00:1729625081.286197 6787641 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.716667 logloss:0.584844\n",
      "I0000 00:00:1729625081.286353 6787639 random_forest.cc:812] Training of tree  72/100 (tree index:73) done accuracy:0.691667 logloss:0.58232\n",
      "I0000 00:00:1729625081.286485 6787640 random_forest.cc:812] Training of tree  82/100 (tree index:82) done accuracy:0.691667 logloss:0.568925\n",
      "I0000 00:00:1729625081.286647 6787642 random_forest.cc:812] Training of tree  92/100 (tree index:92) done accuracy:0.691667 logloss:0.568976\n",
      "I0000 00:00:1729625081.286776 6787635 random_forest.cc:812] Training of tree  100/100 (tree index:97) done accuracy:0.683333 logloss:0.563739\n",
      "I0000 00:00:1729625081.286827 6787626 random_forest.cc:892] Final OOB metrics: accuracy:0.683333 logloss:0.563739\n",
      "I0000 00:00:1729625081.287008 6787626 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpziqkynx5 with prefix 623b4b52ef744633\n",
      "I0000 00:00:1729625081.288490 6787626 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625081.289128 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.683333  CI95[W][0.60641 0.75331]\n",
      "LogLoss: : 0.563739\n",
      "ErrorRate: : 0.316667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  33  21\n",
      "2  17  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:41.293502: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpziqkynx5/model/ with prefix 623b4b52ef744633\n",
      "I0000 00:00:1729625081.295489 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1292 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:41.295515: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.165342. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022383\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpve7ewgzn as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625081.597542 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625081.597565 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625081.597587 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625081.597826 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625081.597838 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625081.597933 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625081.597953 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625081.597966 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625081.597978 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625081.598037 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625081.598072 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625081.598301 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625081.598338 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpagzgrwm1/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625081.598521 6787695 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625081.598770 6787695 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625081.599444 6787704 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.716981 logloss:10.201\n",
      "I0000 00:00:1729625081.599702 6787705 random_forest.cc:812] Training of tree  11/100 (tree index:1) done accuracy:0.672269 logloss:4.02708\n",
      "I0000 00:00:1729625081.600001 6787704 random_forest.cc:812] Training of tree  21/100 (tree index:17) done accuracy:0.725 logloss:1.11403\n",
      "I0000 00:00:1729625081.600278 6787710 random_forest.cc:812] Training of tree  31/100 (tree index:34) done accuracy:0.733333 logloss:0.811171\n",
      "I0000 00:00:1729625081.600608 6787710 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.75 logloss:0.82116\n",
      "I0000 00:00:1729625081.600840 6787704 random_forest.cc:812] Training of tree  51/100 (tree index:51) done accuracy:0.75 logloss:0.807825\n",
      "I0000 00:00:1729625081.601216 6787704 random_forest.cc:812] Training of tree  61/100 (tree index:60) done accuracy:0.741667 logloss:0.804429\n",
      "I0000 00:00:1729625081.601715 6787706 random_forest.cc:812] Training of tree  71/100 (tree index:72) done accuracy:0.75 logloss:0.528912\n",
      "I0000 00:00:1729625081.602006 6787706 random_forest.cc:812] Training of tree  81/100 (tree index:82) done accuracy:0.741667 logloss:0.532266\n",
      "I0000 00:00:1729625081.602312 6787711 random_forest.cc:812] Training of tree  91/100 (tree index:89) done accuracy:0.75 logloss:0.521954\n",
      "I0000 00:00:1729625081.602759 6787708 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.783333 logloss:0.516345\n",
      "I0000 00:00:1729625081.602790 6787695 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.516345\n",
      "I0000 00:00:1729625081.603192 6787695 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpagzgrwm1 with prefix f48026e003d7413f\n",
      "I0000 00:00:1729625081.604883 6787695 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625081.605786 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.516345\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:41.615129: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpagzgrwm1/model/ with prefix f48026e003d7413f\n",
      "I0000 00:00:1729625081.617346 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1218 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:41.617368: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.327342. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013659\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 30, 'min_examples': 20, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfi4b9lq1 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625082.090160 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625082.090172 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625082.090177 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625082.090251 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625082.090257 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625082.090309 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.090347 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.090371 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.090397 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.090436 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625082.090456 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625082.090595 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625082.090622 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpve7ewgzn/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625082.090667 6787787 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625082.090831 6787787 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625082.091275 6787796 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.735849 logloss:9.52096\n",
      "I0000 00:00:1729625082.091398 6787799 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.764706 logloss:2.17307\n",
      "I0000 00:00:1729625082.091531 6787798 random_forest.cc:812] Training of tree  21/100 (tree index:22) done accuracy:0.758333 logloss:0.761899\n",
      "I0000 00:00:1729625082.091714 6787803 random_forest.cc:812] Training of tree  32/100 (tree index:30) done accuracy:0.75 logloss:0.472984\n",
      "I0000 00:00:1729625082.091896 6787800 random_forest.cc:812] Training of tree  43/100 (tree index:44) done accuracy:0.741667 logloss:0.520662\n",
      "I0000 00:00:1729625082.092042 6787802 random_forest.cc:812] Training of tree  53/100 (tree index:53) done accuracy:0.775 logloss:0.514372\n",
      "I0000 00:00:1729625082.092176 6787801 random_forest.cc:812] Training of tree  63/100 (tree index:63) done accuracy:0.758333 logloss:0.528013\n",
      "I0000 00:00:1729625082.092291 6787802 random_forest.cc:812] Training of tree  73/100 (tree index:72) done accuracy:0.775 logloss:0.524059\n",
      "I0000 00:00:1729625082.092478 6787796 random_forest.cc:812] Training of tree  83/100 (tree index:83) done accuracy:0.758333 logloss:0.519787\n",
      "I0000 00:00:1729625082.092650 6787796 random_forest.cc:812] Training of tree  93/100 (tree index:94) done accuracy:0.758333 logloss:0.519067\n",
      "I0000 00:00:1729625082.092759 6787801 random_forest.cc:812] Training of tree  100/100 (tree index:90) done accuracy:0.775 logloss:0.518928\n",
      "I0000 00:00:1729625082.092781 6787787 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.518928\n",
      "I0000 00:00:1729625082.093014 6787787 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpve7ewgzn with prefix 6a0401c3bc7b4904\n",
      "I0000 00:00:1729625082.094592 6787787 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625082.095308 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.518928\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  16\n",
      "2  11  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:42.100436: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpve7ewgzn/model/ with prefix 6a0401c3bc7b4904\n",
      "I0000 00:00:1729625082.102194 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1226 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:42.102210: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.142249. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011865\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 79ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625082.383382 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625082.383395 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625082.383399 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625082.383460 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625082.383466 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625082.383506 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.383516 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.383521 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.383526 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.383555 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625082.383574 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625082.383704 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625082.383726 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfi4b9lq1/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625082.383778 6787857 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625082.383873 6787857 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625082.384341 6787866 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.454545 logloss:19.6602\n",
      "I0000 00:00:1729625082.384491 6787873 random_forest.cc:812] Training of tree  13/100 (tree index:12) done accuracy:0.709402 logloss:4.35362\n",
      "I0000 00:00:1729625082.384654 6787872 random_forest.cc:812] Training of tree  23/100 (tree index:22) done accuracy:0.725 logloss:2.25919\n",
      "I0000 00:00:1729625082.384809 6787872 random_forest.cc:812] Training of tree  33/100 (tree index:33) done accuracy:0.733333 logloss:1.69201\n",
      "I0000 00:00:1729625082.384956 6787869 random_forest.cc:812] Training of tree  43/100 (tree index:45) done accuracy:0.725 logloss:1.41724\n",
      "I0000 00:00:1729625082.385084 6787868 random_forest.cc:812] Training of tree  53/100 (tree index:53) done accuracy:0.725 logloss:1.13817\n",
      "I0000 00:00:1729625082.385204 6787872 random_forest.cc:812] Training of tree  63/100 (tree index:63) done accuracy:0.7 logloss:0.840035\n",
      "I0000 00:00:1729625082.385350 6787868 random_forest.cc:812] Training of tree  73/100 (tree index:74) done accuracy:0.7 logloss:0.84012\n",
      "I0000 00:00:1729625082.385470 6787872 random_forest.cc:812] Training of tree  83/100 (tree index:82) done accuracy:0.691667 logloss:0.850085\n",
      "I0000 00:00:1729625082.385618 6787868 random_forest.cc:812] Training of tree  93/100 (tree index:95) done accuracy:0.691667 logloss:0.849634\n",
      "I0000 00:00:1729625082.385698 6787868 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.7 logloss:0.578909\n",
      "I0000 00:00:1729625082.385773 6787857 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.578909\n",
      "I0000 00:00:1729625082.385916 6787857 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfi4b9lq1 with prefix 5a88e73308bb4e26\n",
      "I0000 00:00:1729625082.387092 6787857 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625082.387793 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.578909\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  16\n",
      "2  20  42\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:42.392456: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfi4b9lq1/model/ with prefix 5a88e73308bb4e26\n",
      "I0000 00:00:1729625082.393716 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 832 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:42.393731: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps37pw6bm as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.138838. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011269\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625082.732448 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625082.732463 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625082.732467 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625082.732533 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625082.732537 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625082.732584 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.732595 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.732601 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.732607 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625082.732634 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625082.732652 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625082.732794 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625082.732816 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps37pw6bm/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625082.732855 6787949 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625082.732958 6787949 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625082.733414 6787958 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.675 logloss:11.7142\n",
      "I0000 00:00:1729625082.733527 6787960 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.621849 logloss:6.70496\n",
      "I0000 00:00:1729625082.733666 6787962 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.658333 logloss:2.31102\n",
      "I0000 00:00:1729625082.733849 6787965 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.658333 logloss:0.902322\n",
      "I0000 00:00:1729625082.733976 6787958 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.725 logloss:0.614183\n",
      "I0000 00:00:1729625082.734139 6787962 random_forest.cc:812] Training of tree  53/100 (tree index:53) done accuracy:0.708333 logloss:0.619787\n",
      "I0000 00:00:1729625082.734307 6787958 random_forest.cc:812] Training of tree  64/100 (tree index:64) done accuracy:0.7 logloss:0.62155\n",
      "I0000 00:00:1729625082.734432 6787961 random_forest.cc:812] Training of tree  74/100 (tree index:73) done accuracy:0.725 logloss:0.611666\n",
      "I0000 00:00:1729625082.734568 6787960 random_forest.cc:812] Training of tree  84/100 (tree index:74) done accuracy:0.725 logloss:0.610075\n",
      "I0000 00:00:1729625082.734670 6787964 random_forest.cc:812] Training of tree  94/100 (tree index:93) done accuracy:0.733333 logloss:0.602358\n",
      "I0000 00:00:1729625082.734774 6787961 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.741667 logloss:0.590314\n",
      "I0000 00:00:1729625082.734819 6787949 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.590314\n",
      "I0000 00:00:1729625082.734944 6787949 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps37pw6bm with prefix c216f242dba64e1b\n",
      "I0000 00:00:1729625082.736066 6787949 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625082.736636 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.590314\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  34  19\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:42.740988: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps37pw6bm/model/ with prefix c216f242dba64e1b\n",
      "I0000 00:00:1729625082.742182 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 814 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:42.742196: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfwhbtkl8 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.141414. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012122\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625083.037746 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625083.037757 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625083.037761 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625083.037824 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625083.037831 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625083.037872 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.037882 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.037887 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.037892 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.037922 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625083.037999 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625083.038205 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625083.038230 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfwhbtkl8/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625083.038263 6788025 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625083.038351 6788025 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625083.038853 6788040 random_forest.cc:812] Training of tree  1/100 (tree index:4) done accuracy:0.645833 logloss:12.7655\n",
      "I0000 00:00:1729625083.038969 6788034 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.579832 logloss:4.41664\n",
      "I0000 00:00:1729625083.039107 6788037 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.683333 logloss:1.70406\n",
      "I0000 00:00:1729625083.039260 6788037 random_forest.cc:812] Training of tree  31/100 (tree index:31) done accuracy:0.691667 logloss:0.610667\n",
      "I0000 00:00:1729625083.039404 6788041 random_forest.cc:812] Training of tree  42/100 (tree index:38) done accuracy:0.7 logloss:0.60078\n",
      "I0000 00:00:1729625083.039577 6788036 random_forest.cc:812] Training of tree  52/100 (tree index:50) done accuracy:0.691667 logloss:0.603352\n",
      "I0000 00:00:1729625083.039714 6788037 random_forest.cc:812] Training of tree  62/100 (tree index:56) done accuracy:0.7 logloss:0.598584\n",
      "I0000 00:00:1729625083.039847 6788041 random_forest.cc:812] Training of tree  72/100 (tree index:72) done accuracy:0.716667 logloss:0.608184\n",
      "I0000 00:00:1729625083.039980 6788040 random_forest.cc:812] Training of tree  83/100 (tree index:82) done accuracy:0.725 logloss:0.602007\n",
      "I0000 00:00:1729625083.040179 6788035 random_forest.cc:812] Training of tree  93/100 (tree index:93) done accuracy:0.716667 logloss:0.591346\n",
      "I0000 00:00:1729625083.040274 6788039 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.725 logloss:0.577642\n",
      "I0000 00:00:1729625083.040306 6788025 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.577642\n",
      "I0000 00:00:1729625083.040442 6788025 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfwhbtkl8 with prefix 82321b64b0df4e6f\n",
      "I0000 00:00:1729625083.041882 6788025 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625083.042461 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.577642\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  18\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:43.047016: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfwhbtkl8/model/ with prefix 82321b64b0df4e6f\n",
      "I0000 00:00:1729625083.048233 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 810 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:43.048251: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpv3rluj3d as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.142825. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012372\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625083.327617 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625083.327628 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625083.327634 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625083.327698 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625083.327703 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625083.327748 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.327758 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.327763 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.327768 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.327797 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625083.327823 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625083.327961 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625083.327984 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpv3rluj3d/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625083.328044 6788094 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625083.328139 6788094 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625083.328604 6788105 random_forest.cc:812] Training of tree  1/100 (tree index:5) done accuracy:0.704545 logloss:10.6493\n",
      "I0000 00:00:1729625083.328772 6788106 random_forest.cc:812] Training of tree  12/100 (tree index:11) done accuracy:0.722689 logloss:4.53989\n",
      "I0000 00:00:1729625083.328957 6788105 random_forest.cc:812] Training of tree  22/100 (tree index:21) done accuracy:0.716667 logloss:1.93508\n",
      "I0000 00:00:1729625083.329071 6788108 random_forest.cc:812] Training of tree  32/100 (tree index:29) done accuracy:0.75 logloss:1.64037\n",
      "I0000 00:00:1729625083.329199 6788107 random_forest.cc:812] Training of tree  43/100 (tree index:42) done accuracy:0.725 logloss:0.817282\n",
      "I0000 00:00:1729625083.329334 6788107 random_forest.cc:812] Training of tree  54/100 (tree index:53) done accuracy:0.75 logloss:0.537367\n",
      "I0000 00:00:1729625083.329519 6788108 random_forest.cc:812] Training of tree  64/100 (tree index:66) done accuracy:0.741667 logloss:0.520461\n",
      "I0000 00:00:1729625083.329691 6788105 random_forest.cc:812] Training of tree  74/100 (tree index:75) done accuracy:0.741667 logloss:0.511235\n",
      "I0000 00:00:1729625083.329875 6788110 random_forest.cc:812] Training of tree  84/100 (tree index:60) done accuracy:0.741667 logloss:0.514455\n",
      "I0000 00:00:1729625083.330063 6788104 random_forest.cc:812] Training of tree  94/100 (tree index:84) done accuracy:0.758333 logloss:0.513251\n",
      "I0000 00:00:1729625083.330175 6788107 random_forest.cc:812] Training of tree  100/100 (tree index:93) done accuracy:0.766667 logloss:0.506933\n",
      "I0000 00:00:1729625083.330215 6788094 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.506933\n",
      "I0000 00:00:1729625083.330343 6788094 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpv3rluj3d with prefix a36ea8430ca64023\n",
      "I0000 00:00:1729625083.331545 6788094 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625083.332253 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.506933\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  16\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:43.336966: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpv3rluj3d/model/ with prefix a36ea8430ca64023\n",
      "I0000 00:00:1729625083.338364 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 792 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:43.338383: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0admif3i as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143986. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012405\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625083.664034 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625083.664046 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625083.664052 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625083.664115 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625083.664120 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625083.664162 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.664172 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.664177 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.664183 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.664211 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625083.664227 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625083.664361 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625083.664386 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0admif3i/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625083.664456 6788162 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625083.664565 6788162 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625083.665063 6788171 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625083.665239 6788178 random_forest.cc:812] Training of tree  11/100 (tree index:13) done accuracy:0.669492 logloss:4.35108\n",
      "I0000 00:00:1729625083.665361 6788176 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.683333 logloss:1.44618\n",
      "I0000 00:00:1729625083.665505 6788176 random_forest.cc:812] Training of tree  31/100 (tree index:32) done accuracy:0.683333 logloss:1.15112\n",
      "I0000 00:00:1729625083.665667 6788173 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.741667 logloss:0.855978\n",
      "I0000 00:00:1729625083.665809 6788171 random_forest.cc:812] Training of tree  51/100 (tree index:51) done accuracy:0.758333 logloss:0.847922\n",
      "I0000 00:00:1729625083.665979 6788176 random_forest.cc:812] Training of tree  63/100 (tree index:60) done accuracy:0.766667 logloss:0.84499\n",
      "I0000 00:00:1729625083.666196 6788178 random_forest.cc:812] Training of tree  73/100 (tree index:73) done accuracy:0.733333 logloss:0.851939\n",
      "I0000 00:00:1729625083.666337 6788178 random_forest.cc:812] Training of tree  83/100 (tree index:84) done accuracy:0.716667 logloss:0.847776\n",
      "I0000 00:00:1729625083.666489 6788172 random_forest.cc:812] Training of tree  93/100 (tree index:95) done accuracy:0.716667 logloss:0.843547\n",
      "I0000 00:00:1729625083.666627 6788174 random_forest.cc:812] Training of tree  100/100 (tree index:92) done accuracy:0.741667 logloss:0.836746\n",
      "I0000 00:00:1729625083.666705 6788162 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.836746\n",
      "I0000 00:00:1729625083.666868 6788162 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0admif3i with prefix 17ece61f08c944b5\n",
      "I0000 00:00:1729625083.667951 6788162 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625083.668664 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.836746\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  17\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:43.673455: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0admif3i/model/ with prefix 17ece61f08c944b5\n",
      "I0000 00:00:1729625083.674656 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 796 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:43.674673: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': 30, 'min_examples': 20, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvltwuyc8 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144486. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011492\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625083.960286 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625083.960298 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625083.960303 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625083.960371 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625083.960383 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625083.960430 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.960441 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.960455 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.960466 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625083.960495 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625083.960515 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625083.960662 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625083.960688 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvltwuyc8/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625083.960745 6788232 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625083.960882 6788232 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625083.961365 6788241 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.531915 logloss:16.8715\n",
      "I0000 00:00:1729625083.961455 6788248 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.697479 logloss:4.01517\n",
      "I0000 00:00:1729625083.961584 6788248 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.691667 logloss:1.44052\n",
      "I0000 00:00:1729625083.961679 6788241 random_forest.cc:812] Training of tree  31/100 (tree index:29) done accuracy:0.691667 logloss:1.43704\n",
      "I0000 00:00:1729625083.961789 6788245 random_forest.cc:812] Training of tree  41/100 (tree index:40) done accuracy:0.7 logloss:0.602884\n",
      "I0000 00:00:1729625083.961899 6788247 random_forest.cc:812] Training of tree  51/100 (tree index:50) done accuracy:0.725 logloss:0.586242\n",
      "I0000 00:00:1729625083.961991 6788246 random_forest.cc:812] Training of tree  61/100 (tree index:56) done accuracy:0.708333 logloss:0.582545\n",
      "I0000 00:00:1729625083.962095 6788248 random_forest.cc:812] Training of tree  71/100 (tree index:70) done accuracy:0.675 logloss:0.587169\n",
      "I0000 00:00:1729625083.962233 6788244 random_forest.cc:812] Training of tree  81/100 (tree index:84) done accuracy:0.7 logloss:0.58661\n",
      "I0000 00:00:1729625083.962335 6788247 random_forest.cc:812] Training of tree  91/100 (tree index:90) done accuracy:0.691667 logloss:0.582448\n",
      "I0000 00:00:1729625083.962429 6788245 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.683333 logloss:0.589066\n",
      "I0000 00:00:1729625083.962459 6788232 random_forest.cc:892] Final OOB metrics: accuracy:0.683333 logloss:0.589066\n",
      "I0000 00:00:1729625083.962576 6788232 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvltwuyc8 with prefix f6947bf563754b62\n",
      "I0000 00:00:1729625083.963692 6788232 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625083.964322 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.683333  CI95[W][0.60641 0.75331]\n",
      "LogLoss: : 0.589066\n",
      "ErrorRate: : 0.316667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  21\n",
      "2  17  45\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:43.968904: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvltwuyc8/model/ with prefix f6947bf563754b62\n",
      "I0000 00:00:1729625083.969936 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 658 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:43.969949: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwxngxssu as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.196837. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625084.309359 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625084.309371 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625084.309376 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625084.309443 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625084.309448 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625084.309518 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.309530 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.309536 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.309542 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.309571 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625084.309588 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625084.309745 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625084.309786 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwxngxssu/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625084.309865 6788301 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625084.309961 6788301 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.011465\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpn3bd9l51 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625084.310530 6788313 random_forest.cc:812] Training of tree  1/100 (tree index:2) done accuracy:0.530612 logloss:16.9184\n",
      "I0000 00:00:1729625084.310672 6788316 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.680672 logloss:5.77305\n",
      "I0000 00:00:1729625084.310865 6788317 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.666667 logloss:1.19272\n",
      "I0000 00:00:1729625084.311082 6788310 random_forest.cc:812] Training of tree  32/100 (tree index:30) done accuracy:0.725 logloss:0.893877\n",
      "I0000 00:00:1729625084.311242 6788313 random_forest.cc:812] Training of tree  42/100 (tree index:39) done accuracy:0.725 logloss:0.885102\n",
      "I0000 00:00:1729625084.311396 6788312 random_forest.cc:812] Training of tree  52/100 (tree index:55) done accuracy:0.725 logloss:0.602738\n",
      "I0000 00:00:1729625084.311525 6788312 random_forest.cc:812] Training of tree  62/100 (tree index:63) done accuracy:0.725 logloss:0.606123\n",
      "I0000 00:00:1729625084.311661 6788316 random_forest.cc:812] Training of tree  72/100 (tree index:71) done accuracy:0.708333 logloss:0.608072\n",
      "I0000 00:00:1729625084.311764 6788314 random_forest.cc:812] Training of tree  82/100 (tree index:82) done accuracy:0.708333 logloss:0.600535\n",
      "I0000 00:00:1729625084.311914 6788314 random_forest.cc:812] Training of tree  92/100 (tree index:93) done accuracy:0.7 logloss:0.619246\n",
      "I0000 00:00:1729625084.312017 6788314 random_forest.cc:812] Training of tree  100/100 (tree index:97) done accuracy:0.733333 logloss:0.612301\n",
      "I0000 00:00:1729625084.312071 6788301 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.612301\n",
      "I0000 00:00:1729625084.312184 6788301 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwxngxssu with prefix 05c448ecddf94bd5\n",
      "I0000 00:00:1729625084.313296 6788301 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625084.313957 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.612301\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  33  20\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:44.318204: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwxngxssu/model/ with prefix 05c448ecddf94bd5\n",
      "I0000 00:00:1729625084.319219 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 660 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:24:44.319235: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145318. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012309\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphjsrp9tv as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625084.602726 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625084.602742 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625084.602748 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625084.602815 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625084.602825 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625084.602870 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.602880 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.602885 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.602890 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.602918 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625084.602936 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625084.603114 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625084.603147 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpn3bd9l51/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625084.603232 6788371 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625084.603382 6788371 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625084.603826 6788387 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.45283 logloss:19.722\n",
      "I0000 00:00:1729625084.603946 6788383 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.559322 logloss:5.05536\n",
      "I0000 00:00:1729625084.604143 6788382 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.641667 logloss:0.897193\n",
      "I0000 00:00:1729625084.604271 6788381 random_forest.cc:812] Training of tree  32/100 (tree index:33) done accuracy:0.716667 logloss:0.574299\n",
      "I0000 00:00:1729625084.604412 6788383 random_forest.cc:812] Training of tree  42/100 (tree index:45) done accuracy:0.7 logloss:0.598209\n",
      "I0000 00:00:1729625084.604531 6788385 random_forest.cc:812] Training of tree  52/100 (tree index:53) done accuracy:0.675 logloss:0.609523\n",
      "I0000 00:00:1729625084.604619 6788387 random_forest.cc:812] Training of tree  62/100 (tree index:52) done accuracy:0.691667 logloss:0.602354\n",
      "I0000 00:00:1729625084.604750 6788384 random_forest.cc:812] Training of tree  72/100 (tree index:72) done accuracy:0.7 logloss:0.607277\n",
      "I0000 00:00:1729625084.604862 6788382 random_forest.cc:812] Training of tree  82/100 (tree index:82) done accuracy:0.725 logloss:0.60129\n",
      "I0000 00:00:1729625084.604953 6788381 random_forest.cc:812] Training of tree  92/100 (tree index:91) done accuracy:0.7 logloss:0.609088\n",
      "I0000 00:00:1729625084.605083 6788385 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.7 logloss:0.606111\n",
      "I0000 00:00:1729625084.605113 6788371 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.606111\n",
      "I0000 00:00:1729625084.605251 6788371 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpn3bd9l51 with prefix e615531abcc248e3\n",
      "I0000 00:00:1729625084.606360 6788371 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625084.607041 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.606111\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  33  21\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:44.612232: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpn3bd9l51/model/ with prefix e615531abcc248e3\n",
      "I0000 00:00:1729625084.613216 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 638 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:24:44.613232: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.142440. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.010806\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3spcwu_4 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625084.903027 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625084.903038 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625084.903042 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625084.903107 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625084.903113 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625084.903155 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.903164 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.903170 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.903175 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625084.903205 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625084.903223 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625084.903355 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625084.903377 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphjsrp9tv/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625084.903420 6788441 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625084.903518 6788441 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625084.903997 6788453 random_forest.cc:812] Training of tree  1/100 (tree index:4) done accuracy:0.428571 logloss:20.5964\n",
      "I0000 00:00:1729625084.904119 6788453 random_forest.cc:812] Training of tree  11/100 (tree index:12) done accuracy:0.644068 logloss:4.10706\n",
      "I0000 00:00:1729625084.904236 6788455 random_forest.cc:812] Training of tree  21/100 (tree index:23) done accuracy:0.7 logloss:1.44574\n",
      "I0000 00:00:1729625084.904371 6788457 random_forest.cc:812] Training of tree  32/100 (tree index:33) done accuracy:0.716667 logloss:0.873725\n",
      "I0000 00:00:1729625084.904535 6788456 random_forest.cc:812] Training of tree  42/100 (tree index:41) done accuracy:0.733333 logloss:0.56329\n",
      "I0000 00:00:1729625084.904666 6788451 random_forest.cc:812] Training of tree  52/100 (tree index:51) done accuracy:0.75 logloss:0.570465\n",
      "I0000 00:00:1729625084.904799 6788456 random_forest.cc:812] Training of tree  63/100 (tree index:63) done accuracy:0.725 logloss:0.572545\n",
      "I0000 00:00:1729625084.904928 6788455 random_forest.cc:812] Training of tree  73/100 (tree index:72) done accuracy:0.733333 logloss:0.573668\n",
      "I0000 00:00:1729625084.905086 6788457 random_forest.cc:812] Training of tree  83/100 (tree index:82) done accuracy:0.725 logloss:0.564322\n",
      "I0000 00:00:1729625084.905176 6788453 random_forest.cc:812] Training of tree  93/100 (tree index:93) done accuracy:0.733333 logloss:0.56126\n",
      "I0000 00:00:1729625084.905245 6788453 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.741667 logloss:0.558285\n",
      "I0000 00:00:1729625084.905310 6788441 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.558285\n",
      "I0000 00:00:1729625084.905456 6788441 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphjsrp9tv with prefix d41a958e76354836\n",
      "I0000 00:00:1729625084.906694 6788441 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625084.907238 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.558285\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  20\n",
      "2  11  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:44.911368: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphjsrp9tv/model/ with prefix d41a958e76354836\n",
      "I0000 00:00:1729625084.912346 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 654 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:44.912367: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143958. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012620\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': -1, 'min_examples': 5, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2yr5qduc as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625085.198482 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625085.198492 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625085.198498 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625085.198559 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625085.198568 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625085.198611 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.198626 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.198631 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.198636 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.198664 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625085.198682 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625085.198818 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625085.198844 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3spcwu_4/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625085.198899 6788511 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625085.199066 6788511 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625085.199524 6788527 random_forest.cc:812] Training of tree  1/100 (tree index:4) done accuracy:0.678571 logloss:11.5855\n",
      "I0000 00:00:1729625085.199645 6788523 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.658333 logloss:4.27744\n",
      "I0000 00:00:1729625085.199825 6788525 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.683333 logloss:1.16522\n",
      "I0000 00:00:1729625085.199983 6788527 random_forest.cc:812] Training of tree  32/100 (tree index:32) done accuracy:0.733333 logloss:1.14201\n",
      "I0000 00:00:1729625085.200106 6788527 random_forest.cc:812] Training of tree  42/100 (tree index:42) done accuracy:0.716667 logloss:0.855203\n",
      "I0000 00:00:1729625085.200240 6788523 random_forest.cc:812] Training of tree  52/100 (tree index:46) done accuracy:0.666667 logloss:0.876852\n",
      "I0000 00:00:1729625085.200434 6788524 random_forest.cc:812] Training of tree  63/100 (tree index:63) done accuracy:0.708333 logloss:0.583935\n",
      "I0000 00:00:1729625085.200558 6788521 random_forest.cc:812] Training of tree  73/100 (tree index:73) done accuracy:0.716667 logloss:0.584639\n",
      "I0000 00:00:1729625085.200671 6788522 random_forest.cc:812] Training of tree  83/100 (tree index:82) done accuracy:0.716667 logloss:0.579233\n",
      "I0000 00:00:1729625085.200799 6788520 random_forest.cc:812] Training of tree  93/100 (tree index:93) done accuracy:0.7 logloss:0.578084\n",
      "I0000 00:00:1729625085.200890 6788527 random_forest.cc:812] Training of tree  100/100 (tree index:91) done accuracy:0.708333 logloss:0.580873\n",
      "I0000 00:00:1729625085.200975 6788511 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.580873\n",
      "I0000 00:00:1729625085.201078 6788511 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3spcwu_4 with prefix 22294b8c39204ff0\n",
      "I0000 00:00:1729625085.202283 6788511 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625085.203112 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.580873\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  35  20\n",
      "2  15  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:45.208079: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3spcwu_4/model/ with prefix 22294b8c39204ff0\n",
      "I0000 00:00:1729625085.209216 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 638 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:45.209235: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.138910. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015836\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2hn0leag as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625085.533587 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625085.533601 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625085.533606 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625085.533673 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625085.533679 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625085.533770 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.533796 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.533802 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.533809 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.533841 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625085.533859 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625085.533985 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625085.534011 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2yr5qduc/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625085.534049 6788581 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625085.534124 6788581 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625085.534636 6788591 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.55814 logloss:15.9263\n",
      "I0000 00:00:1729625085.534835 6788591 random_forest.cc:812] Training of tree  11/100 (tree index:12) done accuracy:0.689076 logloss:4.34223\n",
      "I0000 00:00:1729625085.535063 6788596 random_forest.cc:812] Training of tree  22/100 (tree index:21) done accuracy:0.75 logloss:1.43615\n",
      "I0000 00:00:1729625085.535258 6788595 random_forest.cc:812] Training of tree  32/100 (tree index:29) done accuracy:0.708333 logloss:0.859818\n",
      "I0000 00:00:1729625085.535450 6788590 random_forest.cc:812] Training of tree  42/100 (tree index:40) done accuracy:0.733333 logloss:0.841105\n",
      "I0000 00:00:1729625085.535714 6788595 random_forest.cc:812] Training of tree  56/100 (tree index:54) done accuracy:0.733333 logloss:0.555914\n",
      "I0000 00:00:1729625085.535985 6788595 random_forest.cc:812] Training of tree  66/100 (tree index:66) done accuracy:0.766667 logloss:0.524385\n",
      "I0000 00:00:1729625085.536178 6788593 random_forest.cc:812] Training of tree  76/100 (tree index:74) done accuracy:0.758333 logloss:0.526514\n",
      "I0000 00:00:1729625085.536355 6788596 random_forest.cc:812] Training of tree  86/100 (tree index:85) done accuracy:0.733333 logloss:0.525743\n",
      "I0000 00:00:1729625085.536561 6788596 random_forest.cc:812] Training of tree  96/100 (tree index:98) done accuracy:0.741667 logloss:0.523542\n",
      "I0000 00:00:1729625085.536645 6788597 random_forest.cc:812] Training of tree  100/100 (tree index:96) done accuracy:0.758333 logloss:0.522872\n",
      "I0000 00:00:1729625085.536676 6788581 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.522872\n",
      "I0000 00:00:1729625085.536940 6788581 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2yr5qduc with prefix 6bd9ebbdfdfe49de\n",
      "I0000 00:00:1729625085.538786 6788581 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625085.539506 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.522872\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  15\n",
      "2  14  48\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:45.544664: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2yr5qduc/model/ with prefix 6bd9ebbdfdfe49de\n",
      "I0000 00:00:1729625085.547685 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2188 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:45.547702: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.169545. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.106743\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625085.851502 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625085.851517 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625085.851523 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625085.851590 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625085.851595 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625085.851648 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.851666 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.851673 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.851679 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625085.851707 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625085.851726 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625085.851987 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625085.852024 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2hn0leag/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625085.852105 6788654 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625085.852211 6788654 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625085.852893 6788663 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.475 logloss:18.9229\n",
      "I0000 00:00:1729625085.853237 6788668 random_forest.cc:812] Training of tree  11/100 (tree index:13) done accuracy:0.70339 logloss:4.00414\n",
      "I0000 00:00:1729625085.853733 6788666 random_forest.cc:812] Training of tree  21/100 (tree index:23) done accuracy:0.75 logloss:1.08139\n",
      "I0000 00:00:1729625085.854095 6788669 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.766667 logloss:1.06467\n",
      "I0000 00:00:1729625085.854384 6788665 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.741667 logloss:0.51759\n",
      "I0000 00:00:1729625085.854608 6788665 random_forest.cc:812] Training of tree  51/100 (tree index:50) done accuracy:0.741667 logloss:0.523781\n",
      "I0000 00:00:1729625085.854854 6788664 random_forest.cc:812] Training of tree  61/100 (tree index:54) done accuracy:0.741667 logloss:0.515763\n",
      "I0000 00:00:1729625085.855139 6788666 random_forest.cc:812] Training of tree  71/100 (tree index:73) done accuracy:0.733333 logloss:0.506659\n",
      "I0000 00:00:1729625085.855363 6788666 random_forest.cc:812] Training of tree  81/100 (tree index:81) done accuracy:0.741667 logloss:0.505909\n",
      "I0000 00:00:1729625085.855555 6788666 random_forest.cc:812] Training of tree  91/100 (tree index:91) done accuracy:0.766667 logloss:0.502817\n",
      "I0000 00:00:1729625085.855801 6788664 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.766667 logloss:0.490591\n",
      "I0000 00:00:1729625085.855994 6788654 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.490591\n",
      "I0000 00:00:1729625085.856411 6788654 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2hn0leag with prefix a52177cad32b458b\n",
      "I0000 00:00:1729625085.858438 6788654 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625085.859920 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.490591\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  13  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:45.934850: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2hn0leag/model/ with prefix a52177cad32b458b\n",
      "I0000 00:00:1729625085.956053 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2252 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:45.956079: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptzphtaf5 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.159511. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015161\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625086.306816 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625086.306831 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625086.306836 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625086.306904 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625086.306909 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625086.306954 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.306964 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.306970 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.306975 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.307003 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625086.307022 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625086.307160 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625086.307187 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptzphtaf5/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625086.307249 6788729 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625086.307351 6788729 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625086.307775 6788741 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.697674 logloss:10.8969\n",
      "I0000 00:00:1729625086.307979 6788744 random_forest.cc:812] Training of tree  11/100 (tree index:12) done accuracy:0.714286 logloss:2.23471\n",
      "I0000 00:00:1729625086.308135 6788745 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.691667 logloss:0.559889\n",
      "I0000 00:00:1729625086.308337 6788742 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.7 logloss:0.570228\n",
      "I0000 00:00:1729625086.308530 6788738 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.733333 logloss:0.56138\n",
      "I0000 00:00:1729625086.308719 6788739 random_forest.cc:812] Training of tree  51/100 (tree index:50) done accuracy:0.725 logloss:0.547164\n",
      "I0000 00:00:1729625086.308943 6788740 random_forest.cc:812] Training of tree  61/100 (tree index:60) done accuracy:0.741667 logloss:0.546046\n",
      "I0000 00:00:1729625086.309307 6788738 random_forest.cc:812] Training of tree  72/100 (tree index:70) done accuracy:0.708333 logloss:0.546697\n",
      "I0000 00:00:1729625086.309493 6788741 random_forest.cc:812] Training of tree  82/100 (tree index:84) done accuracy:0.741667 logloss:0.544535\n",
      "I0000 00:00:1729625086.309654 6788742 random_forest.cc:812] Training of tree  92/100 (tree index:92) done accuracy:0.725 logloss:0.546993\n",
      "I0000 00:00:1729625086.309855 6788743 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.733333 logloss:0.534692\n",
      "I0000 00:00:1729625086.309886 6788729 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.534692\n",
      "I0000 00:00:1729625086.310207 6788729 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptzphtaf5 with prefix d74928d19e2e4593\n",
      "I0000 00:00:1729625086.311956 6788729 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625086.312509 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.534692\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:46.317209: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptzphtaf5/model/ with prefix d74928d19e2e4593\n",
      "I0000 00:00:1729625086.320171 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2286 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:46.320184: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp5akpf_o as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.192672. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625086.653472 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625086.653482 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625086.653486 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625086.653551 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625086.653556 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625086.653617 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.653640 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.653646 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.653652 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.653682 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625086.653702 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625086.653835 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625086.653860 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp5akpf_o/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625086.653909 6788798 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625086.654065 6788798 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625086.654500 6788811 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625086.654652 6788812 random_forest.cc:812] Training of tree  11/100 (tree index:7) done accuracy:0.737288 logloss:2.17697\n",
      "I0000 00:00:1729625086.654877 6788809 random_forest.cc:812] Training of tree  21/100 (tree index:13) done accuracy:0.833333 logloss:0.42028\n",
      "I0000 00:00:1729625086.655052 6788809 random_forest.cc:812] Training of tree  31/100 (tree index:28) done accuracy:0.808333 logloss:0.420732\n",
      "I0000 00:00:1729625086.655224 6788814 random_forest.cc:812] Training of tree  41/100 (tree index:43) done accuracy:0.791667 logloss:0.430377\n",
      "I0000 00:00:1729625086.655359 6788810 random_forest.cc:812] Training of tree  51/100 (tree index:51) done accuracy:0.8 logloss:0.429181\n",
      "I0000 00:00:1729625086.655607 6788811 random_forest.cc:812] Training of tree  61/100 (tree index:59) done accuracy:0.775 logloss:0.431296\n",
      "I0000 00:00:1729625086.655776 6788810 random_forest.cc:812] Training of tree  71/100 (tree index:71) done accuracy:0.775 logloss:0.443276\n",
      "I0000 00:00:1729625086.656060 6788813 random_forest.cc:812] Training of tree  81/100 (tree index:69) done accuracy:0.808333 logloss:0.452133\n",
      "I0000 00:00:1729625086.656246 6788808 random_forest.cc:812] Training of tree  91/100 (tree index:90) done accuracy:0.808333 logloss:0.446877\n",
      "I0000 00:00:1729625086.656431 6788812 random_forest.cc:812] Training of tree  100/100 (tree index:92) done accuracy:0.808333 logloss:0.449186\n",
      "I0000 00:00:1729625086.656480 6788798 random_forest.cc:892] Final OOB metrics: accuracy:0.808333 logloss:0.449186\n",
      "I0000 00:00:1729625086.656759 6788798 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp5akpf_o with prefix a95f69fd86394caa\n",
      "I0000 00:00:1729625086.658482 6788798 kernel.cc:938] Save model in resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.015041\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpapv9mm5f as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625086.659236 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.808333  CI95[W][0.739526 0.865316]\n",
      "LogLoss: : 0.449186\n",
      "ErrorRate: : 0.191667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  13\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:46.663978: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp5akpf_o/model/ with prefix a95f69fd86394caa\n",
      "I0000 00:00:1729625086.666874 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2090 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:46.666890: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143843. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015618\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': -1, 'min_examples': 5, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvkf504il as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625086.952651 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625086.952662 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625086.952670 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625086.952731 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625086.952736 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625086.952794 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.952818 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.952824 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.952829 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625086.952858 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625086.952876 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625086.953006 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625086.953034 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpapv9mm5f/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625086.953076 6788869 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625086.953233 6788869 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625086.953732 6788878 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625086.953928 6788879 random_forest.cc:812] Training of tree  11/100 (tree index:12) done accuracy:0.705882 logloss:4.54904\n",
      "I0000 00:00:1729625086.954077 6788882 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.741667 logloss:1.94079\n",
      "I0000 00:00:1729625086.954279 6788878 random_forest.cc:812] Training of tree  31/100 (tree index:31) done accuracy:0.775 logloss:1.06199\n",
      "I0000 00:00:1729625086.954525 6788881 random_forest.cc:812] Training of tree  41/100 (tree index:40) done accuracy:0.783333 logloss:0.780108\n",
      "I0000 00:00:1729625086.954716 6788885 random_forest.cc:812] Training of tree  51/100 (tree index:52) done accuracy:0.791667 logloss:0.480645\n",
      "I0000 00:00:1729625086.954894 6788882 random_forest.cc:812] Training of tree  61/100 (tree index:62) done accuracy:0.783333 logloss:0.494031\n",
      "I0000 00:00:1729625086.955148 6788880 random_forest.cc:812] Training of tree  71/100 (tree index:74) done accuracy:0.775 logloss:0.488301\n",
      "I0000 00:00:1729625086.955336 6788881 random_forest.cc:812] Training of tree  81/100 (tree index:81) done accuracy:0.766667 logloss:0.478289\n",
      "I0000 00:00:1729625086.955585 6788880 random_forest.cc:812] Training of tree  91/100 (tree index:93) done accuracy:0.783333 logloss:0.483673\n",
      "I0000 00:00:1729625086.955776 6788881 random_forest.cc:812] Training of tree  100/100 (tree index:97) done accuracy:0.783333 logloss:0.475094\n",
      "I0000 00:00:1729625086.955816 6788869 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.475094\n",
      "I0000 00:00:1729625086.956157 6788869 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpapv9mm5f with prefix 507fc345071049e9\n",
      "I0000 00:00:1729625086.958025 6788869 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625086.958707 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.475094\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  44  11\n",
      "2  15  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:46.963455: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpapv9mm5f/model/ with prefix 507fc345071049e9\n",
      "I0000 00:00:1729625086.966480 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 2184 node(s), and 19 input feature(s).\n",
      "I0000 00:00:1729625086.966494 6784195 abstract_model.cc:1323] Engine \"RandomForestOptPred\" built\n",
      "2024-10-22 20:24:46.966499: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145394. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014631\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2m4stljz as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625087.255156 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625087.255166 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625087.255172 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625087.255234 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625087.255238 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625087.255282 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.255294 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.255300 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.255305 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.255334 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625087.255351 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625087.255528 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625087.255568 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvkf504il/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625087.255693 6788939 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625087.255798 6788939 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625087.256288 6788951 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625087.256524 6788949 random_forest.cc:812] Training of tree  12/100 (tree index:12) done accuracy:0.728814 logloss:1.38307\n",
      "I0000 00:00:1729625087.256701 6788949 random_forest.cc:812] Training of tree  22/100 (tree index:24) done accuracy:0.733333 logloss:0.779599\n",
      "I0000 00:00:1729625087.256842 6788948 random_forest.cc:812] Training of tree  32/100 (tree index:31) done accuracy:0.725 logloss:0.526015\n",
      "I0000 00:00:1729625087.257051 6788949 random_forest.cc:812] Training of tree  42/100 (tree index:42) done accuracy:0.683333 logloss:0.575058\n",
      "I0000 00:00:1729625087.257254 6788954 random_forest.cc:812] Training of tree  52/100 (tree index:52) done accuracy:0.683333 logloss:0.560386\n",
      "I0000 00:00:1729625087.257416 6788951 random_forest.cc:812] Training of tree  64/100 (tree index:61) done accuracy:0.725 logloss:0.543191\n",
      "I0000 00:00:1729625087.257649 6788953 random_forest.cc:812] Training of tree  75/100 (tree index:74) done accuracy:0.716667 logloss:0.543261\n",
      "I0000 00:00:1729625087.257877 6788948 random_forest.cc:812] Training of tree  85/100 (tree index:84) done accuracy:0.708333 logloss:0.538719\n",
      "I0000 00:00:1729625087.258024 6788948 random_forest.cc:812] Training of tree  96/100 (tree index:92) done accuracy:0.708333 logloss:0.541963\n",
      "I0000 00:00:1729625087.258132 6788948 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.716667 logloss:0.538451\n",
      "I0000 00:00:1729625087.258221 6788939 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.538451\n",
      "I0000 00:00:1729625087.258476 6788939 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvkf504il with prefix 636ca5d9576344dd\n",
      "I0000 00:00:1729625087.260118 6788939 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625087.260711 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.538451\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:47.265408: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvkf504il/model/ with prefix 636ca5d9576344dd\n",
      "I0000 00:00:1729625087.267998 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1896 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:47.268016: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.186924. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014797\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyjehe4v4 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625087.588712 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625087.588727 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625087.588735 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625087.588808 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625087.588813 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625087.588862 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.588872 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.588877 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.588882 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.588909 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625087.588926 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625087.589067 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625087.589091 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2m4stljz/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625087.589144 6789009 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625087.589234 6789009 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625087.589694 6789023 random_forest.cc:812] Training of tree  1/100 (tree index:4) done accuracy:0.660714 logloss:12.2291\n",
      "I0000 00:00:1729625087.589871 6789020 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.641667 logloss:3.17207\n",
      "I0000 00:00:1729625087.590029 6789024 random_forest.cc:812] Training of tree  21/100 (tree index:17) done accuracy:0.7 logloss:1.16141\n",
      "I0000 00:00:1729625087.590200 6789022 random_forest.cc:812] Training of tree  31/100 (tree index:28) done accuracy:0.691667 logloss:0.871425\n",
      "I0000 00:00:1729625087.590416 6789019 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.716667 logloss:0.5853\n",
      "I0000 00:00:1729625087.590628 6789018 random_forest.cc:812] Training of tree  51/100 (tree index:50) done accuracy:0.725 logloss:0.562174\n",
      "I0000 00:00:1729625087.590910 6789022 random_forest.cc:812] Training of tree  63/100 (tree index:62) done accuracy:0.725 logloss:0.565956\n",
      "I0000 00:00:1729625087.591111 6789020 random_forest.cc:812] Training of tree  73/100 (tree index:73) done accuracy:0.708333 logloss:0.569504\n",
      "I0000 00:00:1729625087.591267 6789021 random_forest.cc:812] Training of tree  83/100 (tree index:83) done accuracy:0.741667 logloss:0.561654\n",
      "I0000 00:00:1729625087.591459 6789021 random_forest.cc:812] Training of tree  93/100 (tree index:94) done accuracy:0.725 logloss:0.561732\n",
      "I0000 00:00:1729625087.591603 6789025 random_forest.cc:812] Training of tree  100/100 (tree index:97) done accuracy:0.733333 logloss:0.55753\n",
      "I0000 00:00:1729625087.591642 6789009 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.55753\n",
      "I0000 00:00:1729625087.591904 6789009 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2m4stljz with prefix d99b29dd144a4547\n",
      "I0000 00:00:1729625087.593784 6789009 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625087.594442 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.55753\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  16\n",
      "2  16  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:47.599191: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2m4stljz/model/ with prefix d99b29dd144a4547\n",
      "I0000 00:00:1729625087.601802 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1930 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:47.601820: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144121. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014565\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpe9498ah0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625087.895994 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625087.896008 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625087.896011 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625087.896070 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625087.896076 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625087.896117 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.896126 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.896132 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.896136 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625087.896162 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625087.896180 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625087.896305 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625087.896327 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyjehe4v4/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625087.896367 6789083 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625087.896463 6789083 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625087.896962 6789098 random_forest.cc:812] Training of tree  1/100 (tree index:2) done accuracy:0.632653 logloss:13.2405\n",
      "I0000 00:00:1729625087.897096 6789093 random_forest.cc:812] Training of tree  12/100 (tree index:10) done accuracy:0.647059 logloss:4.05263\n",
      "I0000 00:00:1729625087.897289 6789098 random_forest.cc:812] Training of tree  22/100 (tree index:22) done accuracy:0.666667 logloss:1.19163\n",
      "I0000 00:00:1729625087.897462 6789096 random_forest.cc:812] Training of tree  32/100 (tree index:32) done accuracy:0.7 logloss:0.57133\n",
      "I0000 00:00:1729625087.897663 6789096 random_forest.cc:812] Training of tree  42/100 (tree index:44) done accuracy:0.741667 logloss:0.578772\n",
      "I0000 00:00:1729625087.897848 6789092 random_forest.cc:812] Training of tree  54/100 (tree index:53) done accuracy:0.733333 logloss:0.556244\n",
      "I0000 00:00:1729625087.898108 6789092 random_forest.cc:812] Training of tree  64/100 (tree index:63) done accuracy:0.783333 logloss:0.544764\n",
      "I0000 00:00:1729625087.898320 6789095 random_forest.cc:812] Training of tree  74/100 (tree index:73) done accuracy:0.791667 logloss:0.545027\n",
      "I0000 00:00:1729625087.898509 6789096 random_forest.cc:812] Training of tree  86/100 (tree index:85) done accuracy:0.75 logloss:0.534968\n",
      "I0000 00:00:1729625087.898756 6789094 random_forest.cc:812] Training of tree  96/100 (tree index:94) done accuracy:0.8 logloss:0.532072\n",
      "I0000 00:00:1729625087.898852 6789095 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.791667 logloss:0.53188\n",
      "I0000 00:00:1729625087.898891 6789083 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.53188\n",
      "I0000 00:00:1729625087.899153 6789083 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyjehe4v4 with prefix 5458cb194d434562\n",
      "I0000 00:00:1729625087.900936 6789083 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625087.901686 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.53188\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  13\n",
      "2  12  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:47.906322: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyjehe4v4/model/ with prefix 5458cb194d434562\n",
      "I0000 00:00:1729625087.909003 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1970 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:47.909020: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144124. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014995\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpmzytumbs as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625088.188310 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625088.188319 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625088.188327 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625088.188388 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625088.188395 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625088.188435 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.188444 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.188450 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.188454 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.188487 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625088.188506 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625088.188635 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625088.188657 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpe9498ah0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625088.188723 6789150 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625088.188823 6789150 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625088.189301 6789165 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625088.189448 6789162 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.666667 logloss:3.35013\n",
      "I0000 00:00:1729625088.189654 6789166 random_forest.cc:812] Training of tree  21/100 (tree index:18) done accuracy:0.783333 logloss:1.33581\n",
      "I0000 00:00:1729625088.189885 6789160 random_forest.cc:812] Training of tree  32/100 (tree index:31) done accuracy:0.766667 logloss:1.03665\n",
      "I0000 00:00:1729625088.190104 6789162 random_forest.cc:812] Training of tree  45/100 (tree index:45) done accuracy:0.775 logloss:0.477525\n",
      "I0000 00:00:1729625088.190363 6789162 random_forest.cc:812] Training of tree  57/100 (tree index:56) done accuracy:0.766667 logloss:0.491619\n",
      "I0000 00:00:1729625088.190584 6789161 random_forest.cc:812] Training of tree  67/100 (tree index:67) done accuracy:0.783333 logloss:0.487455\n",
      "I0000 00:00:1729625088.190775 6789160 random_forest.cc:812] Training of tree  77/100 (tree index:77) done accuracy:0.766667 logloss:0.483227\n",
      "I0000 00:00:1729625088.190963 6789161 random_forest.cc:812] Training of tree  87/100 (tree index:87) done accuracy:0.758333 logloss:0.477828\n",
      "I0000 00:00:1729625088.191130 6789164 random_forest.cc:812] Training of tree  97/100 (tree index:97) done accuracy:0.775 logloss:0.474795\n",
      "I0000 00:00:1729625088.191194 6789160 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.775 logloss:0.475327\n",
      "I0000 00:00:1729625088.191238 6789150 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.475327\n",
      "I0000 00:00:1729625088.191480 6789150 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpe9498ah0 with prefix 85ed0d2295654678\n",
      "I0000 00:00:1729625088.193426 6789150 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625088.194029 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.475327\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  13\n",
      "2  14  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:48.199034: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpe9498ah0/model/ with prefix 85ed0d2295654678\n",
      "I0000 00:00:1729625088.201485 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1776 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:48.201504: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.188825. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014067\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': -1, 'min_examples': 10, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpnv_jc007 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625088.527005 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625088.527015 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625088.527023 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625088.527092 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625088.527097 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625088.527143 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.527152 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.527157 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.527162 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.527189 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625088.527207 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625088.527351 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625088.527380 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpmzytumbs/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625088.527430 6789218 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625088.527509 6789218 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625088.527941 6789229 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.641509 logloss:12.9213\n",
      "I0000 00:00:1729625088.528132 6789229 random_forest.cc:812] Training of tree  12/100 (tree index:14) done accuracy:0.741667 logloss:1.56529\n",
      "I0000 00:00:1729625088.528323 6789228 random_forest.cc:812] Training of tree  23/100 (tree index:23) done accuracy:0.75 logloss:0.736395\n",
      "I0000 00:00:1729625088.528525 6789227 random_forest.cc:812] Training of tree  33/100 (tree index:32) done accuracy:0.741667 logloss:0.740235\n",
      "I0000 00:00:1729625088.528726 6789233 random_forest.cc:812] Training of tree  44/100 (tree index:43) done accuracy:0.758333 logloss:0.476905\n",
      "I0000 00:00:1729625088.528924 6789230 random_forest.cc:812] Training of tree  54/100 (tree index:55) done accuracy:0.758333 logloss:0.472354\n",
      "I0000 00:00:1729625088.529074 6789232 random_forest.cc:812] Training of tree  64/100 (tree index:64) done accuracy:0.766667 logloss:0.473556\n",
      "I0000 00:00:1729625088.529223 6789227 random_forest.cc:812] Training of tree  75/100 (tree index:74) done accuracy:0.775 logloss:0.472293\n",
      "I0000 00:00:1729625088.529417 6789230 random_forest.cc:812] Training of tree  85/100 (tree index:84) done accuracy:0.783333 logloss:0.462216\n",
      "I0000 00:00:1729625088.529557 6789233 random_forest.cc:812] Training of tree  95/100 (tree index:95) done accuracy:0.783333 logloss:0.451775\n",
      "I0000 00:00:1729625088.529666 6789227 random_forest.cc:812] Training of tree  100/100 (tree index:88) done accuracy:0.775 logloss:0.46055\n",
      "I0000 00:00:1729625088.529751 6789218 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.46055\n",
      "I0000 00:00:1729625088.530001 6789218 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpmzytumbs with prefix da58c84ab7eb4705\n",
      "I0000 00:00:1729625088.531742 6789218 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625088.532408 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.46055\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  13\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:48.536901: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpmzytumbs/model/ with prefix da58c84ab7eb4705\n",
      "I0000 00:00:1729625088.539375 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1826 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:48.539392: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.153529. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013187\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp974qjv6p as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625088.827417 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625088.827431 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625088.827435 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625088.827501 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625088.827507 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625088.827551 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.827562 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.827567 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.827573 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625088.827602 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625088.827619 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625088.827756 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625088.827780 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpnv_jc007/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625088.827824 6789287 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625088.827920 6789287 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625088.828391 6789296 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.72093 logloss:10.0587\n",
      "I0000 00:00:1729625088.828589 6789296 random_forest.cc:812] Training of tree  12/100 (tree index:12) done accuracy:0.661017 logloss:4.86329\n",
      "I0000 00:00:1729625088.828813 6789301 random_forest.cc:812] Training of tree  23/100 (tree index:22) done accuracy:0.75 logloss:1.132\n",
      "I0000 00:00:1729625088.828996 6789296 random_forest.cc:812] Training of tree  34/100 (tree index:33) done accuracy:0.766667 logloss:1.11115\n",
      "I0000 00:00:1729625088.829190 6789296 random_forest.cc:812] Training of tree  44/100 (tree index:45) done accuracy:0.775 logloss:1.09756\n",
      "I0000 00:00:1729625088.829376 6789300 random_forest.cc:812] Training of tree  55/100 (tree index:55) done accuracy:0.758333 logloss:0.810824\n",
      "I0000 00:00:1729625088.829555 6789301 random_forest.cc:812] Training of tree  65/100 (tree index:64) done accuracy:0.733333 logloss:0.803595\n",
      "I0000 00:00:1729625088.829739 6789303 random_forest.cc:812] Training of tree  75/100 (tree index:71) done accuracy:0.708333 logloss:0.808427\n",
      "I0000 00:00:1729625088.829941 6789298 random_forest.cc:812] Training of tree  85/100 (tree index:85) done accuracy:0.708333 logloss:0.814182\n",
      "I0000 00:00:1729625088.830058 6789301 random_forest.cc:812] Training of tree  95/100 (tree index:93) done accuracy:0.708333 logloss:0.549482\n",
      "I0000 00:00:1729625088.830173 6789297 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.708333 logloss:0.545663\n",
      "I0000 00:00:1729625088.830248 6789287 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.545663\n",
      "I0000 00:00:1729625088.830452 6789287 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpnv_jc007 with prefix c841582f4f5c4336\n",
      "I0000 00:00:1729625088.831886 6789287 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625088.832434 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.545663\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  20\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:48.836787: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpnv_jc007/model/ with prefix c841582f4f5c4336\n",
      "I0000 00:00:1729625088.838920 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1502 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:48.838937: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146270. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013440\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625089.122990 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625089.123003 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625089.123008 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625089.123075 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625089.123080 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625089.123126 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.123135 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.123141 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.123146 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.123173 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625089.123205 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625089.123352 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625089.123376 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp974qjv6p/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625089.123433 6789355 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625089.123529 6789355 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625089.123983 6789370 random_forest.cc:812] Training of tree  1/100 (tree index:7) done accuracy:0.666667 logloss:12.0146\n",
      "I0000 00:00:1729625089.124122 6789364 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.697479 logloss:4.86184\n",
      "I0000 00:00:1729625089.124291 6789371 random_forest.cc:812] Training of tree  21/100 (tree index:22) done accuracy:0.741667 logloss:1.07178\n",
      "I0000 00:00:1729625089.124453 6789369 random_forest.cc:812] Training of tree  31/100 (tree index:31) done accuracy:0.758333 logloss:1.07533\n",
      "I0000 00:00:1729625089.124598 6789365 random_forest.cc:812] Training of tree  41/100 (tree index:40) done accuracy:0.775 logloss:0.809452\n",
      "I0000 00:00:1729625089.124761 6789371 random_forest.cc:812] Training of tree  51/100 (tree index:53) done accuracy:0.766667 logloss:0.549926\n",
      "I0000 00:00:1729625089.124941 6789365 random_forest.cc:812] Training of tree  61/100 (tree index:61) done accuracy:0.775 logloss:0.546063\n",
      "I0000 00:00:1729625089.125098 6789370 random_forest.cc:812] Training of tree  71/100 (tree index:72) done accuracy:0.783333 logloss:0.529364\n",
      "I0000 00:00:1729625089.125228 6789367 random_forest.cc:812] Training of tree  81/100 (tree index:81) done accuracy:0.775 logloss:0.52097\n",
      "I0000 00:00:1729625089.125423 6789369 random_forest.cc:812] Training of tree  91/100 (tree index:91) done accuracy:0.758333 logloss:0.528613\n",
      "I0000 00:00:1729625089.125580 6789370 random_forest.cc:812] Training of tree  100/100 (tree index:95) done accuracy:0.775 logloss:0.522878\n",
      "I0000 00:00:1729625089.125611 6789355 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.522878\n",
      "I0000 00:00:1729625089.125816 6789355 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp974qjv6p with prefix 7f8f1b8d240142c7\n",
      "I0000 00:00:1729625089.127320 6789355 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625089.127894 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.522878\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  13  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:49.132500: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp974qjv6p/model/ with prefix 7f8f1b8d240142c7\n",
      "I0000 00:00:1729625089.134621 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1548 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:49.134640: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp997ey0mi as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.196809. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625089.679429 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625089.679439 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625089.679443 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625089.679516 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625089.679522 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625089.679590 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.679601 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.679608 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.679619 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.679650 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625089.679668 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625089.679839 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625089.679861 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp997ey0mi/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625089.679922 6789424 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625089.680018 6789424 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625089.680492 6789435 random_forest.cc:812] Training of tree  1/100 (tree index:2) done accuracy:0.682927 logloss:11.4285\n",
      "I0000 00:00:1729625089.680705 6789433 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.705882 logloss:2.20272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.013873\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_1muv6n7 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625089.680958 6789440 random_forest.cc:812] Training of tree  23/100 (tree index:21) done accuracy:0.725 logloss:1.12403\n",
      "I0000 00:00:1729625089.681223 6789434 random_forest.cc:812] Training of tree  33/100 (tree index:32) done accuracy:0.733333 logloss:0.594154\n",
      "I0000 00:00:1729625089.681412 6789436 random_forest.cc:812] Training of tree  43/100 (tree index:41) done accuracy:0.708333 logloss:0.594143\n",
      "I0000 00:00:1729625089.681589 6789433 random_forest.cc:812] Training of tree  54/100 (tree index:53) done accuracy:0.666667 logloss:0.602052\n",
      "I0000 00:00:1729625089.681828 6789437 random_forest.cc:812] Training of tree  64/100 (tree index:62) done accuracy:0.691667 logloss:0.587513\n",
      "I0000 00:00:1729625089.682024 6789438 random_forest.cc:812] Training of tree  74/100 (tree index:72) done accuracy:0.725 logloss:0.597335\n",
      "I0000 00:00:1729625089.682163 6789435 random_forest.cc:812] Training of tree  84/100 (tree index:79) done accuracy:0.725 logloss:0.589795\n",
      "I0000 00:00:1729625089.682344 6789440 random_forest.cc:812] Training of tree  94/100 (tree index:96) done accuracy:0.708333 logloss:0.584014\n",
      "I0000 00:00:1729625089.682427 6789438 random_forest.cc:812] Training of tree  100/100 (tree index:85) done accuracy:0.733333 logloss:0.584303\n",
      "I0000 00:00:1729625089.682529 6789424 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.584303\n",
      "I0000 00:00:1729625089.682744 6789424 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp997ey0mi with prefix e8232141d01f4750\n",
      "I0000 00:00:1729625089.684173 6789424 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625089.684922 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.584303\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  16\n",
      "2  16  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:49.689658: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp997ey0mi/model/ with prefix e8232141d01f4750\n",
      "I0000 00:00:1729625089.691756 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1544 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:49.691770: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.149225. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014097\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmph584lee9 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625089.985740 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625089.985749 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625089.985760 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625089.985829 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625089.985843 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625089.985897 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.985909 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.985916 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.985921 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625089.985957 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625089.985981 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625089.986123 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625089.986149 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_1muv6n7/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625089.986214 6789495 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625089.986302 6789495 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625089.986784 6789504 random_forest.cc:812] Training of tree  1/100 (tree index:5) done accuracy:0.454545 logloss:19.6602\n",
      "I0000 00:00:1729625089.986958 6789509 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.694915 logloss:4.61719\n",
      "I0000 00:00:1729625089.987272 6789507 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.75 logloss:0.792378\n",
      "I0000 00:00:1729625089.987404 6789506 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.741667 logloss:0.774732\n",
      "I0000 00:00:1729625089.987610 6789505 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.725 logloss:0.771969\n",
      "I0000 00:00:1729625089.987796 6789511 random_forest.cc:812] Training of tree  52/100 (tree index:53) done accuracy:0.75 logloss:0.499495\n",
      "I0000 00:00:1729625089.987989 6789504 random_forest.cc:812] Training of tree  62/100 (tree index:64) done accuracy:0.766667 logloss:0.496888\n",
      "I0000 00:00:1729625089.988113 6789508 random_forest.cc:812] Training of tree  72/100 (tree index:72) done accuracy:0.75 logloss:0.492423\n",
      "I0000 00:00:1729625089.988314 6789509 random_forest.cc:812] Training of tree  82/100 (tree index:81) done accuracy:0.775 logloss:0.491281\n",
      "I0000 00:00:1729625089.988462 6789510 random_forest.cc:812] Training of tree  92/100 (tree index:91) done accuracy:0.766667 logloss:0.478318\n",
      "I0000 00:00:1729625089.988577 6789507 random_forest.cc:812] Training of tree  100/100 (tree index:89) done accuracy:0.783333 logloss:0.47527\n",
      "I0000 00:00:1729625089.988658 6789495 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.47527\n",
      "I0000 00:00:1729625089.988858 6789495 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_1muv6n7 with prefix b6f46f255ad44040\n",
      "I0000 00:00:1729625089.990308 6789495 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625089.990927 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.47527\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  16\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:49.995980: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_1muv6n7/model/ with prefix b6f46f255ad44040\n",
      "I0000 00:00:1729625089.997984 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1442 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:49.998001: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.150213. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013886\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': -1, 'min_examples': 10, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5wyxwtv3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625090.286917 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625090.286929 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625090.286936 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625090.287010 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625090.287020 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625090.287066 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.287076 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.287082 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.287087 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.287117 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625090.287134 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625090.287304 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625090.287327 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmph584lee9/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625090.287390 6789562 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625090.287491 6789562 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625090.288055 6789574 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625090.288255 6789572 random_forest.cc:812] Training of tree  11/100 (tree index:14) done accuracy:0.716667 logloss:3.34236\n",
      "I0000 00:00:1729625090.288457 6789572 random_forest.cc:812] Training of tree  21/100 (tree index:23) done accuracy:0.75 logloss:1.07656\n",
      "I0000 00:00:1729625090.288643 6789572 random_forest.cc:812] Training of tree  32/100 (tree index:32) done accuracy:0.725 logloss:1.075\n",
      "I0000 00:00:1729625090.288890 6789576 random_forest.cc:812] Training of tree  42/100 (tree index:33) done accuracy:0.758333 logloss:0.498589\n",
      "I0000 00:00:1729625090.289084 6789573 random_forest.cc:812] Training of tree  52/100 (tree index:49) done accuracy:0.766667 logloss:0.48662\n",
      "I0000 00:00:1729625090.289280 6789576 random_forest.cc:812] Training of tree  63/100 (tree index:64) done accuracy:0.775 logloss:0.487758\n",
      "I0000 00:00:1729625090.289482 6789576 random_forest.cc:812] Training of tree  73/100 (tree index:74) done accuracy:0.766667 logloss:0.494157\n",
      "I0000 00:00:1729625090.289669 6789577 random_forest.cc:812] Training of tree  85/100 (tree index:83) done accuracy:0.758333 logloss:0.498286\n",
      "I0000 00:00:1729625090.289886 6789577 random_forest.cc:812] Training of tree  95/100 (tree index:96) done accuracy:0.758333 logloss:0.490176\n",
      "I0000 00:00:1729625090.290024 6789578 random_forest.cc:812] Training of tree  100/100 (tree index:95) done accuracy:0.766667 logloss:0.491437\n",
      "I0000 00:00:1729625090.290060 6789562 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.491437\n",
      "I0000 00:00:1729625090.290260 6789562 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmph584lee9 with prefix 14029afec1174ff7\n",
      "I0000 00:00:1729625090.291787 6789562 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625090.292515 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.491437\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:50.297071: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmph584lee9/model/ with prefix 14029afec1174ff7\n",
      "I0000 00:00:1729625090.299153 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1514 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:50.299172: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.192036. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013678\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxqxr79rj as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625090.628461 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625090.628476 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625090.628481 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625090.628543 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625090.628548 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625090.628595 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.628605 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.628610 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.628615 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.628644 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625090.628661 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625090.628795 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625090.628816 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5wyxwtv3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625090.628871 6789633 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625090.628991 6789633 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625090.629510 6789643 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.510638 logloss:17.6384\n",
      "I0000 00:00:1729625090.629706 6789643 random_forest.cc:812] Training of tree  15/100 (tree index:15) done accuracy:0.766667 logloss:3.09719\n",
      "I0000 00:00:1729625090.629954 6789647 random_forest.cc:812] Training of tree  27/100 (tree index:27) done accuracy:0.766667 logloss:1.37931\n",
      "I0000 00:00:1729625090.630158 6789644 random_forest.cc:812] Training of tree  37/100 (tree index:37) done accuracy:0.783333 logloss:0.829168\n",
      "I0000 00:00:1729625090.630347 6789648 random_forest.cc:812] Training of tree  49/100 (tree index:48) done accuracy:0.733333 logloss:0.842529\n",
      "I0000 00:00:1729625090.630540 6789643 random_forest.cc:812] Training of tree  59/100 (tree index:57) done accuracy:0.733333 logloss:0.556722\n",
      "I0000 00:00:1729625090.630686 6789647 random_forest.cc:812] Training of tree  69/100 (tree index:69) done accuracy:0.725 logloss:0.549523\n",
      "I0000 00:00:1729625090.630861 6789646 random_forest.cc:812] Training of tree  79/100 (tree index:67) done accuracy:0.691667 logloss:0.556502\n",
      "I0000 00:00:1729625090.631036 6789647 random_forest.cc:812] Training of tree  91/100 (tree index:91) done accuracy:0.708333 logloss:0.54955\n",
      "I0000 00:00:1729625090.631179 6789645 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.716667 logloss:0.555788\n",
      "I0000 00:00:1729625090.631258 6789633 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.555788\n",
      "I0000 00:00:1729625090.631479 6789633 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5wyxwtv3 with prefix 9b9cd4e465e14041\n",
      "I0000 00:00:1729625090.632858 6789633 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625090.633440 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.555788\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  44  14\n",
      "2  20  42\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:50.638678: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5wyxwtv3/model/ with prefix 9b9cd4e465e14041\n",
      "I0000 00:00:1729625090.640498 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1250 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:24:50.640514: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.158196. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013182\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdhtacsbq as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625090.931839 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625090.931850 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625090.931854 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625090.931915 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625090.931922 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625090.931965 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.931974 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.931979 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.931984 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625090.932010 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625090.932029 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625090.932158 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625090.932180 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxqxr79rj/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625090.932243 6789710 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625090.932342 6789710 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625090.932900 6789725 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.510638 logloss:17.6384\n",
      "I0000 00:00:1729625090.933113 6789719 random_forest.cc:812] Training of tree  13/100 (tree index:13) done accuracy:0.705882 logloss:2.29006\n",
      "I0000 00:00:1729625090.933316 6789722 random_forest.cc:812] Training of tree  23/100 (tree index:24) done accuracy:0.716667 logloss:1.14653\n",
      "I0000 00:00:1729625090.933481 6789719 random_forest.cc:812] Training of tree  34/100 (tree index:33) done accuracy:0.733333 logloss:0.846957\n",
      "I0000 00:00:1729625090.933683 6789726 random_forest.cc:812] Training of tree  44/100 (tree index:46) done accuracy:0.725 logloss:0.570782\n",
      "I0000 00:00:1729625090.933847 6789724 random_forest.cc:812] Training of tree  54/100 (tree index:53) done accuracy:0.733333 logloss:0.572803\n",
      "I0000 00:00:1729625090.933994 6789723 random_forest.cc:812] Training of tree  64/100 (tree index:55) done accuracy:0.716667 logloss:0.570149\n",
      "I0000 00:00:1729625090.934171 6789721 random_forest.cc:812] Training of tree  74/100 (tree index:75) done accuracy:0.733333 logloss:0.569694\n",
      "I0000 00:00:1729625090.934369 6789720 random_forest.cc:812] Training of tree  84/100 (tree index:86) done accuracy:0.733333 logloss:0.566715\n",
      "I0000 00:00:1729625090.934545 6789725 random_forest.cc:812] Training of tree  96/100 (tree index:96) done accuracy:0.741667 logloss:0.558947\n",
      "I0000 00:00:1729625090.934590 6789721 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.741667 logloss:0.559507\n",
      "I0000 00:00:1729625090.934684 6789710 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.559507\n",
      "I0000 00:00:1729625090.934898 6789710 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxqxr79rj with prefix e3081b6e75b24198\n",
      "I0000 00:00:1729625090.936218 6789710 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625090.936962 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.559507\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  16  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:50.941509: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxqxr79rj/model/ with prefix e3081b6e75b24198\n",
      "I0000 00:00:1729625090.943307 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1276 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:50.943321: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.159252. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014257\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpge316xfk as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625091.248233 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625091.248244 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625091.248248 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625091.248355 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625091.248370 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625091.248416 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.248428 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.248434 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.248440 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.248468 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625091.248487 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625091.248627 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625091.248655 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdhtacsbq/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625091.248701 6789810 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625091.248874 6789810 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625091.249343 6789819 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625091.249513 6789819 random_forest.cc:812] Training of tree  11/100 (tree index:14) done accuracy:0.633333 logloss:3.46779\n",
      "I0000 00:00:1729625091.249710 6789826 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.641667 logloss:1.18939\n",
      "I0000 00:00:1729625091.249880 6789821 random_forest.cc:812] Training of tree  31/100 (tree index:31) done accuracy:0.691667 logloss:0.858244\n",
      "I0000 00:00:1729625091.250099 6789824 random_forest.cc:812] Training of tree  42/100 (tree index:41) done accuracy:0.725 logloss:0.583005\n",
      "I0000 00:00:1729625091.250251 6789825 random_forest.cc:812] Training of tree  52/100 (tree index:53) done accuracy:0.7 logloss:0.594286\n",
      "I0000 00:00:1729625091.250419 6789825 random_forest.cc:812] Training of tree  62/100 (tree index:62) done accuracy:0.691667 logloss:0.587165\n",
      "I0000 00:00:1729625091.250649 6789825 random_forest.cc:812] Training of tree  75/100 (tree index:75) done accuracy:0.691667 logloss:0.581535\n",
      "I0000 00:00:1729625091.250877 6789825 random_forest.cc:812] Training of tree  85/100 (tree index:78) done accuracy:0.708333 logloss:0.57197\n",
      "I0000 00:00:1729625091.251106 6789820 random_forest.cc:812] Training of tree  96/100 (tree index:97) done accuracy:0.7 logloss:0.560866\n",
      "I0000 00:00:1729625091.251187 6789825 random_forest.cc:812] Training of tree  100/100 (tree index:95) done accuracy:0.675 logloss:0.562212\n",
      "I0000 00:00:1729625091.251262 6789810 random_forest.cc:892] Final OOB metrics: accuracy:0.675 logloss:0.562212\n",
      "I0000 00:00:1729625091.251454 6789810 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdhtacsbq with prefix 4a78157e246d4636\n",
      "I0000 00:00:1729625091.253046 6789810 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625091.253728 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.675  CI95[W][0.597764 0.745608]\n",
      "LogLoss: : 0.562212\n",
      "ErrorRate: : 0.325\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  32  22\n",
      "2  17  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:51.258737: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdhtacsbq/model/ with prefix 4a78157e246d4636\n",
      "I0000 00:00:1729625091.260800 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1292 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:51.260819: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.194545. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013294\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjtu03fiv as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625091.595389 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625091.595400 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625091.595404 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625091.595466 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625091.595470 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625091.595522 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.595538 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.595545 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.595551 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.595580 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625091.595599 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625091.595771 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625091.595793 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpge316xfk/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625091.595860 6789902 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625091.595955 6789902 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625091.596399 6789916 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.716981 logloss:10.201\n",
      "I0000 00:00:1729625091.596566 6789914 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.683333 logloss:3.68727\n",
      "I0000 00:00:1729625091.596753 6789911 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.716667 logloss:1.11426\n",
      "I0000 00:00:1729625091.596936 6789911 random_forest.cc:812] Training of tree  31/100 (tree index:29) done accuracy:0.733333 logloss:0.793199\n",
      "I0000 00:00:1729625091.597177 6789915 random_forest.cc:812] Training of tree  41/100 (tree index:41) done accuracy:0.741667 logloss:0.517565\n",
      "I0000 00:00:1729625091.597323 6789918 random_forest.cc:812] Training of tree  51/100 (tree index:50) done accuracy:0.758333 logloss:0.523809\n",
      "I0000 00:00:1729625091.597578 6789911 random_forest.cc:812] Training of tree  61/100 (tree index:61) done accuracy:0.75 logloss:0.518934\n",
      "I0000 00:00:1729625091.597736 6789916 random_forest.cc:812] Training of tree  73/100 (tree index:72) done accuracy:0.775 logloss:0.520072\n",
      "I0000 00:00:1729625091.597952 6789915 random_forest.cc:812] Training of tree  83/100 (tree index:83) done accuracy:0.733333 logloss:0.52066\n",
      "I0000 00:00:1729625091.598102 6789912 random_forest.cc:812] Training of tree  93/100 (tree index:91) done accuracy:0.758333 logloss:0.515467\n",
      "I0000 00:00:1729625091.598257 6789913 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.783333 logloss:0.516345\n",
      "I0000 00:00:1729625091.598348 6789902 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.516345\n",
      "I0000 00:00:1729625091.598530 6789902 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpge316xfk with prefix 37b21abdbdda4872\n",
      "I0000 00:00:1729625091.599924 6789902 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625091.600740 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.516345\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:51.605330: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpge316xfk/model/ with prefix 37b21abdbdda4872\n",
      "I0000 00:00:1729625091.607072 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1218 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:51.607088: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.156739. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012901\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': -1, 'min_examples': 20, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdbqr6ezs as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625091.915004 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625091.915015 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625091.915019 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625091.915079 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625091.915084 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625091.915137 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.915170 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.915176 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.915182 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625091.915214 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625091.915234 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625091.915373 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625091.915404 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjtu03fiv/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625091.915488 6789971 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625091.915579 6789971 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625091.916217 6789983 random_forest.cc:812] Training of tree  1/100 (tree index:2) done accuracy:0.673469 logloss:11.7694\n",
      "I0000 00:00:1729625091.916450 6789987 random_forest.cc:812] Training of tree  11/100 (tree index:8) done accuracy:0.638655 logloss:2.58203\n",
      "I0000 00:00:1729625091.916666 6789983 random_forest.cc:812] Training of tree  23/100 (tree index:22) done accuracy:0.758333 logloss:0.783115\n",
      "I0000 00:00:1729625091.916837 6789982 random_forest.cc:812] Training of tree  33/100 (tree index:32) done accuracy:0.775 logloss:0.497337\n",
      "I0000 00:00:1729625091.917050 6789985 random_forest.cc:812] Training of tree  45/100 (tree index:38) done accuracy:0.766667 logloss:0.515918\n",
      "I0000 00:00:1729625091.917206 6789987 random_forest.cc:812] Training of tree  55/100 (tree index:55) done accuracy:0.766667 logloss:0.507714\n",
      "I0000 00:00:1729625091.917353 6789980 random_forest.cc:812] Training of tree  65/100 (tree index:64) done accuracy:0.741667 logloss:0.525481\n",
      "I0000 00:00:1729625091.917496 6789982 random_forest.cc:812] Training of tree  75/100 (tree index:66) done accuracy:0.766667 logloss:0.523137\n",
      "I0000 00:00:1729625091.917630 6789985 random_forest.cc:812] Training of tree  85/100 (tree index:84) done accuracy:0.766667 logloss:0.523303\n",
      "I0000 00:00:1729625091.917808 6789985 random_forest.cc:812] Training of tree  95/100 (tree index:93) done accuracy:0.766667 logloss:0.517057\n",
      "I0000 00:00:1729625091.917899 6789982 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.775 logloss:0.518928\n",
      "I0000 00:00:1729625091.917956 6789971 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.518928\n",
      "I0000 00:00:1729625091.918130 6789971 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjtu03fiv with prefix bccfeb91e036400f\n",
      "I0000 00:00:1729625091.919419 6789971 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625091.920132 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.518928\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  16\n",
      "2  11  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:51.924540: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjtu03fiv/model/ with prefix bccfeb91e036400f\n",
      "I0000 00:00:1729625091.926224 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 1226 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:51.926239: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.151549. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.012277\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 87ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625092.220105 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625092.220130 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625092.220136 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625092.220201 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625092.220205 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625092.220249 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.220259 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.220264 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.220269 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.220296 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625092.220314 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625092.220447 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625092.220472 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdbqr6ezs/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625092.220539 6790038 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625092.220642 6790038 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625092.221149 6790054 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.454545 logloss:19.6602\n",
      "I0000 00:00:1729625092.221274 6790054 random_forest.cc:812] Training of tree  11/100 (tree index:8) done accuracy:0.666667 logloss:3.70715\n",
      "I0000 00:00:1729625092.221457 6790050 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.758333 logloss:2.22952\n",
      "I0000 00:00:1729625092.221576 6790054 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.741667 logloss:1.39166\n",
      "I0000 00:00:1729625092.221788 6790053 random_forest.cc:812] Training of tree  41/100 (tree index:43) done accuracy:0.741667 logloss:1.40161\n",
      "I0000 00:00:1729625092.221941 6790051 random_forest.cc:812] Training of tree  51/100 (tree index:51) done accuracy:0.741667 logloss:1.14387\n",
      "I0000 00:00:1729625092.222081 6790052 random_forest.cc:812] Training of tree  61/100 (tree index:60) done accuracy:0.725 logloss:1.13835\n",
      "I0000 00:00:1729625092.222256 6790048 random_forest.cc:812] Training of tree  71/100 (tree index:69) done accuracy:0.725 logloss:0.840466\n",
      "I0000 00:00:1729625092.222458 6790048 random_forest.cc:812] Training of tree  81/100 (tree index:83) done accuracy:0.7 logloss:0.8523\n",
      "I0000 00:00:1729625092.222621 6790052 random_forest.cc:812] Training of tree  95/100 (tree index:94) done accuracy:0.7 logloss:0.852389\n",
      "I0000 00:00:1729625092.222763 6790051 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.7 logloss:0.578909\n",
      "I0000 00:00:1729625092.222790 6790038 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.578909\n",
      "I0000 00:00:1729625092.222952 6790038 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdbqr6ezs with prefix 364860a7c08e41d7\n",
      "I0000 00:00:1729625092.224127 6790038 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625092.224701 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.578909\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  16\n",
      "2  20  42\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:52.229096: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdbqr6ezs/model/ with prefix 364860a7c08e41d7\n",
      "I0000 00:00:1729625092.230374 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 832 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:52.230390: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7ysenpya as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.181908. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013191\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625092.616632 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625092.616651 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625092.616657 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625092.616725 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625092.616730 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625092.616775 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.616785 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.616791 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.616799 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.616825 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625092.616843 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625092.616980 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625092.617005 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7ysenpya/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625092.617069 6790109 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625092.617184 6790109 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625092.617674 6790118 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.675 logloss:11.7142\n",
      "I0000 00:00:1729625092.617926 6790124 random_forest.cc:812] Training of tree  11/100 (tree index:7) done accuracy:0.638655 logloss:5.20226\n",
      "I0000 00:00:1729625092.618078 6790119 random_forest.cc:812] Training of tree  22/100 (tree index:21) done accuracy:0.65 logloss:2.62059\n",
      "I0000 00:00:1729625092.618352 6790118 random_forest.cc:812] Training of tree  32/100 (tree index:31) done accuracy:0.708333 logloss:0.895533\n",
      "I0000 00:00:1729625092.618558 6790123 random_forest.cc:812] Training of tree  42/100 (tree index:42) done accuracy:0.708333 logloss:0.600205\n",
      "I0000 00:00:1729625092.618765 6790121 random_forest.cc:812] Training of tree  52/100 (tree index:52) done accuracy:0.691667 logloss:0.61766\n",
      "I0000 00:00:1729625092.618983 6790125 random_forest.cc:812] Training of tree  63/100 (tree index:65) done accuracy:0.708333 logloss:0.620329\n",
      "I0000 00:00:1729625092.619227 6790123 random_forest.cc:812] Training of tree  75/100 (tree index:70) done accuracy:0.725 logloss:0.619687\n",
      "I0000 00:00:1729625092.619448 6790122 random_forest.cc:812] Training of tree  86/100 (tree index:86) done accuracy:0.725 logloss:0.610232\n",
      "I0000 00:00:1729625092.619591 6790118 random_forest.cc:812] Training of tree  96/100 (tree index:97) done accuracy:0.733333 logloss:0.597016\n",
      "I0000 00:00:1729625092.619635 6790124 random_forest.cc:812] Training of tree  100/100 (tree index:96) done accuracy:0.741667 logloss:0.590314\n",
      "I0000 00:00:1729625092.619722 6790109 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.590314\n",
      "I0000 00:00:1729625092.619878 6790109 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7ysenpya with prefix 3682bfbc73e94e9c\n",
      "I0000 00:00:1729625092.621253 6790109 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625092.622083 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.590314\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  34  19\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:52.626898: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7ysenpya/model/ with prefix 3682bfbc73e94e9c\n",
      "I0000 00:00:1729625092.628105 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 814 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:52.628120: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6cor9u1h as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.150126. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016474\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625092.925025 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625092.925038 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625092.925044 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625092.925112 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625092.925117 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625092.925163 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.925175 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.925183 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.925188 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625092.925220 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625092.925237 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625092.925373 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625092.925397 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6cor9u1h/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625092.925479 6790192 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625092.925567 6790192 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625092.926051 6790206 random_forest.cc:812] Training of tree  1/100 (tree index:2) done accuracy:0.658537 logloss:12.3076\n",
      "I0000 00:00:1729625092.926399 6790203 random_forest.cc:812] Training of tree  11/100 (tree index:8) done accuracy:0.606838 logloss:4.11512\n",
      "I0000 00:00:1729625092.926605 6790203 random_forest.cc:812] Training of tree  21/100 (tree index:22) done accuracy:0.65 logloss:2.06229\n",
      "I0000 00:00:1729625092.927072 6790203 random_forest.cc:812] Training of tree  31/100 (tree index:34) done accuracy:0.708333 logloss:0.612626\n",
      "I0000 00:00:1729625092.927358 6790206 random_forest.cc:812] Training of tree  41/100 (tree index:27) done accuracy:0.7 logloss:0.615704\n",
      "I0000 00:00:1729625092.927541 6790205 random_forest.cc:812] Training of tree  51/100 (tree index:49) done accuracy:0.683333 logloss:0.608078\n",
      "I0000 00:00:1729625092.927793 6790207 random_forest.cc:812] Training of tree  61/100 (tree index:57) done accuracy:0.725 logloss:0.596906\n",
      "I0000 00:00:1729625092.928012 6790208 random_forest.cc:812] Training of tree  71/100 (tree index:71) done accuracy:0.708333 logloss:0.600277\n",
      "I0000 00:00:1729625092.928173 6790202 random_forest.cc:812] Training of tree  81/100 (tree index:81) done accuracy:0.725 logloss:0.596676\n",
      "I0000 00:00:1729625092.928371 6790203 random_forest.cc:812] Training of tree  91/100 (tree index:87) done accuracy:0.708333 logloss:0.592601\n",
      "I0000 00:00:1729625092.928560 6790202 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.725 logloss:0.577642\n",
      "I0000 00:00:1729625092.928690 6790192 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.577642\n",
      "I0000 00:00:1729625092.928815 6790192 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6cor9u1h with prefix 7ce1fdf06a224cf2\n",
      "I0000 00:00:1729625092.930028 6790192 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625092.931053 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.577642\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  18\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:52.937375: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6cor9u1h/model/ with prefix 7ce1fdf06a224cf2\n",
      "I0000 00:00:1729625092.939047 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 810 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:52.939069: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpybziglha as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.158314. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015860\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625093.356687 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625093.356701 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625093.356722 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625093.356837 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625093.356845 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625093.356919 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625093.356933 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625093.356939 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625093.356945 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625093.356974 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625093.356992 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625093.357137 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625093.357164 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpybziglha/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625093.357395 6790322 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625093.358349 6790322 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625093.359081 6790333 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625093.359428 6790333 random_forest.cc:812] Training of tree  11/100 (tree index:12) done accuracy:0.722689 logloss:3.37937\n",
      "I0000 00:00:1729625093.359698 6790334 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.725 logloss:1.92565\n",
      "I0000 00:00:1729625093.359921 6790338 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.766667 logloss:1.08657\n",
      "I0000 00:00:1729625093.360116 6790332 random_forest.cc:812] Training of tree  41/100 (tree index:41) done accuracy:0.733333 logloss:0.811467\n",
      "I0000 00:00:1729625093.360321 6790332 random_forest.cc:812] Training of tree  51/100 (tree index:48) done accuracy:0.716667 logloss:0.537967\n",
      "I0000 00:00:1729625093.360621 6790332 random_forest.cc:812] Training of tree  61/100 (tree index:60) done accuracy:0.75 logloss:0.523663\n",
      "I0000 00:00:1729625093.360914 6790334 random_forest.cc:812] Training of tree  71/100 (tree index:71) done accuracy:0.733333 logloss:0.519982\n",
      "I0000 00:00:1729625093.361224 6790337 random_forest.cc:812] Training of tree  81/100 (tree index:80) done accuracy:0.766667 logloss:0.51174\n",
      "I0000 00:00:1729625093.361421 6790332 random_forest.cc:812] Training of tree  92/100 (tree index:91) done accuracy:0.766667 logloss:0.50856\n",
      "I0000 00:00:1729625093.361808 6790336 random_forest.cc:812] Training of tree  100/100 (tree index:92) done accuracy:0.766667 logloss:0.506933\n",
      "I0000 00:00:1729625093.361835 6790322 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.506933\n",
      "I0000 00:00:1729625093.361957 6790322 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpybziglha with prefix 2977c4518e834818\n",
      "I0000 00:00:1729625093.363134 6790322 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625093.363993 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.506933\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  16\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:53.369235: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpybziglha/model/ with prefix 2977c4518e834818\n",
      "I0000 00:00:1729625093.370571 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 792 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:53.370591: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzk91t2wy as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.148636. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013230\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625093.676474 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625093.676488 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625093.676492 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625093.676555 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625093.676559 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625093.676602 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625093.676612 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625093.676617 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625093.676622 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625093.676650 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625093.676667 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625093.676803 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625093.676827 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzk91t2wy/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625093.676868 6790413 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625093.676948 6790413 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625093.677496 6790428 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625093.677634 6790424 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.701754 logloss:5.93686\n",
      "I0000 00:00:1729625093.677880 6790428 random_forest.cc:812] Training of tree  21/100 (tree index:21) done accuracy:0.633333 logloss:2.04967\n",
      "I0000 00:00:1729625093.678027 6790429 random_forest.cc:812] Training of tree  31/100 (tree index:30) done accuracy:0.683333 logloss:1.45549\n",
      "I0000 00:00:1729625093.678212 6790427 random_forest.cc:812] Training of tree  41/100 (tree index:42) done accuracy:0.691667 logloss:0.859168\n",
      "I0000 00:00:1729625093.678360 6790426 random_forest.cc:812] Training of tree  51/100 (tree index:50) done accuracy:0.75 logloss:0.847935\n",
      "I0000 00:00:1729625093.678501 6790426 random_forest.cc:812] Training of tree  61/100 (tree index:60) done accuracy:0.758333 logloss:0.839149\n",
      "I0000 00:00:1729625093.678642 6790426 random_forest.cc:812] Training of tree  71/100 (tree index:70) done accuracy:0.741667 logloss:0.838568\n",
      "I0000 00:00:1729625093.678807 6790429 random_forest.cc:812] Training of tree  81/100 (tree index:81) done accuracy:0.741667 logloss:0.840479\n",
      "I0000 00:00:1729625093.678951 6790426 random_forest.cc:812] Training of tree  91/100 (tree index:90) done accuracy:0.725 logloss:0.837814\n",
      "I0000 00:00:1729625093.679077 6790424 random_forest.cc:812] Training of tree  100/100 (tree index:98) done accuracy:0.741667 logloss:0.835822\n",
      "I0000 00:00:1729625093.679138 6790413 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.835822\n",
      "I0000 00:00:1729625093.679270 6790413 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzk91t2wy with prefix dd5b48653e1244bb\n",
      "I0000 00:00:1729625093.680515 6790413 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625093.681360 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.835822\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  17\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:53.686721: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzk91t2wy/model/ with prefix dd5b48653e1244bb\n",
      "I0000 00:00:1729625093.688106 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 796 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:53.688123: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 100, 'max_depth': -1, 'min_examples': 20, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpu_hhugeb as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.149258. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011212\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625094.034581 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625094.034591 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625094.034595 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625094.034660 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625094.034666 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625094.034712 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.034722 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.034728 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.034734 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.034762 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625094.034780 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625094.034912 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625094.034933 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpu_hhugeb/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625094.035003 6790519 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625094.035088 6790519 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625094.035486 6790534 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.531915 logloss:16.8715\n",
      "I0000 00:00:1729625094.035642 6790531 random_forest.cc:812] Training of tree  12/100 (tree index:12) done accuracy:0.630252 logloss:4.89961\n",
      "I0000 00:00:1729625094.035772 6790534 random_forest.cc:812] Training of tree  22/100 (tree index:19) done accuracy:0.658333 logloss:1.17923\n",
      "I0000 00:00:1729625094.035897 6790529 random_forest.cc:812] Training of tree  32/100 (tree index:33) done accuracy:0.683333 logloss:1.16341\n",
      "I0000 00:00:1729625094.036028 6790529 random_forest.cc:812] Training of tree  43/100 (tree index:42) done accuracy:0.691667 logloss:0.605973\n",
      "I0000 00:00:1729625094.036151 6790532 random_forest.cc:812] Training of tree  53/100 (tree index:54) done accuracy:0.708333 logloss:0.599254\n",
      "I0000 00:00:1729625094.036265 6790535 random_forest.cc:812] Training of tree  63/100 (tree index:63) done accuracy:0.691667 logloss:0.588241\n",
      "I0000 00:00:1729625094.036367 6790530 random_forest.cc:812] Training of tree  73/100 (tree index:72) done accuracy:0.675 logloss:0.58888\n",
      "I0000 00:00:1729625094.036464 6790533 random_forest.cc:812] Training of tree  83/100 (tree index:83) done accuracy:0.691667 logloss:0.586801\n",
      "I0000 00:00:1729625094.036569 6790535 random_forest.cc:812] Training of tree  94/100 (tree index:93) done accuracy:0.683333 logloss:0.587701\n",
      "I0000 00:00:1729625094.036693 6790535 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.683333 logloss:0.589066\n",
      "I0000 00:00:1729625094.036716 6790519 random_forest.cc:892] Final OOB metrics: accuracy:0.683333 logloss:0.589066\n",
      "I0000 00:00:1729625094.036826 6790519 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpu_hhugeb with prefix 18de60541d2e4581\n",
      "I0000 00:00:1729625094.037985 6790519 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625094.038736 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.683333  CI95[W][0.60641 0.75331]\n",
      "LogLoss: : 0.589066\n",
      "ErrorRate: : 0.316667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  21\n",
      "2  17  45\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:54.043460: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpu_hhugeb/model/ with prefix 18de60541d2e4581\n",
      "I0000 00:00:1729625094.044451 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 658 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:54.044464: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppzsv46lr as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.142778. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.010909\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625094.330800 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625094.330811 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625094.330815 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625094.330882 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625094.330886 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625094.330937 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.330948 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.330954 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.330960 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.330988 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625094.331005 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625094.331143 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625094.331166 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppzsv46lr/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625094.331224 6790591 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625094.331329 6790591 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625094.331782 6790606 random_forest.cc:812] Training of tree  1/100 (tree index:1) done accuracy:0.574468 logloss:15.3377\n",
      "I0000 00:00:1729625094.331926 6790605 random_forest.cc:812] Training of tree  12/100 (tree index:11) done accuracy:0.589744 logloss:4.71805\n",
      "I0000 00:00:1729625094.332099 6790605 random_forest.cc:812] Training of tree  22/100 (tree index:22) done accuracy:0.7 logloss:1.46047\n",
      "I0000 00:00:1729625094.332228 6790603 random_forest.cc:812] Training of tree  33/100 (tree index:33) done accuracy:0.708333 logloss:0.889947\n",
      "I0000 00:00:1729625094.332343 6790600 random_forest.cc:812] Training of tree  43/100 (tree index:40) done accuracy:0.725 logloss:0.887408\n",
      "I0000 00:00:1729625094.332437 6790606 random_forest.cc:812] Training of tree  53/100 (tree index:53) done accuracy:0.716667 logloss:0.611218\n",
      "I0000 00:00:1729625094.332537 6790605 random_forest.cc:812] Training of tree  63/100 (tree index:62) done accuracy:0.708333 logloss:0.60751\n",
      "I0000 00:00:1729625094.332676 6790602 random_forest.cc:812] Training of tree  73/100 (tree index:73) done accuracy:0.708333 logloss:0.601059\n",
      "I0000 00:00:1729625094.332816 6790604 random_forest.cc:812] Training of tree  84/100 (tree index:84) done accuracy:0.716667 logloss:0.600916\n",
      "I0000 00:00:1729625094.332949 6790607 random_forest.cc:812] Training of tree  94/100 (tree index:92) done accuracy:0.725 logloss:0.607142\n",
      "I0000 00:00:1729625094.333047 6790602 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.733333 logloss:0.612301\n",
      "I0000 00:00:1729625094.333122 6790591 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.612301\n",
      "I0000 00:00:1729625094.333263 6790591 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppzsv46lr with prefix a44e7f00330f4c35\n",
      "I0000 00:00:1729625094.334519 6790591 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625094.335038 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.612301\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  33  20\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:54.339202: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppzsv46lr/model/ with prefix a44e7f00330f4c35\n",
      "I0000 00:00:1729625094.340229 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 660 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:24:54.340243: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp4plfudsb as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.141774. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.010494\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625094.665131 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625094.665143 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625094.665147 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625094.665213 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625094.665220 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625094.665262 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.665271 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.665277 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.665282 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.665309 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625094.665328 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625094.665456 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625094.665481 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp4plfudsb/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625094.665541 6790664 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625094.665640 6790664 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625094.666077 6790677 random_forest.cc:812] Training of tree  1/100 (tree index:3) done accuracy:0.45283 logloss:19.722\n",
      "I0000 00:00:1729625094.666177 6790675 random_forest.cc:812] Training of tree  11/100 (tree index:10) done accuracy:0.59292 logloss:7.69388\n",
      "I0000 00:00:1729625094.666320 6790676 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.658333 logloss:0.889525\n",
      "I0000 00:00:1729625094.666442 6790675 random_forest.cc:812] Training of tree  32/100 (tree index:32) done accuracy:0.683333 logloss:0.594541\n",
      "I0000 00:00:1729625094.666590 6790674 random_forest.cc:812] Training of tree  42/100 (tree index:43) done accuracy:0.691667 logloss:0.596641\n",
      "I0000 00:00:1729625094.666721 6790679 random_forest.cc:812] Training of tree  53/100 (tree index:52) done accuracy:0.691667 logloss:0.61375\n",
      "I0000 00:00:1729625094.666855 6790678 random_forest.cc:812] Training of tree  63/100 (tree index:63) done accuracy:0.7 logloss:0.601956\n",
      "I0000 00:00:1729625094.666956 6790679 random_forest.cc:812] Training of tree  73/100 (tree index:72) done accuracy:0.708333 logloss:0.602452\n",
      "I0000 00:00:1729625094.667090 6790673 random_forest.cc:812] Training of tree  83/100 (tree index:83) done accuracy:0.708333 logloss:0.599446\n",
      "I0000 00:00:1729625094.667220 6790674 random_forest.cc:812] Training of tree  93/100 (tree index:94) done accuracy:0.708333 logloss:0.606978\n",
      "I0000 00:00:1729625094.667286 6790679 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.7 logloss:0.606836\n",
      "I0000 00:00:1729625094.667337 6790664 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.606836\n",
      "I0000 00:00:1729625094.667449 6790664 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp4plfudsb with prefix 13acdcc57e0a4ec7\n",
      "I0000 00:00:1729625094.668468 6790664 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625094.669168 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.606836\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  33  21\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:54.673417: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp4plfudsb/model/ with prefix 13acdcc57e0a4ec7\n",
      "I0000 00:00:1729625094.674374 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 638 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:24:54.674390: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpapu6amzv as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143108. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011054\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625094.956133 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625094.956146 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625094.956151 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625094.956219 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625094.956224 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625094.956273 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.956282 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.956288 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.956293 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625094.956320 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625094.956338 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625094.956476 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625094.956498 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpapu6amzv/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625094.956557 6790734 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625094.956646 6790734 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625094.957051 6790746 random_forest.cc:812] Training of tree  1/100 (tree index:4) done accuracy:0.428571 logloss:20.5964\n",
      "I0000 00:00:1729625094.957189 6790747 random_forest.cc:812] Training of tree  11/100 (tree index:11) done accuracy:0.633333 logloss:4.04356\n",
      "I0000 00:00:1729625094.957317 6790747 random_forest.cc:812] Training of tree  21/100 (tree index:20) done accuracy:0.683333 logloss:1.73811\n",
      "I0000 00:00:1729625094.957417 6790749 random_forest.cc:812] Training of tree  31/100 (tree index:31) done accuracy:0.708333 logloss:0.876997\n",
      "I0000 00:00:1729625094.957520 6790745 random_forest.cc:812] Training of tree  41/100 (tree index:41) done accuracy:0.733333 logloss:0.56329\n",
      "I0000 00:00:1729625094.957659 6790746 random_forest.cc:812] Training of tree  52/100 (tree index:52) done accuracy:0.741667 logloss:0.571286\n",
      "I0000 00:00:1729625094.957787 6790744 random_forest.cc:812] Training of tree  62/100 (tree index:61) done accuracy:0.741667 logloss:0.573831\n",
      "I0000 00:00:1729625094.957915 6790748 random_forest.cc:812] Training of tree  72/100 (tree index:71) done accuracy:0.733333 logloss:0.575473\n",
      "I0000 00:00:1729625094.958039 6790748 random_forest.cc:812] Training of tree  82/100 (tree index:82) done accuracy:0.725 logloss:0.566697\n",
      "I0000 00:00:1729625094.958130 6790746 random_forest.cc:812] Training of tree  92/100 (tree index:92) done accuracy:0.733333 logloss:0.564351\n",
      "I0000 00:00:1729625094.958231 6790745 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.741667 logloss:0.558289\n",
      "I0000 00:00:1729625094.958279 6790734 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.558289\n",
      "I0000 00:00:1729625094.958401 6790734 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpapu6amzv with prefix 048965cb8a014ba8\n",
      "I0000 00:00:1729625094.959500 6790734 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625094.960051 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.558289\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  20\n",
      "2  11  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:54.964670: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpapu6amzv/model/ with prefix 048965cb8a014ba8\n",
      "I0000 00:00:1729625094.965659 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 654 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:54.965673: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0ulxg729 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.183412. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.011036\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625095.286149 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625095.286158 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625095.286165 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625095.286232 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625095.286254 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625095.286298 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.286307 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.286312 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.286318 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.286345 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625095.286362 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625095.286498 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 100\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625095.286523 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0ulxg729/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625095.286572 6790801 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625095.286664 6790801 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625095.287059 6790816 random_forest.cc:812] Training of tree  1/100 (tree index:0) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625095.287228 6790810 random_forest.cc:812] Training of tree  12/100 (tree index:11) done accuracy:0.7 logloss:2.83146\n",
      "I0000 00:00:1729625095.287333 6790811 random_forest.cc:812] Training of tree  22/100 (tree index:23) done accuracy:0.716667 logloss:1.16014\n",
      "I0000 00:00:1729625095.287448 6790817 random_forest.cc:812] Training of tree  33/100 (tree index:33) done accuracy:0.725 logloss:0.866819\n",
      "I0000 00:00:1729625095.287559 6790810 random_forest.cc:812] Training of tree  43/100 (tree index:43) done accuracy:0.716667 logloss:0.867939\n",
      "I0000 00:00:1729625095.287677 6790814 random_forest.cc:812] Training of tree  53/100 (tree index:52) done accuracy:0.691667 logloss:0.867096\n",
      "I0000 00:00:1729625095.287810 6790817 random_forest.cc:812] Training of tree  63/100 (tree index:60) done accuracy:0.708333 logloss:0.583702\n",
      "I0000 00:00:1729625095.287949 6790811 random_forest.cc:812] Training of tree  73/100 (tree index:74) done accuracy:0.716667 logloss:0.582174\n",
      "I0000 00:00:1729625095.288082 6790811 random_forest.cc:812] Training of tree  83/100 (tree index:84) done accuracy:0.708333 logloss:0.575136\n",
      "I0000 00:00:1729625095.288220 6790813 random_forest.cc:812] Training of tree  93/100 (tree index:87) done accuracy:0.708333 logloss:0.587744\n",
      "I0000 00:00:1729625095.288318 6790814 random_forest.cc:812] Training of tree  100/100 (tree index:99) done accuracy:0.7 logloss:0.581723\n",
      "I0000 00:00:1729625095.288395 6790801 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.581723\n",
      "I0000 00:00:1729625095.288513 6790801 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0ulxg729 with prefix ed599a814210432f\n",
      "I0000 00:00:1729625095.289617 6790801 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625095.290221 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.581723\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  35  20\n",
      "2  16  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:55.294595: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0ulxg729/model/ with prefix ed599a814210432f\n",
      "I0000 00:00:1729625095.295789 6784195 decision_forest.cc:761] Model loaded with 100 root(s), 638 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:55.295807: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 20, 'min_examples': 5, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgrc1x_ly as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.141526. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021740\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625095.576625 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625095.576636 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625095.576640 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625095.576702 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625095.576708 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625095.576751 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.576760 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.576765 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.576770 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.576797 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625095.576816 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625095.576949 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625095.576971 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgrc1x_ly/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625095.577019 6790869 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625095.577113 6790869 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625095.577619 6790879 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.55814 logloss:15.9263\n",
      "I0000 00:00:1729625095.577792 6790879 random_forest.cc:812] Training of tree  11/200 (tree index:8) done accuracy:0.705882 logloss:3.40013\n",
      "I0000 00:00:1729625095.577980 6790880 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.7 logloss:1.13172\n",
      "I0000 00:00:1729625095.578137 6790885 random_forest.cc:812] Training of tree  31/200 (tree index:29) done accuracy:0.725 logloss:1.13759\n",
      "I0000 00:00:1729625095.578305 6790880 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.716667 logloss:0.837514\n",
      "I0000 00:00:1729625095.578495 6790882 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.741667 logloss:0.557091\n",
      "I0000 00:00:1729625095.578668 6790881 random_forest.cc:812] Training of tree  61/200 (tree index:62) done accuracy:0.75 logloss:0.530859\n",
      "I0000 00:00:1729625095.578840 6790879 random_forest.cc:812] Training of tree  71/200 (tree index:71) done accuracy:0.766667 logloss:0.522646\n",
      "I0000 00:00:1729625095.579051 6790878 random_forest.cc:812] Training of tree  81/200 (tree index:82) done accuracy:0.766667 logloss:0.521257\n",
      "I0000 00:00:1729625095.579358 6790884 random_forest.cc:812] Training of tree  91/200 (tree index:89) done accuracy:0.741667 logloss:0.52065\n",
      "I0000 00:00:1729625095.579540 6790883 random_forest.cc:812] Training of tree  101/200 (tree index:100) done accuracy:0.758333 logloss:0.522696\n",
      "I0000 00:00:1729625095.579692 6790884 random_forest.cc:812] Training of tree  111/200 (tree index:111) done accuracy:0.733333 logloss:0.528894\n",
      "I0000 00:00:1729625095.579866 6790885 random_forest.cc:812] Training of tree  121/200 (tree index:123) done accuracy:0.75 logloss:0.521719\n",
      "I0000 00:00:1729625095.580027 6790878 random_forest.cc:812] Training of tree  131/200 (tree index:132) done accuracy:0.741667 logloss:0.528734\n",
      "I0000 00:00:1729625095.580242 6790882 random_forest.cc:812] Training of tree  141/200 (tree index:135) done accuracy:0.741667 logloss:0.530261\n",
      "I0000 00:00:1729625095.580406 6790878 random_forest.cc:812] Training of tree  152/200 (tree index:151) done accuracy:0.75 logloss:0.534271\n",
      "I0000 00:00:1729625095.580684 6790883 random_forest.cc:812] Training of tree  162/200 (tree index:161) done accuracy:0.733333 logloss:0.535164\n",
      "I0000 00:00:1729625095.580846 6790882 random_forest.cc:812] Training of tree  172/200 (tree index:170) done accuracy:0.733333 logloss:0.533493\n",
      "I0000 00:00:1729625095.581022 6790885 random_forest.cc:812] Training of tree  182/200 (tree index:182) done accuracy:0.741667 logloss:0.527231\n",
      "I0000 00:00:1729625095.581193 6790882 random_forest.cc:812] Training of tree  192/200 (tree index:192) done accuracy:0.725 logloss:0.524181\n",
      "I0000 00:00:1729625095.581353 6790878 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.741667 logloss:0.519991\n",
      "I0000 00:00:1729625095.581444 6790869 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.519991\n",
      "I0000 00:00:1729625095.582000 6790869 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgrc1x_ly with prefix c76266d91105488d\n",
      "I0000 00:00:1729625095.584376 6790869 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625095.584997 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.519991\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  44  14\n",
      "2  17  45\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:55.590460: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgrc1x_ly/model/ with prefix c76266d91105488d\n",
      "I0000 00:00:1729625095.596302 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4390 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:55.596319: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk_lh3e4_ as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.185326. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625095.925665 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625095.925675 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625095.925680 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625095.925751 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625095.925757 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625095.925803 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.925813 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.925819 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.925825 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625095.925852 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625095.925869 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625095.926022 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625095.926056 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk_lh3e4_/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625095.926106 6790946 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625095.926264 6790946 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625095.926763 6790957 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625095.926916 6790956 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.672269 logloss:4.03093\n",
      "I0000 00:00:1729625095.927116 6790960 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.725 logloss:1.09007\n",
      "I0000 00:00:1729625095.927275 6790959 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.758333 logloss:0.781267\n",
      "I0000 00:00:1729625095.927543 6790959 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.741667 logloss:0.804619\n",
      "I0000 00:00:1729625095.927741 6790956 random_forest.cc:812] Training of tree  51/200 (tree index:51) done accuracy:0.741667 logloss:0.517751\n",
      "I0000 00:00:1729625095.927935 6790960 random_forest.cc:812] Training of tree  61/200 (tree index:61) done accuracy:0.725 logloss:0.518001\n",
      "I0000 00:00:1729625095.928129 6790955 random_forest.cc:812] Training of tree  71/200 (tree index:73) done accuracy:0.733333 logloss:0.509797\n",
      "I0000 00:00:1729625095.928291 6790960 random_forest.cc:812] Training of tree  81/200 (tree index:82) done accuracy:0.741667 logloss:0.516542\n",
      "I0000 00:00:1729625095.928544 6790961 random_forest.cc:812] Training of tree  92/200 (tree index:94) done accuracy:0.766667 logloss:0.490923\n",
      "I0000 00:00:1729625095.928740 6790955 random_forest.cc:812] Training of tree  103/200 (tree index:103) done accuracy:0.766667 logloss:0.49025\n",
      "I0000 00:00:1729625095.928973 6790956 random_forest.cc:812] Training of tree  113/200 (tree index:115) done accuracy:0.766667 logloss:0.493846\n",
      "I0000 00:00:1729625095.929149 6790962 random_forest.cc:812] Training of tree  123/200 (tree index:122) done accuracy:0.775 logloss:0.492956\n",
      "I0000 00:00:1729625095.929285 6790956 random_forest.cc:812] Training of tree  133/200 (tree index:133) done accuracy:0.766667 logloss:0.49221\n",
      "I0000 00:00:1729625095.929463 6790958 random_forest.cc:812] Training of tree  143/200 (tree index:144) done accuracy:0.775 logloss:0.492055\n",
      "I0000 00:00:1729625095.929626 6790960 random_forest.cc:812] Training of tree  153/200 (tree index:154) done accuracy:0.766667 logloss:0.494534\n",
      "I0000 00:00:1729625095.929838 6790955 random_forest.cc:812] Training of tree  164/200 (tree index:163) done accuracy:0.766667 logloss:0.496559\n",
      "I0000 00:00:1729625095.930112 6790957 random_forest.cc:812] Training of tree  176/200 (tree index:176) done accuracy:0.775 logloss:0.495092\n",
      "I0000 00:00:1729625095.930323 6790958 random_forest.cc:812] Training of tree  186/200 (tree index:186) done accuracy:0.766667 logloss:0.495296\n",
      "I0000 00:00:1729625095.930492 6790957 random_forest.cc:812] Training of tree  196/200 (tree index:195) done accuracy:0.766667 logloss:0.497139\n",
      "I0000 00:00:1729625095.930596 6790962 random_forest.cc:812] Training of tree  200/200 (tree index:185) done accuracy:0.758333 logloss:0.498196\n",
      "I0000 00:00:1729625095.930642 6790946 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.498196\n",
      "I0000 00:00:1729625095.931130 6790946 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk_lh3e4_ with prefix c26e439689d74919\n",
      "I0000 00:00:1729625095.933637 6790946 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625095.934266 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.498196\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  14  53\n",
      "Total: 120\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.022355\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqngfgfww as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 20:24:55.940078: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk_lh3e4_/model/ with prefix c26e439689d74919\n",
      "I0000 00:00:1729625095.945890 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4500 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:55.945912: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145110. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.025490\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpujltookl as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625096.230190 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625096.230199 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625096.230206 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625096.230281 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625096.230286 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625096.230329 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.230339 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.230344 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.230349 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.230391 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625096.230418 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625096.230563 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625096.230587 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqngfgfww/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625096.230639 6791014 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625096.230734 6791014 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625096.231150 6791027 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.697674 logloss:10.8969\n",
      "I0000 00:00:1729625096.231342 6791024 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.711864 logloss:3.10494\n",
      "I0000 00:00:1729625096.231518 6791030 random_forest.cc:812] Training of tree  21/200 (tree index:17) done accuracy:0.733333 logloss:0.552054\n",
      "I0000 00:00:1729625096.231723 6791025 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.7 logloss:0.55814\n",
      "I0000 00:00:1729625096.231953 6791025 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.733333 logloss:0.537254\n",
      "I0000 00:00:1729625096.232152 6791023 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.725 logloss:0.551522\n",
      "I0000 00:00:1729625096.232525 6791024 random_forest.cc:812] Training of tree  61/200 (tree index:60) done accuracy:0.75 logloss:0.545598\n",
      "I0000 00:00:1729625096.232951 6791027 random_forest.cc:812] Training of tree  71/200 (tree index:70) done accuracy:0.716667 logloss:0.550591\n",
      "I0000 00:00:1729625096.233237 6791028 random_forest.cc:812] Training of tree  81/200 (tree index:80) done accuracy:0.75 logloss:0.544184\n",
      "I0000 00:00:1729625096.233515 6791025 random_forest.cc:812] Training of tree  91/200 (tree index:90) done accuracy:0.716667 logloss:0.54322\n",
      "I0000 00:00:1729625096.233772 6791023 random_forest.cc:812] Training of tree  101/200 (tree index:100) done accuracy:0.725 logloss:0.539286\n",
      "I0000 00:00:1729625096.234079 6791028 random_forest.cc:812] Training of tree  111/200 (tree index:110) done accuracy:0.716667 logloss:0.538481\n",
      "I0000 00:00:1729625096.234417 6791027 random_forest.cc:812] Training of tree  121/200 (tree index:120) done accuracy:0.708333 logloss:0.541822\n",
      "I0000 00:00:1729625096.234632 6791027 random_forest.cc:812] Training of tree  131/200 (tree index:130) done accuracy:0.716667 logloss:0.549339\n",
      "I0000 00:00:1729625096.234863 6791028 random_forest.cc:812] Training of tree  141/200 (tree index:141) done accuracy:0.716667 logloss:0.543215\n",
      "I0000 00:00:1729625096.235068 6791028 random_forest.cc:812] Training of tree  151/200 (tree index:150) done accuracy:0.725 logloss:0.544636\n",
      "I0000 00:00:1729625096.235293 6791026 random_forest.cc:812] Training of tree  161/200 (tree index:160) done accuracy:0.725 logloss:0.544521\n",
      "I0000 00:00:1729625096.235529 6791027 random_forest.cc:812] Training of tree  171/200 (tree index:171) done accuracy:0.725 logloss:0.540284\n",
      "I0000 00:00:1729625096.235752 6791024 random_forest.cc:812] Training of tree  181/200 (tree index:181) done accuracy:0.733333 logloss:0.538708\n",
      "I0000 00:00:1729625096.236017 6791024 random_forest.cc:812] Training of tree  191/200 (tree index:190) done accuracy:0.741667 logloss:0.540447\n",
      "I0000 00:00:1729625096.236336 6791025 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.741667 logloss:0.542373\n",
      "I0000 00:00:1729625096.236422 6791014 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.542373\n",
      "I0000 00:00:1729625096.236965 6791014 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqngfgfww with prefix 7230004810764737\n",
      "I0000 00:00:1729625096.239497 6791014 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625096.240451 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.542373\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  16\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:56.246582: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqngfgfww/model/ with prefix 7230004810764737\n",
      "I0000 00:00:1729625096.252986 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4606 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:56.253014: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.196683. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022300\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdxs7mw9c as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625096.597280 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625096.597294 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625096.597298 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625096.597363 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625096.597368 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625096.597413 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.597423 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.597428 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.597433 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.597461 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625096.597481 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625096.597621 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625096.597646 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpujltookl/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625096.597719 6791089 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625096.597818 6791089 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625096.598264 6791099 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625096.598413 6791101 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.715517 logloss:3.71002\n",
      "I0000 00:00:1729625096.598573 6791099 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.8 logloss:0.98696\n",
      "I0000 00:00:1729625096.598758 6791102 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.816667 logloss:0.41638\n",
      "I0000 00:00:1729625096.598914 6791101 random_forest.cc:812] Training of tree  41/200 (tree index:39) done accuracy:0.8 logloss:0.433176\n",
      "I0000 00:00:1729625096.599107 6791099 random_forest.cc:812] Training of tree  51/200 (tree index:53) done accuracy:0.808333 logloss:0.431175\n",
      "I0000 00:00:1729625096.599300 6791105 random_forest.cc:812] Training of tree  62/200 (tree index:60) done accuracy:0.766667 logloss:0.43546\n",
      "I0000 00:00:1729625096.599514 6791105 random_forest.cc:812] Training of tree  73/200 (tree index:72) done accuracy:0.766667 logloss:0.444779\n",
      "I0000 00:00:1729625096.599716 6791103 random_forest.cc:812] Training of tree  83/200 (tree index:82) done accuracy:0.791667 logloss:0.45104\n",
      "I0000 00:00:1729625096.599891 6791099 random_forest.cc:812] Training of tree  93/200 (tree index:93) done accuracy:0.783333 logloss:0.449536\n",
      "I0000 00:00:1729625096.600071 6791104 random_forest.cc:812] Training of tree  103/200 (tree index:102) done accuracy:0.8 logloss:0.454158\n",
      "I0000 00:00:1729625096.600310 6791100 random_forest.cc:812] Training of tree  113/200 (tree index:89) done accuracy:0.783333 logloss:0.45122\n",
      "I0000 00:00:1729625096.600574 6791101 random_forest.cc:812] Training of tree  123/200 (tree index:121) done accuracy:0.8 logloss:0.454499\n",
      "I0000 00:00:1729625096.600943 6791101 random_forest.cc:812] Training of tree  133/200 (tree index:133) done accuracy:0.791667 logloss:0.447626\n",
      "I0000 00:00:1729625096.601218 6791102 random_forest.cc:812] Training of tree  145/200 (tree index:143) done accuracy:0.8 logloss:0.446436\n",
      "I0000 00:00:1729625096.601508 6791099 random_forest.cc:812] Training of tree  155/200 (tree index:155) done accuracy:0.8 logloss:0.447494\n",
      "I0000 00:00:1729625096.601744 6791098 random_forest.cc:812] Training of tree  165/200 (tree index:166) done accuracy:0.8 logloss:0.445367\n",
      "I0000 00:00:1729625096.602003 6791100 random_forest.cc:812] Training of tree  175/200 (tree index:171) done accuracy:0.8 logloss:0.449886\n",
      "I0000 00:00:1729625096.602149 6791099 random_forest.cc:812] Training of tree  185/200 (tree index:184) done accuracy:0.783333 logloss:0.455364\n",
      "I0000 00:00:1729625096.602307 6791101 random_forest.cc:812] Training of tree  195/200 (tree index:194) done accuracy:0.783333 logloss:0.456234\n",
      "I0000 00:00:1729625096.602413 6791098 random_forest.cc:812] Training of tree  200/200 (tree index:196) done accuracy:0.783333 logloss:0.458263\n",
      "I0000 00:00:1729625096.602477 6791089 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.458263\n",
      "I0000 00:00:1729625096.602935 6791089 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpujltookl with prefix 325a2635cf624cea\n",
      "I0000 00:00:1729625096.605162 6791089 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625096.605828 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.458263\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:56.611738: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpujltookl/model/ with prefix 325a2635cf624cea\n",
      "I0000 00:00:1729625096.617263 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4132 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:56.617288: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.153135. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022265\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 20, 'min_examples': 5, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpc1cxmhu4 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625096.920756 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625096.920766 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625096.920771 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625096.920831 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625096.920835 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625096.920879 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.920889 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.920894 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.920900 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625096.920926 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625096.920943 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625096.921069 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625096.921091 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdxs7mw9c/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625096.921150 6791163 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625096.921264 6791163 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625096.921727 6791177 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625096.921933 6791174 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.672269 logloss:3.96588\n",
      "I0000 00:00:1729625096.922129 6791172 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.691667 logloss:2.21691\n",
      "I0000 00:00:1729625096.922370 6791178 random_forest.cc:812] Training of tree  33/200 (tree index:32) done accuracy:0.766667 logloss:1.06125\n",
      "I0000 00:00:1729625096.922595 6791178 random_forest.cc:812] Training of tree  43/200 (tree index:42) done accuracy:0.775 logloss:0.780205\n",
      "I0000 00:00:1729625096.922849 6791178 random_forest.cc:812] Training of tree  53/200 (tree index:53) done accuracy:0.783333 logloss:0.48111\n",
      "I0000 00:00:1729625096.923038 6791175 random_forest.cc:812] Training of tree  63/200 (tree index:63) done accuracy:0.8 logloss:0.4822\n",
      "I0000 00:00:1729625096.923254 6791179 random_forest.cc:812] Training of tree  74/200 (tree index:74) done accuracy:0.791667 logloss:0.483139\n",
      "I0000 00:00:1729625096.923448 6791174 random_forest.cc:812] Training of tree  84/200 (tree index:84) done accuracy:0.783333 logloss:0.477747\n",
      "I0000 00:00:1729625096.923604 6791173 random_forest.cc:812] Training of tree  94/200 (tree index:93) done accuracy:0.783333 logloss:0.471643\n",
      "I0000 00:00:1729625096.923845 6791176 random_forest.cc:812] Training of tree  104/200 (tree index:103) done accuracy:0.783333 logloss:0.479852\n",
      "I0000 00:00:1729625096.923984 6791173 random_forest.cc:812] Training of tree  115/200 (tree index:115) done accuracy:0.775 logloss:0.487386\n",
      "I0000 00:00:1729625096.924184 6791178 random_forest.cc:812] Training of tree  125/200 (tree index:124) done accuracy:0.783333 logloss:0.488945\n",
      "I0000 00:00:1729625096.924343 6791179 random_forest.cc:812] Training of tree  135/200 (tree index:133) done accuracy:0.775 logloss:0.486993\n",
      "I0000 00:00:1729625096.924508 6791175 random_forest.cc:812] Training of tree  145/200 (tree index:144) done accuracy:0.775 logloss:0.493573\n",
      "I0000 00:00:1729625096.924674 6791173 random_forest.cc:812] Training of tree  155/200 (tree index:152) done accuracy:0.775 logloss:0.491824\n",
      "I0000 00:00:1729625096.924847 6791177 random_forest.cc:812] Training of tree  165/200 (tree index:165) done accuracy:0.766667 logloss:0.493181\n",
      "I0000 00:00:1729625096.925015 6791179 random_forest.cc:812] Training of tree  175/200 (tree index:177) done accuracy:0.766667 logloss:0.492531\n",
      "I0000 00:00:1729625096.925170 6791177 random_forest.cc:812] Training of tree  185/200 (tree index:184) done accuracy:0.766667 logloss:0.494911\n",
      "I0000 00:00:1729625096.925432 6791173 random_forest.cc:812] Training of tree  195/200 (tree index:194) done accuracy:0.766667 logloss:0.494131\n",
      "I0000 00:00:1729625096.925508 6791172 random_forest.cc:812] Training of tree  200/200 (tree index:198) done accuracy:0.766667 logloss:0.489188\n",
      "I0000 00:00:1729625096.925565 6791163 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.489188\n",
      "I0000 00:00:1729625096.926046 6791163 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdxs7mw9c with prefix 1f759ed495f54b4d\n",
      "I0000 00:00:1729625096.928547 6791163 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625096.929255 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.489188\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  12\n",
      "2  16  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:56.934813: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdxs7mw9c/model/ with prefix 1f759ed495f54b4d\n",
      "I0000 00:00:1729625096.940500 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4372 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:56.940526: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147168. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023876\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625097.234500 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625097.234509 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625097.234517 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625097.234584 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625097.234590 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625097.234635 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.234645 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.234651 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.234656 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.234683 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625097.234719 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625097.234862 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625097.234886 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpc1cxmhu4/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625097.234943 6791232 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625097.235036 6791232 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625097.235560 6791246 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625097.235735 6791246 random_forest.cc:812] Training of tree  11/200 (tree index:8) done accuracy:0.714286 logloss:2.83445\n",
      "I0000 00:00:1729625097.235977 6791241 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.741667 logloss:1.08536\n",
      "I0000 00:00:1729625097.236182 6791242 random_forest.cc:812] Training of tree  31/200 (tree index:29) done accuracy:0.758333 logloss:0.497528\n",
      "I0000 00:00:1729625097.236467 6791245 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.7 logloss:0.561242\n",
      "I0000 00:00:1729625097.236699 6791247 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.666667 logloss:0.57008\n",
      "I0000 00:00:1729625097.236924 6791245 random_forest.cc:812] Training of tree  61/200 (tree index:63) done accuracy:0.708333 logloss:0.542716\n",
      "I0000 00:00:1729625097.237108 6791246 random_forest.cc:812] Training of tree  71/200 (tree index:62) done accuracy:0.7 logloss:0.5457\n",
      "I0000 00:00:1729625097.237225 6791248 random_forest.cc:812] Training of tree  81/200 (tree index:81) done accuracy:0.708333 logloss:0.546783\n",
      "I0000 00:00:1729625097.237452 6791248 random_forest.cc:812] Training of tree  91/200 (tree index:91) done accuracy:0.708333 logloss:0.542394\n",
      "I0000 00:00:1729625097.237680 6791241 random_forest.cc:812] Training of tree  102/200 (tree index:100) done accuracy:0.716667 logloss:0.5382\n",
      "I0000 00:00:1729625097.237949 6791247 random_forest.cc:812] Training of tree  112/200 (tree index:112) done accuracy:0.716667 logloss:0.54063\n",
      "I0000 00:00:1729625097.238120 6791247 random_forest.cc:812] Training of tree  122/200 (tree index:124) done accuracy:0.741667 logloss:0.53368\n",
      "I0000 00:00:1729625097.238266 6791243 random_forest.cc:812] Training of tree  132/200 (tree index:133) done accuracy:0.741667 logloss:0.530967\n",
      "I0000 00:00:1729625097.238426 6791245 random_forest.cc:812] Training of tree  142/200 (tree index:142) done accuracy:0.733333 logloss:0.52606\n",
      "I0000 00:00:1729625097.238656 6791245 random_forest.cc:812] Training of tree  153/200 (tree index:155) done accuracy:0.733333 logloss:0.52633\n",
      "I0000 00:00:1729625097.238821 6791241 random_forest.cc:812] Training of tree  163/200 (tree index:163) done accuracy:0.741667 logloss:0.5303\n",
      "I0000 00:00:1729625097.238956 6791247 random_forest.cc:812] Training of tree  174/200 (tree index:175) done accuracy:0.733333 logloss:0.526725\n",
      "I0000 00:00:1729625097.239110 6791244 random_forest.cc:812] Training of tree  184/200 (tree index:184) done accuracy:0.741667 logloss:0.521933\n",
      "I0000 00:00:1729625097.239247 6791245 random_forest.cc:812] Training of tree  194/200 (tree index:195) done accuracy:0.725 logloss:0.521771\n",
      "I0000 00:00:1729625097.239356 6791242 random_forest.cc:812] Training of tree  200/200 (tree index:187) done accuracy:0.733333 logloss:0.518974\n",
      "I0000 00:00:1729625097.239443 6791232 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.518974\n",
      "I0000 00:00:1729625097.240004 6791232 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpc1cxmhu4 with prefix 70a611d0c5cc49c0\n",
      "I0000 00:00:1729625097.242214 6791232 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625097.242871 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.518974\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:57.248878: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpc1cxmhu4/model/ with prefix 70a611d0c5cc49c0\n",
      "I0000 00:00:1729625097.255684 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3776 node(s), and 19 input feature(s).\n",
      "I0000 00:00:1729625097.255703 6784195 abstract_model.cc:1323] Engine \"RandomForestOptPred\" built\n",
      "2024-10-22 20:24:57.255709: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpkumfwre0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.160906. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022680\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625097.610804 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625097.610814 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625097.610819 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625097.610886 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625097.610892 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625097.610941 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.610951 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.610956 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.610962 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.611009 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625097.611054 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625097.611225 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625097.611261 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpkumfwre0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625097.611305 6791307 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625097.611394 6791307 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625097.611851 6791320 random_forest.cc:812] Training of tree  1/200 (tree index:4) done accuracy:0.660714 logloss:12.2291\n",
      "I0000 00:00:1729625097.612031 6791319 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.672269 logloss:4.31189\n",
      "I0000 00:00:1729625097.612236 6791320 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.691667 logloss:1.18108\n",
      "I0000 00:00:1729625097.612421 6791318 random_forest.cc:812] Training of tree  31/200 (tree index:29) done accuracy:0.716667 logloss:0.603041\n",
      "I0000 00:00:1729625097.612592 6791321 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.691667 logloss:0.580194\n",
      "I0000 00:00:1729625097.612762 6791318 random_forest.cc:812] Training of tree  52/200 (tree index:51) done accuracy:0.7 logloss:0.564357\n",
      "I0000 00:00:1729625097.612968 6791322 random_forest.cc:812] Training of tree  63/200 (tree index:62) done accuracy:0.725 logloss:0.565872\n",
      "I0000 00:00:1729625097.613134 6791316 random_forest.cc:812] Training of tree  73/200 (tree index:73) done accuracy:0.716667 logloss:0.57081\n",
      "I0000 00:00:1729625097.613305 6791319 random_forest.cc:812] Training of tree  83/200 (tree index:82) done accuracy:0.733333 logloss:0.559655\n",
      "I0000 00:00:1729625097.613433 6791323 random_forest.cc:812] Training of tree  93/200 (tree index:93) done accuracy:0.725 logloss:0.560241\n",
      "I0000 00:00:1729625097.613644 6791318 random_forest.cc:812] Training of tree  103/200 (tree index:105) done accuracy:0.716667 logloss:0.549737\n",
      "I0000 00:00:1729625097.613853 6791321 random_forest.cc:812] Training of tree  113/200 (tree index:112) done accuracy:0.716667 logloss:0.553502\n",
      "I0000 00:00:1729625097.614125 6791318 random_forest.cc:812] Training of tree  123/200 (tree index:116) done accuracy:0.75 logloss:0.547055\n",
      "I0000 00:00:1729625097.614329 6791316 random_forest.cc:812] Training of tree  134/200 (tree index:134) done accuracy:0.75 logloss:0.551103\n",
      "I0000 00:00:1729625097.614524 6791316 random_forest.cc:812] Training of tree  144/200 (tree index:144) done accuracy:0.766667 logloss:0.552149\n",
      "I0000 00:00:1729625097.614741 6791317 random_forest.cc:812] Training of tree  154/200 (tree index:147) done accuracy:0.766667 logloss:0.55007\n",
      "I0000 00:00:1729625097.614950 6791319 random_forest.cc:812] Training of tree  166/200 (tree index:167) done accuracy:0.766667 logloss:0.547998\n",
      "I0000 00:00:1729625097.615107 6791318 random_forest.cc:812] Training of tree  176/200 (tree index:176) done accuracy:0.775 logloss:0.546063\n",
      "I0000 00:00:1729625097.615287 6791320 random_forest.cc:812] Training of tree  186/200 (tree index:185) done accuracy:0.783333 logloss:0.544655\n",
      "I0000 00:00:1729625097.615469 6791319 random_forest.cc:812] Training of tree  196/200 (tree index:198) done accuracy:0.783333 logloss:0.542035\n",
      "I0000 00:00:1729625097.615521 6791321 random_forest.cc:812] Training of tree  200/200 (tree index:189) done accuracy:0.775 logloss:0.541575\n",
      "I0000 00:00:1729625097.615581 6791307 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.541575\n",
      "I0000 00:00:1729625097.615995 6791307 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpkumfwre0 with prefix 88cfeafbfd934add\n",
      "I0000 00:00:1729625097.618082 6791307 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625097.618802 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.541575\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:57.625698: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpkumfwre0/model/ with prefix 88cfeafbfd934add\n",
      "I0000 00:00:1729625097.631073 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3862 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:57.631096: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy10hcl51 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.155094. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021703\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625097.937534 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625097.937544 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625097.937550 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625097.937617 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625097.937623 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625097.937668 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.937677 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.937682 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.937687 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625097.937715 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625097.937732 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625097.937868 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625097.937894 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy10hcl51/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625097.937946 6791382 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625097.938048 6791382 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625097.938502 6791397 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.660377 logloss:12.2412\n",
      "I0000 00:00:1729625097.938672 6791395 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.720339 logloss:3.17118\n",
      "I0000 00:00:1729625097.938855 6791391 random_forest.cc:812] Training of tree  21/200 (tree index:19) done accuracy:0.666667 logloss:1.46368\n",
      "I0000 00:00:1729625097.939003 6791394 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.708333 logloss:0.568991\n",
      "I0000 00:00:1729625097.939168 6791395 random_forest.cc:812] Training of tree  41/200 (tree index:42) done accuracy:0.725 logloss:0.549939\n",
      "I0000 00:00:1729625097.939344 6791395 random_forest.cc:812] Training of tree  51/200 (tree index:51) done accuracy:0.75 logloss:0.558905\n",
      "I0000 00:00:1729625097.939491 6791393 random_forest.cc:812] Training of tree  61/200 (tree index:61) done accuracy:0.766667 logloss:0.54449\n",
      "I0000 00:00:1729625097.939674 6791394 random_forest.cc:812] Training of tree  71/200 (tree index:70) done accuracy:0.783333 logloss:0.547818\n",
      "I0000 00:00:1729625097.939810 6791395 random_forest.cc:812] Training of tree  81/200 (tree index:80) done accuracy:0.783333 logloss:0.540136\n",
      "I0000 00:00:1729625097.939943 6791394 random_forest.cc:812] Training of tree  91/200 (tree index:89) done accuracy:0.791667 logloss:0.533316\n",
      "I0000 00:00:1729625097.940126 6791392 random_forest.cc:812] Training of tree  101/200 (tree index:101) done accuracy:0.791667 logloss:0.529631\n",
      "I0000 00:00:1729625097.940276 6791396 random_forest.cc:812] Training of tree  111/200 (tree index:110) done accuracy:0.8 logloss:0.521952\n",
      "I0000 00:00:1729625097.940461 6791397 random_forest.cc:812] Training of tree  121/200 (tree index:119) done accuracy:0.783333 logloss:0.525184\n",
      "I0000 00:00:1729625097.940600 6791391 random_forest.cc:812] Training of tree  131/200 (tree index:129) done accuracy:0.783333 logloss:0.520212\n",
      "I0000 00:00:1729625097.940749 6791394 random_forest.cc:812] Training of tree  141/200 (tree index:141) done accuracy:0.758333 logloss:0.524239\n",
      "I0000 00:00:1729625097.941030 6791395 random_forest.cc:812] Training of tree  152/200 (tree index:154) done accuracy:0.775 logloss:0.522472\n",
      "I0000 00:00:1729625097.941288 6791398 random_forest.cc:812] Training of tree  162/200 (tree index:162) done accuracy:0.775 logloss:0.524438\n",
      "I0000 00:00:1729625097.941533 6791392 random_forest.cc:812] Training of tree  172/200 (tree index:173) done accuracy:0.783333 logloss:0.527056\n",
      "I0000 00:00:1729625097.941874 6791396 random_forest.cc:812] Training of tree  182/200 (tree index:169) done accuracy:0.783333 logloss:0.527294\n",
      "I0000 00:00:1729625097.942038 6791392 random_forest.cc:812] Training of tree  192/200 (tree index:193) done accuracy:0.783333 logloss:0.524579\n",
      "I0000 00:00:1729625097.942185 6791396 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.783333 logloss:0.524861\n",
      "I0000 00:00:1729625097.942226 6791382 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.524861\n",
      "I0000 00:00:1729625097.942651 6791382 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy10hcl51 with prefix 18dac7828abf4e2e\n",
      "I0000 00:00:1729625097.944714 6791382 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625097.945368 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.524861\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  15\n",
      "2  11  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:57.951709: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy10hcl51/model/ with prefix 18dac7828abf4e2e\n",
      "I0000 00:00:1729625097.957076 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3900 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:57.957095: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp8sb23pei as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.421027. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022735\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg9243l2f as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625098.577426 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625098.577436 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625098.577441 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625098.577517 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625098.577523 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625098.577575 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625098.577585 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625098.577591 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625098.577596 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625098.577625 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625098.577644 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625098.577822 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625098.577847 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp8sb23pei/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625098.577902 6791460 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625098.578019 6791460 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625098.578549 6791475 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625098.578748 6791471 random_forest.cc:812] Training of tree  12/200 (tree index:12) done accuracy:0.677966 logloss:3.44578\n",
      "I0000 00:00:1729625098.578964 6791470 random_forest.cc:812] Training of tree  22/200 (tree index:23) done accuracy:0.741667 logloss:1.34895\n",
      "I0000 00:00:1729625098.579275 6791475 random_forest.cc:812] Training of tree  32/200 (tree index:33) done accuracy:0.766667 logloss:1.04645\n",
      "I0000 00:00:1729625098.579487 6791472 random_forest.cc:812] Training of tree  42/200 (tree index:40) done accuracy:0.75 logloss:0.483176\n",
      "I0000 00:00:1729625098.579623 6791469 random_forest.cc:812] Training of tree  53/200 (tree index:53) done accuracy:0.758333 logloss:0.495558\n",
      "I0000 00:00:1729625098.579833 6791472 random_forest.cc:812] Training of tree  63/200 (tree index:63) done accuracy:0.766667 logloss:0.491722\n",
      "I0000 00:00:1729625098.579965 6791469 random_forest.cc:812] Training of tree  73/200 (tree index:73) done accuracy:0.775 logloss:0.491506\n",
      "I0000 00:00:1729625098.580138 6791474 random_forest.cc:812] Training of tree  83/200 (tree index:83) done accuracy:0.75 logloss:0.487543\n",
      "I0000 00:00:1729625098.580294 6791475 random_forest.cc:812] Training of tree  93/200 (tree index:93) done accuracy:0.766667 logloss:0.476886\n",
      "I0000 00:00:1729625098.580467 6791475 random_forest.cc:812] Training of tree  103/200 (tree index:104) done accuracy:0.766667 logloss:0.473739\n",
      "I0000 00:00:1729625098.580659 6791469 random_forest.cc:812] Training of tree  113/200 (tree index:112) done accuracy:0.775 logloss:0.479944\n",
      "I0000 00:00:1729625098.580910 6791474 random_forest.cc:812] Training of tree  123/200 (tree index:123) done accuracy:0.791667 logloss:0.48101\n",
      "I0000 00:00:1729625098.581072 6791472 random_forest.cc:812] Training of tree  133/200 (tree index:132) done accuracy:0.791667 logloss:0.479238\n",
      "I0000 00:00:1729625098.581232 6791474 random_forest.cc:812] Training of tree  143/200 (tree index:141) done accuracy:0.791667 logloss:0.474743\n",
      "I0000 00:00:1729625098.581376 6791471 random_forest.cc:812] Training of tree  153/200 (tree index:152) done accuracy:0.783333 logloss:0.477375\n",
      "I0000 00:00:1729625098.581530 6791473 random_forest.cc:812] Training of tree  164/200 (tree index:163) done accuracy:0.783333 logloss:0.476691\n",
      "I0000 00:00:1729625098.581749 6791474 random_forest.cc:812] Training of tree  174/200 (tree index:173) done accuracy:0.775 logloss:0.477318\n",
      "I0000 00:00:1729625098.581918 6791472 random_forest.cc:812] Training of tree  186/200 (tree index:186) done accuracy:0.775 logloss:0.478596\n",
      "I0000 00:00:1729625098.582097 6791473 random_forest.cc:812] Training of tree  196/200 (tree index:195) done accuracy:0.783333 logloss:0.479873\n",
      "I0000 00:00:1729625098.582158 6791474 random_forest.cc:812] Training of tree  200/200 (tree index:196) done accuracy:0.783333 logloss:0.479409\n",
      "I0000 00:00:1729625098.582223 6791460 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.479409\n",
      "I0000 00:00:1729625098.582690 6791460 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp8sb23pei with prefix 7445899c010d4eaf\n",
      "I0000 00:00:1729625098.585107 6791460 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625098.585883 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.479409\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:58.592220: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp8sb23pei/model/ with prefix 7445899c010d4eaf\n",
      "I0000 00:00:1729625098.597481 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3526 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:58.597501: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.162781. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022794\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 20, 'min_examples': 10, 'bootstrap_size_ratio': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625098.922100 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625098.922111 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625098.922115 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625098.922178 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625098.922182 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625098.922226 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625098.922237 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625098.922243 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625098.922248 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625098.922274 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625098.922293 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625098.922424 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625098.922448 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg9243l2f/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625098.922518 6791540 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625098.922606 6791540 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625098.923069 6791549 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.641509 logloss:12.9213\n",
      "I0000 00:00:1729625098.923315 6791553 random_forest.cc:812] Training of tree  11/200 (tree index:3) done accuracy:0.766667 logloss:2.42863\n",
      "I0000 00:00:1729625098.923557 6791553 random_forest.cc:812] Training of tree  21/200 (tree index:17) done accuracy:0.725 logloss:0.758601\n",
      "I0000 00:00:1729625098.923760 6791551 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.75 logloss:0.739381\n",
      "I0000 00:00:1729625098.923991 6791553 random_forest.cc:812] Training of tree  41/200 (tree index:42) done accuracy:0.758333 logloss:0.476964\n",
      "I0000 00:00:1729625098.924183 6791554 random_forest.cc:812] Training of tree  51/200 (tree index:51) done accuracy:0.775 logloss:0.475368\n",
      "I0000 00:00:1729625098.924371 6791549 random_forest.cc:812] Training of tree  61/200 (tree index:61) done accuracy:0.766667 logloss:0.470757\n",
      "I0000 00:00:1729625098.924580 6791555 random_forest.cc:812] Training of tree  71/200 (tree index:72) done accuracy:0.766667 logloss:0.476321\n",
      "I0000 00:00:1729625098.924734 6791554 random_forest.cc:812] Training of tree  81/200 (tree index:71) done accuracy:0.775 logloss:0.467994\n",
      "I0000 00:00:1729625098.924893 6791556 random_forest.cc:812] Training of tree  91/200 (tree index:91) done accuracy:0.783333 logloss:0.453258\n",
      "I0000 00:00:1729625098.925072 6791550 random_forest.cc:812] Training of tree  101/200 (tree index:103) done accuracy:0.808333 logloss:0.452657\n",
      "I0000 00:00:1729625098.925355 6791550 random_forest.cc:812] Training of tree  111/200 (tree index:111) done accuracy:0.8 logloss:0.459014\n",
      "I0000 00:00:1729625098.925542 6791550 random_forest.cc:812] Training of tree  121/200 (tree index:122) done accuracy:0.783333 logloss:0.462626\n",
      "I0000 00:00:1729625098.925738 6791554 random_forest.cc:812] Training of tree  131/200 (tree index:124) done accuracy:0.791667 logloss:0.464054\n",
      "I0000 00:00:1729625098.925937 6791556 random_forest.cc:812] Training of tree  141/200 (tree index:142) done accuracy:0.783333 logloss:0.466924\n",
      "I0000 00:00:1729625098.926128 6791552 random_forest.cc:812] Training of tree  151/200 (tree index:150) done accuracy:0.775 logloss:0.471477\n",
      "I0000 00:00:1729625098.926319 6791552 random_forest.cc:812] Training of tree  161/200 (tree index:160) done accuracy:0.783333 logloss:0.472456\n",
      "I0000 00:00:1729625098.926509 6791553 random_forest.cc:812] Training of tree  172/200 (tree index:159) done accuracy:0.783333 logloss:0.473627\n",
      "I0000 00:00:1729625098.926651 6791549 random_forest.cc:812] Training of tree  182/200 (tree index:177) done accuracy:0.783333 logloss:0.476267\n",
      "I0000 00:00:1729625098.926897 6791550 random_forest.cc:812] Training of tree  192/200 (tree index:192) done accuracy:0.766667 logloss:0.47332\n",
      "I0000 00:00:1729625098.927244 6791550 random_forest.cc:812] Training of tree  200/200 (tree index:196) done accuracy:0.766667 logloss:0.475475\n",
      "I0000 00:00:1729625098.927339 6791540 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.475475\n",
      "I0000 00:00:1729625098.927762 6791540 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg9243l2f with prefix 949c1a570ac24ce0\n",
      "I0000 00:00:1729625098.929806 6791540 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625098.930510 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.475475\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:58.936813: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg9243l2f/model/ with prefix 949c1a570ac24ce0\n",
      "I0000 00:00:1729625098.942121 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3668 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:58.942147: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqzc53p7e as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.157830. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018578\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625099.302922 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625099.302935 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625099.302940 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625099.303004 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625099.303008 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625099.303053 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625099.303064 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625099.303070 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625099.303075 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625099.303102 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625099.303119 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625099.303252 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625099.303275 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqzc53p7e/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625099.303320 6791615 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625099.303453 6791615 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625099.303944 6791630 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625099.304136 6791629 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.689076 logloss:4.86561\n",
      "I0000 00:00:1729625099.304331 6791624 random_forest.cc:812] Training of tree  23/200 (tree index:24) done accuracy:0.766667 logloss:1.4329\n",
      "I0000 00:00:1729625099.304581 6791626 random_forest.cc:812] Training of tree  33/200 (tree index:30) done accuracy:0.775 logloss:1.12026\n",
      "I0000 00:00:1729625099.304821 6791627 random_forest.cc:812] Training of tree  43/200 (tree index:42) done accuracy:0.758333 logloss:0.825131\n",
      "I0000 00:00:1729625099.304952 6791627 random_forest.cc:812] Training of tree  53/200 (tree index:50) done accuracy:0.733333 logloss:0.815506\n",
      "I0000 00:00:1729625099.305119 6791628 random_forest.cc:812] Training of tree  63/200 (tree index:64) done accuracy:0.733333 logloss:0.809501\n",
      "I0000 00:00:1729625099.305300 6791626 random_forest.cc:812] Training of tree  73/200 (tree index:53) done accuracy:0.716667 logloss:0.807516\n",
      "I0000 00:00:1729625099.305464 6791629 random_forest.cc:812] Training of tree  83/200 (tree index:83) done accuracy:0.716667 logloss:0.811729\n",
      "I0000 00:00:1729625099.305607 6791626 random_forest.cc:812] Training of tree  93/200 (tree index:93) done accuracy:0.708333 logloss:0.548161\n",
      "I0000 00:00:1729625099.305778 6791631 random_forest.cc:812] Training of tree  104/200 (tree index:103) done accuracy:0.716667 logloss:0.54711\n",
      "I0000 00:00:1729625099.305922 6791626 random_forest.cc:812] Training of tree  114/200 (tree index:114) done accuracy:0.716667 logloss:0.548142\n",
      "I0000 00:00:1729625099.306058 6791631 random_forest.cc:812] Training of tree  124/200 (tree index:124) done accuracy:0.725 logloss:0.542924\n",
      "I0000 00:00:1729625099.306215 6791627 random_forest.cc:812] Training of tree  134/200 (tree index:133) done accuracy:0.708333 logloss:0.546662\n",
      "I0000 00:00:1729625099.306392 6791627 random_forest.cc:812] Training of tree  144/200 (tree index:144) done accuracy:0.7 logloss:0.55629\n",
      "I0000 00:00:1729625099.306579 6791629 random_forest.cc:812] Training of tree  154/200 (tree index:153) done accuracy:0.708333 logloss:0.560806\n",
      "I0000 00:00:1729625099.306726 6791631 random_forest.cc:812] Training of tree  165/200 (tree index:164) done accuracy:0.708333 logloss:0.559095\n",
      "I0000 00:00:1729625099.306929 6791624 random_forest.cc:812] Training of tree  175/200 (tree index:173) done accuracy:0.708333 logloss:0.546995\n",
      "I0000 00:00:1729625099.307092 6791628 random_forest.cc:812] Training of tree  185/200 (tree index:187) done accuracy:0.691667 logloss:0.547269\n",
      "I0000 00:00:1729625099.307236 6791629 random_forest.cc:812] Training of tree  195/200 (tree index:195) done accuracy:0.7 logloss:0.549905\n",
      "I0000 00:00:1729625099.307311 6791631 random_forest.cc:812] Training of tree  200/200 (tree index:180) done accuracy:0.708333 logloss:0.548091\n",
      "I0000 00:00:1729625099.307377 6791615 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.548091\n",
      "I0000 00:00:1729625099.307711 6791615 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqzc53p7e with prefix bdb77c9e17714a4b\n",
      "I0000 00:00:1729625099.309538 6791615 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625099.310248 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.548091\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  18\n",
      "2  17  45\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:59.315432: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqzc53p7e/model/ with prefix bdb77c9e17714a4b\n",
      "I0000 00:00:1729625099.319371 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3054 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:59.319387: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpt4so4ljh as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.158980. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.020118\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625099.632525 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625099.632537 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625099.632542 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625099.632610 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625099.632614 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625099.632658 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625099.632671 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625099.632676 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625099.632682 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625099.632709 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625099.632727 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625099.632868 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625099.632895 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpt4so4ljh/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625099.632940 6791689 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625099.633068 6791689 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625099.633540 6791698 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.772727 logloss:8.19174\n",
      "I0000 00:00:1729625099.633730 6791705 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.693694 logloss:6.71775\n",
      "I0000 00:00:1729625099.633981 6791700 random_forest.cc:812] Training of tree  22/200 (tree index:22) done accuracy:0.75 logloss:1.08784\n",
      "I0000 00:00:1729625099.634173 6791698 random_forest.cc:812] Training of tree  32/200 (tree index:32) done accuracy:0.758333 logloss:1.06925\n",
      "I0000 00:00:1729625099.634354 6791699 random_forest.cc:812] Training of tree  42/200 (tree index:42) done accuracy:0.775 logloss:0.507053\n",
      "I0000 00:00:1729625099.634539 6791699 random_forest.cc:812] Training of tree  52/200 (tree index:53) done accuracy:0.758333 logloss:0.539795\n",
      "I0000 00:00:1729625099.634753 6791702 random_forest.cc:812] Training of tree  63/200 (tree index:63) done accuracy:0.758333 logloss:0.539412\n",
      "I0000 00:00:1729625099.634908 6791704 random_forest.cc:812] Training of tree  73/200 (tree index:73) done accuracy:0.783333 logloss:0.528507\n",
      "I0000 00:00:1729625099.635066 6791700 random_forest.cc:812] Training of tree  84/200 (tree index:77) done accuracy:0.766667 logloss:0.540333\n",
      "I0000 00:00:1729625099.635230 6791702 random_forest.cc:812] Training of tree  94/200 (tree index:94) done accuracy:0.783333 logloss:0.520183\n",
      "I0000 00:00:1729625099.635423 6791698 random_forest.cc:812] Training of tree  104/200 (tree index:107) done accuracy:0.775 logloss:0.526686\n",
      "I0000 00:00:1729625099.635586 6791701 random_forest.cc:812] Training of tree  114/200 (tree index:113) done accuracy:0.75 logloss:0.53409\n",
      "I0000 00:00:1729625099.635718 6791704 random_forest.cc:812] Training of tree  124/200 (tree index:124) done accuracy:0.758333 logloss:0.526235\n",
      "I0000 00:00:1729625099.635868 6791703 random_forest.cc:812] Training of tree  134/200 (tree index:133) done accuracy:0.75 logloss:0.526543\n",
      "I0000 00:00:1729625099.636021 6791705 random_forest.cc:812] Training of tree  144/200 (tree index:145) done accuracy:0.733333 logloss:0.530768\n",
      "I0000 00:00:1729625099.636257 6791705 random_forest.cc:812] Training of tree  154/200 (tree index:158) done accuracy:0.75 logloss:0.532794\n",
      "I0000 00:00:1729625099.636402 6791704 random_forest.cc:812] Training of tree  164/200 (tree index:163) done accuracy:0.758333 logloss:0.535388\n",
      "I0000 00:00:1729625099.636587 6791704 random_forest.cc:812] Training of tree  174/200 (tree index:173) done accuracy:0.75 logloss:0.537039\n",
      "I0000 00:00:1729625099.636762 6791703 random_forest.cc:812] Training of tree  184/200 (tree index:183) done accuracy:0.741667 logloss:0.5366\n",
      "I0000 00:00:1729625099.636939 6791702 random_forest.cc:812] Training of tree  194/200 (tree index:194) done accuracy:0.741667 logloss:0.538755\n",
      "I0000 00:00:1729625099.637039 6791702 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.775 logloss:0.544829\n",
      "I0000 00:00:1729625099.637085 6791689 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.544829\n",
      "I0000 00:00:1729625099.637447 6791689 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpt4so4ljh with prefix 6e088ee1ce2d4012\n",
      "I0000 00:00:1729625099.639264 6791689 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625099.640099 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.544829\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:24:59.646408: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpt4so4ljh/model/ with prefix 6e088ee1ce2d4012\n",
      "I0000 00:00:1729625099.650601 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3088 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:24:59.650626: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0oso57lr as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.154085. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022180\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625100.023641 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625100.023654 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625100.023658 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625100.023720 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625100.023724 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625100.023767 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.023778 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.023784 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.023789 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.023818 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625100.023835 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625100.023965 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625100.023987 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0oso57lr/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625100.024026 6791766 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625100.024241 6791766 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625100.024930 6791779 random_forest.cc:812] Training of tree  1/200 (tree index:2) done accuracy:0.682927 logloss:11.4285\n",
      "I0000 00:00:1729625100.025150 6791782 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.724138 logloss:2.24703\n",
      "I0000 00:00:1729625100.025405 6791777 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.7 logloss:0.842303\n",
      "I0000 00:00:1729625100.025571 6791776 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.716667 logloss:0.590105\n",
      "I0000 00:00:1729625100.025758 6791779 random_forest.cc:812] Training of tree  41/200 (tree index:33) done accuracy:0.7 logloss:0.595137\n",
      "I0000 00:00:1729625100.025974 6791778 random_forest.cc:812] Training of tree  52/200 (tree index:51) done accuracy:0.666667 logloss:0.595961\n",
      "I0000 00:00:1729625100.026124 6791781 random_forest.cc:812] Training of tree  62/200 (tree index:62) done accuracy:0.691667 logloss:0.590036\n",
      "I0000 00:00:1729625100.026266 6791778 random_forest.cc:812] Training of tree  72/200 (tree index:70) done accuracy:0.7 logloss:0.596467\n",
      "I0000 00:00:1729625100.026419 6791781 random_forest.cc:812] Training of tree  82/200 (tree index:82) done accuracy:0.716667 logloss:0.589362\n",
      "I0000 00:00:1729625100.026578 6791776 random_forest.cc:812] Training of tree  92/200 (tree index:83) done accuracy:0.733333 logloss:0.592003\n",
      "I0000 00:00:1729625100.026718 6791778 random_forest.cc:812] Training of tree  102/200 (tree index:102) done accuracy:0.725 logloss:0.580487\n",
      "I0000 00:00:1729625100.026923 6791777 random_forest.cc:812] Training of tree  113/200 (tree index:100) done accuracy:0.725 logloss:0.585013\n",
      "I0000 00:00:1729625100.027072 6791778 random_forest.cc:812] Training of tree  123/200 (tree index:122) done accuracy:0.725 logloss:0.584682\n",
      "I0000 00:00:1729625100.027304 6791775 random_forest.cc:812] Training of tree  134/200 (tree index:129) done accuracy:0.725 logloss:0.58248\n",
      "I0000 00:00:1729625100.027478 6791780 random_forest.cc:812] Training of tree  144/200 (tree index:144) done accuracy:0.716667 logloss:0.583194\n",
      "I0000 00:00:1729625100.027639 6791781 random_forest.cc:812] Training of tree  154/200 (tree index:153) done accuracy:0.716667 logloss:0.584238\n",
      "I0000 00:00:1729625100.027845 6791775 random_forest.cc:812] Training of tree  164/200 (tree index:160) done accuracy:0.716667 logloss:0.577174\n",
      "I0000 00:00:1729625100.028035 6791780 random_forest.cc:812] Training of tree  174/200 (tree index:173) done accuracy:0.716667 logloss:0.574996\n",
      "I0000 00:00:1729625100.028200 6791775 random_forest.cc:812] Training of tree  184/200 (tree index:182) done accuracy:0.716667 logloss:0.570213\n",
      "I0000 00:00:1729625100.028344 6791780 random_forest.cc:812] Training of tree  194/200 (tree index:194) done accuracy:0.716667 logloss:0.572357\n",
      "I0000 00:00:1729625100.028448 6791778 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.716667 logloss:0.569787\n",
      "I0000 00:00:1729625100.028515 6791766 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.569787\n",
      "I0000 00:00:1729625100.028935 6791766 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0oso57lr with prefix f07db34e111d428d\n",
      "I0000 00:00:1729625100.031248 6791766 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625100.032043 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.569787\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  17  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:00.039527: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0oso57lr/model/ with prefix f07db34e111d428d\n",
      "I0000 00:00:1729625100.043781 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3078 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:00.043806: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqi0ny954 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.155243. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.019074\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625100.390132 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625100.390146 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625100.390151 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625100.390223 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625100.390228 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625100.390275 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.390288 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.390295 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.390301 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.390330 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625100.390348 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625100.390512 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625100.390536 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqi0ny954/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625100.390597 6791845 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625100.390694 6791845 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625100.391187 6791861 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.75 logloss:9.01091\n",
      "I0000 00:00:1729625100.391371 6791860 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.745614 logloss:3.16128\n",
      "I0000 00:00:1729625100.391595 6791861 random_forest.cc:812] Training of tree  21/200 (tree index:23) done accuracy:0.75 logloss:0.778518\n",
      "I0000 00:00:1729625100.391749 6791855 random_forest.cc:812] Training of tree  31/200 (tree index:18) done accuracy:0.741667 logloss:0.777011\n",
      "I0000 00:00:1729625100.392037 6791855 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.75 logloss:0.767433\n",
      "I0000 00:00:1729625100.392180 6791860 random_forest.cc:812] Training of tree  51/200 (tree index:53) done accuracy:0.733333 logloss:0.4856\n",
      "I0000 00:00:1729625100.392333 6791855 random_forest.cc:812] Training of tree  61/200 (tree index:60) done accuracy:0.758333 logloss:0.499381\n",
      "I0000 00:00:1729625100.392492 6791860 random_forest.cc:812] Training of tree  71/200 (tree index:72) done accuracy:0.758333 logloss:0.486675\n",
      "I0000 00:00:1729625100.392693 6791860 random_forest.cc:812] Training of tree  81/200 (tree index:80) done accuracy:0.775 logloss:0.490994\n",
      "I0000 00:00:1729625100.392843 6791859 random_forest.cc:812] Training of tree  91/200 (tree index:89) done accuracy:0.766667 logloss:0.482846\n",
      "I0000 00:00:1729625100.392999 6791857 random_forest.cc:812] Training of tree  101/200 (tree index:100) done accuracy:0.775 logloss:0.479806\n",
      "I0000 00:00:1729625100.393152 6791854 random_forest.cc:812] Training of tree  111/200 (tree index:109) done accuracy:0.783333 logloss:0.468791\n",
      "I0000 00:00:1729625100.393308 6791858 random_forest.cc:812] Training of tree  121/200 (tree index:123) done accuracy:0.783333 logloss:0.469109\n",
      "I0000 00:00:1729625100.393624 6791858 random_forest.cc:812] Training of tree  131/200 (tree index:131) done accuracy:0.791667 logloss:0.472352\n",
      "I0000 00:00:1729625100.393955 6791857 random_forest.cc:812] Training of tree  141/200 (tree index:142) done accuracy:0.791667 logloss:0.472101\n",
      "I0000 00:00:1729625100.394130 6791861 random_forest.cc:812] Training of tree  151/200 (tree index:149) done accuracy:0.791667 logloss:0.476612\n",
      "I0000 00:00:1729625100.394328 6791860 random_forest.cc:812] Training of tree  161/200 (tree index:162) done accuracy:0.791667 logloss:0.476378\n",
      "I0000 00:00:1729625100.394599 6791861 random_forest.cc:812] Training of tree  171/200 (tree index:172) done accuracy:0.8 logloss:0.481454\n",
      "I0000 00:00:1729625100.394785 6791858 random_forest.cc:812] Training of tree  181/200 (tree index:183) done accuracy:0.8 logloss:0.481544\n",
      "I0000 00:00:1729625100.394952 6791854 random_forest.cc:812] Training of tree  191/200 (tree index:192) done accuracy:0.791667 logloss:0.481941\n",
      "I0000 00:00:1729625100.395151 6791857 random_forest.cc:812] Training of tree  200/200 (tree index:195) done accuracy:0.791667 logloss:0.481198\n",
      "I0000 00:00:1729625100.395210 6791845 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.481198\n",
      "I0000 00:00:1729625100.395547 6791845 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqi0ny954 with prefix 1016ebe5eef642da\n",
      "I0000 00:00:1729625100.397453 6791845 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625100.398206 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.481198\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  11  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:00.403329: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqi0ny954/model/ with prefix 1016ebe5eef642da\n",
      "I0000 00:00:1729625100.407132 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2908 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:00.407148: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpcfn6d356 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.157236. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.020055\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625100.773122 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625100.773135 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625100.773142 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625100.773209 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625100.773216 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625100.773258 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.773267 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.773272 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.773277 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625100.773303 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625100.773320 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625100.773457 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625100.773480 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpcfn6d356/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625100.773547 6791914 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625100.773645 6791914 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625100.774210 6791927 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625100.774415 6791929 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.773109 logloss:2.74265\n",
      "I0000 00:00:1729625100.774575 6791928 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.741667 logloss:1.64824\n",
      "I0000 00:00:1729625100.774769 6791923 random_forest.cc:812] Training of tree  31/200 (tree index:29) done accuracy:0.741667 logloss:0.797208\n",
      "I0000 00:00:1729625100.774900 6791930 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.733333 logloss:0.793471\n",
      "I0000 00:00:1729625100.775085 6791923 random_forest.cc:812] Training of tree  51/200 (tree index:51) done accuracy:0.758333 logloss:0.483342\n",
      "I0000 00:00:1729625100.775317 6791925 random_forest.cc:812] Training of tree  63/200 (tree index:60) done accuracy:0.783333 logloss:0.483241\n",
      "I0000 00:00:1729625100.775608 6791929 random_forest.cc:812] Training of tree  73/200 (tree index:73) done accuracy:0.791667 logloss:0.489092\n",
      "I0000 00:00:1729625100.775814 6791926 random_forest.cc:812] Training of tree  83/200 (tree index:85) done accuracy:0.766667 logloss:0.487348\n",
      "I0000 00:00:1729625100.775961 6791928 random_forest.cc:812] Training of tree  93/200 (tree index:91) done accuracy:0.766667 logloss:0.489986\n",
      "I0000 00:00:1729625100.776149 6791923 random_forest.cc:812] Training of tree  103/200 (tree index:98) done accuracy:0.766667 logloss:0.49365\n",
      "I0000 00:00:1729625100.776304 6791930 random_forest.cc:812] Training of tree  113/200 (tree index:112) done accuracy:0.758333 logloss:0.494414\n",
      "I0000 00:00:1729625100.776511 6791923 random_forest.cc:812] Training of tree  123/200 (tree index:123) done accuracy:0.775 logloss:0.495021\n",
      "I0000 00:00:1729625100.776662 6791929 random_forest.cc:812] Training of tree  133/200 (tree index:134) done accuracy:0.758333 logloss:0.492073\n",
      "I0000 00:00:1729625100.776834 6791927 random_forest.cc:812] Training of tree  143/200 (tree index:144) done accuracy:0.75 logloss:0.498082\n",
      "I0000 00:00:1729625100.776989 6791923 random_forest.cc:812] Training of tree  154/200 (tree index:152) done accuracy:0.741667 logloss:0.499495\n",
      "I0000 00:00:1729625100.777185 6791923 random_forest.cc:812] Training of tree  165/200 (tree index:165) done accuracy:0.75 logloss:0.499846\n",
      "I0000 00:00:1729625100.777350 6791928 random_forest.cc:812] Training of tree  175/200 (tree index:174) done accuracy:0.758333 logloss:0.495633\n",
      "I0000 00:00:1729625100.777615 6791930 random_forest.cc:812] Training of tree  185/200 (tree index:183) done accuracy:0.75 logloss:0.496937\n",
      "I0000 00:00:1729625100.777787 6791928 random_forest.cc:812] Training of tree  195/200 (tree index:195) done accuracy:0.75 logloss:0.496598\n",
      "I0000 00:00:1729625100.777882 6791930 random_forest.cc:812] Training of tree  200/200 (tree index:192) done accuracy:0.758333 logloss:0.494298\n",
      "I0000 00:00:1729625100.777930 6791914 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.494298\n",
      "I0000 00:00:1729625100.778325 6791914 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpcfn6d356 with prefix f6f186b048264a7f\n",
      "I0000 00:00:1729625100.780687 6791914 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625100.781483 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.494298\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  15  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:00.786821: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpcfn6d356/model/ with prefix f6f186b048264a7f\n",
      "I0000 00:00:1729625100.790802 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3012 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:00.790827: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 20, 'min_examples': 10, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps2mfpytg as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.158634. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018326\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625101.095041 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625101.095059 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625101.095063 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625101.095127 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625101.095134 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625101.095175 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.095185 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.095191 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.095195 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.095222 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625101.095239 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625101.095370 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625101.095398 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps2mfpytg/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625101.095440 6791990 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625101.095562 6791990 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625101.096058 6792004 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625101.096223 6792000 random_forest.cc:812] Training of tree  13/200 (tree index:12) done accuracy:0.735043 logloss:2.85394\n",
      "I0000 00:00:1729625101.096451 6792000 random_forest.cc:812] Training of tree  24/200 (tree index:24) done accuracy:0.75 logloss:1.36701\n",
      "I0000 00:00:1729625101.096677 6792003 random_forest.cc:812] Training of tree  35/200 (tree index:34) done accuracy:0.775 logloss:1.10427\n",
      "I0000 00:00:1729625101.096824 6792003 random_forest.cc:812] Training of tree  46/200 (tree index:46) done accuracy:0.741667 logloss:0.84023\n",
      "I0000 00:00:1729625101.096971 6792005 random_forest.cc:812] Training of tree  56/200 (tree index:54) done accuracy:0.741667 logloss:0.559398\n",
      "I0000 00:00:1729625101.097119 6792006 random_forest.cc:812] Training of tree  66/200 (tree index:66) done accuracy:0.708333 logloss:0.545303\n",
      "I0000 00:00:1729625101.097257 6791999 random_forest.cc:812] Training of tree  76/200 (tree index:75) done accuracy:0.683333 logloss:0.555731\n",
      "I0000 00:00:1729625101.097401 6792006 random_forest.cc:812] Training of tree  86/200 (tree index:85) done accuracy:0.7 logloss:0.549741\n",
      "I0000 00:00:1729625101.097529 6792002 random_forest.cc:812] Training of tree  96/200 (tree index:95) done accuracy:0.725 logloss:0.553091\n",
      "I0000 00:00:1729625101.097655 6792001 random_forest.cc:812] Training of tree  106/200 (tree index:106) done accuracy:0.708333 logloss:0.557719\n",
      "I0000 00:00:1729625101.097781 6792004 random_forest.cc:812] Training of tree  117/200 (tree index:116) done accuracy:0.725 logloss:0.554238\n",
      "I0000 00:00:1729625101.097933 6792000 random_forest.cc:812] Training of tree  127/200 (tree index:126) done accuracy:0.716667 logloss:0.552885\n",
      "I0000 00:00:1729625101.098058 6792006 random_forest.cc:812] Training of tree  137/200 (tree index:136) done accuracy:0.708333 logloss:0.547136\n",
      "I0000 00:00:1729625101.098187 6792005 random_forest.cc:812] Training of tree  147/200 (tree index:146) done accuracy:0.725 logloss:0.55156\n",
      "I0000 00:00:1729625101.098328 6792003 random_forest.cc:812] Training of tree  157/200 (tree index:156) done accuracy:0.716667 logloss:0.550831\n",
      "I0000 00:00:1729625101.098489 6792001 random_forest.cc:812] Training of tree  167/200 (tree index:166) done accuracy:0.7 logloss:0.5544\n",
      "I0000 00:00:1729625101.098595 6792004 random_forest.cc:812] Training of tree  177/200 (tree index:175) done accuracy:0.708333 logloss:0.553011\n",
      "I0000 00:00:1729625101.098778 6792004 random_forest.cc:812] Training of tree  187/200 (tree index:187) done accuracy:0.708333 logloss:0.548826\n",
      "I0000 00:00:1729625101.098967 6792000 random_forest.cc:812] Training of tree  197/200 (tree index:199) done accuracy:0.708333 logloss:0.544528\n",
      "I0000 00:00:1729625101.099010 6792003 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.7 logloss:0.546815\n",
      "I0000 00:00:1729625101.099060 6791990 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.546815\n",
      "I0000 00:00:1729625101.099379 6791990 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps2mfpytg with prefix 7302081497a044b5\n",
      "I0000 00:00:1729625101.101505 6791990 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625101.102308 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.546815\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  19  43\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:01.107983: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps2mfpytg/model/ with prefix 7302081497a044b5\n",
      "I0000 00:00:1729625101.111440 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2516 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:01.111458: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpeflalyp9 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.151283. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017499\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625101.460948 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625101.460959 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625101.460963 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625101.461031 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625101.461037 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625101.461087 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.461099 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.461105 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.461110 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.461140 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625101.461158 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625101.461297 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625101.461325 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpeflalyp9/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625101.461387 6792061 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625101.461536 6792061 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625101.462082 6792071 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625101.462279 6792071 random_forest.cc:812] Training of tree  14/200 (tree index:14) done accuracy:0.683333 logloss:2.56959\n",
      "I0000 00:00:1729625101.462465 6792074 random_forest.cc:812] Training of tree  24/200 (tree index:24) done accuracy:0.725 logloss:0.860519\n",
      "I0000 00:00:1729625101.462607 6792072 random_forest.cc:812] Training of tree  34/200 (tree index:36) done accuracy:0.75 logloss:0.5741\n",
      "I0000 00:00:1729625101.462748 6792077 random_forest.cc:812] Training of tree  45/200 (tree index:44) done accuracy:0.708333 logloss:0.580817\n",
      "I0000 00:00:1729625101.462987 6792075 random_forest.cc:812] Training of tree  55/200 (tree index:51) done accuracy:0.708333 logloss:0.579971\n",
      "I0000 00:00:1729625101.463159 6792073 random_forest.cc:812] Training of tree  65/200 (tree index:65) done accuracy:0.733333 logloss:0.571917\n",
      "I0000 00:00:1729625101.463388 6792075 random_forest.cc:812] Training of tree  75/200 (tree index:76) done accuracy:0.733333 logloss:0.575008\n",
      "I0000 00:00:1729625101.463569 6792070 random_forest.cc:812] Training of tree  85/200 (tree index:82) done accuracy:0.733333 logloss:0.570032\n",
      "I0000 00:00:1729625101.463676 6792075 random_forest.cc:812] Training of tree  95/200 (tree index:94) done accuracy:0.741667 logloss:0.559877\n",
      "I0000 00:00:1729625101.463825 6792075 random_forest.cc:812] Training of tree  105/200 (tree index:106) done accuracy:0.758333 logloss:0.558803\n",
      "I0000 00:00:1729625101.463942 6792073 random_forest.cc:812] Training of tree  115/200 (tree index:114) done accuracy:0.758333 logloss:0.557995\n",
      "I0000 00:00:1729625101.464103 6792075 random_forest.cc:812] Training of tree  125/200 (tree index:126) done accuracy:0.758333 logloss:0.561651\n",
      "I0000 00:00:1729625101.464251 6792076 random_forest.cc:812] Training of tree  135/200 (tree index:137) done accuracy:0.775 logloss:0.557938\n",
      "I0000 00:00:1729625101.464431 6792071 random_forest.cc:812] Training of tree  145/200 (tree index:144) done accuracy:0.783333 logloss:0.558518\n",
      "I0000 00:00:1729625101.464567 6792072 random_forest.cc:812] Training of tree  157/200 (tree index:156) done accuracy:0.783333 logloss:0.562245\n",
      "I0000 00:00:1729625101.464744 6792077 random_forest.cc:812] Training of tree  167/200 (tree index:166) done accuracy:0.766667 logloss:0.563843\n",
      "I0000 00:00:1729625101.464854 6792070 random_forest.cc:812] Training of tree  177/200 (tree index:176) done accuracy:0.775 logloss:0.563155\n",
      "I0000 00:00:1729625101.465007 6792074 random_forest.cc:812] Training of tree  187/200 (tree index:186) done accuracy:0.783333 logloss:0.561121\n",
      "I0000 00:00:1729625101.465169 6792074 random_forest.cc:812] Training of tree  197/200 (tree index:196) done accuracy:0.783333 logloss:0.560153\n",
      "I0000 00:00:1729625101.465226 6792073 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.783333 logloss:0.558271\n",
      "I0000 00:00:1729625101.465313 6792061 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.558271\n",
      "I0000 00:00:1729625101.465616 6792061 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpeflalyp9 with prefix 3da398a18de94ff0\n",
      "I0000 00:00:1729625101.467418 6792061 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625101.467997 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.558271\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:01.473079: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpeflalyp9/model/ with prefix 3da398a18de94ff0\n",
      "I0000 00:00:1729625101.476709 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2536 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:01.476726: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3l9ram6s as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.155182. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018187\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625101.777418 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625101.777435 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625101.777441 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625101.777508 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625101.777513 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625101.777556 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.777565 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.777572 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.777577 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625101.777607 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625101.777624 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625101.777759 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625101.777781 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3l9ram6s/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625101.777828 6792130 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625101.777918 6792130 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625101.778358 6792141 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625101.778466 6792143 random_forest.cc:812] Training of tree  12/200 (tree index:1) done accuracy:0.694915 logloss:3.46786\n",
      "I0000 00:00:1729625101.778653 6792141 random_forest.cc:812] Training of tree  22/200 (tree index:24) done accuracy:0.675 logloss:1.17668\n",
      "I0000 00:00:1729625101.778771 6792141 random_forest.cc:812] Training of tree  32/200 (tree index:29) done accuracy:0.666667 logloss:0.866972\n",
      "I0000 00:00:1729625101.778910 6792145 random_forest.cc:812] Training of tree  42/200 (tree index:42) done accuracy:0.733333 logloss:0.585898\n",
      "I0000 00:00:1729625101.779071 6792146 random_forest.cc:812] Training of tree  52/200 (tree index:53) done accuracy:0.691667 logloss:0.595412\n",
      "I0000 00:00:1729625101.779297 6792139 random_forest.cc:812] Training of tree  62/200 (tree index:61) done accuracy:0.7 logloss:0.588464\n",
      "I0000 00:00:1729625101.779449 6792141 random_forest.cc:812] Training of tree  72/200 (tree index:72) done accuracy:0.7 logloss:0.582171\n",
      "I0000 00:00:1729625101.779567 6792144 random_forest.cc:812] Training of tree  82/200 (tree index:82) done accuracy:0.7 logloss:0.570567\n",
      "I0000 00:00:1729625101.779708 6792141 random_forest.cc:812] Training of tree  92/200 (tree index:93) done accuracy:0.7 logloss:0.565335\n",
      "I0000 00:00:1729625101.779856 6792143 random_forest.cc:812] Training of tree  103/200 (tree index:73) done accuracy:0.683333 logloss:0.567731\n",
      "I0000 00:00:1729625101.780025 6792145 random_forest.cc:812] Training of tree  113/200 (tree index:112) done accuracy:0.708333 logloss:0.557695\n",
      "I0000 00:00:1729625101.780154 6792143 random_forest.cc:812] Training of tree  123/200 (tree index:123) done accuracy:0.691667 logloss:0.557127\n",
      "I0000 00:00:1729625101.780285 6792142 random_forest.cc:812] Training of tree  134/200 (tree index:133) done accuracy:0.7 logloss:0.552338\n",
      "I0000 00:00:1729625101.780418 6792140 random_forest.cc:812] Training of tree  144/200 (tree index:144) done accuracy:0.683333 logloss:0.554154\n",
      "I0000 00:00:1729625101.780575 6792146 random_forest.cc:812] Training of tree  155/200 (tree index:154) done accuracy:0.708333 logloss:0.555337\n",
      "I0000 00:00:1729625101.780726 6792139 random_forest.cc:812] Training of tree  165/200 (tree index:164) done accuracy:0.708333 logloss:0.560403\n",
      "I0000 00:00:1729625101.780906 6792146 random_forest.cc:812] Training of tree  175/200 (tree index:175) done accuracy:0.716667 logloss:0.562761\n",
      "I0000 00:00:1729625101.781126 6792141 random_forest.cc:812] Training of tree  185/200 (tree index:178) done accuracy:0.733333 logloss:0.566695\n",
      "I0000 00:00:1729625101.781334 6792146 random_forest.cc:812] Training of tree  195/200 (tree index:193) done accuracy:0.733333 logloss:0.567638\n",
      "I0000 00:00:1729625101.781476 6792143 random_forest.cc:812] Training of tree  200/200 (tree index:198) done accuracy:0.733333 logloss:0.568615\n",
      "I0000 00:00:1729625101.781588 6792130 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.568615\n",
      "I0000 00:00:1729625101.781882 6792130 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3l9ram6s with prefix 6be341a511324b32\n",
      "I0000 00:00:1729625101.783733 6792130 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625101.784395 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.568615\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  35  19\n",
      "2  13  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:01.790321: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3l9ram6s/model/ with prefix 6be341a511324b32\n",
      "I0000 00:00:1729625101.793658 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2558 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:01.793674: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptaop8zku as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.149780. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018017\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625102.140498 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625102.140512 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625102.140516 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625102.140580 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625102.140585 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625102.140628 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.140637 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.140643 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.140648 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.140674 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625102.140692 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625102.140829 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625102.140854 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptaop8zku/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625102.140902 6792199 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625102.141007 6792199 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625102.141486 6792210 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625102.141640 6792214 random_forest.cc:812] Training of tree  11/200 (tree index:9) done accuracy:0.672414 logloss:4.98921\n",
      "I0000 00:00:1729625102.141823 6792210 random_forest.cc:812] Training of tree  21/200 (tree index:17) done accuracy:0.7 logloss:1.13715\n",
      "I0000 00:00:1729625102.142018 6792211 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.741667 logloss:0.807028\n",
      "I0000 00:00:1729625102.142178 6792209 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.758333 logloss:0.804181\n",
      "I0000 00:00:1729625102.142400 6792210 random_forest.cc:812] Training of tree  51/200 (tree index:51) done accuracy:0.741667 logloss:0.51995\n",
      "I0000 00:00:1729625102.142604 6792211 random_forest.cc:812] Training of tree  61/200 (tree index:62) done accuracy:0.758333 logloss:0.519444\n",
      "I0000 00:00:1729625102.142775 6792213 random_forest.cc:812] Training of tree  71/200 (tree index:71) done accuracy:0.758333 logloss:0.517675\n",
      "I0000 00:00:1729625102.142906 6792215 random_forest.cc:812] Training of tree  81/200 (tree index:78) done accuracy:0.758333 logloss:0.521986\n",
      "I0000 00:00:1729625102.143050 6792209 random_forest.cc:812] Training of tree  91/200 (tree index:83) done accuracy:0.75 logloss:0.517205\n",
      "I0000 00:00:1729625102.143223 6792215 random_forest.cc:812] Training of tree  103/200 (tree index:102) done accuracy:0.783333 logloss:0.516492\n",
      "I0000 00:00:1729625102.143450 6792214 random_forest.cc:812] Training of tree  113/200 (tree index:113) done accuracy:0.775 logloss:0.511359\n",
      "I0000 00:00:1729625102.143627 6792211 random_forest.cc:812] Training of tree  124/200 (tree index:123) done accuracy:0.783333 logloss:0.50735\n",
      "I0000 00:00:1729625102.143825 6792215 random_forest.cc:812] Training of tree  135/200 (tree index:134) done accuracy:0.775 logloss:0.499204\n",
      "I0000 00:00:1729625102.143988 6792213 random_forest.cc:812] Training of tree  147/200 (tree index:147) done accuracy:0.775 logloss:0.496586\n",
      "I0000 00:00:1729625102.144154 6792214 random_forest.cc:812] Training of tree  157/200 (tree index:156) done accuracy:0.783333 logloss:0.499436\n",
      "I0000 00:00:1729625102.144340 6792212 random_forest.cc:812] Training of tree  167/200 (tree index:166) done accuracy:0.775 logloss:0.499114\n",
      "I0000 00:00:1729625102.144490 6792208 random_forest.cc:812] Training of tree  177/200 (tree index:176) done accuracy:0.766667 logloss:0.500216\n",
      "I0000 00:00:1729625102.144676 6792212 random_forest.cc:812] Training of tree  187/200 (tree index:185) done accuracy:0.775 logloss:0.500857\n",
      "I0000 00:00:1729625102.144831 6792209 random_forest.cc:812] Training of tree  199/200 (tree index:198) done accuracy:0.766667 logloss:0.501823\n",
      "I0000 00:00:1729625102.144891 6792211 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.766667 logloss:0.501334\n",
      "I0000 00:00:1729625102.144927 6792199 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.501334\n",
      "I0000 00:00:1729625102.145221 6792199 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptaop8zku with prefix f06216f0f9bd4ca0\n",
      "I0000 00:00:1729625102.147373 6792199 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625102.148011 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.501334\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  16\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:02.153221: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptaop8zku/model/ with prefix f06216f0f9bd4ca0\n",
      "I0000 00:00:1729625102.156520 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2434 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:02.156546: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy39cmcaa as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.150706. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016533\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625102.446415 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625102.446430 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625102.446434 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625102.446499 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625102.446506 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625102.446550 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.446559 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.446564 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.446574 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.446602 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625102.446620 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625102.446754 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625102.446779 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy39cmcaa/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625102.446840 6792268 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625102.446934 6792268 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625102.447464 6792277 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.735849 logloss:9.52096\n",
      "I0000 00:00:1729625102.447594 6792278 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.783333 logloss:1.87583\n",
      "I0000 00:00:1729625102.447736 6792282 random_forest.cc:812] Training of tree  21/200 (tree index:13) done accuracy:0.725 logloss:0.79422\n",
      "I0000 00:00:1729625102.447943 6792284 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.733333 logloss:0.484528\n",
      "I0000 00:00:1729625102.448114 6792284 random_forest.cc:812] Training of tree  41/200 (tree index:42) done accuracy:0.75 logloss:0.515159\n",
      "I0000 00:00:1729625102.448212 6792284 random_forest.cc:812] Training of tree  51/200 (tree index:48) done accuracy:0.75 logloss:0.512973\n",
      "I0000 00:00:1729625102.448398 6792283 random_forest.cc:812] Training of tree  61/200 (tree index:59) done accuracy:0.775 logloss:0.518971\n",
      "I0000 00:00:1729625102.448504 6792280 random_forest.cc:812] Training of tree  71/200 (tree index:71) done accuracy:0.775 logloss:0.523656\n",
      "I0000 00:00:1729625102.448658 6792280 random_forest.cc:812] Training of tree  82/200 (tree index:83) done accuracy:0.758333 logloss:0.522911\n",
      "I0000 00:00:1729625102.448811 6792284 random_forest.cc:812] Training of tree  92/200 (tree index:94) done accuracy:0.775 logloss:0.520428\n",
      "I0000 00:00:1729625102.448912 6792277 random_forest.cc:812] Training of tree  102/200 (tree index:101) done accuracy:0.766667 logloss:0.517825\n",
      "I0000 00:00:1729625102.449051 6792280 random_forest.cc:812] Training of tree  113/200 (tree index:112) done accuracy:0.775 logloss:0.518217\n",
      "I0000 00:00:1729625102.449261 6792278 random_forest.cc:812] Training of tree  125/200 (tree index:120) done accuracy:0.775 logloss:0.513398\n",
      "I0000 00:00:1729625102.449467 6792277 random_forest.cc:812] Training of tree  136/200 (tree index:136) done accuracy:0.775 logloss:0.51186\n",
      "I0000 00:00:1729625102.449623 6792277 random_forest.cc:812] Training of tree  146/200 (tree index:147) done accuracy:0.775 logloss:0.510458\n",
      "I0000 00:00:1729625102.449764 6792283 random_forest.cc:812] Training of tree  156/200 (tree index:145) done accuracy:0.783333 logloss:0.51215\n",
      "I0000 00:00:1729625102.449936 6792283 random_forest.cc:812] Training of tree  166/200 (tree index:166) done accuracy:0.783333 logloss:0.512782\n",
      "I0000 00:00:1729625102.450111 6792283 random_forest.cc:812] Training of tree  179/200 (tree index:180) done accuracy:0.783333 logloss:0.512033\n",
      "I0000 00:00:1729625102.450264 6792283 random_forest.cc:812] Training of tree  189/200 (tree index:191) done accuracy:0.783333 logloss:0.513976\n",
      "I0000 00:00:1729625102.450430 6792278 random_forest.cc:812] Training of tree  199/200 (tree index:198) done accuracy:0.766667 logloss:0.5157\n",
      "I0000 00:00:1729625102.450455 6792277 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.766667 logloss:0.516313\n",
      "I0000 00:00:1729625102.450510 6792268 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.516313\n",
      "I0000 00:00:1729625102.450801 6792268 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy39cmcaa with prefix 38450523d4e740e4\n",
      "I0000 00:00:1729625102.452458 6792268 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625102.453085 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.516313\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  16\n",
      "2  12  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:02.457925: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy39cmcaa/model/ with prefix 38450523d4e740e4\n",
      "I0000 00:00:1729625102.461167 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2486 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:02.461182: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 20, 'min_examples': 20, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjthj482q as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.152410. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015610\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625102.807148 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625102.807161 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625102.807165 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625102.807227 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625102.807232 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625102.807277 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.807287 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.807292 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.807297 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625102.807325 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625102.807359 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625102.807513 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625102.807536 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjthj482q/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625102.807586 6792337 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625102.807679 6792337 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625102.808182 6792346 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.454545 logloss:19.6602\n",
      "I0000 00:00:1729625102.808381 6792348 random_forest.cc:812] Training of tree  13/200 (tree index:11) done accuracy:0.538462 logloss:5.94113\n",
      "I0000 00:00:1729625102.808619 6792351 random_forest.cc:812] Training of tree  23/200 (tree index:24) done accuracy:0.741667 logloss:2.2524\n",
      "I0000 00:00:1729625102.808777 6792346 random_forest.cc:812] Training of tree  34/200 (tree index:33) done accuracy:0.775 logloss:1.40884\n",
      "I0000 00:00:1729625102.809053 6792347 random_forest.cc:812] Training of tree  44/200 (tree index:47) done accuracy:0.741667 logloss:1.40719\n",
      "I0000 00:00:1729625102.809261 6792347 random_forest.cc:812] Training of tree  55/200 (tree index:56) done accuracy:0.708333 logloss:1.13521\n",
      "I0000 00:00:1729625102.809407 6792347 random_forest.cc:812] Training of tree  65/200 (tree index:67) done accuracy:0.716667 logloss:0.838259\n",
      "I0000 00:00:1729625102.809604 6792351 random_forest.cc:812] Training of tree  75/200 (tree index:74) done accuracy:0.708333 logloss:0.836999\n",
      "I0000 00:00:1729625102.809797 6792348 random_forest.cc:812] Training of tree  85/200 (tree index:85) done accuracy:0.716667 logloss:0.847739\n",
      "I0000 00:00:1729625102.809911 6792352 random_forest.cc:812] Training of tree  95/200 (tree index:94) done accuracy:0.7 logloss:0.586994\n",
      "I0000 00:00:1729625102.810026 6792353 random_forest.cc:812] Training of tree  105/200 (tree index:105) done accuracy:0.708333 logloss:0.59067\n",
      "I0000 00:00:1729625102.810168 6792348 random_forest.cc:812] Training of tree  118/200 (tree index:117) done accuracy:0.708333 logloss:0.595957\n",
      "I0000 00:00:1729625102.810393 6792350 random_forest.cc:812] Training of tree  129/200 (tree index:129) done accuracy:0.708333 logloss:0.588528\n",
      "I0000 00:00:1729625102.810543 6792349 random_forest.cc:812] Training of tree  141/200 (tree index:139) done accuracy:0.708333 logloss:0.58092\n",
      "I0000 00:00:1729625102.810700 6792351 random_forest.cc:812] Training of tree  152/200 (tree index:151) done accuracy:0.708333 logloss:0.581159\n",
      "I0000 00:00:1729625102.810868 6792348 random_forest.cc:812] Training of tree  162/200 (tree index:158) done accuracy:0.733333 logloss:0.579531\n",
      "I0000 00:00:1729625102.810996 6792352 random_forest.cc:812] Training of tree  172/200 (tree index:174) done accuracy:0.733333 logloss:0.569618\n",
      "I0000 00:00:1729625102.811157 6792349 random_forest.cc:812] Training of tree  183/200 (tree index:182) done accuracy:0.716667 logloss:0.569337\n",
      "I0000 00:00:1729625102.811337 6792350 random_forest.cc:812] Training of tree  193/200 (tree index:190) done accuracy:0.708333 logloss:0.572996\n",
      "I0000 00:00:1729625102.811419 6792350 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.725 logloss:0.573783\n",
      "I0000 00:00:1729625102.811471 6792337 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.573783\n",
      "I0000 00:00:1729625102.811711 6792337 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjthj482q with prefix 53675efcf33e456d\n",
      "I0000 00:00:1729625102.813082 6792337 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625102.813796 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.573783\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  18\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:02.818973: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjthj482q/model/ with prefix 53675efcf33e456d\n",
      "I0000 00:00:1729625102.821206 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1636 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:02.821227: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpj7cwyz9c as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.188217. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625103.148955 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625103.148979 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625103.148983 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625103.149046 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625103.149052 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625103.149094 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.149104 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.149112 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.149116 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.149143 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625103.149161 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625103.149286 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625103.149313 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpj7cwyz9c/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625103.149358 6792406 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625103.149508 6792406 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625103.150039 6792422 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.767442 logloss:8.38224\n",
      "I0000 00:00:1729625103.150200 6792422 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.661017 logloss:6.42147\n",
      "I0000 00:00:1729625103.150340 6792422 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.658333 logloss:2.0399\n",
      "I0000 00:00:1729625103.150466 6792420 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.666667 logloss:1.17673\n",
      "I0000 00:00:1729625103.150599 6792415 random_forest.cc:812] Training of tree  42/200 (tree index:37) done accuracy:0.716667 logloss:0.892698\n",
      "I0000 00:00:1729625103.150776 6792422 random_forest.cc:812] Training of tree  52/200 (tree index:52) done accuracy:0.7 logloss:0.618534\n",
      "I0000 00:00:1729625103.150902 6792417 random_forest.cc:812] Training of tree  62/200 (tree index:63) done accuracy:0.7 logloss:0.622158\n",
      "I0000 00:00:1729625103.151042 6792417 random_forest.cc:812] Training of tree  72/200 (tree index:75) done accuracy:0.708333 logloss:0.621019\n",
      "I0000 00:00:1729625103.151154 6792415 random_forest.cc:812] Training of tree  82/200 (tree index:83) done accuracy:0.716667 logloss:0.617043\n",
      "I0000 00:00:1729625103.151296 6792415 random_forest.cc:812] Training of tree  92/200 (tree index:92) done accuracy:0.733333 logloss:0.597709\n",
      "I0000 00:00:1729625103.151410 6792420 random_forest.cc:812] Training of tree  102/200 (tree index:102) done accuracy:0.741667 logloss:0.591536\n",
      "I0000 00:00:1729625103.151555 6792417 random_forest.cc:812] Training of tree  113/200 (tree index:113) done accuracy:0.725 logloss:0.595527\n",
      "I0000 00:00:1729625103.151736 6792418 random_forest.cc:812] Training of tree  123/200 (tree index:123) done accuracy:0.741667 logloss:0.591348\n",
      "I0000 00:00:1729625103.151886 6792420 random_forest.cc:812] Training of tree  133/200 (tree index:132) done accuracy:0.75 logloss:0.593343\n",
      "I0000 00:00:1729625103.152035 6792421 random_forest.cc:812] Training of tree  143/200 (tree index:143) done accuracy:0.766667 logloss:0.601486\n",
      "I0000 00:00:1729625103.152145 6792418 random_forest.cc:812] Training of tree  153/200 (tree index:152) done accuracy:0.75 logloss:0.602941\n",
      "I0000 00:00:1729625103.152263 6792416 random_forest.cc:812] Training of tree  163/200 (tree index:162) done accuracy:0.741667 logloss:0.603856\n",
      "I0000 00:00:1729625103.152413 6792417 random_forest.cc:812] Training of tree  173/200 (tree index:172) done accuracy:0.758333 logloss:0.601718\n",
      "I0000 00:00:1729625103.152605 6792420 random_forest.cc:812] Training of tree  184/200 (tree index:184) done accuracy:0.75 logloss:0.599595\n",
      "I0000 00:00:1729625103.152774 6792416 random_forest.cc:812] Training of tree  195/200 (tree index:194) done accuracy:0.766667 logloss:0.599625\n",
      "I0000 00:00:1729625103.152834 6792415 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.766667 logloss:0.599058\n",
      "I0000 00:00:1729625103.152930 6792406 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.599058\n",
      "I0000 00:00:1729625103.153125 6792406 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpj7cwyz9c with prefix d5513712a79b4ce9\n",
      "I0000 00:00:1729625103.154566 6792406 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625103.155316 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.599058\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  17\n",
      "2  11  56\n",
      "Total: 120\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.015512\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppwmbg7vp as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 20:25:03.160642: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpj7cwyz9c/model/ with prefix d5513712a79b4ce9\n",
      "I0000 00:00:1729625103.162843 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1628 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:03.162858: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.152414. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014826\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw1t5wzug as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625103.457508 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625103.457530 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625103.457540 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625103.457611 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625103.457615 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625103.457663 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.457673 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.457681 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.457686 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.457715 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625103.457733 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625103.457874 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625103.457896 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppwmbg7vp/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625103.457945 6792476 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625103.458033 6792476 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625103.458508 6792486 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.475 logloss:18.9229\n",
      "I0000 00:00:1729625103.458639 6792492 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.632479 logloss:6.47428\n",
      "I0000 00:00:1729625103.458809 6792485 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.666667 logloss:1.14807\n",
      "I0000 00:00:1729625103.458962 6792485 random_forest.cc:812] Training of tree  33/200 (tree index:32) done accuracy:0.7 logloss:0.877678\n",
      "I0000 00:00:1729625103.459145 6792488 random_forest.cc:812] Training of tree  43/200 (tree index:41) done accuracy:0.7 logloss:0.610073\n",
      "I0000 00:00:1729625103.459290 6792490 random_forest.cc:812] Training of tree  53/200 (tree index:47) done accuracy:0.716667 logloss:0.609128\n",
      "I0000 00:00:1729625103.459401 6792492 random_forest.cc:812] Training of tree  63/200 (tree index:62) done accuracy:0.733333 logloss:0.606191\n",
      "I0000 00:00:1729625103.459528 6792485 random_forest.cc:812] Training of tree  73/200 (tree index:73) done accuracy:0.716667 logloss:0.60316\n",
      "I0000 00:00:1729625103.459628 6792486 random_forest.cc:812] Training of tree  83/200 (tree index:83) done accuracy:0.733333 logloss:0.603507\n",
      "I0000 00:00:1729625103.459771 6792486 random_forest.cc:812] Training of tree  93/200 (tree index:94) done accuracy:0.733333 logloss:0.58965\n",
      "I0000 00:00:1729625103.459899 6792487 random_forest.cc:812] Training of tree  103/200 (tree index:105) done accuracy:0.725 logloss:0.583368\n",
      "I0000 00:00:1729625103.459983 6792486 random_forest.cc:812] Training of tree  113/200 (tree index:112) done accuracy:0.708333 logloss:0.585158\n",
      "I0000 00:00:1729625103.460107 6792489 random_forest.cc:812] Training of tree  123/200 (tree index:122) done accuracy:0.708333 logloss:0.58739\n",
      "I0000 00:00:1729625103.460211 6792488 random_forest.cc:812] Training of tree  133/200 (tree index:132) done accuracy:0.691667 logloss:0.58928\n",
      "I0000 00:00:1729625103.460377 6792489 random_forest.cc:812] Training of tree  144/200 (tree index:143) done accuracy:0.7 logloss:0.591533\n",
      "I0000 00:00:1729625103.460512 6792492 random_forest.cc:812] Training of tree  154/200 (tree index:154) done accuracy:0.7 logloss:0.596339\n",
      "I0000 00:00:1729625103.460635 6792488 random_forest.cc:812] Training of tree  164/200 (tree index:162) done accuracy:0.7 logloss:0.591729\n",
      "I0000 00:00:1729625103.460858 6792489 random_forest.cc:812] Training of tree  177/200 (tree index:176) done accuracy:0.708333 logloss:0.588428\n",
      "I0000 00:00:1729625103.461042 6792488 random_forest.cc:812] Training of tree  187/200 (tree index:187) done accuracy:0.716667 logloss:0.588344\n",
      "I0000 00:00:1729625103.461149 6792486 random_forest.cc:812] Training of tree  197/200 (tree index:198) done accuracy:0.716667 logloss:0.589179\n",
      "I0000 00:00:1729625103.461231 6792485 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.716667 logloss:0.589941\n",
      "I0000 00:00:1729625103.461286 6792476 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.589941\n",
      "I0000 00:00:1729625103.461495 6792476 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppwmbg7vp with prefix 953f0e66a4884f0d\n",
      "I0000 00:00:1729625103.462956 6792476 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625103.463592 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.589941\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  32  22\n",
      "2  12  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:03.468320: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppwmbg7vp/model/ with prefix 953f0e66a4884f0d\n",
      "I0000 00:00:1729625103.470660 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1622 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:03.470681: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.205102. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015951\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp15iq5dyv as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625103.837358 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625103.837369 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625103.837373 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625103.837437 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625103.837445 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625103.837494 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.837504 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.837509 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.837514 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625103.837543 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625103.837561 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625103.837699 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625103.837723 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw1t5wzug/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625103.837781 6792560 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625103.837890 6792560 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625103.838386 6792572 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625103.838533 6792575 random_forest.cc:812] Training of tree  11/200 (tree index:13) done accuracy:0.689076 logloss:3.97742\n",
      "I0000 00:00:1729625103.838664 6792576 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.725 logloss:1.93433\n",
      "I0000 00:00:1729625103.838789 6792573 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.75 logloss:1.35776\n",
      "I0000 00:00:1729625103.838969 6792575 random_forest.cc:812] Training of tree  41/200 (tree index:43) done accuracy:0.716667 logloss:0.817618\n",
      "I0000 00:00:1729625103.839087 6792572 random_forest.cc:812] Training of tree  51/200 (tree index:53) done accuracy:0.741667 logloss:0.533596\n",
      "I0000 00:00:1729625103.839254 6792573 random_forest.cc:812] Training of tree  61/200 (tree index:52) done accuracy:0.716667 logloss:0.527165\n",
      "I0000 00:00:1729625103.839407 6792572 random_forest.cc:812] Training of tree  72/200 (tree index:69) done accuracy:0.75 logloss:0.518575\n",
      "I0000 00:00:1729625103.839561 6792572 random_forest.cc:812] Training of tree  83/200 (tree index:82) done accuracy:0.741667 logloss:0.516849\n",
      "I0000 00:00:1729625103.839681 6792571 random_forest.cc:812] Training of tree  93/200 (tree index:94) done accuracy:0.758333 logloss:0.511688\n",
      "I0000 00:00:1729625103.839781 6792574 random_forest.cc:812] Training of tree  104/200 (tree index:103) done accuracy:0.766667 logloss:0.507602\n",
      "I0000 00:00:1729625103.839948 6792575 random_forest.cc:812] Training of tree  114/200 (tree index:113) done accuracy:0.766667 logloss:0.50463\n",
      "I0000 00:00:1729625103.840063 6792570 random_forest.cc:812] Training of tree  124/200 (tree index:122) done accuracy:0.775 logloss:0.50732\n",
      "I0000 00:00:1729625103.840185 6792571 random_forest.cc:812] Training of tree  136/200 (tree index:135) done accuracy:0.8 logloss:0.507639\n",
      "I0000 00:00:1729625103.840311 6792575 random_forest.cc:812] Training of tree  146/200 (tree index:145) done accuracy:0.791667 logloss:0.51202\n",
      "I0000 00:00:1729625103.840432 6792572 random_forest.cc:812] Training of tree  157/200 (tree index:156) done accuracy:0.791667 logloss:0.513923\n",
      "I0000 00:00:1729625103.840590 6792574 random_forest.cc:812] Training of tree  167/200 (tree index:167) done accuracy:0.775 logloss:0.515537\n",
      "I0000 00:00:1729625103.840746 6792575 random_forest.cc:812] Training of tree  177/200 (tree index:177) done accuracy:0.791667 logloss:0.51191\n",
      "I0000 00:00:1729625103.840856 6792572 random_forest.cc:812] Training of tree  187/200 (tree index:186) done accuracy:0.783333 logloss:0.514383\n",
      "I0000 00:00:1729625103.840983 6792573 random_forest.cc:812] Training of tree  197/200 (tree index:196) done accuracy:0.8 logloss:0.510909\n",
      "I0000 00:00:1729625103.841031 6792574 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.8 logloss:0.51219\n",
      "I0000 00:00:1729625103.841053 6792560 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.51219\n",
      "I0000 00:00:1729625103.841233 6792560 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw1t5wzug with prefix 1a746a188e54473c\n",
      "I0000 00:00:1729625103.842465 6792560 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625103.843326 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.51219\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:03.848914: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw1t5wzug/model/ with prefix 1a746a188e54473c\n",
      "I0000 00:00:1729625103.851325 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1584 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:03.851347: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.156527. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015284\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 20, 'min_examples': 20, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptku4rhh6 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625104.165442 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625104.165453 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625104.165458 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625104.165530 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625104.165539 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625104.165584 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.165594 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.165603 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.165609 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.165638 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625104.165656 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625104.165796 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625104.165822 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp15iq5dyv/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625104.165875 6792657 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625104.165977 6792657 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625104.166520 6792669 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625104.166664 6792668 random_forest.cc:812] Training of tree  11/200 (tree index:5) done accuracy:0.725 logloss:4.18829\n",
      "I0000 00:00:1729625104.166793 6792670 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.666667 logloss:1.41773\n",
      "I0000 00:00:1729625104.166941 6792673 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.725 logloss:0.846417\n",
      "I0000 00:00:1729625104.167117 6792671 random_forest.cc:812] Training of tree  43/200 (tree index:43) done accuracy:0.766667 logloss:0.853837\n",
      "I0000 00:00:1729625104.167295 6792674 random_forest.cc:812] Training of tree  53/200 (tree index:53) done accuracy:0.758333 logloss:0.84842\n",
      "I0000 00:00:1729625104.167410 6792668 random_forest.cc:812] Training of tree  63/200 (tree index:63) done accuracy:0.766667 logloss:0.834761\n",
      "I0000 00:00:1729625104.167519 6792670 random_forest.cc:812] Training of tree  73/200 (tree index:72) done accuracy:0.75 logloss:0.834398\n",
      "I0000 00:00:1729625104.167652 6792670 random_forest.cc:812] Training of tree  83/200 (tree index:84) done accuracy:0.741667 logloss:0.836782\n",
      "I0000 00:00:1729625104.167757 6792672 random_forest.cc:812] Training of tree  93/200 (tree index:93) done accuracy:0.725 logloss:0.839647\n",
      "I0000 00:00:1729625104.167902 6792671 random_forest.cc:812] Training of tree  103/200 (tree index:102) done accuracy:0.741667 logloss:0.837508\n",
      "I0000 00:00:1729625104.168123 6792668 random_forest.cc:812] Training of tree  114/200 (tree index:105) done accuracy:0.733333 logloss:0.837746\n",
      "I0000 00:00:1729625104.168296 6792669 random_forest.cc:812] Training of tree  124/200 (tree index:126) done accuracy:0.75 logloss:0.564294\n",
      "I0000 00:00:1729625104.168419 6792670 random_forest.cc:812] Training of tree  134/200 (tree index:134) done accuracy:0.766667 logloss:0.559952\n",
      "I0000 00:00:1729625104.168685 6792674 random_forest.cc:812] Training of tree  144/200 (tree index:136) done accuracy:0.766667 logloss:0.565905\n",
      "I0000 00:00:1729625104.168879 6792670 random_forest.cc:812] Training of tree  154/200 (tree index:153) done accuracy:0.766667 logloss:0.569009\n",
      "I0000 00:00:1729625104.169053 6792670 random_forest.cc:812] Training of tree  164/200 (tree index:164) done accuracy:0.75 logloss:0.570584\n",
      "I0000 00:00:1729625104.169244 6792669 random_forest.cc:812] Training of tree  174/200 (tree index:175) done accuracy:0.758333 logloss:0.560501\n",
      "I0000 00:00:1729625104.169379 6792668 random_forest.cc:812] Training of tree  184/200 (tree index:184) done accuracy:0.75 logloss:0.557959\n",
      "I0000 00:00:1729625104.169487 6792669 random_forest.cc:812] Training of tree  194/200 (tree index:192) done accuracy:0.758333 logloss:0.553244\n",
      "I0000 00:00:1729625104.169579 6792667 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.75 logloss:0.553303\n",
      "I0000 00:00:1729625104.169704 6792657 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.553303\n",
      "I0000 00:00:1729625104.169898 6792657 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp15iq5dyv with prefix 9edf5eb8bb98469c\n",
      "I0000 00:00:1729625104.171232 6792657 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625104.171826 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.553303\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  18\n",
      "2  12  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:04.176726: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp15iq5dyv/model/ with prefix 9edf5eb8bb98469c\n",
      "I0000 00:00:1729625104.179009 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1606 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:04.179026: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.206660. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014537\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpaldsvagi as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625104.540629 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625104.540638 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625104.540642 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625104.540705 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625104.540710 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625104.540755 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.540764 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.540770 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.540775 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.540805 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625104.540822 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625104.540959 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625104.540981 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptku4rhh6/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625104.541040 6792733 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625104.541194 6792733 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625104.541634 6792747 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.531915 logloss:16.8715\n",
      "I0000 00:00:1729625104.541835 6792742 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.666667 logloss:3.98796\n",
      "I0000 00:00:1729625104.542088 6792743 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.658333 logloss:1.46387\n",
      "I0000 00:00:1729625104.542252 6792743 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.666667 logloss:1.16386\n",
      "I0000 00:00:1729625104.542393 6792744 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.7 logloss:0.60867\n",
      "I0000 00:00:1729625104.542524 6792743 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.7 logloss:0.589036\n",
      "I0000 00:00:1729625104.542695 6792743 random_forest.cc:812] Training of tree  61/200 (tree index:62) done accuracy:0.725 logloss:0.582509\n",
      "I0000 00:00:1729625104.542822 6792748 random_forest.cc:812] Training of tree  71/200 (tree index:71) done accuracy:0.675 logloss:0.58621\n",
      "I0000 00:00:1729625104.542940 6792748 random_forest.cc:812] Training of tree  81/200 (tree index:81) done accuracy:0.7 logloss:0.583618\n",
      "I0000 00:00:1729625104.543071 6792747 random_forest.cc:812] Training of tree  91/200 (tree index:93) done accuracy:0.683333 logloss:0.585115\n",
      "I0000 00:00:1729625104.543191 6792746 random_forest.cc:812] Training of tree  101/200 (tree index:101) done accuracy:0.691667 logloss:0.591928\n",
      "I0000 00:00:1729625104.543305 6792747 random_forest.cc:812] Training of tree  111/200 (tree index:111) done accuracy:0.7 logloss:0.572695\n",
      "I0000 00:00:1729625104.543456 6792748 random_forest.cc:812] Training of tree  121/200 (tree index:116) done accuracy:0.708333 logloss:0.573418\n",
      "I0000 00:00:1729625104.543552 6792745 random_forest.cc:812] Training of tree  132/200 (tree index:131) done accuracy:0.725 logloss:0.572239\n",
      "I0000 00:00:1729625104.543704 6792742 random_forest.cc:812] Training of tree  145/200 (tree index:135) done accuracy:0.716667 logloss:0.576337\n",
      "I0000 00:00:1729625104.543839 6792748 random_forest.cc:812] Training of tree  155/200 (tree index:154) done accuracy:0.716667 logloss:0.576355\n",
      "I0000 00:00:1729625104.543927 6792742 random_forest.cc:812] Training of tree  165/200 (tree index:164) done accuracy:0.716667 logloss:0.576359\n",
      "I0000 00:00:1729625104.544087 6792744 random_forest.cc:812] Training of tree  176/200 (tree index:176) done accuracy:0.708333 logloss:0.574273\n",
      "I0000 00:00:1729625104.544316 6792747 random_forest.cc:812] Training of tree  186/200 (tree index:184) done accuracy:0.708333 logloss:0.573674\n",
      "I0000 00:00:1729625104.544445 6792747 random_forest.cc:812] Training of tree  196/200 (tree index:196) done accuracy:0.725 logloss:0.571948\n",
      "I0000 00:00:1729625104.544509 6792742 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.725 logloss:0.573119\n",
      "I0000 00:00:1729625104.544695 6792733 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.573119\n",
      "I0000 00:00:1729625104.544928 6792733 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptku4rhh6 with prefix e70068c9c9454acd\n",
      "I0000 00:00:1729625104.546134 6792733 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625104.546862 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.573119\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  14  48\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:04.551507: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptku4rhh6/model/ with prefix e70068c9c9454acd\n",
      "I0000 00:00:1729625104.553499 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1304 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:04.553519: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.158238. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.019325\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625104.870206 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625104.870216 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625104.870220 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625104.870279 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625104.870284 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625104.870328 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.870340 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.870345 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.870350 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625104.870376 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625104.870393 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625104.870525 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625104.870548 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpaldsvagi/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625104.870618 6792810 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625104.870701 6792810 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625104.871156 6792821 random_forest.cc:812] Training of tree  1/200 (tree index:2) done accuracy:0.530612 logloss:16.9184\n",
      "I0000 00:00:1729625104.871292 6792824 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.605042 logloss:4.95521\n",
      "I0000 00:00:1729625104.871521 6792824 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.675 logloss:2.3125\n",
      "I0000 00:00:1729625104.871772 6792823 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.708333 logloss:1.17133\n",
      "I0000 00:00:1729625104.871900 6792823 random_forest.cc:812] Training of tree  42/200 (tree index:41) done accuracy:0.708333 logloss:0.88111\n",
      "I0000 00:00:1729625104.872004 6792822 random_forest.cc:812] Training of tree  52/200 (tree index:51) done accuracy:0.725 logloss:0.619001\n",
      "I0000 00:00:1729625104.872195 6792820 random_forest.cc:812] Training of tree  62/200 (tree index:54) done accuracy:0.733333 logloss:0.609864\n",
      "I0000 00:00:1729625104.872330 6792820 random_forest.cc:812] Training of tree  72/200 (tree index:71) done accuracy:0.683333 logloss:0.614853\n",
      "I0000 00:00:1729625104.872487 6792825 random_forest.cc:812] Training of tree  82/200 (tree index:83) done accuracy:0.7 logloss:0.612984\n",
      "I0000 00:00:1729625104.872610 6792825 random_forest.cc:812] Training of tree  92/200 (tree index:91) done accuracy:0.725 logloss:0.608122\n",
      "I0000 00:00:1729625104.872741 6792824 random_forest.cc:812] Training of tree  102/200 (tree index:102) done accuracy:0.733333 logloss:0.611829\n",
      "I0000 00:00:1729625104.872843 6792822 random_forest.cc:812] Training of tree  112/200 (tree index:111) done accuracy:0.733333 logloss:0.604807\n",
      "I0000 00:00:1729625104.872947 6792825 random_forest.cc:812] Training of tree  123/200 (tree index:122) done accuracy:0.716667 logloss:0.608143\n",
      "I0000 00:00:1729625104.873060 6792824 random_forest.cc:812] Training of tree  133/200 (tree index:132) done accuracy:0.733333 logloss:0.607213\n",
      "I0000 00:00:1729625104.873154 6792819 random_forest.cc:812] Training of tree  144/200 (tree index:143) done accuracy:0.733333 logloss:0.603802\n",
      "I0000 00:00:1729625104.873254 6792822 random_forest.cc:812] Training of tree  154/200 (tree index:152) done accuracy:0.741667 logloss:0.602175\n",
      "I0000 00:00:1729625104.873364 6792825 random_forest.cc:812] Training of tree  164/200 (tree index:163) done accuracy:0.741667 logloss:0.605691\n",
      "I0000 00:00:1729625104.873459 6792822 random_forest.cc:812] Training of tree  174/200 (tree index:174) done accuracy:0.733333 logloss:0.604899\n",
      "I0000 00:00:1729625104.873561 6792825 random_forest.cc:812] Training of tree  184/200 (tree index:183) done accuracy:0.75 logloss:0.600866\n",
      "I0000 00:00:1729625104.873685 6792823 random_forest.cc:812] Training of tree  194/200 (tree index:185) done accuracy:0.758333 logloss:0.596996\n",
      "I0000 00:00:1729625104.873786 6792820 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.733333 logloss:0.601887\n",
      "I0000 00:00:1729625104.873887 6792810 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.601887\n",
      "I0000 00:00:1729625104.874055 6792810 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpaldsvagi with prefix 5a9274aaa57e4278\n",
      "I0000 00:00:1729625104.875692 6792810 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625104.876581 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.601887\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  33  20\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:04.885891: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpaldsvagi/model/ with prefix 5a9274aaa57e4278\n",
      "I0000 00:00:1729625104.887807 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1298 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:25:04.887824: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpi65a02se as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.220749. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014473\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1sonpq9e as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625105.301389 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625105.301399 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625105.301405 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625105.301479 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625105.301484 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625105.301533 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.301543 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.301549 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.301555 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.301585 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625105.301604 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625105.301744 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625105.301855 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpi65a02se/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625105.301913 6792879 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625105.302002 6792879 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625105.302532 6792889 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625105.302639 6792893 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.691667 logloss:2.53573\n",
      "I0000 00:00:1729625105.302785 6792889 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.641667 logloss:0.8642\n",
      "I0000 00:00:1729625105.302918 6792895 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.691667 logloss:0.592644\n",
      "I0000 00:00:1729625105.303033 6792891 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.708333 logloss:0.591659\n",
      "I0000 00:00:1729625105.303154 6792889 random_forest.cc:812] Training of tree  51/200 (tree index:52) done accuracy:0.7 logloss:0.619125\n",
      "I0000 00:00:1729625105.303261 6792892 random_forest.cc:812] Training of tree  61/200 (tree index:61) done accuracy:0.708333 logloss:0.595833\n",
      "I0000 00:00:1729625105.303425 6792892 random_forest.cc:812] Training of tree  72/200 (tree index:73) done accuracy:0.708333 logloss:0.610501\n",
      "I0000 00:00:1729625105.303581 6792888 random_forest.cc:812] Training of tree  82/200 (tree index:81) done accuracy:0.708333 logloss:0.609196\n",
      "I0000 00:00:1729625105.303733 6792894 random_forest.cc:812] Training of tree  92/200 (tree index:92) done accuracy:0.708333 logloss:0.610752\n",
      "I0000 00:00:1729625105.303856 6792893 random_forest.cc:812] Training of tree  102/200 (tree index:104) done accuracy:0.716667 logloss:0.610692\n",
      "I0000 00:00:1729625105.303994 6792891 random_forest.cc:812] Training of tree  112/200 (tree index:96) done accuracy:0.716667 logloss:0.610848\n",
      "I0000 00:00:1729625105.304128 6792892 random_forest.cc:812] Training of tree  122/200 (tree index:122) done accuracy:0.708333 logloss:0.613599\n",
      "I0000 00:00:1729625105.304266 6792895 random_forest.cc:812] Training of tree  132/200 (tree index:131) done accuracy:0.7 logloss:0.614766\n",
      "I0000 00:00:1729625105.304377 6792890 random_forest.cc:812] Training of tree  142/200 (tree index:141) done accuracy:0.716667 logloss:0.609318\n",
      "I0000 00:00:1729625105.304505 6792890 random_forest.cc:812] Training of tree  152/200 (tree index:153) done accuracy:0.7 logloss:0.612579\n",
      "I0000 00:00:1729625105.304635 6792889 random_forest.cc:812] Training of tree  163/200 (tree index:163) done accuracy:0.691667 logloss:0.608573\n",
      "I0000 00:00:1729625105.304757 6792892 random_forest.cc:812] Training of tree  173/200 (tree index:174) done accuracy:0.691667 logloss:0.611322\n",
      "I0000 00:00:1729625105.304897 6792888 random_forest.cc:812] Training of tree  184/200 (tree index:185) done accuracy:0.691667 logloss:0.61165\n",
      "I0000 00:00:1729625105.305044 6792890 random_forest.cc:812] Training of tree  194/200 (tree index:192) done accuracy:0.691667 logloss:0.611901\n",
      "I0000 00:00:1729625105.305186 6792888 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.675 logloss:0.61671\n",
      "I0000 00:00:1729625105.305270 6792879 random_forest.cc:892] Final OOB metrics: accuracy:0.675 logloss:0.61671\n",
      "I0000 00:00:1729625105.305455 6792879 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpi65a02se with prefix 59485e0f16c240a5\n",
      "I0000 00:00:1729625105.306740 6792879 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625105.307493 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.675  CI95[W][0.597764 0.745608]\n",
      "LogLoss: : 0.61671\n",
      "ErrorRate: : 0.325\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  29  25\n",
      "2  14  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:05.312347: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpi65a02se/model/ with prefix 59485e0f16c240a5\n",
      "I0000 00:00:1729625105.314172 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1280 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:05.314188: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.155172. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.013334\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp14tni646 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625105.626111 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625105.626124 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625105.626129 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625105.626197 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625105.626208 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625105.626262 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.626272 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.626278 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.626283 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.626310 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625105.626331 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625105.626477 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625105.626513 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1sonpq9e/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625105.626557 6792953 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625105.626643 6792953 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625105.627068 6792963 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.574468 logloss:15.3377\n",
      "I0000 00:00:1729625105.627217 6792969 random_forest.cc:812] Training of tree  11/200 (tree index:7) done accuracy:0.630252 logloss:2.89529\n",
      "I0000 00:00:1729625105.627327 6792968 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.708333 logloss:1.73208\n",
      "I0000 00:00:1729625105.627423 6792965 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.741667 logloss:0.857794\n",
      "I0000 00:00:1729625105.627565 6792963 random_forest.cc:812] Training of tree  41/200 (tree index:44) done accuracy:0.741667 logloss:0.577682\n",
      "I0000 00:00:1729625105.627712 6792966 random_forest.cc:812] Training of tree  51/200 (tree index:52) done accuracy:0.75 logloss:0.573457\n",
      "I0000 00:00:1729625105.627834 6792966 random_forest.cc:812] Training of tree  61/200 (tree index:62) done accuracy:0.741667 logloss:0.570375\n",
      "I0000 00:00:1729625105.628001 6792965 random_forest.cc:812] Training of tree  73/200 (tree index:64) done accuracy:0.716667 logloss:0.573643\n",
      "I0000 00:00:1729625105.628114 6792965 random_forest.cc:812] Training of tree  83/200 (tree index:84) done accuracy:0.725 logloss:0.565595\n",
      "I0000 00:00:1729625105.628207 6792963 random_forest.cc:812] Training of tree  93/200 (tree index:92) done accuracy:0.725 logloss:0.567934\n",
      "I0000 00:00:1729625105.628357 6792967 random_forest.cc:812] Training of tree  103/200 (tree index:103) done accuracy:0.733333 logloss:0.562197\n",
      "I0000 00:00:1729625105.628486 6792963 random_forest.cc:812] Training of tree  114/200 (tree index:113) done accuracy:0.75 logloss:0.552105\n",
      "I0000 00:00:1729625105.628610 6792962 random_forest.cc:812] Training of tree  124/200 (tree index:124) done accuracy:0.741667 logloss:0.558639\n",
      "I0000 00:00:1729625105.628705 6792963 random_forest.cc:812] Training of tree  134/200 (tree index:132) done accuracy:0.733333 logloss:0.549519\n",
      "I0000 00:00:1729625105.628827 6792963 random_forest.cc:812] Training of tree  144/200 (tree index:144) done accuracy:0.75 logloss:0.546431\n",
      "I0000 00:00:1729625105.628960 6792962 random_forest.cc:812] Training of tree  154/200 (tree index:153) done accuracy:0.741667 logloss:0.548373\n",
      "I0000 00:00:1729625105.629086 6792967 random_forest.cc:812] Training of tree  164/200 (tree index:164) done accuracy:0.75 logloss:0.54916\n",
      "I0000 00:00:1729625105.629189 6792968 random_forest.cc:812] Training of tree  174/200 (tree index:175) done accuracy:0.741667 logloss:0.54501\n",
      "I0000 00:00:1729625105.629286 6792967 random_forest.cc:812] Training of tree  184/200 (tree index:184) done accuracy:0.741667 logloss:0.543797\n",
      "I0000 00:00:1729625105.629369 6792969 random_forest.cc:812] Training of tree  194/200 (tree index:193) done accuracy:0.75 logloss:0.545266\n",
      "I0000 00:00:1729625105.629512 6792965 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.75 logloss:0.540872\n",
      "I0000 00:00:1729625105.629560 6792953 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.540872\n",
      "I0000 00:00:1729625105.629727 6792953 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1sonpq9e with prefix b49def279d0b4510\n",
      "I0000 00:00:1729625105.630952 6792953 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625105.631545 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.540872\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  18\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:05.635849: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1sonpq9e/model/ with prefix b49def279d0b4510\n",
      "I0000 00:00:1729625105.637670 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1306 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:05.637691: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.190930. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014674\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 30, 'min_examples': 5, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpej7ohkvj as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625105.964501 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625105.964511 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625105.964516 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625105.964584 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625105.964588 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625105.964634 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.964644 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.964650 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.964686 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625105.964730 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625105.964757 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625105.964915 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625105.964947 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp14tni646/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625105.965005 6793027 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625105.965109 6793027 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625105.965534 6793043 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625105.965650 6793037 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.65812 logloss:4.0582\n",
      "I0000 00:00:1729625105.965825 6793036 random_forest.cc:812] Training of tree  24/200 (tree index:23) done accuracy:0.725 logloss:1.71929\n",
      "I0000 00:00:1729625105.965955 6793042 random_forest.cc:812] Training of tree  34/200 (tree index:33) done accuracy:0.733333 logloss:0.862389\n",
      "I0000 00:00:1729625105.966089 6793043 random_forest.cc:812] Training of tree  44/200 (tree index:43) done accuracy:0.733333 logloss:0.86299\n",
      "I0000 00:00:1729625105.966201 6793040 random_forest.cc:812] Training of tree  54/200 (tree index:54) done accuracy:0.675 logloss:0.58948\n",
      "I0000 00:00:1729625105.966293 6793037 random_forest.cc:812] Training of tree  64/200 (tree index:66) done accuracy:0.691667 logloss:0.590741\n",
      "I0000 00:00:1729625105.966380 6793043 random_forest.cc:812] Training of tree  74/200 (tree index:74) done accuracy:0.683333 logloss:0.587211\n",
      "I0000 00:00:1729625105.966574 6793036 random_forest.cc:812] Training of tree  89/200 (tree index:88) done accuracy:0.716667 logloss:0.575915\n",
      "I0000 00:00:1729625105.966720 6793041 random_forest.cc:812] Training of tree  99/200 (tree index:97) done accuracy:0.716667 logloss:0.577227\n",
      "I0000 00:00:1729625105.966810 6793038 random_forest.cc:812] Training of tree  109/200 (tree index:106) done accuracy:0.7 logloss:0.584159\n",
      "I0000 00:00:1729625105.966934 6793042 random_forest.cc:812] Training of tree  119/200 (tree index:118) done accuracy:0.708333 logloss:0.577554\n",
      "I0000 00:00:1729625105.967021 6793038 random_forest.cc:812] Training of tree  129/200 (tree index:129) done accuracy:0.716667 logloss:0.579759\n",
      "I0000 00:00:1729625105.967141 6793036 random_forest.cc:812] Training of tree  139/200 (tree index:138) done accuracy:0.708333 logloss:0.575935\n",
      "I0000 00:00:1729625105.967251 6793036 random_forest.cc:812] Training of tree  149/200 (tree index:150) done accuracy:0.725 logloss:0.575206\n",
      "I0000 00:00:1729625105.967346 6793040 random_forest.cc:812] Training of tree  160/200 (tree index:160) done accuracy:0.725 logloss:0.576734\n",
      "I0000 00:00:1729625105.967503 6793042 random_forest.cc:812] Training of tree  170/200 (tree index:169) done accuracy:0.716667 logloss:0.578386\n",
      "I0000 00:00:1729625105.967641 6793041 random_forest.cc:812] Training of tree  181/200 (tree index:173) done accuracy:0.716667 logloss:0.580736\n",
      "I0000 00:00:1729625105.967755 6793042 random_forest.cc:812] Training of tree  191/200 (tree index:190) done accuracy:0.716667 logloss:0.574337\n",
      "I0000 00:00:1729625105.967894 6793037 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.708333 logloss:0.57533\n",
      "I0000 00:00:1729625105.968012 6793027 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.57533\n",
      "I0000 00:00:1729625105.968211 6793027 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp14tni646 with prefix 2d1b18a217a24885\n",
      "I0000 00:00:1729625105.969669 6793027 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625105.970359 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.57533\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  19\n",
      "2  16  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:05.975583: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp14tni646/model/ with prefix 2d1b18a217a24885\n",
      "I0000 00:00:1729625105.977517 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1278 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:05.977531: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.159319. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.024071\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625106.281277 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625106.281294 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625106.281300 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625106.281367 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625106.281372 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625106.281439 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625106.281454 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625106.281460 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625106.281465 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625106.281501 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625106.281523 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625106.281660 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625106.281684 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpej7ohkvj/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625106.281746 6793107 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625106.281852 6793107 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625106.282383 6793118 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.55814 logloss:15.9263\n",
      "I0000 00:00:1729625106.282522 6793118 random_forest.cc:812] Training of tree  11/200 (tree index:8) done accuracy:0.705882 logloss:3.70979\n",
      "I0000 00:00:1729625106.282749 6793122 random_forest.cc:812] Training of tree  21/200 (tree index:14) done accuracy:0.7 logloss:1.4218\n",
      "I0000 00:00:1729625106.282934 6793119 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.708333 logloss:0.866228\n",
      "I0000 00:00:1729625106.283093 6793117 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.75 logloss:0.84022\n",
      "I0000 00:00:1729625106.283275 6793122 random_forest.cc:812] Training of tree  52/200 (tree index:53) done accuracy:0.725 logloss:0.544891\n",
      "I0000 00:00:1729625106.283468 6793121 random_forest.cc:812] Training of tree  62/200 (tree index:63) done accuracy:0.775 logloss:0.527299\n",
      "I0000 00:00:1729625106.283617 6793118 random_forest.cc:812] Training of tree  72/200 (tree index:72) done accuracy:0.75 logloss:0.527669\n",
      "I0000 00:00:1729625106.283789 6793121 random_forest.cc:812] Training of tree  82/200 (tree index:83) done accuracy:0.766667 logloss:0.523107\n",
      "I0000 00:00:1729625106.283937 6793117 random_forest.cc:812] Training of tree  92/200 (tree index:93) done accuracy:0.733333 logloss:0.525223\n",
      "I0000 00:00:1729625106.284149 6793116 random_forest.cc:812] Training of tree  102/200 (tree index:101) done accuracy:0.758333 logloss:0.523194\n",
      "I0000 00:00:1729625106.284331 6793121 random_forest.cc:812] Training of tree  112/200 (tree index:113) done accuracy:0.75 logloss:0.527507\n",
      "I0000 00:00:1729625106.284510 6793118 random_forest.cc:812] Training of tree  122/200 (tree index:122) done accuracy:0.75 logloss:0.523281\n",
      "I0000 00:00:1729625106.284673 6793122 random_forest.cc:812] Training of tree  132/200 (tree index:132) done accuracy:0.741667 logloss:0.527528\n",
      "I0000 00:00:1729625106.284934 6793121 random_forest.cc:812] Training of tree  144/200 (tree index:139) done accuracy:0.741667 logloss:0.530292\n",
      "I0000 00:00:1729625106.285170 6793120 random_forest.cc:812] Training of tree  154/200 (tree index:155) done accuracy:0.733333 logloss:0.536048\n",
      "I0000 00:00:1729625106.285380 6793123 random_forest.cc:812] Training of tree  166/200 (tree index:166) done accuracy:0.725 logloss:0.534613\n",
      "I0000 00:00:1729625106.285618 6793117 random_forest.cc:812] Training of tree  176/200 (tree index:176) done accuracy:0.741667 logloss:0.525714\n",
      "I0000 00:00:1729625106.285829 6793120 random_forest.cc:812] Training of tree  187/200 (tree index:185) done accuracy:0.733333 logloss:0.528133\n",
      "I0000 00:00:1729625106.286026 6793119 random_forest.cc:812] Training of tree  197/200 (tree index:198) done accuracy:0.75 logloss:0.522189\n",
      "I0000 00:00:1729625106.286081 6793123 random_forest.cc:812] Training of tree  200/200 (tree index:196) done accuracy:0.741667 logloss:0.519991\n",
      "I0000 00:00:1729625106.286112 6793107 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.519991\n",
      "I0000 00:00:1729625106.286612 6793107 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpej7ohkvj with prefix 719a6cf161f04ac8\n",
      "I0000 00:00:1729625106.289451 6793107 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625106.290181 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.519991\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  44  14\n",
      "2  17  45\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:06.296772: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpej7ohkvj/model/ with prefix 719a6cf161f04ac8\n",
      "I0000 00:00:1729625106.302634 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4390 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:06.302657: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpos4mnl4d as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.153512. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023125\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625106.682584 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625106.682595 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625106.682601 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625106.682661 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625106.682667 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625106.682709 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625106.682719 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625106.682724 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625106.682730 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625106.682756 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625106.682773 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625106.682897 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625106.682923 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpos4mnl4d/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625106.682975 6793201 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625106.683074 6793201 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625106.683605 6793216 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625106.683815 6793216 random_forest.cc:812] Training of tree  11/200 (tree index:8) done accuracy:0.677966 logloss:4.92866\n",
      "I0000 00:00:1729625106.684060 6793214 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.7 logloss:1.11828\n",
      "I0000 00:00:1729625106.684328 6793213 random_forest.cc:812] Training of tree  31/200 (tree index:33) done accuracy:0.766667 logloss:0.783028\n",
      "I0000 00:00:1729625106.684526 6793217 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.741667 logloss:0.804619\n",
      "I0000 00:00:1729625106.684702 6793212 random_forest.cc:812] Training of tree  51/200 (tree index:52) done accuracy:0.741667 logloss:0.51764\n",
      "I0000 00:00:1729625106.684905 6793215 random_forest.cc:812] Training of tree  61/200 (tree index:61) done accuracy:0.733333 logloss:0.507801\n",
      "I0000 00:00:1729625106.685056 6793215 random_forest.cc:812] Training of tree  71/200 (tree index:68) done accuracy:0.733333 logloss:0.508763\n",
      "I0000 00:00:1729625106.685254 6793217 random_forest.cc:812] Training of tree  81/200 (tree index:82) done accuracy:0.741667 logloss:0.514716\n",
      "I0000 00:00:1729625106.685429 6793216 random_forest.cc:812] Training of tree  91/200 (tree index:89) done accuracy:0.758333 logloss:0.498729\n",
      "I0000 00:00:1729625106.685639 6793211 random_forest.cc:812] Training of tree  101/200 (tree index:99) done accuracy:0.766667 logloss:0.492156\n",
      "I0000 00:00:1729625106.685860 6793217 random_forest.cc:812] Training of tree  111/200 (tree index:110) done accuracy:0.766667 logloss:0.493533\n",
      "I0000 00:00:1729625106.686123 6793212 random_forest.cc:812] Training of tree  125/200 (tree index:125) done accuracy:0.766667 logloss:0.497063\n",
      "I0000 00:00:1729625106.686358 6793217 random_forest.cc:812] Training of tree  135/200 (tree index:133) done accuracy:0.766667 logloss:0.493732\n",
      "I0000 00:00:1729625106.686538 6793210 random_forest.cc:812] Training of tree  145/200 (tree index:143) done accuracy:0.766667 logloss:0.495192\n",
      "I0000 00:00:1729625106.686699 6793216 random_forest.cc:812] Training of tree  155/200 (tree index:154) done accuracy:0.766667 logloss:0.492318\n",
      "I0000 00:00:1729625106.686922 6793215 random_forest.cc:812] Training of tree  165/200 (tree index:158) done accuracy:0.766667 logloss:0.497264\n",
      "I0000 00:00:1729625106.687116 6793214 random_forest.cc:812] Training of tree  178/200 (tree index:177) done accuracy:0.775 logloss:0.496227\n",
      "I0000 00:00:1729625106.687426 6793217 random_forest.cc:812] Training of tree  189/200 (tree index:191) done accuracy:0.766667 logloss:0.497523\n",
      "I0000 00:00:1729625106.687696 6793212 random_forest.cc:812] Training of tree  199/200 (tree index:189) done accuracy:0.758333 logloss:0.498385\n",
      "I0000 00:00:1729625106.687732 6793211 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.758333 logloss:0.498196\n",
      "I0000 00:00:1729625106.687807 6793201 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.498196\n",
      "I0000 00:00:1729625106.688368 6793201 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpos4mnl4d with prefix e0697381f86846e3\n",
      "I0000 00:00:1729625106.691130 6793201 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625106.691800 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.498196\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  14  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:06.697507: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpos4mnl4d/model/ with prefix e0697381f86846e3\n",
      "I0000 00:00:1729625106.703497 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4500 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:06.703518: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpv8g3hj8e as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.201738. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.025065\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpl3yyoy98 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625107.061074 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625107.061084 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625107.061092 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625107.061157 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625107.061164 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625107.061209 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.061219 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.061225 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.061230 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.061257 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625107.061274 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625107.061413 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625107.061437 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpv8g3hj8e/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625107.061499 6793273 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625107.061586 6793273 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625107.062119 6793287 random_forest.cc:812] Training of tree  1/200 (tree index:2) done accuracy:0.634146 logloss:13.1867\n",
      "I0000 00:00:1729625107.062345 6793285 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.672269 logloss:3.98393\n",
      "I0000 00:00:1729625107.062609 6793285 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.675 logloss:1.43625\n",
      "I0000 00:00:1729625107.062901 6793285 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.658333 logloss:0.585851\n",
      "I0000 00:00:1729625107.063223 6793285 random_forest.cc:812] Training of tree  42/200 (tree index:44) done accuracy:0.716667 logloss:0.560181\n",
      "I0000 00:00:1729625107.063440 6793285 random_forest.cc:812] Training of tree  52/200 (tree index:54) done accuracy:0.733333 logloss:0.548353\n",
      "I0000 00:00:1729625107.063672 6793288 random_forest.cc:812] Training of tree  62/200 (tree index:60) done accuracy:0.75 logloss:0.554132\n",
      "I0000 00:00:1729625107.063932 6793286 random_forest.cc:812] Training of tree  72/200 (tree index:70) done accuracy:0.733333 logloss:0.544346\n",
      "I0000 00:00:1729625107.064165 6793286 random_forest.cc:812] Training of tree  82/200 (tree index:83) done accuracy:0.758333 logloss:0.539816\n",
      "I0000 00:00:1729625107.064323 6793287 random_forest.cc:812] Training of tree  93/200 (tree index:94) done accuracy:0.708333 logloss:0.537516\n",
      "I0000 00:00:1729625107.064585 6793284 random_forest.cc:812] Training of tree  103/200 (tree index:96) done accuracy:0.725 logloss:0.539433\n",
      "I0000 00:00:1729625107.064830 6793286 random_forest.cc:812] Training of tree  113/200 (tree index:113) done accuracy:0.725 logloss:0.54096\n",
      "I0000 00:00:1729625107.065035 6793284 random_forest.cc:812] Training of tree  123/200 (tree index:125) done accuracy:0.708333 logloss:0.542406\n",
      "I0000 00:00:1729625107.065214 6793287 random_forest.cc:812] Training of tree  133/200 (tree index:134) done accuracy:0.708333 logloss:0.544625\n",
      "I0000 00:00:1729625107.065392 6793282 random_forest.cc:812] Training of tree  143/200 (tree index:144) done accuracy:0.716667 logloss:0.542398\n",
      "I0000 00:00:1729625107.065590 6793283 random_forest.cc:812] Training of tree  153/200 (tree index:154) done accuracy:0.733333 logloss:0.546478\n",
      "I0000 00:00:1729625107.065897 6793287 random_forest.cc:812] Training of tree  163/200 (tree index:139) done accuracy:0.741667 logloss:0.543111\n",
      "I0000 00:00:1729625107.066253 6793287 random_forest.cc:812] Training of tree  173/200 (tree index:175) done accuracy:0.733333 logloss:0.542388\n",
      "I0000 00:00:1729625107.066509 6793288 random_forest.cc:812] Training of tree  184/200 (tree index:186) done accuracy:0.741667 logloss:0.541281\n",
      "I0000 00:00:1729625107.066776 6793288 random_forest.cc:812] Training of tree  194/200 (tree index:195) done accuracy:0.741667 logloss:0.542186\n",
      "I0000 00:00:1729625107.066919 6793288 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.741667 logloss:0.541956\n",
      "I0000 00:00:1729625107.066995 6793273 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.541956\n",
      "I0000 00:00:1729625107.067548 6793273 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpv8g3hj8e with prefix bfdbe3a896d74437\n",
      "I0000 00:00:1729625107.070073 6793273 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625107.070976 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.541956\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  16\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:07.076924: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpv8g3hj8e/model/ with prefix bfdbe3a896d74437\n",
      "I0000 00:00:1729625107.083721 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4606 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:07.083747: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.165452. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022440\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625107.410223 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625107.410234 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625107.410237 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625107.410297 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625107.410303 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625107.410344 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.410353 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.410358 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.410363 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.410390 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625107.410406 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625107.410536 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625107.410562 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpl3yyoy98/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625107.410613 6793350 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625107.410709 6793350 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625107.411266 6793360 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625107.411472 6793362 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.747899 logloss:2.17782\n",
      "I0000 00:00:1729625107.411664 6793361 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.816667 logloss:0.701023\n",
      "I0000 00:00:1729625107.411851 6793362 random_forest.cc:812] Training of tree  31/200 (tree index:26) done accuracy:0.808333 logloss:0.41593\n",
      "I0000 00:00:1729625107.412020 6793362 random_forest.cc:812] Training of tree  41/200 (tree index:38) done accuracy:0.783333 logloss:0.431407\n",
      "I0000 00:00:1729625107.412173 6793363 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.791667 logloss:0.429712\n",
      "I0000 00:00:1729625107.412403 6793365 random_forest.cc:812] Training of tree  61/200 (tree index:62) done accuracy:0.766667 logloss:0.435192\n",
      "I0000 00:00:1729625107.412544 6793361 random_forest.cc:812] Training of tree  71/200 (tree index:70) done accuracy:0.766667 logloss:0.445749\n",
      "I0000 00:00:1729625107.412695 6793364 random_forest.cc:812] Training of tree  81/200 (tree index:81) done accuracy:0.775 logloss:0.451353\n",
      "I0000 00:00:1729625107.412837 6793359 random_forest.cc:812] Training of tree  91/200 (tree index:90) done accuracy:0.808333 logloss:0.446877\n",
      "I0000 00:00:1729625107.413020 6793360 random_forest.cc:812] Training of tree  101/200 (tree index:101) done accuracy:0.8 logloss:0.452713\n",
      "I0000 00:00:1729625107.413206 6793359 random_forest.cc:812] Training of tree  111/200 (tree index:113) done accuracy:0.8 logloss:0.450905\n",
      "I0000 00:00:1729625107.413464 6793366 random_forest.cc:812] Training of tree  121/200 (tree index:117) done accuracy:0.8 logloss:0.451188\n",
      "I0000 00:00:1729625107.413681 6793359 random_forest.cc:812] Training of tree  131/200 (tree index:132) done accuracy:0.8 logloss:0.44706\n",
      "I0000 00:00:1729625107.413882 6793360 random_forest.cc:812] Training of tree  141/200 (tree index:138) done accuracy:0.791667 logloss:0.448955\n",
      "I0000 00:00:1729625107.414069 6793366 random_forest.cc:812] Training of tree  152/200 (tree index:141) done accuracy:0.791667 logloss:0.448637\n",
      "I0000 00:00:1729625107.414266 6793366 random_forest.cc:812] Training of tree  162/200 (tree index:163) done accuracy:0.791667 logloss:0.445402\n",
      "I0000 00:00:1729625107.414418 6793363 random_forest.cc:812] Training of tree  172/200 (tree index:173) done accuracy:0.8 logloss:0.447965\n",
      "I0000 00:00:1729625107.414585 6793365 random_forest.cc:812] Training of tree  183/200 (tree index:183) done accuracy:0.783333 logloss:0.454884\n",
      "I0000 00:00:1729625107.414753 6793364 random_forest.cc:812] Training of tree  193/200 (tree index:193) done accuracy:0.783333 logloss:0.454853\n",
      "I0000 00:00:1729625107.414853 6793359 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.783333 logloss:0.458263\n",
      "I0000 00:00:1729625107.414938 6793350 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.458263\n",
      "I0000 00:00:1729625107.415381 6793350 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpl3yyoy98 with prefix 77e4121016bf43ab\n",
      "I0000 00:00:1729625107.417577 6793350 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625107.418187 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.458263\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:07.424967: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpl3yyoy98/model/ with prefix 77e4121016bf43ab\n",
      "I0000 00:00:1729625107.430441 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4132 node(s), and 19 input feature(s).\n",
      "I0000 00:00:1729625107.430457 6784195 abstract_model.cc:1323] Engine \"RandomForestOptPred\" built\n",
      "2024-10-22 20:25:07.430462: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6men2mel as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.151600. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021597\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625107.778683 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625107.778694 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625107.778697 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625107.778759 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625107.778765 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625107.778806 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.778816 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.778821 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.778827 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625107.778854 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625107.778873 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625107.778998 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625107.779023 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6men2mel/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625107.779066 6793421 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625107.779172 6793421 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625107.779682 6793435 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625107.779823 6793433 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.689076 logloss:4.55231\n",
      "I0000 00:00:1729625107.780029 6793432 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.741667 logloss:1.93925\n",
      "I0000 00:00:1729625107.780205 6793435 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.758333 logloss:1.07347\n",
      "I0000 00:00:1729625107.780401 6793434 random_forest.cc:812] Training of tree  41/200 (tree index:32) done accuracy:0.775 logloss:0.786095\n",
      "I0000 00:00:1729625107.780604 6793431 random_forest.cc:812] Training of tree  51/200 (tree index:49) done accuracy:0.775 logloss:0.481224\n",
      "I0000 00:00:1729625107.780793 6793436 random_forest.cc:812] Training of tree  61/200 (tree index:62) done accuracy:0.783333 logloss:0.490688\n",
      "I0000 00:00:1729625107.781056 6793433 random_forest.cc:812] Training of tree  71/200 (tree index:72) done accuracy:0.791667 logloss:0.485123\n",
      "I0000 00:00:1729625107.781235 6793433 random_forest.cc:812] Training of tree  81/200 (tree index:81) done accuracy:0.783333 logloss:0.480288\n",
      "I0000 00:00:1729625107.781388 6793436 random_forest.cc:812] Training of tree  91/200 (tree index:91) done accuracy:0.783333 logloss:0.476674\n",
      "I0000 00:00:1729625107.781555 6793432 random_forest.cc:812] Training of tree  101/200 (tree index:101) done accuracy:0.783333 logloss:0.477296\n",
      "I0000 00:00:1729625107.781743 6793436 random_forest.cc:812] Training of tree  111/200 (tree index:111) done accuracy:0.783333 logloss:0.483265\n",
      "I0000 00:00:1729625107.781952 6793430 random_forest.cc:812] Training of tree  121/200 (tree index:122) done accuracy:0.783333 logloss:0.49274\n",
      "I0000 00:00:1729625107.782154 6793432 random_forest.cc:812] Training of tree  131/200 (tree index:134) done accuracy:0.775 logloss:0.487809\n",
      "I0000 00:00:1729625107.782340 6793433 random_forest.cc:812] Training of tree  141/200 (tree index:139) done accuracy:0.775 logloss:0.492465\n",
      "I0000 00:00:1729625107.782528 6793434 random_forest.cc:812] Training of tree  151/200 (tree index:150) done accuracy:0.775 logloss:0.49373\n",
      "I0000 00:00:1729625107.782715 6793434 random_forest.cc:812] Training of tree  161/200 (tree index:161) done accuracy:0.766667 logloss:0.493341\n",
      "I0000 00:00:1729625107.782964 6793430 random_forest.cc:812] Training of tree  171/200 (tree index:165) done accuracy:0.766667 logloss:0.495472\n",
      "I0000 00:00:1729625107.783198 6793432 random_forest.cc:812] Training of tree  181/200 (tree index:181) done accuracy:0.766667 logloss:0.495311\n",
      "I0000 00:00:1729625107.783374 6793437 random_forest.cc:812] Training of tree  191/200 (tree index:191) done accuracy:0.766667 logloss:0.49615\n",
      "I0000 00:00:1729625107.783554 6793430 random_forest.cc:812] Training of tree  200/200 (tree index:198) done accuracy:0.766667 logloss:0.489188\n",
      "I0000 00:00:1729625107.783660 6793421 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.489188\n",
      "I0000 00:00:1729625107.784238 6793421 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6men2mel with prefix 15f7dfea06e84ebd\n",
      "I0000 00:00:1729625107.786705 6793421 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625107.787300 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.489188\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  12\n",
      "2  16  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:07.792597: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6men2mel/model/ with prefix 15f7dfea06e84ebd\n",
      "I0000 00:00:1729625107.798296 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4372 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:07.798314: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 30, 'min_examples': 5, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo6cmbkp9 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.471771. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021268\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpblbqh889 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625108.425659 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625108.425672 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625108.425677 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625108.425751 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625108.425756 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625108.425802 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625108.425812 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625108.425818 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625108.425824 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625108.425851 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625108.425869 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625108.426022 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625108.426044 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo6cmbkp9/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625108.426096 6793496 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625108.426196 6793496 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625108.426757 6793512 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625108.426902 6793506 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.65 logloss:2.86254\n",
      "I0000 00:00:1729625108.427109 6793509 random_forest.cc:812] Training of tree  23/200 (tree index:23) done accuracy:0.733333 logloss:0.788314\n",
      "I0000 00:00:1729625108.427336 6793512 random_forest.cc:812] Training of tree  33/200 (tree index:29) done accuracy:0.725 logloss:0.516024\n",
      "I0000 00:00:1729625108.427577 6793505 random_forest.cc:812] Training of tree  43/200 (tree index:42) done accuracy:0.666667 logloss:0.581371\n",
      "I0000 00:00:1729625108.427710 6793507 random_forest.cc:812] Training of tree  53/200 (tree index:55) done accuracy:0.716667 logloss:0.558019\n",
      "I0000 00:00:1729625108.427889 6793509 random_forest.cc:812] Training of tree  64/200 (tree index:64) done accuracy:0.733333 logloss:0.538854\n",
      "I0000 00:00:1729625108.428061 6793510 random_forest.cc:812] Training of tree  74/200 (tree index:73) done accuracy:0.683333 logloss:0.546771\n",
      "I0000 00:00:1729625108.428242 6793506 random_forest.cc:812] Training of tree  84/200 (tree index:83) done accuracy:0.725 logloss:0.53822\n",
      "I0000 00:00:1729625108.428431 6793512 random_forest.cc:812] Training of tree  95/200 (tree index:85) done accuracy:0.708333 logloss:0.541109\n",
      "I0000 00:00:1729625108.428603 6793507 random_forest.cc:812] Training of tree  105/200 (tree index:105) done accuracy:0.708333 logloss:0.540359\n",
      "I0000 00:00:1729625108.428775 6793510 random_forest.cc:812] Training of tree  115/200 (tree index:116) done accuracy:0.733333 logloss:0.528939\n",
      "I0000 00:00:1729625108.428931 6793507 random_forest.cc:812] Training of tree  125/200 (tree index:124) done accuracy:0.725 logloss:0.53148\n",
      "I0000 00:00:1729625108.429135 6793510 random_forest.cc:812] Training of tree  136/200 (tree index:136) done accuracy:0.75 logloss:0.527611\n",
      "I0000 00:00:1729625108.429314 6793507 random_forest.cc:812] Training of tree  146/200 (tree index:145) done accuracy:0.733333 logloss:0.52979\n",
      "I0000 00:00:1729625108.429463 6793506 random_forest.cc:812] Training of tree  156/200 (tree index:156) done accuracy:0.741667 logloss:0.527945\n",
      "I0000 00:00:1729625108.429608 6793505 random_forest.cc:812] Training of tree  166/200 (tree index:167) done accuracy:0.725 logloss:0.531426\n",
      "I0000 00:00:1729625108.429812 6793510 random_forest.cc:812] Training of tree  180/200 (tree index:180) done accuracy:0.741667 logloss:0.523931\n",
      "I0000 00:00:1729625108.430070 6793511 random_forest.cc:812] Training of tree  190/200 (tree index:190) done accuracy:0.733333 logloss:0.519544\n",
      "I0000 00:00:1729625108.430217 6793507 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.733333 logloss:0.518974\n",
      "I0000 00:00:1729625108.430264 6793496 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.518974\n",
      "I0000 00:00:1729625108.430681 6793496 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo6cmbkp9 with prefix a8200ee4391b4fa8\n",
      "I0000 00:00:1729625108.432891 6793496 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625108.433540 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.518974\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:08.439703: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo6cmbkp9/model/ with prefix a8200ee4391b4fa8\n",
      "I0000 00:00:1729625108.444779 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3776 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:08.444797: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.185558. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027645\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625108.779722 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625108.779737 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625108.779743 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625108.779814 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625108.779821 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625108.779867 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625108.779877 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625108.779883 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625108.779889 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625108.779917 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625108.779947 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625108.780111 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625108.780137 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpblbqh889/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625108.780218 6793565 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625108.780326 6793565 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625108.780927 6793574 random_forest.cc:812] Training of tree  1/200 (tree index:4) done accuracy:0.660714 logloss:12.2291\n",
      "I0000 00:00:1729625108.781180 6793580 random_forest.cc:812] Training of tree  11/200 (tree index:9) done accuracy:0.672269 logloss:2.86783\n",
      "I0000 00:00:1729625108.781565 6793576 random_forest.cc:812] Training of tree  21/200 (tree index:23) done accuracy:0.675 logloss:1.16832\n",
      "I0000 00:00:1729625108.781951 6793575 random_forest.cc:812] Training of tree  31/200 (tree index:0) done accuracy:0.675 logloss:0.601939\n",
      "I0000 00:00:1729625108.782336 6793579 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.691667 logloss:0.586761\n",
      "I0000 00:00:1729625108.782615 6793579 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.716667 logloss:0.563739\n",
      "I0000 00:00:1729625108.782877 6793580 random_forest.cc:812] Training of tree  61/200 (tree index:59) done accuracy:0.758333 logloss:0.555722\n",
      "I0000 00:00:1729625108.783111 6793575 random_forest.cc:812] Training of tree  71/200 (tree index:72) done accuracy:0.741667 logloss:0.562634\n",
      "I0000 00:00:1729625108.783361 6793578 random_forest.cc:812] Training of tree  81/200 (tree index:82) done accuracy:0.741667 logloss:0.559911\n",
      "I0000 00:00:1729625108.783599 6793580 random_forest.cc:812] Training of tree  91/200 (tree index:91) done accuracy:0.725 logloss:0.561483\n",
      "I0000 00:00:1729625108.783948 6793581 random_forest.cc:812] Training of tree  101/200 (tree index:99) done accuracy:0.733333 logloss:0.559556\n",
      "I0000 00:00:1729625108.784218 6793579 random_forest.cc:812] Training of tree  111/200 (tree index:111) done accuracy:0.725 logloss:0.555717\n",
      "I0000 00:00:1729625108.784546 6793575 random_forest.cc:812] Training of tree  121/200 (tree index:117) done accuracy:0.75 logloss:0.549188\n",
      "I0000 00:00:1729625108.785023 6793580 random_forest.cc:812] Training of tree  131/200 (tree index:118) done accuracy:0.741667 logloss:0.551694\n",
      "I0000 00:00:1729625108.785465 6793578 random_forest.cc:812] Training of tree  141/200 (tree index:142) done accuracy:0.758333 logloss:0.547697\n",
      "I0000 00:00:1729625108.785796 6793578 random_forest.cc:812] Training of tree  151/200 (tree index:144) done accuracy:0.766667 logloss:0.547608\n",
      "I0000 00:00:1729625108.786068 6793581 random_forest.cc:812] Training of tree  161/200 (tree index:160) done accuracy:0.766667 logloss:0.548942\n",
      "I0000 00:00:1729625108.786372 6793574 random_forest.cc:812] Training of tree  171/200 (tree index:172) done accuracy:0.766667 logloss:0.547851\n",
      "I0000 00:00:1729625108.786618 6793576 random_forest.cc:812] Training of tree  181/200 (tree index:183) done accuracy:0.775 logloss:0.544328\n",
      "I0000 00:00:1729625108.786885 6793580 random_forest.cc:812] Training of tree  191/200 (tree index:177) done accuracy:0.783333 logloss:0.54689\n",
      "I0000 00:00:1729625108.787116 6793576 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.775 logloss:0.541575\n",
      "I0000 00:00:1729625108.787233 6793565 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.541575\n",
      "I0000 00:00:1729625108.787844 6793565 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpblbqh889 with prefix fff5e9902ed8405d\n",
      "I0000 00:00:1729625108.790531 6793565 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625108.791426 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.541575\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:08.799442: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpblbqh889/model/ with prefix fff5e9902ed8405d\n",
      "I0000 00:00:1729625108.804926 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3862 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:08.804954: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxog4m720 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.171453. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022981\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625109.241972 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625109.241984 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625109.241993 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625109.242066 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625109.242071 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625109.242116 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.242125 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.242131 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.242136 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.242164 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625109.242182 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625109.242318 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625109.242340 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxog4m720/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625109.242405 6793635 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625109.242513 6793635 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625109.243104 6793644 random_forest.cc:812] Training of tree  1/200 (tree index:2) done accuracy:0.632653 logloss:13.2405\n",
      "I0000 00:00:1729625109.243364 6793649 random_forest.cc:812] Training of tree  12/200 (tree index:8) done accuracy:0.675 logloss:4.02905\n",
      "I0000 00:00:1729625109.243561 6793649 random_forest.cc:812] Training of tree  22/200 (tree index:24) done accuracy:0.666667 logloss:1.17629\n",
      "I0000 00:00:1729625109.243751 6793650 random_forest.cc:812] Training of tree  32/200 (tree index:31) done accuracy:0.7 logloss:0.574378\n",
      "I0000 00:00:1729625109.243938 6793649 random_forest.cc:812] Training of tree  42/200 (tree index:41) done accuracy:0.716667 logloss:0.570692\n",
      "I0000 00:00:1729625109.244112 6793649 random_forest.cc:812] Training of tree  52/200 (tree index:52) done accuracy:0.75 logloss:0.550747\n",
      "I0000 00:00:1729625109.244304 6793648 random_forest.cc:812] Training of tree  63/200 (tree index:63) done accuracy:0.75 logloss:0.555499\n",
      "I0000 00:00:1729625109.244493 6793647 random_forest.cc:812] Training of tree  74/200 (tree index:74) done accuracy:0.766667 logloss:0.542297\n",
      "I0000 00:00:1729625109.244721 6793649 random_forest.cc:812] Training of tree  84/200 (tree index:67) done accuracy:0.783333 logloss:0.532803\n",
      "I0000 00:00:1729625109.244896 6793649 random_forest.cc:812] Training of tree  94/200 (tree index:94) done accuracy:0.791667 logloss:0.530089\n",
      "I0000 00:00:1729625109.245067 6793645 random_forest.cc:812] Training of tree  104/200 (tree index:107) done accuracy:0.8 logloss:0.524681\n",
      "I0000 00:00:1729625109.245279 6793649 random_forest.cc:812] Training of tree  114/200 (tree index:111) done accuracy:0.8 logloss:0.526705\n",
      "I0000 00:00:1729625109.245522 6793647 random_forest.cc:812] Training of tree  124/200 (tree index:126) done accuracy:0.783333 logloss:0.523274\n",
      "I0000 00:00:1729625109.245754 6793646 random_forest.cc:812] Training of tree  135/200 (tree index:136) done accuracy:0.766667 logloss:0.520369\n",
      "I0000 00:00:1729625109.246085 6793649 random_forest.cc:812] Training of tree  145/200 (tree index:138) done accuracy:0.775 logloss:0.522962\n",
      "I0000 00:00:1729625109.246285 6793647 random_forest.cc:812] Training of tree  155/200 (tree index:152) done accuracy:0.766667 logloss:0.521292\n",
      "I0000 00:00:1729625109.246503 6793648 random_forest.cc:812] Training of tree  165/200 (tree index:156) done accuracy:0.775 logloss:0.523839\n",
      "I0000 00:00:1729625109.246703 6793649 random_forest.cc:812] Training of tree  175/200 (tree index:177) done accuracy:0.775 logloss:0.526292\n",
      "I0000 00:00:1729625109.246883 6793648 random_forest.cc:812] Training of tree  185/200 (tree index:185) done accuracy:0.783333 logloss:0.52713\n",
      "I0000 00:00:1729625109.247073 6793647 random_forest.cc:812] Training of tree  195/200 (tree index:194) done accuracy:0.783333 logloss:0.522284\n",
      "I0000 00:00:1729625109.247251 6793644 random_forest.cc:812] Training of tree  200/200 (tree index:196) done accuracy:0.783333 logloss:0.524861\n",
      "I0000 00:00:1729625109.247357 6793635 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.524861\n",
      "I0000 00:00:1729625109.247892 6793635 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxog4m720 with prefix 8b1ccba062134132\n",
      "I0000 00:00:1729625109.250314 6793635 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625109.251149 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.524861\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  15\n",
      "2  11  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:09.257672: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxog4m720/model/ with prefix 8b1ccba062134132\n",
      "I0000 00:00:1729625109.262702 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3900 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:09.262722: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3afxcqu5 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.197516. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625109.603618 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625109.603631 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625109.603635 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625109.603698 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625109.603702 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625109.603746 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.603757 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.603762 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.603768 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.603797 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625109.603815 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625109.603950 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625109.603973 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3afxcqu5/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625109.604054 6793708 kernel.cc:888] Train model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.020719\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpot2zxr51 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625109.604157 6793708 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625109.604634 6793717 random_forest.cc:812] Training of tree  1/200 (tree index:4) done accuracy:0.696429 logloss:10.9418\n",
      "I0000 00:00:1729625109.604791 6793721 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.689076 logloss:3.08324\n",
      "I0000 00:00:1729625109.604955 6793723 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.775 logloss:1.3423\n",
      "I0000 00:00:1729625109.605180 6793721 random_forest.cc:812] Training of tree  32/200 (tree index:29) done accuracy:0.766667 logloss:1.03773\n",
      "I0000 00:00:1729625109.605341 6793717 random_forest.cc:812] Training of tree  42/200 (tree index:40) done accuracy:0.758333 logloss:0.481649\n",
      "I0000 00:00:1729625109.605475 6793719 random_forest.cc:812] Training of tree  52/200 (tree index:53) done accuracy:0.758333 logloss:0.487998\n",
      "I0000 00:00:1729625109.605657 6793722 random_forest.cc:812] Training of tree  62/200 (tree index:61) done accuracy:0.783333 logloss:0.483065\n",
      "I0000 00:00:1729625109.605816 6793723 random_forest.cc:812] Training of tree  72/200 (tree index:73) done accuracy:0.791667 logloss:0.486688\n",
      "I0000 00:00:1729625109.606020 6793719 random_forest.cc:812] Training of tree  82/200 (tree index:82) done accuracy:0.758333 logloss:0.485782\n",
      "I0000 00:00:1729625109.606181 6793718 random_forest.cc:812] Training of tree  92/200 (tree index:92) done accuracy:0.766667 logloss:0.473531\n",
      "I0000 00:00:1729625109.606313 6793724 random_forest.cc:812] Training of tree  102/200 (tree index:100) done accuracy:0.775 logloss:0.473916\n",
      "I0000 00:00:1729625109.606488 6793721 random_forest.cc:812] Training of tree  112/200 (tree index:114) done accuracy:0.791667 logloss:0.482151\n",
      "I0000 00:00:1729625109.606656 6793717 random_forest.cc:812] Training of tree  122/200 (tree index:125) done accuracy:0.8 logloss:0.483059\n",
      "I0000 00:00:1729625109.606801 6793721 random_forest.cc:812] Training of tree  133/200 (tree index:132) done accuracy:0.791667 logloss:0.478375\n",
      "I0000 00:00:1729625109.606982 6793723 random_forest.cc:812] Training of tree  143/200 (tree index:135) done accuracy:0.783333 logloss:0.479259\n",
      "I0000 00:00:1729625109.607221 6793720 random_forest.cc:812] Training of tree  154/200 (tree index:156) done accuracy:0.775 logloss:0.478654\n",
      "I0000 00:00:1729625109.607468 6793723 random_forest.cc:812] Training of tree  164/200 (tree index:164) done accuracy:0.783333 logloss:0.476361\n",
      "I0000 00:00:1729625109.607620 6793721 random_forest.cc:812] Training of tree  174/200 (tree index:175) done accuracy:0.775 logloss:0.476438\n",
      "I0000 00:00:1729625109.607811 6793722 random_forest.cc:812] Training of tree  184/200 (tree index:184) done accuracy:0.775 logloss:0.480048\n",
      "I0000 00:00:1729625109.607992 6793723 random_forest.cc:812] Training of tree  195/200 (tree index:194) done accuracy:0.775 logloss:0.481565\n",
      "I0000 00:00:1729625109.608090 6793721 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.783333 logloss:0.479409\n",
      "I0000 00:00:1729625109.608143 6793708 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.479409\n",
      "I0000 00:00:1729625109.608625 6793708 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3afxcqu5 with prefix 33e7e6acaf0f4949\n",
      "I0000 00:00:1729625109.610797 6793708 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625109.611375 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.479409\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:09.616911: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3afxcqu5/model/ with prefix 33e7e6acaf0f4949\n",
      "I0000 00:00:1729625109.622201 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3526 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:09.622219: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.169694. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022399\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 30, 'min_examples': 10, 'bootstrap_size_ratio': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625109.950407 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625109.950418 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625109.950423 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625109.950497 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625109.950504 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625109.950550 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.950561 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.950567 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.950572 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625109.950600 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625109.950618 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625109.950785 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625109.950809 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpot2zxr51/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625109.950884 6793781 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625109.951040 6793781 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625109.951467 6793790 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.641509 logloss:12.9213\n",
      "I0000 00:00:1729625109.951598 6793792 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.75 logloss:2.18793\n",
      "I0000 00:00:1729625109.951741 6793791 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.725 logloss:0.755519\n",
      "I0000 00:00:1729625109.951882 6793793 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.75 logloss:0.728411\n",
      "I0000 00:00:1729625109.952047 6793796 random_forest.cc:812] Training of tree  42/200 (tree index:42) done accuracy:0.766667 logloss:0.486866\n",
      "I0000 00:00:1729625109.952201 6793797 random_forest.cc:812] Training of tree  52/200 (tree index:51) done accuracy:0.775 logloss:0.472148\n",
      "I0000 00:00:1729625109.952425 6793792 random_forest.cc:812] Training of tree  67/200 (tree index:66) done accuracy:0.775 logloss:0.470243\n",
      "I0000 00:00:1729625109.952677 6793795 random_forest.cc:812] Training of tree  77/200 (tree index:76) done accuracy:0.775 logloss:0.472886\n",
      "I0000 00:00:1729625109.952863 6793792 random_forest.cc:812] Training of tree  88/200 (tree index:89) done accuracy:0.783333 logloss:0.455572\n",
      "I0000 00:00:1729625109.953022 6793796 random_forest.cc:812] Training of tree  98/200 (tree index:98) done accuracy:0.775 logloss:0.462411\n",
      "I0000 00:00:1729625109.953185 6793796 random_forest.cc:812] Training of tree  108/200 (tree index:108) done accuracy:0.775 logloss:0.460691\n",
      "I0000 00:00:1729625109.953392 6793791 random_forest.cc:812] Training of tree  118/200 (tree index:117) done accuracy:0.775 logloss:0.464129\n",
      "I0000 00:00:1729625109.953605 6793792 random_forest.cc:812] Training of tree  130/200 (tree index:130) done accuracy:0.783333 logloss:0.462399\n",
      "I0000 00:00:1729625109.953806 6793792 random_forest.cc:812] Training of tree  140/200 (tree index:139) done accuracy:0.783333 logloss:0.465512\n",
      "I0000 00:00:1729625109.953930 6793791 random_forest.cc:812] Training of tree  150/200 (tree index:150) done accuracy:0.775 logloss:0.470078\n",
      "I0000 00:00:1729625109.954098 6793795 random_forest.cc:812] Training of tree  160/200 (tree index:155) done accuracy:0.775 logloss:0.473908\n",
      "I0000 00:00:1729625109.954308 6793791 random_forest.cc:812] Training of tree  170/200 (tree index:171) done accuracy:0.783333 logloss:0.473797\n",
      "I0000 00:00:1729625109.954427 6793790 random_forest.cc:812] Training of tree  180/200 (tree index:180) done accuracy:0.775 logloss:0.472331\n",
      "I0000 00:00:1729625109.954592 6793796 random_forest.cc:812] Training of tree  190/200 (tree index:190) done accuracy:0.775 logloss:0.472754\n",
      "I0000 00:00:1729625109.954854 6793796 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.766667 logloss:0.475475\n",
      "I0000 00:00:1729625109.954917 6793781 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.475475\n",
      "I0000 00:00:1729625109.955432 6793781 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpot2zxr51 with prefix e1eb99869a764507\n",
      "I0000 00:00:1729625109.957748 6793781 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625109.958723 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.475475\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:09.963961: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpot2zxr51/model/ with prefix e1eb99869a764507\n",
      "I0000 00:00:1729625109.970453 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3668 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:09.970469: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp99s8chx5 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.166704. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022477\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625110.343083 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625110.343097 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625110.343101 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625110.343173 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625110.343180 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625110.343231 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625110.343244 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625110.343250 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625110.343255 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625110.343286 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625110.343303 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625110.343456 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625110.343477 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp99s8chx5/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625110.343539 6793851 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625110.343754 6793851 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625110.344440 6793861 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.72093 logloss:10.0587\n",
      "I0000 00:00:1729625110.344638 6793866 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.728814 logloss:4.57257\n",
      "I0000 00:00:1729625110.344833 6793866 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.75 logloss:1.68467\n",
      "I0000 00:00:1729625110.345019 6793867 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.766667 logloss:1.10566\n",
      "I0000 00:00:1729625110.345236 6793867 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.766667 logloss:0.816431\n",
      "I0000 00:00:1729625110.345415 6793865 random_forest.cc:812] Training of tree  51/200 (tree index:53) done accuracy:0.75 logloss:0.824592\n",
      "I0000 00:00:1729625110.345563 6793866 random_forest.cc:812] Training of tree  61/200 (tree index:62) done accuracy:0.733333 logloss:0.803703\n",
      "I0000 00:00:1729625110.345738 6793864 random_forest.cc:812] Training of tree  71/200 (tree index:71) done accuracy:0.725 logloss:0.807199\n",
      "I0000 00:00:1729625110.345909 6793865 random_forest.cc:812] Training of tree  81/200 (tree index:82) done accuracy:0.725 logloss:0.80804\n",
      "I0000 00:00:1729625110.346078 6793865 random_forest.cc:812] Training of tree  91/200 (tree index:90) done accuracy:0.708333 logloss:0.817596\n",
      "I0000 00:00:1729625110.346269 6793867 random_forest.cc:812] Training of tree  101/200 (tree index:102) done accuracy:0.708333 logloss:0.544078\n",
      "I0000 00:00:1729625110.346428 6793864 random_forest.cc:812] Training of tree  111/200 (tree index:110) done accuracy:0.708333 logloss:0.549689\n",
      "I0000 00:00:1729625110.346622 6793865 random_forest.cc:812] Training of tree  121/200 (tree index:122) done accuracy:0.708333 logloss:0.547007\n",
      "I0000 00:00:1729625110.346840 6793864 random_forest.cc:812] Training of tree  131/200 (tree index:131) done accuracy:0.7 logloss:0.543633\n",
      "I0000 00:00:1729625110.347081 6793862 random_forest.cc:812] Training of tree  141/200 (tree index:143) done accuracy:0.7 logloss:0.55187\n",
      "I0000 00:00:1729625110.347252 6793862 random_forest.cc:812] Training of tree  151/200 (tree index:151) done accuracy:0.708333 logloss:0.553183\n",
      "I0000 00:00:1729625110.347434 6793862 random_forest.cc:812] Training of tree  162/200 (tree index:162) done accuracy:0.716667 logloss:0.554489\n",
      "I0000 00:00:1729625110.347682 6793864 random_forest.cc:812] Training of tree  172/200 (tree index:173) done accuracy:0.708333 logloss:0.558572\n",
      "I0000 00:00:1729625110.347966 6793865 random_forest.cc:812] Training of tree  182/200 (tree index:177) done accuracy:0.691667 logloss:0.54397\n",
      "I0000 00:00:1729625110.348147 6793866 random_forest.cc:812] Training of tree  192/200 (tree index:188) done accuracy:0.708333 logloss:0.546753\n",
      "I0000 00:00:1729625110.348378 6793864 random_forest.cc:812] Training of tree  200/200 (tree index:194) done accuracy:0.708333 logloss:0.548091\n",
      "I0000 00:00:1729625110.348490 6793851 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.548091\n",
      "I0000 00:00:1729625110.348887 6793851 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp99s8chx5 with prefix c9fcb8daa1a34305\n",
      "I0000 00:00:1729625110.351368 6793851 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625110.352167 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.548091\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  18\n",
      "2  17  45\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:10.357927: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp99s8chx5/model/ with prefix c9fcb8daa1a34305\n",
      "I0000 00:00:1729625110.363486 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3054 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:10.363505: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpoqnlzib5 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.165111. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021867\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625110.751507 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625110.751535 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625110.751540 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625110.751603 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625110.751608 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625110.751653 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625110.751662 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625110.751668 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625110.751673 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625110.751701 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625110.751718 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625110.751848 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625110.751871 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpoqnlzib5/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625110.751930 6793928 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625110.752038 6793928 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625110.752540 6793938 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.772727 logloss:8.19174\n",
      "I0000 00:00:1729625110.752710 6793942 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.691667 logloss:5.13664\n",
      "I0000 00:00:1729625110.752855 6793939 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.741667 logloss:1.67124\n",
      "I0000 00:00:1729625110.753042 6793942 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.766667 logloss:1.06971\n",
      "I0000 00:00:1729625110.753238 6793939 random_forest.cc:812] Training of tree  42/200 (tree index:41) done accuracy:0.766667 logloss:0.795927\n",
      "I0000 00:00:1729625110.753470 6793938 random_forest.cc:812] Training of tree  52/200 (tree index:49) done accuracy:0.766667 logloss:0.534502\n",
      "I0000 00:00:1729625110.753714 6793938 random_forest.cc:812] Training of tree  62/200 (tree index:63) done accuracy:0.783333 logloss:0.539645\n",
      "I0000 00:00:1729625110.753884 6793940 random_forest.cc:812] Training of tree  72/200 (tree index:56) done accuracy:0.775 logloss:0.536798\n",
      "I0000 00:00:1729625110.754057 6793937 random_forest.cc:812] Training of tree  82/200 (tree index:83) done accuracy:0.758333 logloss:0.534275\n",
      "I0000 00:00:1729625110.754199 6793942 random_forest.cc:812] Training of tree  92/200 (tree index:91) done accuracy:0.766667 logloss:0.530247\n",
      "I0000 00:00:1729625110.754352 6793944 random_forest.cc:812] Training of tree  102/200 (tree index:100) done accuracy:0.783333 logloss:0.525054\n",
      "I0000 00:00:1729625110.754549 6793942 random_forest.cc:812] Training of tree  112/200 (tree index:112) done accuracy:0.766667 logloss:0.531306\n",
      "I0000 00:00:1729625110.754709 6793939 random_forest.cc:812] Training of tree  122/200 (tree index:121) done accuracy:0.758333 logloss:0.527874\n",
      "I0000 00:00:1729625110.754851 6793938 random_forest.cc:812] Training of tree  132/200 (tree index:133) done accuracy:0.733333 logloss:0.526586\n",
      "I0000 00:00:1729625110.754996 6793941 random_forest.cc:812] Training of tree  142/200 (tree index:143) done accuracy:0.75 logloss:0.530838\n",
      "I0000 00:00:1729625110.755183 6793943 random_forest.cc:812] Training of tree  153/200 (tree index:141) done accuracy:0.758333 logloss:0.530855\n",
      "I0000 00:00:1729625110.755356 6793943 random_forest.cc:812] Training of tree  163/200 (tree index:163) done accuracy:0.766667 logloss:0.535288\n",
      "I0000 00:00:1729625110.755517 6793942 random_forest.cc:812] Training of tree  173/200 (tree index:172) done accuracy:0.75 logloss:0.535794\n",
      "I0000 00:00:1729625110.755682 6793938 random_forest.cc:812] Training of tree  183/200 (tree index:183) done accuracy:0.75 logloss:0.535849\n",
      "I0000 00:00:1729625110.755828 6793943 random_forest.cc:812] Training of tree  193/200 (tree index:193) done accuracy:0.75 logloss:0.5395\n",
      "I0000 00:00:1729625110.755926 6793944 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.775 logloss:0.544829\n",
      "I0000 00:00:1729625110.755953 6793928 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.544829\n",
      "I0000 00:00:1729625110.756409 6793928 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpoqnlzib5 with prefix 4dd972318d1c4ecb\n",
      "I0000 00:00:1729625110.759093 6793928 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625110.759885 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.544829\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:10.766959: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpoqnlzib5/model/ with prefix 4dd972318d1c4ecb\n",
      "I0000 00:00:1729625110.771367 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3088 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:10.771385: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpms_k9pdw as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.227450. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023704\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625111.169531 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625111.169542 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625111.169548 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625111.169620 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625111.169626 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625111.169675 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625111.169688 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625111.169693 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625111.169699 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625111.169726 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625111.169745 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625111.169954 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625111.169983 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpms_k9pdw/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625111.170086 6794008 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625111.170200 6794008 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625111.170884 6794023 random_forest.cc:812] Training of tree  1/200 (tree index:2) done accuracy:0.682927 logloss:11.4285\n",
      "I0000 00:00:1729625111.171172 6794021 random_forest.cc:812] Training of tree  11/200 (tree index:8) done accuracy:0.716814 logloss:4.72707\n",
      "I0000 00:00:1729625111.171618 6794017 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.675 logloss:1.68551\n",
      "I0000 00:00:1729625111.171977 6794024 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.708333 logloss:0.865086\n",
      "I0000 00:00:1729625111.172218 6794024 random_forest.cc:812] Training of tree  41/200 (tree index:42) done accuracy:0.708333 logloss:0.86261\n",
      "I0000 00:00:1729625111.172642 6794024 random_forest.cc:812] Training of tree  51/200 (tree index:48) done accuracy:0.691667 logloss:0.589035\n",
      "I0000 00:00:1729625111.172912 6794018 random_forest.cc:812] Training of tree  61/200 (tree index:61) done accuracy:0.675 logloss:0.594007\n",
      "I0000 00:00:1729625111.173427 6794018 random_forest.cc:812] Training of tree  71/200 (tree index:72) done accuracy:0.708333 logloss:0.587902\n",
      "I0000 00:00:1729625111.173630 6794021 random_forest.cc:812] Training of tree  81/200 (tree index:81) done accuracy:0.691667 logloss:0.59429\n",
      "I0000 00:00:1729625111.173842 6794022 random_forest.cc:812] Training of tree  91/200 (tree index:91) done accuracy:0.691667 logloss:0.593095\n",
      "I0000 00:00:1729625111.174054 6794023 random_forest.cc:812] Training of tree  101/200 (tree index:101) done accuracy:0.725 logloss:0.582571\n",
      "I0000 00:00:1729625111.174290 6794022 random_forest.cc:812] Training of tree  111/200 (tree index:112) done accuracy:0.708333 logloss:0.584384\n",
      "I0000 00:00:1729625111.174507 6794023 random_forest.cc:812] Training of tree  121/200 (tree index:123) done accuracy:0.725 logloss:0.584983\n",
      "I0000 00:00:1729625111.174704 6794023 random_forest.cc:812] Training of tree  131/200 (tree index:131) done accuracy:0.725 logloss:0.585529\n",
      "I0000 00:00:1729625111.174901 6794017 random_forest.cc:812] Training of tree  141/200 (tree index:141) done accuracy:0.716667 logloss:0.583846\n",
      "I0000 00:00:1729625111.175119 6794019 random_forest.cc:812] Training of tree  151/200 (tree index:152) done accuracy:0.716667 logloss:0.58329\n",
      "I0000 00:00:1729625111.175336 6794021 random_forest.cc:812] Training of tree  161/200 (tree index:162) done accuracy:0.716667 logloss:0.583227\n",
      "I0000 00:00:1729625111.175528 6794022 random_forest.cc:812] Training of tree  171/200 (tree index:173) done accuracy:0.716667 logloss:0.579621\n",
      "I0000 00:00:1729625111.175730 6794022 random_forest.cc:812] Training of tree  181/200 (tree index:181) done accuracy:0.716667 logloss:0.573642\n",
      "I0000 00:00:1729625111.175974 6794020 random_forest.cc:812] Training of tree  192/200 (tree index:185) done accuracy:0.716667 logloss:0.575863\n",
      "I0000 00:00:1729625111.176175 6794023 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.716667 logloss:0.569787\n",
      "I0000 00:00:1729625111.176318 6794008 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.569787\n",
      "I0000 00:00:1729625111.176664 6794008 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpms_k9pdw with prefix 4f2ea921517e40ce\n",
      "I0000 00:00:1729625111.178852 6794008 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625111.179673 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.569787\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  17  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:11.185719: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpms_k9pdw/model/ with prefix 4f2ea921517e40ce\n",
      "I0000 00:00:1729625111.190277 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3078 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:11.190355: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptwoheu0w as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.303472. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.020776\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbfk7osce as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625111.707879 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625111.707890 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625111.707894 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625111.707961 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625111.707967 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625111.708009 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625111.708020 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625111.708026 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625111.708031 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625111.708060 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625111.708076 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625111.708205 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625111.708228 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptwoheu0w/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625111.708263 6794081 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625111.708363 6794081 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625111.708957 6794094 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.674419 logloss:11.7351\n",
      "I0000 00:00:1729625111.709138 6794097 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.720339 logloss:5.18722\n",
      "I0000 00:00:1729625111.709423 6794093 random_forest.cc:812] Training of tree  25/200 (tree index:24) done accuracy:0.741667 logloss:0.791611\n",
      "I0000 00:00:1729625111.709658 6794097 random_forest.cc:812] Training of tree  35/200 (tree index:35) done accuracy:0.741667 logloss:0.768851\n",
      "I0000 00:00:1729625111.709779 6794090 random_forest.cc:812] Training of tree  45/200 (tree index:44) done accuracy:0.733333 logloss:0.777704\n",
      "I0000 00:00:1729625111.709994 6794097 random_forest.cc:812] Training of tree  55/200 (tree index:57) done accuracy:0.741667 logloss:0.505595\n",
      "I0000 00:00:1729625111.710172 6794093 random_forest.cc:812] Training of tree  65/200 (tree index:65) done accuracy:0.75 logloss:0.497963\n",
      "I0000 00:00:1729625111.710358 6794097 random_forest.cc:812] Training of tree  77/200 (tree index:76) done accuracy:0.758333 logloss:0.488037\n",
      "I0000 00:00:1729625111.710542 6794097 random_forest.cc:812] Training of tree  87/200 (tree index:88) done accuracy:0.775 logloss:0.486707\n",
      "I0000 00:00:1729625111.710752 6794091 random_forest.cc:812] Training of tree  97/200 (tree index:97) done accuracy:0.775 logloss:0.480978\n",
      "I0000 00:00:1729625111.710890 6794096 random_forest.cc:812] Training of tree  107/200 (tree index:106) done accuracy:0.783333 logloss:0.471822\n",
      "I0000 00:00:1729625111.711055 6794096 random_forest.cc:812] Training of tree  117/200 (tree index:117) done accuracy:0.791667 logloss:0.471114\n",
      "I0000 00:00:1729625111.711181 6794095 random_forest.cc:812] Training of tree  127/200 (tree index:126) done accuracy:0.791667 logloss:0.467418\n",
      "I0000 00:00:1729625111.711325 6794096 random_forest.cc:812] Training of tree  137/200 (tree index:136) done accuracy:0.8 logloss:0.471738\n",
      "I0000 00:00:1729625111.711489 6794093 random_forest.cc:812] Training of tree  147/200 (tree index:146) done accuracy:0.791667 logloss:0.48022\n",
      "I0000 00:00:1729625111.711629 6794090 random_forest.cc:812] Training of tree  157/200 (tree index:158) done accuracy:0.791667 logloss:0.476145\n",
      "I0000 00:00:1729625111.711812 6794090 random_forest.cc:812] Training of tree  167/200 (tree index:170) done accuracy:0.8 logloss:0.477033\n",
      "I0000 00:00:1729625111.711980 6794096 random_forest.cc:812] Training of tree  177/200 (tree index:179) done accuracy:0.8 logloss:0.477306\n",
      "I0000 00:00:1729625111.712157 6794097 random_forest.cc:812] Training of tree  187/200 (tree index:189) done accuracy:0.8 logloss:0.478943\n",
      "I0000 00:00:1729625111.712312 6794095 random_forest.cc:812] Training of tree  197/200 (tree index:195) done accuracy:0.783333 logloss:0.480168\n",
      "I0000 00:00:1729625111.712384 6794093 random_forest.cc:812] Training of tree  200/200 (tree index:198) done accuracy:0.791667 logloss:0.481198\n",
      "I0000 00:00:1729625111.712430 6794081 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.481198\n",
      "I0000 00:00:1729625111.712773 6794081 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptwoheu0w with prefix c0ff2b3b2b43491f\n",
      "I0000 00:00:1729625111.715634 6794081 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625111.716191 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.481198\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  11  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:11.721739: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptwoheu0w/model/ with prefix c0ff2b3b2b43491f\n",
      "I0000 00:00:1729625111.726702 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2908 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:11.726723: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.212854. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.019098\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 30, 'min_examples': 10, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp52vd8vqz as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625112.098895 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625112.098910 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625112.098920 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625112.098994 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625112.098999 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625112.099044 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.099054 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.099059 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.099064 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.099096 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625112.099113 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625112.099247 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625112.099270 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbfk7osce/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625112.099337 6794154 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625112.099430 6794154 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625112.099950 6794169 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625112.100122 6794164 random_forest.cc:812] Training of tree  11/200 (tree index:1) done accuracy:0.773109 logloss:2.74265\n",
      "I0000 00:00:1729625112.100317 6794170 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.725 logloss:1.64351\n",
      "I0000 00:00:1729625112.100555 6794164 random_forest.cc:812] Training of tree  31/200 (tree index:28) done accuracy:0.75 logloss:0.792145\n",
      "I0000 00:00:1729625112.100686 6794168 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.766667 logloss:0.785825\n",
      "I0000 00:00:1729625112.100885 6794169 random_forest.cc:812] Training of tree  53/200 (tree index:53) done accuracy:0.766667 logloss:0.489795\n",
      "I0000 00:00:1729625112.101053 6794170 random_forest.cc:812] Training of tree  63/200 (tree index:63) done accuracy:0.783333 logloss:0.486857\n",
      "I0000 00:00:1729625112.101218 6794167 random_forest.cc:812] Training of tree  73/200 (tree index:64) done accuracy:0.783333 logloss:0.489644\n",
      "I0000 00:00:1729625112.101370 6794167 random_forest.cc:812] Training of tree  83/200 (tree index:82) done accuracy:0.766667 logloss:0.49223\n",
      "I0000 00:00:1729625112.101540 6794170 random_forest.cc:812] Training of tree  93/200 (tree index:88) done accuracy:0.766667 logloss:0.492974\n",
      "I0000 00:00:1729625112.101703 6794166 random_forest.cc:812] Training of tree  103/200 (tree index:104) done accuracy:0.766667 logloss:0.4917\n",
      "I0000 00:00:1729625112.101872 6794170 random_forest.cc:812] Training of tree  113/200 (tree index:114) done accuracy:0.758333 logloss:0.497336\n",
      "I0000 00:00:1729625112.102003 6794164 random_forest.cc:812] Training of tree  123/200 (tree index:113) done accuracy:0.758333 logloss:0.494633\n",
      "I0000 00:00:1729625112.102196 6794163 random_forest.cc:812] Training of tree  133/200 (tree index:126) done accuracy:0.75 logloss:0.494492\n",
      "I0000 00:00:1729625112.102358 6794164 random_forest.cc:812] Training of tree  143/200 (tree index:138) done accuracy:0.741667 logloss:0.497774\n",
      "I0000 00:00:1729625112.102546 6794168 random_forest.cc:812] Training of tree  153/200 (tree index:149) done accuracy:0.758333 logloss:0.497909\n",
      "I0000 00:00:1729625112.102681 6794163 random_forest.cc:812] Training of tree  163/200 (tree index:162) done accuracy:0.741667 logloss:0.500811\n",
      "I0000 00:00:1729625112.102882 6794164 random_forest.cc:812] Training of tree  174/200 (tree index:173) done accuracy:0.758333 logloss:0.495833\n",
      "I0000 00:00:1729625112.103043 6794167 random_forest.cc:812] Training of tree  184/200 (tree index:184) done accuracy:0.75 logloss:0.497773\n",
      "I0000 00:00:1729625112.103172 6794166 random_forest.cc:812] Training of tree  194/200 (tree index:194) done accuracy:0.758333 logloss:0.494959\n",
      "I0000 00:00:1729625112.103252 6794163 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.758333 logloss:0.494298\n",
      "I0000 00:00:1729625112.103313 6794154 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.494298\n",
      "I0000 00:00:1729625112.103674 6794154 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbfk7osce with prefix 90be90bb17d24565\n",
      "I0000 00:00:1729625112.105633 6794154 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625112.106316 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.494298\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  15  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:12.111819: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbfk7osce/model/ with prefix 90be90bb17d24565\n",
      "I0000 00:00:1729625112.115804 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3012 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:12.115834: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.168809. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018640\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625112.433710 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625112.433732 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625112.433741 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625112.433811 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625112.433816 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625112.433860 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.433872 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.433878 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.433911 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.433955 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625112.433989 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625112.434158 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625112.434193 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp52vd8vqz/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625112.434261 6794223 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625112.434361 6794223 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625112.434936 6794234 random_forest.cc:812] Training of tree  1/200 (tree index:2) done accuracy:0.55102 logloss:16.1829\n",
      "I0000 00:00:1729625112.435087 6794237 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.733333 logloss:2.76854\n",
      "I0000 00:00:1729625112.435250 6794232 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.791667 logloss:1.95457\n",
      "I0000 00:00:1729625112.435429 6794232 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.766667 logloss:1.40237\n",
      "I0000 00:00:1729625112.435576 6794234 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.758333 logloss:0.850527\n",
      "I0000 00:00:1729625112.435708 6794239 random_forest.cc:812] Training of tree  51/200 (tree index:51) done accuracy:0.741667 logloss:0.562634\n",
      "I0000 00:00:1729625112.435827 6794237 random_forest.cc:812] Training of tree  61/200 (tree index:61) done accuracy:0.733333 logloss:0.548343\n",
      "I0000 00:00:1729625112.435935 6794233 random_forest.cc:812] Training of tree  71/200 (tree index:72) done accuracy:0.658333 logloss:0.551678\n",
      "I0000 00:00:1729625112.436038 6794234 random_forest.cc:812] Training of tree  81/200 (tree index:81) done accuracy:0.708333 logloss:0.548358\n",
      "I0000 00:00:1729625112.436190 6794235 random_forest.cc:812] Training of tree  91/200 (tree index:80) done accuracy:0.708333 logloss:0.549477\n",
      "I0000 00:00:1729625112.436334 6794234 random_forest.cc:812] Training of tree  101/200 (tree index:99) done accuracy:0.7 logloss:0.558587\n",
      "I0000 00:00:1729625112.436475 6794233 random_forest.cc:812] Training of tree  111/200 (tree index:110) done accuracy:0.7 logloss:0.554368\n",
      "I0000 00:00:1729625112.436631 6794238 random_forest.cc:812] Training of tree  121/200 (tree index:120) done accuracy:0.733333 logloss:0.550382\n",
      "I0000 00:00:1729625112.436766 6794239 random_forest.cc:812] Training of tree  131/200 (tree index:133) done accuracy:0.691667 logloss:0.549958\n",
      "I0000 00:00:1729625112.436869 6794236 random_forest.cc:812] Training of tree  141/200 (tree index:141) done accuracy:0.7 logloss:0.549073\n",
      "I0000 00:00:1729625112.437035 6794235 random_forest.cc:812] Training of tree  151/200 (tree index:151) done accuracy:0.708333 logloss:0.551024\n",
      "I0000 00:00:1729625112.437176 6794239 random_forest.cc:812] Training of tree  162/200 (tree index:162) done accuracy:0.716667 logloss:0.549335\n",
      "I0000 00:00:1729625112.437344 6794238 random_forest.cc:812] Training of tree  173/200 (tree index:173) done accuracy:0.716667 logloss:0.553941\n",
      "I0000 00:00:1729625112.437498 6794238 random_forest.cc:812] Training of tree  183/200 (tree index:182) done accuracy:0.7 logloss:0.551472\n",
      "I0000 00:00:1729625112.437682 6794235 random_forest.cc:812] Training of tree  193/200 (tree index:186) done accuracy:0.708333 logloss:0.545763\n",
      "I0000 00:00:1729625112.437820 6794235 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.7 logloss:0.546815\n",
      "I0000 00:00:1729625112.437896 6794223 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.546815\n",
      "I0000 00:00:1729625112.438192 6794223 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp52vd8vqz with prefix 74b50aee26354d7f\n",
      "I0000 00:00:1729625112.440070 6794223 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625112.440962 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.546815\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  19  43\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:12.446568: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp52vd8vqz/model/ with prefix 74b50aee26354d7f\n",
      "I0000 00:00:1729625112.450005 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2516 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:12.450028: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpuv6n_67g as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.173633. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018390\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625112.867570 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625112.867582 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625112.867590 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625112.867659 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625112.867665 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625112.867710 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.867721 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.867726 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.867731 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625112.867787 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625112.867830 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625112.868000 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625112.868037 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpuv6n_67g/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625112.868152 6794295 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625112.868247 6794295 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625112.868909 6794310 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.773585 logloss:8.16083\n",
      "I0000 00:00:1729625112.869072 6794306 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.697479 logloss:2.25483\n",
      "I0000 00:00:1729625112.869228 6794309 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.725 logloss:1.42734\n",
      "I0000 00:00:1729625112.869361 6794311 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.741667 logloss:0.593088\n",
      "I0000 00:00:1729625112.869491 6794307 random_forest.cc:812] Training of tree  41/200 (tree index:42) done accuracy:0.725 logloss:0.579559\n",
      "I0000 00:00:1729625112.869611 6794309 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.716667 logloss:0.571565\n",
      "I0000 00:00:1729625112.869776 6794311 random_forest.cc:812] Training of tree  61/200 (tree index:61) done accuracy:0.741667 logloss:0.569109\n",
      "I0000 00:00:1729625112.869915 6794308 random_forest.cc:812] Training of tree  71/200 (tree index:70) done accuracy:0.725 logloss:0.574293\n",
      "I0000 00:00:1729625112.870054 6794307 random_forest.cc:812] Training of tree  82/200 (tree index:81) done accuracy:0.741667 logloss:0.567736\n",
      "I0000 00:00:1729625112.870235 6794305 random_forest.cc:812] Training of tree  92/200 (tree index:90) done accuracy:0.733333 logloss:0.560399\n",
      "I0000 00:00:1729625112.870345 6794309 random_forest.cc:812] Training of tree  102/200 (tree index:100) done accuracy:0.75 logloss:0.556534\n",
      "I0000 00:00:1729625112.870491 6794310 random_forest.cc:812] Training of tree  112/200 (tree index:110) done accuracy:0.75 logloss:0.559483\n",
      "I0000 00:00:1729625112.870641 6794305 random_forest.cc:812] Training of tree  122/200 (tree index:121) done accuracy:0.758333 logloss:0.557913\n",
      "I0000 00:00:1729625112.870831 6794310 random_forest.cc:812] Training of tree  133/200 (tree index:133) done accuracy:0.766667 logloss:0.561488\n",
      "I0000 00:00:1729625112.870990 6794310 random_forest.cc:812] Training of tree  144/200 (tree index:145) done accuracy:0.775 logloss:0.558415\n",
      "I0000 00:00:1729625112.871171 6794308 random_forest.cc:812] Training of tree  154/200 (tree index:152) done accuracy:0.766667 logloss:0.562222\n",
      "I0000 00:00:1729625112.871291 6794310 random_forest.cc:812] Training of tree  165/200 (tree index:164) done accuracy:0.775 logloss:0.563273\n",
      "I0000 00:00:1729625112.871481 6794309 random_forest.cc:812] Training of tree  176/200 (tree index:175) done accuracy:0.775 logloss:0.562476\n",
      "I0000 00:00:1729625112.871631 6794307 random_forest.cc:812] Training of tree  186/200 (tree index:185) done accuracy:0.775 logloss:0.560842\n",
      "I0000 00:00:1729625112.871774 6794308 random_forest.cc:812] Training of tree  196/200 (tree index:195) done accuracy:0.783333 logloss:0.557987\n",
      "I0000 00:00:1729625112.871843 6794307 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.783333 logloss:0.558912\n",
      "I0000 00:00:1729625112.871883 6794295 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.558912\n",
      "I0000 00:00:1729625112.872235 6794295 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpuv6n_67g with prefix ba30f70de720446d\n",
      "I0000 00:00:1729625112.874190 6794295 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625112.875093 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.558912\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:12.880598: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpuv6n_67g/model/ with prefix ba30f70de720446d\n",
      "I0000 00:00:1729625112.883825 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2536 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:12.883840: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzd6w3s2c as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.176296. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.020170\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625113.266660 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625113.266670 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625113.266676 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625113.266738 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625113.266743 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625113.266787 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625113.266796 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625113.266801 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625113.266806 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625113.266833 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625113.266853 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625113.266990 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625113.267011 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzd6w3s2c/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625113.267069 6794382 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625113.267176 6794382 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625113.267858 6794398 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625113.268032 6794396 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.658333 logloss:2.59964\n",
      "I0000 00:00:1729625113.268213 6794397 random_forest.cc:812] Training of tree  21/200 (tree index:18) done accuracy:0.616667 logloss:1.17714\n",
      "I0000 00:00:1729625113.268378 6794395 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.641667 logloss:0.892857\n",
      "I0000 00:00:1729625113.268530 6794397 random_forest.cc:812] Training of tree  41/200 (tree index:38) done accuracy:0.741667 logloss:0.588566\n",
      "I0000 00:00:1729625113.268697 6794394 random_forest.cc:812] Training of tree  51/200 (tree index:43) done accuracy:0.691667 logloss:0.590187\n",
      "I0000 00:00:1729625113.268910 6794391 random_forest.cc:812] Training of tree  62/200 (tree index:61) done accuracy:0.7 logloss:0.594774\n",
      "I0000 00:00:1729625113.269130 6794393 random_forest.cc:812] Training of tree  72/200 (tree index:73) done accuracy:0.716667 logloss:0.573905\n",
      "I0000 00:00:1729625113.269298 6794396 random_forest.cc:812] Training of tree  82/200 (tree index:82) done accuracy:0.675 logloss:0.564156\n",
      "I0000 00:00:1729625113.269440 6794395 random_forest.cc:812] Training of tree  92/200 (tree index:78) done accuracy:0.691667 logloss:0.564179\n",
      "I0000 00:00:1729625113.269582 6794394 random_forest.cc:812] Training of tree  102/200 (tree index:102) done accuracy:0.683333 logloss:0.568044\n",
      "I0000 00:00:1729625113.269720 6794395 random_forest.cc:812] Training of tree  112/200 (tree index:113) done accuracy:0.716667 logloss:0.56478\n",
      "I0000 00:00:1729625113.269870 6794391 random_forest.cc:812] Training of tree  122/200 (tree index:122) done accuracy:0.7 logloss:0.557859\n",
      "I0000 00:00:1729625113.270019 6794391 random_forest.cc:812] Training of tree  132/200 (tree index:131) done accuracy:0.691667 logloss:0.551147\n",
      "I0000 00:00:1729625113.270186 6794397 random_forest.cc:812] Training of tree  142/200 (tree index:142) done accuracy:0.691667 logloss:0.553035\n",
      "I0000 00:00:1729625113.270373 6794396 random_forest.cc:812] Training of tree  152/200 (tree index:152) done accuracy:0.708333 logloss:0.552324\n",
      "I0000 00:00:1729625113.270547 6794396 random_forest.cc:812] Training of tree  162/200 (tree index:163) done accuracy:0.716667 logloss:0.554384\n",
      "I0000 00:00:1729625113.270774 6794396 random_forest.cc:812] Training of tree  173/200 (tree index:173) done accuracy:0.725 logloss:0.560313\n",
      "I0000 00:00:1729625113.271007 6794395 random_forest.cc:812] Training of tree  183/200 (tree index:185) done accuracy:0.733333 logloss:0.562668\n",
      "I0000 00:00:1729625113.271323 6794393 random_forest.cc:812] Training of tree  196/200 (tree index:195) done accuracy:0.716667 logloss:0.568719\n",
      "I0000 00:00:1729625113.271430 6794393 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.733333 logloss:0.568349\n",
      "I0000 00:00:1729625113.271533 6794382 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.568349\n",
      "I0000 00:00:1729625113.271835 6794382 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzd6w3s2c with prefix 7bc9091afa014789\n",
      "I0000 00:00:1729625113.273537 6794382 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625113.274327 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.568349\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  35  19\n",
      "2  13  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:13.280167: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzd6w3s2c/model/ with prefix 7bc9091afa014789\n",
      "I0000 00:00:1729625113.284089 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2558 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:13.284109: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw8fh4jie as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.162200. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017064\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625113.671279 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625113.671301 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625113.671306 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625113.671368 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625113.671373 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625113.671419 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625113.671428 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625113.671434 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625113.671438 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625113.671466 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625113.671484 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625113.671620 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625113.671641 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw8fh4jie/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625113.671699 6794455 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625113.671809 6794455 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625113.672328 6794464 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.716981 logloss:10.201\n",
      "I0000 00:00:1729625113.672438 6794465 random_forest.cc:812] Training of tree  11/200 (tree index:9) done accuracy:0.683761 logloss:4.9362\n",
      "I0000 00:00:1729625113.672615 6794465 random_forest.cc:812] Training of tree  21/200 (tree index:23) done accuracy:0.708333 logloss:1.0945\n",
      "I0000 00:00:1729625113.672772 6794468 random_forest.cc:812] Training of tree  32/200 (tree index:30) done accuracy:0.75 logloss:0.795023\n",
      "I0000 00:00:1729625113.672920 6794465 random_forest.cc:812] Training of tree  42/200 (tree index:42) done accuracy:0.775 logloss:0.807933\n",
      "I0000 00:00:1729625113.673031 6794466 random_forest.cc:812] Training of tree  52/200 (tree index:41) done accuracy:0.741667 logloss:0.526717\n",
      "I0000 00:00:1729625113.673195 6794470 random_forest.cc:812] Training of tree  62/200 (tree index:62) done accuracy:0.741667 logloss:0.520122\n",
      "I0000 00:00:1729625113.673315 6794465 random_forest.cc:812] Training of tree  72/200 (tree index:72) done accuracy:0.758333 logloss:0.516339\n",
      "I0000 00:00:1729625113.673441 6794468 random_forest.cc:812] Training of tree  82/200 (tree index:78) done accuracy:0.741667 logloss:0.516602\n",
      "I0000 00:00:1729625113.673651 6794470 random_forest.cc:812] Training of tree  92/200 (tree index:95) done accuracy:0.75 logloss:0.515529\n",
      "I0000 00:00:1729625113.673794 6794464 random_forest.cc:812] Training of tree  102/200 (tree index:103) done accuracy:0.775 logloss:0.515597\n",
      "I0000 00:00:1729625113.673898 6794466 random_forest.cc:812] Training of tree  112/200 (tree index:111) done accuracy:0.775 logloss:0.510467\n",
      "I0000 00:00:1729625113.674086 6794469 random_forest.cc:812] Training of tree  123/200 (tree index:122) done accuracy:0.783333 logloss:0.505935\n",
      "I0000 00:00:1729625113.674286 6794470 random_forest.cc:812] Training of tree  135/200 (tree index:134) done accuracy:0.775 logloss:0.500192\n",
      "I0000 00:00:1729625113.674494 6794467 random_forest.cc:812] Training of tree  145/200 (tree index:143) done accuracy:0.775 logloss:0.497622\n",
      "I0000 00:00:1729625113.674638 6794467 random_forest.cc:812] Training of tree  156/200 (tree index:155) done accuracy:0.766667 logloss:0.495721\n",
      "I0000 00:00:1729625113.674841 6794464 random_forest.cc:812] Training of tree  167/200 (tree index:169) done accuracy:0.783333 logloss:0.497849\n",
      "I0000 00:00:1729625113.674993 6794465 random_forest.cc:812] Training of tree  178/200 (tree index:178) done accuracy:0.775 logloss:0.502045\n",
      "I0000 00:00:1729625113.675160 6794465 random_forest.cc:812] Training of tree  188/200 (tree index:188) done accuracy:0.766667 logloss:0.503584\n",
      "I0000 00:00:1729625113.675340 6794467 random_forest.cc:812] Training of tree  198/200 (tree index:196) done accuracy:0.775 logloss:0.500923\n",
      "I0000 00:00:1729625113.675380 6794470 random_forest.cc:812] Training of tree  200/200 (tree index:198) done accuracy:0.766667 logloss:0.501334\n",
      "I0000 00:00:1729625113.675416 6794455 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.501334\n",
      "I0000 00:00:1729625113.675714 6794455 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw8fh4jie with prefix 4eab1c52e21c4d29\n",
      "I0000 00:00:1729625113.677389 6794455 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625113.678046 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.501334\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  16\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:13.683030: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw8fh4jie/model/ with prefix 4eab1c52e21c4d29\n",
      "I0000 00:00:1729625113.686448 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2434 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:13.686469: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpeebueqo6 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.204412. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016801\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 30, 'min_examples': 20, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbr6yifyw as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625114.047953 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625114.047975 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625114.047980 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625114.048056 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625114.048071 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625114.048115 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.048125 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.048132 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.048137 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.048165 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625114.048183 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625114.048323 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625114.048348 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpeebueqo6/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625114.048406 6794525 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625114.048491 6794525 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625114.048995 6794534 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.735849 logloss:9.52096\n",
      "I0000 00:00:1729625114.049110 6794541 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.733333 logloss:2.18962\n",
      "I0000 00:00:1729625114.049266 6794535 random_forest.cc:812] Training of tree  21/200 (tree index:12) done accuracy:0.733333 logloss:0.794084\n",
      "I0000 00:00:1729625114.049416 6794535 random_forest.cc:812] Training of tree  33/200 (tree index:33) done accuracy:0.725 logloss:0.496499\n",
      "I0000 00:00:1729625114.049634 6794540 random_forest.cc:812] Training of tree  44/200 (tree index:41) done accuracy:0.766667 logloss:0.515918\n",
      "I0000 00:00:1729625114.049814 6794535 random_forest.cc:812] Training of tree  54/200 (tree index:54) done accuracy:0.766667 logloss:0.527167\n",
      "I0000 00:00:1729625114.049981 6794537 random_forest.cc:812] Training of tree  64/200 (tree index:65) done accuracy:0.758333 logloss:0.513108\n",
      "I0000 00:00:1729625114.050206 6794536 random_forest.cc:812] Training of tree  74/200 (tree index:73) done accuracy:0.758333 logloss:0.525619\n",
      "I0000 00:00:1729625114.050334 6794541 random_forest.cc:812] Training of tree  84/200 (tree index:82) done accuracy:0.775 logloss:0.518772\n",
      "I0000 00:00:1729625114.050482 6794536 random_forest.cc:812] Training of tree  94/200 (tree index:93) done accuracy:0.766667 logloss:0.516215\n",
      "I0000 00:00:1729625114.050658 6794535 random_forest.cc:812] Training of tree  104/200 (tree index:106) done accuracy:0.775 logloss:0.516566\n",
      "I0000 00:00:1729625114.050768 6794538 random_forest.cc:812] Training of tree  114/200 (tree index:113) done accuracy:0.775 logloss:0.515908\n",
      "I0000 00:00:1729625114.050914 6794540 random_forest.cc:812] Training of tree  124/200 (tree index:126) done accuracy:0.766667 logloss:0.512887\n",
      "I0000 00:00:1729625114.051050 6794539 random_forest.cc:812] Training of tree  134/200 (tree index:134) done accuracy:0.775 logloss:0.508942\n",
      "I0000 00:00:1729625114.051195 6794541 random_forest.cc:812] Training of tree  144/200 (tree index:147) done accuracy:0.775 logloss:0.514761\n",
      "I0000 00:00:1729625114.051312 6794539 random_forest.cc:812] Training of tree  154/200 (tree index:141) done accuracy:0.783333 logloss:0.511537\n",
      "I0000 00:00:1729625114.051469 6794534 random_forest.cc:812] Training of tree  164/200 (tree index:165) done accuracy:0.791667 logloss:0.510108\n",
      "I0000 00:00:1729625114.051711 6794540 random_forest.cc:812] Training of tree  176/200 (tree index:175) done accuracy:0.783333 logloss:0.51106\n",
      "I0000 00:00:1729625114.051890 6794540 random_forest.cc:812] Training of tree  186/200 (tree index:186) done accuracy:0.783333 logloss:0.512675\n",
      "I0000 00:00:1729625114.052016 6794535 random_forest.cc:812] Training of tree  196/200 (tree index:195) done accuracy:0.775 logloss:0.514056\n",
      "I0000 00:00:1729625114.052121 6794541 random_forest.cc:812] Training of tree  200/200 (tree index:196) done accuracy:0.766667 logloss:0.516313\n",
      "I0000 00:00:1729625114.052153 6794525 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.516313\n",
      "I0000 00:00:1729625114.052439 6794525 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpeebueqo6 with prefix 2b1460926e174455\n",
      "I0000 00:00:1729625114.054290 6794525 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625114.054919 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.516313\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  16\n",
      "2  12  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:14.059676: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpeebueqo6/model/ with prefix 2b1460926e174455\n",
      "I0000 00:00:1729625114.062842 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2486 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:14.062856: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.165524. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015019\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625114.374122 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625114.374137 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625114.374141 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625114.374203 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625114.374211 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625114.374254 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.374264 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.374270 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.374275 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.374303 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625114.374320 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625114.374453 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625114.374475 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbr6yifyw/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625114.374536 6794597 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625114.374695 6794597 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625114.375135 6794610 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.454545 logloss:19.6602\n",
      "I0000 00:00:1729625114.375243 6794610 random_forest.cc:812] Training of tree  11/200 (tree index:8) done accuracy:0.683333 logloss:3.9563\n",
      "I0000 00:00:1729625114.375368 6794608 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.75 logloss:2.53306\n",
      "I0000 00:00:1729625114.375495 6794609 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.75 logloss:1.40319\n",
      "I0000 00:00:1729625114.375602 6794612 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.741667 logloss:1.39735\n",
      "I0000 00:00:1729625114.375737 6794610 random_forest.cc:812] Training of tree  51/200 (tree index:52) done accuracy:0.7 logloss:1.13665\n",
      "I0000 00:00:1729625114.375849 6794608 random_forest.cc:812] Training of tree  61/200 (tree index:62) done accuracy:0.716667 logloss:0.852315\n",
      "I0000 00:00:1729625114.375965 6794609 random_forest.cc:812] Training of tree  71/200 (tree index:71) done accuracy:0.725 logloss:0.839004\n",
      "I0000 00:00:1729625114.376069 6794606 random_forest.cc:812] Training of tree  81/200 (tree index:81) done accuracy:0.708333 logloss:0.848814\n",
      "I0000 00:00:1729625114.376210 6794611 random_forest.cc:812] Training of tree  91/200 (tree index:91) done accuracy:0.7 logloss:0.857417\n",
      "I0000 00:00:1729625114.376366 6794611 random_forest.cc:812] Training of tree  101/200 (tree index:101) done accuracy:0.7 logloss:0.582563\n",
      "I0000 00:00:1729625114.376499 6794608 random_forest.cc:812] Training of tree  113/200 (tree index:109) done accuracy:0.708333 logloss:0.587715\n",
      "I0000 00:00:1729625114.376699 6794611 random_forest.cc:812] Training of tree  123/200 (tree index:124) done accuracy:0.7 logloss:0.592335\n",
      "I0000 00:00:1729625114.376884 6794610 random_forest.cc:812] Training of tree  133/200 (tree index:129) done accuracy:0.7 logloss:0.587718\n",
      "I0000 00:00:1729625114.376995 6794607 random_forest.cc:812] Training of tree  143/200 (tree index:143) done accuracy:0.708333 logloss:0.580388\n",
      "I0000 00:00:1729625114.377147 6794609 random_forest.cc:812] Training of tree  154/200 (tree index:153) done accuracy:0.708333 logloss:0.58086\n",
      "I0000 00:00:1729625114.377278 6794613 random_forest.cc:812] Training of tree  164/200 (tree index:164) done accuracy:0.716667 logloss:0.577423\n",
      "I0000 00:00:1729625114.377413 6794613 random_forest.cc:812] Training of tree  174/200 (tree index:175) done accuracy:0.716667 logloss:0.571368\n",
      "I0000 00:00:1729625114.377536 6794611 random_forest.cc:812] Training of tree  184/200 (tree index:186) done accuracy:0.708333 logloss:0.570188\n",
      "I0000 00:00:1729625114.377642 6794612 random_forest.cc:812] Training of tree  194/200 (tree index:192) done accuracy:0.708333 logloss:0.572456\n",
      "I0000 00:00:1729625114.377801 6794609 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.725 logloss:0.573817\n",
      "I0000 00:00:1729625114.377877 6794597 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.573817\n",
      "I0000 00:00:1729625114.378094 6794597 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbr6yifyw with prefix ce703cef7e0240d8\n",
      "I0000 00:00:1729625114.379767 6794597 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625114.380446 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.573817\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  18\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:14.385197: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbr6yifyw/model/ with prefix ce703cef7e0240d8\n",
      "I0000 00:00:1729625114.387460 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1636 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:14.387478: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpud6cgo95 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.169192. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015329\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625114.759096 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625114.759108 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625114.759112 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625114.759176 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625114.759182 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625114.759226 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.759236 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.759241 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.759247 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625114.759273 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625114.759291 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625114.759421 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625114.759445 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpud6cgo95/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625114.759505 6794666 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625114.759642 6794666 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625114.760200 6794676 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.659091 logloss:12.2876\n",
      "I0000 00:00:1729625114.760345 6794678 random_forest.cc:812] Training of tree  12/200 (tree index:11) done accuracy:0.635593 logloss:6.71181\n",
      "I0000 00:00:1729625114.760541 6794677 random_forest.cc:812] Training of tree  22/200 (tree index:24) done accuracy:0.658333 logloss:1.75009\n",
      "I0000 00:00:1729625114.760666 6794681 random_forest.cc:812] Training of tree  32/200 (tree index:33) done accuracy:0.7 logloss:1.17266\n",
      "I0000 00:00:1729625114.760775 6794676 random_forest.cc:812] Training of tree  42/200 (tree index:40) done accuracy:0.708333 logloss:0.617823\n",
      "I0000 00:00:1729625114.760894 6794677 random_forest.cc:812] Training of tree  52/200 (tree index:51) done accuracy:0.7 logloss:0.621293\n",
      "I0000 00:00:1729625114.761008 6794680 random_forest.cc:812] Training of tree  62/200 (tree index:63) done accuracy:0.7 logloss:0.62229\n",
      "I0000 00:00:1729625114.761130 6794678 random_forest.cc:812] Training of tree  72/200 (tree index:70) done accuracy:0.733333 logloss:0.607989\n",
      "I0000 00:00:1729625114.761243 6794675 random_forest.cc:812] Training of tree  82/200 (tree index:82) done accuracy:0.725 logloss:0.612013\n",
      "I0000 00:00:1729625114.761382 6794676 random_forest.cc:812] Training of tree  92/200 (tree index:83) done accuracy:0.733333 logloss:0.600489\n",
      "I0000 00:00:1729625114.761515 6794675 random_forest.cc:812] Training of tree  102/200 (tree index:93) done accuracy:0.741667 logloss:0.591415\n",
      "I0000 00:00:1729625114.761638 6794677 random_forest.cc:812] Training of tree  112/200 (tree index:111) done accuracy:0.725 logloss:0.597401\n",
      "I0000 00:00:1729625114.761742 6794675 random_forest.cc:812] Training of tree  122/200 (tree index:121) done accuracy:0.741667 logloss:0.587856\n",
      "I0000 00:00:1729625114.761909 6794680 random_forest.cc:812] Training of tree  134/200 (tree index:133) done accuracy:0.758333 logloss:0.59425\n",
      "I0000 00:00:1729625114.762081 6794682 random_forest.cc:812] Training of tree  145/200 (tree index:144) done accuracy:0.766667 logloss:0.600509\n",
      "I0000 00:00:1729625114.762232 6794678 random_forest.cc:812] Training of tree  155/200 (tree index:155) done accuracy:0.75 logloss:0.604247\n",
      "I0000 00:00:1729625114.762371 6794680 random_forest.cc:812] Training of tree  165/200 (tree index:165) done accuracy:0.75 logloss:0.60314\n",
      "I0000 00:00:1729625114.762466 6794675 random_forest.cc:812] Training of tree  175/200 (tree index:174) done accuracy:0.766667 logloss:0.601723\n",
      "I0000 00:00:1729625114.762646 6794678 random_forest.cc:812] Training of tree  185/200 (tree index:185) done accuracy:0.758333 logloss:0.601584\n",
      "I0000 00:00:1729625114.762794 6794681 random_forest.cc:812] Training of tree  197/200 (tree index:196) done accuracy:0.775 logloss:0.603095\n",
      "I0000 00:00:1729625114.762854 6794678 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.766667 logloss:0.599071\n",
      "I0000 00:00:1729625114.762932 6794666 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.599071\n",
      "I0000 00:00:1729625114.763149 6794666 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpud6cgo95 with prefix 5279a20e09ae4ca6\n",
      "I0000 00:00:1729625114.764775 6794666 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625114.765472 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.599071\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  17\n",
      "2  11  56\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:14.770583: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpud6cgo95/model/ with prefix 5279a20e09ae4ca6\n",
      "I0000 00:00:1729625114.772779 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1628 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:14.772796: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppjpc112z as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.156625. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016117\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625115.134823 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625115.134836 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625115.134840 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625115.134902 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625115.134909 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625115.134975 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.134999 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.135005 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.135010 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.135042 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625115.135061 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625115.135198 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625115.135225 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppjpc112z/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625115.135301 6794736 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625115.135458 6794736 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625115.136005 6794752 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.386364 logloss:22.1177\n",
      "I0000 00:00:1729625115.136140 6794745 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.638655 logloss:2.86927\n",
      "I0000 00:00:1729625115.136285 6794749 random_forest.cc:812] Training of tree  21/200 (tree index:23) done accuracy:0.641667 logloss:0.896937\n",
      "I0000 00:00:1729625115.136398 6794751 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.691667 logloss:0.607695\n",
      "I0000 00:00:1729625115.136510 6794749 random_forest.cc:812] Training of tree  41/200 (tree index:39) done accuracy:0.691667 logloss:0.588868\n",
      "I0000 00:00:1729625115.136659 6794747 random_forest.cc:812] Training of tree  51/200 (tree index:51) done accuracy:0.7 logloss:0.60162\n",
      "I0000 00:00:1729625115.136781 6794746 random_forest.cc:812] Training of tree  61/200 (tree index:60) done accuracy:0.725 logloss:0.598385\n",
      "I0000 00:00:1729625115.136898 6794749 random_forest.cc:812] Training of tree  71/200 (tree index:71) done accuracy:0.725 logloss:0.604008\n",
      "I0000 00:00:1729625115.137000 6794747 random_forest.cc:812] Training of tree  81/200 (tree index:80) done accuracy:0.741667 logloss:0.601366\n",
      "I0000 00:00:1729625115.137133 6794751 random_forest.cc:812] Training of tree  91/200 (tree index:92) done accuracy:0.725 logloss:0.591941\n",
      "I0000 00:00:1729625115.137257 6794752 random_forest.cc:812] Training of tree  102/200 (tree index:93) done accuracy:0.725 logloss:0.577642\n",
      "I0000 00:00:1729625115.137394 6794749 random_forest.cc:812] Training of tree  112/200 (tree index:112) done accuracy:0.716667 logloss:0.584489\n",
      "I0000 00:00:1729625115.137550 6794752 random_forest.cc:812] Training of tree  122/200 (tree index:119) done accuracy:0.716667 logloss:0.584695\n",
      "I0000 00:00:1729625115.137674 6794749 random_forest.cc:812] Training of tree  132/200 (tree index:130) done accuracy:0.7 logloss:0.589874\n",
      "I0000 00:00:1729625115.137844 6794747 random_forest.cc:812] Training of tree  143/200 (tree index:142) done accuracy:0.691667 logloss:0.591235\n",
      "I0000 00:00:1729625115.138050 6794748 random_forest.cc:812] Training of tree  153/200 (tree index:153) done accuracy:0.708333 logloss:0.593139\n",
      "I0000 00:00:1729625115.138175 6794751 random_forest.cc:812] Training of tree  164/200 (tree index:157) done accuracy:0.7 logloss:0.589413\n",
      "I0000 00:00:1729625115.138340 6794747 random_forest.cc:812] Training of tree  174/200 (tree index:175) done accuracy:0.725 logloss:0.586476\n",
      "I0000 00:00:1729625115.138478 6794750 random_forest.cc:812] Training of tree  186/200 (tree index:187) done accuracy:0.716667 logloss:0.587648\n",
      "I0000 00:00:1729625115.138623 6794750 random_forest.cc:812] Training of tree  196/200 (tree index:196) done accuracy:0.725 logloss:0.590369\n",
      "I0000 00:00:1729625115.138738 6794747 random_forest.cc:812] Training of tree  200/200 (tree index:195) done accuracy:0.716667 logloss:0.589941\n",
      "I0000 00:00:1729625115.138791 6794736 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.589941\n",
      "I0000 00:00:1729625115.138990 6794736 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppjpc112z with prefix 6af7e581e54a4ee6\n",
      "I0000 00:00:1729625115.140296 6794736 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625115.140988 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.589941\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  32  22\n",
      "2  12  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:15.146903: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppjpc112z/model/ with prefix 6af7e581e54a4ee6\n",
      "I0000 00:00:1729625115.149280 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1622 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:15.149297: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphbdfvkz0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.224159. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.019178\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpsy8rt898 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625115.533564 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625115.533575 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625115.533580 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625115.533649 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625115.533654 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625115.533702 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.533711 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.533717 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.533722 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.533751 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625115.533770 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625115.533908 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625115.533932 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphbdfvkz0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625115.534033 6794812 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625115.534167 6794812 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625115.534695 6794822 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625115.534961 6794825 random_forest.cc:812] Training of tree  11/200 (tree index:5) done accuracy:0.709402 logloss:4.83102\n",
      "I0000 00:00:1729625115.535216 6794823 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.733333 logloss:2.19272\n",
      "I0000 00:00:1729625115.535446 6794828 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.733333 logloss:1.36461\n",
      "I0000 00:00:1729625115.535659 6794826 random_forest.cc:812] Training of tree  41/200 (tree index:42) done accuracy:0.725 logloss:1.09553\n",
      "I0000 00:00:1729625115.535866 6794826 random_forest.cc:812] Training of tree  51/200 (tree index:52) done accuracy:0.708333 logloss:0.538172\n",
      "I0000 00:00:1729625115.536085 6794824 random_forest.cc:812] Training of tree  62/200 (tree index:63) done accuracy:0.725 logloss:0.518026\n",
      "I0000 00:00:1729625115.536413 6794825 random_forest.cc:812] Training of tree  72/200 (tree index:70) done accuracy:0.733333 logloss:0.524145\n",
      "I0000 00:00:1729625115.536841 6794827 random_forest.cc:812] Training of tree  82/200 (tree index:80) done accuracy:0.741667 logloss:0.513655\n",
      "I0000 00:00:1729625115.537036 6794827 random_forest.cc:812] Training of tree  92/200 (tree index:91) done accuracy:0.75 logloss:0.515194\n",
      "I0000 00:00:1729625115.537273 6794823 random_forest.cc:812] Training of tree  102/200 (tree index:98) done accuracy:0.775 logloss:0.504709\n",
      "I0000 00:00:1729625115.537460 6794822 random_forest.cc:812] Training of tree  112/200 (tree index:114) done accuracy:0.775 logloss:0.509995\n",
      "I0000 00:00:1729625115.537628 6794821 random_forest.cc:812] Training of tree  122/200 (tree index:123) done accuracy:0.775 logloss:0.505019\n",
      "I0000 00:00:1729625115.537929 6794823 random_forest.cc:812] Training of tree  133/200 (tree index:131) done accuracy:0.8 logloss:0.504791\n",
      "I0000 00:00:1729625115.538269 6794821 random_forest.cc:812] Training of tree  144/200 (tree index:145) done accuracy:0.816667 logloss:0.510333\n",
      "I0000 00:00:1729625115.538619 6794826 random_forest.cc:812] Training of tree  154/200 (tree index:153) done accuracy:0.8 logloss:0.514011\n",
      "I0000 00:00:1729625115.538989 6794828 random_forest.cc:812] Training of tree  164/200 (tree index:162) done accuracy:0.783333 logloss:0.512693\n",
      "I0000 00:00:1729625115.539262 6794823 random_forest.cc:812] Training of tree  174/200 (tree index:169) done accuracy:0.783333 logloss:0.512919\n",
      "I0000 00:00:1729625115.539493 6794824 random_forest.cc:812] Training of tree  184/200 (tree index:185) done accuracy:0.791667 logloss:0.51386\n",
      "I0000 00:00:1729625115.539701 6794821 random_forest.cc:812] Training of tree  195/200 (tree index:198) done accuracy:0.808333 logloss:0.510086\n",
      "I0000 00:00:1729625115.539889 6794825 random_forest.cc:812] Training of tree  200/200 (tree index:192) done accuracy:0.8 logloss:0.51219\n",
      "I0000 00:00:1729625115.540026 6794812 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.51219\n",
      "I0000 00:00:1729625115.540315 6794812 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphbdfvkz0 with prefix 57f6f801f28f4932\n",
      "I0000 00:00:1729625115.542030 6794812 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625115.543354 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.51219\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:15.548678: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphbdfvkz0/model/ with prefix 57f6f801f28f4932\n",
      "I0000 00:00:1729625115.550808 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1584 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:15.550824: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.166972. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014878\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': 30, 'min_examples': 20, 'bootstrap_size_ratio': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625115.868061 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625115.868074 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625115.868079 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625115.868147 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625115.868153 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625115.868198 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.868208 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.868214 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.868219 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625115.868247 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625115.868263 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625115.868394 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625115.868418 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpsy8rt898/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625115.868490 6794885 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625115.868623 6794885 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625115.869183 6794894 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625115.869317 6794895 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.762712 logloss:3.98557\n",
      "I0000 00:00:1729625115.869451 6794901 random_forest.cc:812] Training of tree  21/200 (tree index:16) done accuracy:0.7 logloss:1.43281\n",
      "I0000 00:00:1729625115.869552 6794897 random_forest.cc:812] Training of tree  31/200 (tree index:27) done accuracy:0.708333 logloss:1.16006\n",
      "I0000 00:00:1729625115.869667 6794901 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.741667 logloss:0.859919\n",
      "I0000 00:00:1729625115.869801 6794896 random_forest.cc:812] Training of tree  52/200 (tree index:53) done accuracy:0.775 logloss:0.844427\n",
      "I0000 00:00:1729625115.869945 6794896 random_forest.cc:812] Training of tree  63/200 (tree index:63) done accuracy:0.758333 logloss:0.842018\n",
      "I0000 00:00:1729625115.870127 6794895 random_forest.cc:812] Training of tree  74/200 (tree index:60) done accuracy:0.741667 logloss:0.838038\n",
      "I0000 00:00:1729625115.870246 6794894 random_forest.cc:812] Training of tree  84/200 (tree index:84) done accuracy:0.741667 logloss:0.839297\n",
      "I0000 00:00:1729625115.870357 6794901 random_forest.cc:812] Training of tree  94/200 (tree index:87) done accuracy:0.725 logloss:0.840357\n",
      "I0000 00:00:1729625115.870480 6794894 random_forest.cc:812] Training of tree  104/200 (tree index:105) done accuracy:0.733333 logloss:0.843079\n",
      "I0000 00:00:1729625115.870656 6794896 random_forest.cc:812] Training of tree  115/200 (tree index:116) done accuracy:0.725 logloss:0.837927\n",
      "I0000 00:00:1729625115.870759 6794899 random_forest.cc:812] Training of tree  125/200 (tree index:123) done accuracy:0.766667 logloss:0.561931\n",
      "I0000 00:00:1729625115.870972 6794899 random_forest.cc:812] Training of tree  138/200 (tree index:137) done accuracy:0.775 logloss:0.560324\n",
      "I0000 00:00:1729625115.871165 6794898 random_forest.cc:812] Training of tree  148/200 (tree index:147) done accuracy:0.758333 logloss:0.565741\n",
      "I0000 00:00:1729625115.871311 6794901 random_forest.cc:812] Training of tree  158/200 (tree index:159) done accuracy:0.75 logloss:0.571294\n",
      "I0000 00:00:1729625115.871416 6794897 random_forest.cc:812] Training of tree  168/200 (tree index:170) done accuracy:0.758333 logloss:0.56841\n",
      "I0000 00:00:1729625115.871544 6794895 random_forest.cc:812] Training of tree  178/200 (tree index:178) done accuracy:0.766667 logloss:0.55732\n",
      "I0000 00:00:1729625115.871710 6794899 random_forest.cc:812] Training of tree  188/200 (tree index:183) done accuracy:0.758333 logloss:0.556923\n",
      "I0000 00:00:1729625115.871901 6794896 random_forest.cc:812] Training of tree  199/200 (tree index:198) done accuracy:0.758333 logloss:0.551853\n",
      "I0000 00:00:1729625115.871940 6794898 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.758333 logloss:0.55134\n",
      "I0000 00:00:1729625115.872002 6794885 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.55134\n",
      "I0000 00:00:1729625115.872215 6794885 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpsy8rt898 with prefix d9a4c43db9c34a18\n",
      "I0000 00:00:1729625115.873470 6794885 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625115.874421 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.55134\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  18\n",
      "2  11  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:15.878855: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpsy8rt898/model/ with prefix d9a4c43db9c34a18\n",
      "I0000 00:00:1729625115.881056 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1606 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:15.881073: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy67ya5le as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.204967. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015236\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625116.297975 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625116.297988 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625116.297993 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625116.298055 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625116.298060 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625116.298102 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625116.298112 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625116.298117 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625116.298122 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625116.298150 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625116.298169 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625116.298341 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625116.298380 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy67ya5le/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625116.298440 6794962 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625116.298526 6794962 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625116.299033 6794977 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.531915 logloss:16.8715\n",
      "I0000 00:00:1729625116.299160 6794973 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.647059 logloss:3.19158\n",
      "I0000 00:00:1729625116.299324 6794971 random_forest.cc:812] Training of tree  21/200 (tree index:17) done accuracy:0.675 logloss:1.44491\n",
      "I0000 00:00:1729625116.299451 6794974 random_forest.cc:812] Training of tree  31/200 (tree index:29) done accuracy:0.683333 logloss:1.16577\n",
      "I0000 00:00:1729625116.299602 6794973 random_forest.cc:812] Training of tree  43/200 (tree index:42) done accuracy:0.675 logloss:0.604274\n",
      "I0000 00:00:1729625116.299755 6794978 random_forest.cc:812] Training of tree  53/200 (tree index:52) done accuracy:0.691667 logloss:0.594718\n",
      "I0000 00:00:1729625116.299906 6794976 random_forest.cc:812] Training of tree  63/200 (tree index:64) done accuracy:0.708333 logloss:0.584948\n",
      "I0000 00:00:1729625116.300019 6794977 random_forest.cc:812] Training of tree  73/200 (tree index:74) done accuracy:0.675 logloss:0.588743\n",
      "I0000 00:00:1729625116.300107 6794978 random_forest.cc:812] Training of tree  83/200 (tree index:83) done accuracy:0.691667 logloss:0.583555\n",
      "I0000 00:00:1729625116.300198 6794977 random_forest.cc:812] Training of tree  93/200 (tree index:92) done accuracy:0.683333 logloss:0.587629\n",
      "I0000 00:00:1729625116.300307 6794974 random_forest.cc:812] Training of tree  103/200 (tree index:102) done accuracy:0.675 logloss:0.58657\n",
      "I0000 00:00:1729625116.300434 6794972 random_forest.cc:812] Training of tree  113/200 (tree index:114) done accuracy:0.691667 logloss:0.576492\n",
      "I0000 00:00:1729625116.300566 6794972 random_forest.cc:812] Training of tree  123/200 (tree index:122) done accuracy:0.683333 logloss:0.576558\n",
      "I0000 00:00:1729625116.300753 6794971 random_forest.cc:812] Training of tree  133/200 (tree index:136) done accuracy:0.708333 logloss:0.568285\n",
      "I0000 00:00:1729625116.300891 6794971 random_forest.cc:812] Training of tree  143/200 (tree index:144) done accuracy:0.708333 logloss:0.574661\n",
      "I0000 00:00:1729625116.301066 6794976 random_forest.cc:812] Training of tree  156/200 (tree index:155) done accuracy:0.716667 logloss:0.578912\n",
      "I0000 00:00:1729625116.301290 6794974 random_forest.cc:812] Training of tree  166/200 (tree index:163) done accuracy:0.716667 logloss:0.576109\n",
      "I0000 00:00:1729625116.301402 6794974 random_forest.cc:812] Training of tree  176/200 (tree index:177) done accuracy:0.716667 logloss:0.570936\n",
      "I0000 00:00:1729625116.301566 6794977 random_forest.cc:812] Training of tree  186/200 (tree index:183) done accuracy:0.716667 logloss:0.57461\n",
      "I0000 00:00:1729625116.301745 6794976 random_forest.cc:812] Training of tree  196/200 (tree index:195) done accuracy:0.725 logloss:0.571891\n",
      "I0000 00:00:1729625116.301822 6794977 random_forest.cc:812] Training of tree  200/200 (tree index:198) done accuracy:0.716667 logloss:0.57396\n",
      "I0000 00:00:1729625116.301889 6794962 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.57396\n",
      "I0000 00:00:1729625116.302059 6794962 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy67ya5le with prefix e452035d65aa4654\n",
      "I0000 00:00:1729625116.303429 6794962 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625116.304133 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.57396\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:16.309586: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy67ya5le/model/ with prefix e452035d65aa4654\n",
      "I0000 00:00:1729625116.311525 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1304 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:16.311545: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo9fk6pp1 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.175325. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014309\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625116.681564 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625116.681573 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625116.681583 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625116.681656 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625116.681662 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625116.681707 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625116.681717 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625116.681723 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625116.681728 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625116.681757 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625116.681774 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625116.681909 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625116.681933 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo9fk6pp1/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625116.681991 6795034 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625116.682076 6795034 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625116.682572 6795044 random_forest.cc:812] Training of tree  1/200 (tree index:2) done accuracy:0.530612 logloss:16.9184\n",
      "I0000 00:00:1729625116.682717 6795048 random_forest.cc:812] Training of tree  12/200 (tree index:11) done accuracy:0.62931 logloss:5.62257\n",
      "I0000 00:00:1729625116.682878 6795050 random_forest.cc:812] Training of tree  22/200 (tree index:18) done accuracy:0.666667 logloss:1.50262\n",
      "I0000 00:00:1729625116.683064 6795050 random_forest.cc:812] Training of tree  32/200 (tree index:33) done accuracy:0.7 logloss:0.890676\n",
      "I0000 00:00:1729625116.683182 6795050 random_forest.cc:812] Training of tree  42/200 (tree index:45) done accuracy:0.716667 logloss:0.889079\n",
      "I0000 00:00:1729625116.683286 6795045 random_forest.cc:812] Training of tree  52/200 (tree index:52) done accuracy:0.716667 logloss:0.621403\n",
      "I0000 00:00:1729625116.683424 6795048 random_forest.cc:812] Training of tree  62/200 (tree index:61) done accuracy:0.725 logloss:0.609175\n",
      "I0000 00:00:1729625116.683589 6795047 random_forest.cc:812] Training of tree  72/200 (tree index:74) done accuracy:0.7 logloss:0.603041\n",
      "I0000 00:00:1729625116.683698 6795046 random_forest.cc:812] Training of tree  82/200 (tree index:83) done accuracy:0.7 logloss:0.599932\n",
      "I0000 00:00:1729625116.683788 6795047 random_forest.cc:812] Training of tree  92/200 (tree index:91) done accuracy:0.708333 logloss:0.614284\n",
      "I0000 00:00:1729625116.683930 6795045 random_forest.cc:812] Training of tree  103/200 (tree index:103) done accuracy:0.741667 logloss:0.613405\n",
      "I0000 00:00:1729625116.684077 6795048 random_forest.cc:812] Training of tree  113/200 (tree index:113) done accuracy:0.716667 logloss:0.609061\n",
      "I0000 00:00:1729625116.684194 6795048 random_forest.cc:812] Training of tree  123/200 (tree index:124) done accuracy:0.75 logloss:0.610224\n",
      "I0000 00:00:1729625116.684334 6795044 random_forest.cc:812] Training of tree  133/200 (tree index:123) done accuracy:0.75 logloss:0.607562\n",
      "I0000 00:00:1729625116.684447 6795046 random_forest.cc:812] Training of tree  145/200 (tree index:143) done accuracy:0.733333 logloss:0.60758\n",
      "I0000 00:00:1729625116.684618 6795047 random_forest.cc:812] Training of tree  155/200 (tree index:155) done accuracy:0.75 logloss:0.607253\n",
      "I0000 00:00:1729625116.684715 6795049 random_forest.cc:812] Training of tree  165/200 (tree index:164) done accuracy:0.741667 logloss:0.606666\n",
      "I0000 00:00:1729625116.684836 6795048 random_forest.cc:812] Training of tree  175/200 (tree index:165) done accuracy:0.733333 logloss:0.604999\n",
      "I0000 00:00:1729625116.684954 6795048 random_forest.cc:812] Training of tree  187/200 (tree index:186) done accuracy:0.75 logloss:0.599524\n",
      "I0000 00:00:1729625116.685123 6795043 random_forest.cc:812] Training of tree  197/200 (tree index:197) done accuracy:0.758333 logloss:0.600705\n",
      "I0000 00:00:1729625116.685162 6795050 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.741667 logloss:0.602326\n",
      "I0000 00:00:1729625116.685204 6795034 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.602326\n",
      "I0000 00:00:1729625116.685371 6795034 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo9fk6pp1 with prefix 9797dfbc4d2f4ade\n",
      "I0000 00:00:1729625116.686685 6795034 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625116.687273 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.602326\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  33  20\n",
      "2  11  56\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:16.692233: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo9fk6pp1/model/ with prefix 9797dfbc4d2f4ade\n",
      "I0000 00:00:1729625116.694179 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1298 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:25:16.694201: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptr7e7rs8 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.166961. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015083\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625117.073444 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625117.073455 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625117.073460 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625117.073524 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625117.073530 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625117.073573 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.073583 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.073589 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.073595 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.073624 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625117.073644 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625117.073776 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625117.073800 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptr7e7rs8/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625117.073857 6795110 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625117.073952 6795110 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625117.074522 6795119 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.45283 logloss:19.722\n",
      "I0000 00:00:1729625117.074639 6795124 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.613445 logloss:4.36911\n",
      "I0000 00:00:1729625117.074879 6795122 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.608333 logloss:0.875289\n",
      "I0000 00:00:1729625117.075033 6795120 random_forest.cc:812] Training of tree  31/200 (tree index:33) done accuracy:0.691667 logloss:0.586061\n",
      "I0000 00:00:1729625117.075165 6795122 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.725 logloss:0.587632\n",
      "I0000 00:00:1729625117.075291 6795119 random_forest.cc:812] Training of tree  51/200 (tree index:42) done accuracy:0.666667 logloss:0.608\n",
      "I0000 00:00:1729625117.075407 6795123 random_forest.cc:812] Training of tree  61/200 (tree index:62) done accuracy:0.683333 logloss:0.611268\n",
      "I0000 00:00:1729625117.075509 6795121 random_forest.cc:812] Training of tree  71/200 (tree index:72) done accuracy:0.691667 logloss:0.61242\n",
      "I0000 00:00:1729625117.075587 6795121 random_forest.cc:812] Training of tree  81/200 (tree index:78) done accuracy:0.725 logloss:0.602695\n",
      "I0000 00:00:1729625117.075683 6795125 random_forest.cc:812] Training of tree  91/200 (tree index:91) done accuracy:0.708333 logloss:0.610241\n",
      "I0000 00:00:1729625117.075784 6795119 random_forest.cc:812] Training of tree  101/200 (tree index:99) done accuracy:0.7 logloss:0.60952\n",
      "I0000 00:00:1729625117.075892 6795124 random_forest.cc:812] Training of tree  111/200 (tree index:112) done accuracy:0.708333 logloss:0.610255\n",
      "I0000 00:00:1729625117.076039 6795122 random_forest.cc:812] Training of tree  121/200 (tree index:119) done accuracy:0.716667 logloss:0.612068\n",
      "I0000 00:00:1729625117.076136 6795119 random_forest.cc:812] Training of tree  131/200 (tree index:127) done accuracy:0.708333 logloss:0.615692\n",
      "I0000 00:00:1729625117.076266 6795120 random_forest.cc:812] Training of tree  142/200 (tree index:143) done accuracy:0.708333 logloss:0.610893\n",
      "I0000 00:00:1729625117.076438 6795123 random_forest.cc:812] Training of tree  152/200 (tree index:152) done accuracy:0.708333 logloss:0.608381\n",
      "I0000 00:00:1729625117.076567 6795123 random_forest.cc:812] Training of tree  162/200 (tree index:162) done accuracy:0.7 logloss:0.609443\n",
      "I0000 00:00:1729625117.076701 6795125 random_forest.cc:812] Training of tree  172/200 (tree index:173) done accuracy:0.683333 logloss:0.612803\n",
      "I0000 00:00:1729625117.076836 6795126 random_forest.cc:812] Training of tree  182/200 (tree index:182) done accuracy:0.675 logloss:0.612362\n",
      "I0000 00:00:1729625117.076989 6795119 random_forest.cc:812] Training of tree  192/200 (tree index:192) done accuracy:0.683333 logloss:0.610177\n",
      "I0000 00:00:1729625117.077072 6795123 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.675 logloss:0.61644\n",
      "I0000 00:00:1729625117.077188 6795110 random_forest.cc:892] Final OOB metrics: accuracy:0.675 logloss:0.61644\n",
      "I0000 00:00:1729625117.077356 6795110 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptr7e7rs8 with prefix b219fe8111704caf\n",
      "I0000 00:00:1729625117.078951 6795110 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625117.079818 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.675  CI95[W][0.597764 0.745608]\n",
      "LogLoss: : 0.61644\n",
      "ErrorRate: : 0.325\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  29  25\n",
      "2  14  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:17.084876: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptr7e7rs8/model/ with prefix b219fe8111704caf\n",
      "I0000 00:00:1729625117.086804 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1280 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:17.086821: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1_pdqlf9 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.158068. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014938\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625117.452952 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625117.452973 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625117.452978 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625117.453039 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625117.453046 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625117.453087 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.453096 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.453102 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.453107 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.453133 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625117.453150 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625117.453274 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625117.453297 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1_pdqlf9/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625117.453362 6795186 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625117.453459 6795186 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625117.454024 6795203 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625117.454133 6795202 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.655462 logloss:3.17143\n",
      "I0000 00:00:1729625117.454263 6795197 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.691667 logloss:2.01682\n",
      "I0000 00:00:1729625117.454361 6795199 random_forest.cc:812] Training of tree  31/200 (tree index:29) done accuracy:0.675 logloss:0.900813\n",
      "I0000 00:00:1729625117.454499 6795201 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.725 logloss:0.57054\n",
      "I0000 00:00:1729625117.454597 6795201 random_forest.cc:812] Training of tree  51/200 (tree index:46) done accuracy:0.75 logloss:0.565529\n",
      "I0000 00:00:1729625117.454722 6795201 random_forest.cc:812] Training of tree  61/200 (tree index:60) done accuracy:0.725 logloss:0.568707\n",
      "I0000 00:00:1729625117.454879 6795202 random_forest.cc:812] Training of tree  71/200 (tree index:71) done accuracy:0.741667 logloss:0.56917\n",
      "I0000 00:00:1729625117.455030 6795203 random_forest.cc:812] Training of tree  81/200 (tree index:80) done accuracy:0.716667 logloss:0.567842\n",
      "I0000 00:00:1729625117.455179 6795200 random_forest.cc:812] Training of tree  91/200 (tree index:91) done accuracy:0.741667 logloss:0.56082\n",
      "I0000 00:00:1729625117.455323 6795198 random_forest.cc:812] Training of tree  101/200 (tree index:100) done accuracy:0.725 logloss:0.558931\n",
      "I0000 00:00:1729625117.455460 6795198 random_forest.cc:812] Training of tree  111/200 (tree index:111) done accuracy:0.733333 logloss:0.555831\n",
      "I0000 00:00:1729625117.455593 6795202 random_forest.cc:812] Training of tree  121/200 (tree index:121) done accuracy:0.725 logloss:0.557137\n",
      "I0000 00:00:1729625117.455786 6795199 random_forest.cc:812] Training of tree  131/200 (tree index:128) done accuracy:0.741667 logloss:0.553184\n",
      "I0000 00:00:1729625117.455998 6795197 random_forest.cc:812] Training of tree  141/200 (tree index:140) done accuracy:0.741667 logloss:0.548052\n",
      "I0000 00:00:1729625117.456156 6795200 random_forest.cc:812] Training of tree  154/200 (tree index:153) done accuracy:0.75 logloss:0.546295\n",
      "I0000 00:00:1729625117.456429 6795199 random_forest.cc:812] Training of tree  166/200 (tree index:164) done accuracy:0.75 logloss:0.550308\n",
      "I0000 00:00:1729625117.456642 6795198 random_forest.cc:812] Training of tree  177/200 (tree index:178) done accuracy:0.733333 logloss:0.547207\n",
      "I0000 00:00:1729625117.456815 6795200 random_forest.cc:812] Training of tree  187/200 (tree index:184) done accuracy:0.733333 logloss:0.544234\n",
      "I0000 00:00:1729625117.457015 6795202 random_forest.cc:812] Training of tree  197/200 (tree index:199) done accuracy:0.741667 logloss:0.542139\n",
      "I0000 00:00:1729625117.457125 6795198 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.75 logloss:0.54082\n",
      "I0000 00:00:1729625117.457190 6795186 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.54082\n",
      "I0000 00:00:1729625117.457368 6795186 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1_pdqlf9 with prefix 45663048876b493d\n",
      "I0000 00:00:1729625117.458581 6795186 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625117.459266 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.54082\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  18\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:17.463994: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1_pdqlf9/model/ with prefix 45663048876b493d\n",
      "I0000 00:00:1729625117.466067 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1306 node(s), and 19 input feature(s).\n",
      "I0000 00:00:1729625117.466092 6784195 abstract_model.cc:1323] Engine \"RandomForestOptPred\" built\n",
      "2024-10-22 20:25:17.466099: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpakvn9ynr as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.159385. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014786\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625117.834289 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625117.834299 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625117.834307 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625117.834373 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625117.834378 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625117.834424 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.834434 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.834439 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.834445 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625117.834473 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625117.834491 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625117.834628 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625117.834650 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpakvn9ynr/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625117.834708 6795260 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625117.834810 6795260 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625117.835351 6795269 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625117.835473 6795276 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.661017 logloss:3.43935\n",
      "I0000 00:00:1729625117.835613 6795270 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.716667 logloss:1.70577\n",
      "I0000 00:00:1729625117.835781 6795272 random_forest.cc:812] Training of tree  31/200 (tree index:27) done accuracy:0.725 logloss:1.14165\n",
      "I0000 00:00:1729625117.835908 6795272 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.708333 logloss:1.13849\n",
      "I0000 00:00:1729625117.836068 6795271 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.683333 logloss:0.600737\n",
      "I0000 00:00:1729625117.836192 6795276 random_forest.cc:812] Training of tree  61/200 (tree index:60) done accuracy:0.691667 logloss:0.59611\n",
      "I0000 00:00:1729625117.836339 6795273 random_forest.cc:812] Training of tree  71/200 (tree index:70) done accuracy:0.708333 logloss:0.579565\n",
      "I0000 00:00:1729625117.836446 6795275 random_forest.cc:812] Training of tree  81/200 (tree index:80) done accuracy:0.7 logloss:0.581141\n",
      "I0000 00:00:1729625117.836558 6795270 random_forest.cc:812] Training of tree  91/200 (tree index:91) done accuracy:0.716667 logloss:0.586726\n",
      "I0000 00:00:1729625117.836701 6795273 random_forest.cc:812] Training of tree  102/200 (tree index:101) done accuracy:0.691667 logloss:0.579054\n",
      "I0000 00:00:1729625117.836949 6795276 random_forest.cc:812] Training of tree  112/200 (tree index:110) done accuracy:0.725 logloss:0.581367\n",
      "I0000 00:00:1729625117.837099 6795273 random_forest.cc:812] Training of tree  122/200 (tree index:111) done accuracy:0.716667 logloss:0.580004\n",
      "I0000 00:00:1729625117.837235 6795276 random_forest.cc:812] Training of tree  132/200 (tree index:134) done accuracy:0.716667 logloss:0.576456\n",
      "I0000 00:00:1729625117.837413 6795273 random_forest.cc:812] Training of tree  142/200 (tree index:144) done accuracy:0.725 logloss:0.576247\n",
      "I0000 00:00:1729625117.837535 6795274 random_forest.cc:812] Training of tree  152/200 (tree index:151) done accuracy:0.725 logloss:0.575851\n",
      "I0000 00:00:1729625117.837652 6795273 random_forest.cc:812] Training of tree  162/200 (tree index:160) done accuracy:0.725 logloss:0.579004\n",
      "I0000 00:00:1729625117.837783 6795271 random_forest.cc:812] Training of tree  172/200 (tree index:171) done accuracy:0.716667 logloss:0.577134\n",
      "I0000 00:00:1729625117.837893 6795276 random_forest.cc:812] Training of tree  182/200 (tree index:181) done accuracy:0.716667 logloss:0.577048\n",
      "I0000 00:00:1729625117.838028 6795271 random_forest.cc:812] Training of tree  192/200 (tree index:191) done accuracy:0.716667 logloss:0.576585\n",
      "I0000 00:00:1729625117.838122 6795274 random_forest.cc:812] Training of tree  200/200 (tree index:195) done accuracy:0.708333 logloss:0.576028\n",
      "I0000 00:00:1729625117.838192 6795260 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.576028\n",
      "I0000 00:00:1729625117.838362 6795260 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpakvn9ynr with prefix 95eeb2061c0945c9\n",
      "I0000 00:00:1729625117.839612 6795260 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625117.840296 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.576028\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  19\n",
      "2  16  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:17.845427: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpakvn9ynr/model/ with prefix 95eeb2061c0945c9\n",
      "I0000 00:00:1729625117.847305 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1278 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:17.847323: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': -1, 'min_examples': 5, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr7kjoyvd as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.140995. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.025952\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625118.135453 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625118.135466 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625118.135474 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625118.135542 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625118.135547 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625118.135594 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.135722 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.135741 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.135747 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.135791 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625118.135846 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625118.136016 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625118.136046 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr7kjoyvd/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625118.136116 6795329 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625118.136221 6795329 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625118.136904 6795338 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.55814 logloss:15.9263\n",
      "I0000 00:00:1729625118.137150 6795339 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.666667 logloss:3.74076\n",
      "I0000 00:00:1729625118.137409 6795341 random_forest.cc:812] Training of tree  21/200 (tree index:16) done accuracy:0.7 logloss:1.14382\n",
      "I0000 00:00:1729625118.137640 6795341 random_forest.cc:812] Training of tree  31/200 (tree index:29) done accuracy:0.716667 logloss:1.12515\n",
      "I0000 00:00:1729625118.137842 6795341 random_forest.cc:812] Training of tree  42/200 (tree index:41) done accuracy:0.741667 logloss:0.820242\n",
      "I0000 00:00:1729625118.138174 6795340 random_forest.cc:812] Training of tree  52/200 (tree index:54) done accuracy:0.725 logloss:0.557302\n",
      "I0000 00:00:1729625118.138330 6795345 random_forest.cc:812] Training of tree  62/200 (tree index:63) done accuracy:0.733333 logloss:0.536081\n",
      "I0000 00:00:1729625118.138542 6795345 random_forest.cc:812] Training of tree  72/200 (tree index:73) done accuracy:0.758333 logloss:0.52658\n",
      "I0000 00:00:1729625118.138884 6795343 random_forest.cc:812] Training of tree  82/200 (tree index:76) done accuracy:0.75 logloss:0.523449\n",
      "I0000 00:00:1729625118.139169 6795338 random_forest.cc:812] Training of tree  92/200 (tree index:95) done accuracy:0.75 logloss:0.521436\n",
      "I0000 00:00:1729625118.139450 6795343 random_forest.cc:812] Training of tree  102/200 (tree index:88) done accuracy:0.75 logloss:0.52331\n",
      "I0000 00:00:1729625118.139660 6795339 random_forest.cc:812] Training of tree  112/200 (tree index:112) done accuracy:0.75 logloss:0.530766\n",
      "I0000 00:00:1729625118.139906 6795341 random_forest.cc:812] Training of tree  122/200 (tree index:124) done accuracy:0.741667 logloss:0.527578\n",
      "I0000 00:00:1729625118.140103 6795341 random_forest.cc:812] Training of tree  132/200 (tree index:133) done accuracy:0.766667 logloss:0.523917\n",
      "I0000 00:00:1729625118.140297 6795340 random_forest.cc:812] Training of tree  142/200 (tree index:130) done accuracy:0.75 logloss:0.529641\n",
      "I0000 00:00:1729625118.140557 6795341 random_forest.cc:812] Training of tree  152/200 (tree index:154) done accuracy:0.741667 logloss:0.534965\n",
      "I0000 00:00:1729625118.140828 6795339 random_forest.cc:812] Training of tree  162/200 (tree index:164) done accuracy:0.733333 logloss:0.532316\n",
      "I0000 00:00:1729625118.141041 6795342 random_forest.cc:812] Training of tree  172/200 (tree index:173) done accuracy:0.741667 logloss:0.532798\n",
      "I0000 00:00:1729625118.141294 6795340 random_forest.cc:812] Training of tree  182/200 (tree index:171) done accuracy:0.741667 logloss:0.523395\n",
      "I0000 00:00:1729625118.141526 6795344 random_forest.cc:812] Training of tree  192/200 (tree index:194) done accuracy:0.741667 logloss:0.524321\n",
      "I0000 00:00:1729625118.141709 6795340 random_forest.cc:812] Training of tree  200/200 (tree index:193) done accuracy:0.741667 logloss:0.519991\n",
      "I0000 00:00:1729625118.141842 6795329 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.519991\n",
      "I0000 00:00:1729625118.142484 6795329 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr7kjoyvd with prefix 813a9745aeb14613\n",
      "I0000 00:00:1729625118.145449 6795329 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625118.146480 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.519991\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  44  14\n",
      "2  17  45\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:18.152757: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr7kjoyvd/model/ with prefix 813a9745aeb14613\n",
      "I0000 00:00:1729625118.158759 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4390 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:18.158780: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw23swy8s as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143671. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023752\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625118.444220 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625118.444231 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625118.444236 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625118.444308 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625118.444314 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625118.444360 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.444370 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.444375 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.444380 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.444410 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625118.444429 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625118.444563 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625118.444588 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw23swy8s/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625118.444642 6795398 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625118.444745 6795398 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625118.445290 6795412 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625118.445456 6795409 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.663866 logloss:4.32412\n",
      "I0000 00:00:1729625118.445641 6795413 random_forest.cc:812] Training of tree  21/200 (tree index:19) done accuracy:0.7 logloss:1.11067\n",
      "I0000 00:00:1729625118.445852 6795413 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.741667 logloss:1.06511\n",
      "I0000 00:00:1729625118.446058 6795414 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.741667 logloss:0.811637\n",
      "I0000 00:00:1729625118.446259 6795407 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.741667 logloss:0.513219\n",
      "I0000 00:00:1729625118.446462 6795409 random_forest.cc:812] Training of tree  61/200 (tree index:60) done accuracy:0.741667 logloss:0.514639\n",
      "I0000 00:00:1729625118.446696 6795410 random_forest.cc:812] Training of tree  72/200 (tree index:72) done accuracy:0.733333 logloss:0.509177\n",
      "I0000 00:00:1729625118.446918 6795412 random_forest.cc:812] Training of tree  82/200 (tree index:81) done accuracy:0.758333 logloss:0.501077\n",
      "I0000 00:00:1729625118.447144 6795411 random_forest.cc:812] Training of tree  92/200 (tree index:92) done accuracy:0.775 logloss:0.491561\n",
      "I0000 00:00:1729625118.447324 6795413 random_forest.cc:812] Training of tree  102/200 (tree index:101) done accuracy:0.766667 logloss:0.492943\n",
      "I0000 00:00:1729625118.447529 6795408 random_forest.cc:812] Training of tree  112/200 (tree index:112) done accuracy:0.775 logloss:0.500707\n",
      "I0000 00:00:1729625118.447760 6795410 random_forest.cc:812] Training of tree  123/200 (tree index:122) done accuracy:0.783333 logloss:0.491498\n",
      "I0000 00:00:1729625118.448080 6795410 random_forest.cc:812] Training of tree  133/200 (tree index:132) done accuracy:0.766667 logloss:0.491776\n",
      "I0000 00:00:1729625118.448479 6795412 random_forest.cc:812] Training of tree  143/200 (tree index:139) done accuracy:0.766667 logloss:0.494283\n",
      "I0000 00:00:1729625118.448830 6795412 random_forest.cc:812] Training of tree  153/200 (tree index:148) done accuracy:0.766667 logloss:0.493648\n",
      "I0000 00:00:1729625118.449147 6795412 random_forest.cc:812] Training of tree  163/200 (tree index:157) done accuracy:0.766667 logloss:0.491954\n",
      "I0000 00:00:1729625118.449406 6795408 random_forest.cc:812] Training of tree  173/200 (tree index:173) done accuracy:0.775 logloss:0.494781\n",
      "I0000 00:00:1729625118.449642 6795407 random_forest.cc:812] Training of tree  183/200 (tree index:174) done accuracy:0.758333 logloss:0.494856\n",
      "I0000 00:00:1729625118.449841 6795413 random_forest.cc:812] Training of tree  193/200 (tree index:193) done accuracy:0.766667 logloss:0.50044\n",
      "I0000 00:00:1729625118.450036 6795409 random_forest.cc:812] Training of tree  200/200 (tree index:196) done accuracy:0.758333 logloss:0.498196\n",
      "I0000 00:00:1729625118.450119 6795398 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.498196\n",
      "I0000 00:00:1729625118.450639 6795398 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw23swy8s with prefix fa91a6b507be4886\n",
      "I0000 00:00:1729625118.452922 6795398 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625118.453653 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.498196\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  14  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:18.459383: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw23swy8s/model/ with prefix fa91a6b507be4886\n",
      "I0000 00:00:1729625118.465628 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4500 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:18.465652: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjp1g41su as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.150723. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.024083\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625118.766087 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625118.766097 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625118.766102 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625118.766175 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625118.766180 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625118.766224 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.766234 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.766240 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.766245 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625118.766272 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625118.766288 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625118.766426 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625118.766449 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjp1g41su/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625118.766514 6795468 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625118.766609 6795468 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625118.767152 6795479 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.697674 logloss:10.8969\n",
      "I0000 00:00:1729625118.767486 6795479 random_forest.cc:812] Training of tree  12/200 (tree index:14) done accuracy:0.683333 logloss:1.7003\n",
      "I0000 00:00:1729625118.767725 6795482 random_forest.cc:812] Training of tree  22/200 (tree index:7) done accuracy:0.691667 logloss:0.580607\n",
      "I0000 00:00:1729625118.767968 6795481 random_forest.cc:812] Training of tree  33/200 (tree index:31) done accuracy:0.716667 logloss:0.588338\n",
      "I0000 00:00:1729625118.768211 6795482 random_forest.cc:812] Training of tree  43/200 (tree index:43) done accuracy:0.725 logloss:0.543063\n",
      "I0000 00:00:1729625118.768433 6795482 random_forest.cc:812] Training of tree  54/200 (tree index:52) done accuracy:0.716667 logloss:0.550701\n",
      "I0000 00:00:1729625118.768900 6795479 random_forest.cc:812] Training of tree  64/200 (tree index:62) done accuracy:0.741667 logloss:0.544931\n",
      "I0000 00:00:1729625118.769251 6795477 random_forest.cc:812] Training of tree  74/200 (tree index:67) done accuracy:0.733333 logloss:0.54307\n",
      "I0000 00:00:1729625118.769444 6795478 random_forest.cc:812] Training of tree  84/200 (tree index:84) done accuracy:0.741667 logloss:0.547358\n",
      "I0000 00:00:1729625118.769723 6795483 random_forest.cc:812] Training of tree  94/200 (tree index:86) done accuracy:0.708333 logloss:0.544917\n",
      "I0000 00:00:1729625118.769987 6795480 random_forest.cc:812] Training of tree  104/200 (tree index:106) done accuracy:0.75 logloss:0.533574\n",
      "I0000 00:00:1729625118.770228 6795483 random_forest.cc:812] Training of tree  114/200 (tree index:113) done accuracy:0.725 logloss:0.53714\n",
      "I0000 00:00:1729625118.770462 6795483 random_forest.cc:812] Training of tree  124/200 (tree index:127) done accuracy:0.708333 logloss:0.541093\n",
      "I0000 00:00:1729625118.770713 6795478 random_forest.cc:812] Training of tree  134/200 (tree index:135) done accuracy:0.716667 logloss:0.541097\n",
      "I0000 00:00:1729625118.770984 6795482 random_forest.cc:812] Training of tree  144/200 (tree index:143) done accuracy:0.716667 logloss:0.542677\n",
      "I0000 00:00:1729625118.771137 6795479 random_forest.cc:812] Training of tree  154/200 (tree index:154) done accuracy:0.733333 logloss:0.543802\n",
      "I0000 00:00:1729625118.771388 6795478 random_forest.cc:812] Training of tree  165/200 (tree index:165) done accuracy:0.725 logloss:0.544392\n",
      "I0000 00:00:1729625118.771636 6795482 random_forest.cc:812] Training of tree  177/200 (tree index:176) done accuracy:0.733333 logloss:0.539496\n",
      "I0000 00:00:1729625118.771853 6795481 random_forest.cc:812] Training of tree  187/200 (tree index:185) done accuracy:0.725 logloss:0.542699\n",
      "I0000 00:00:1729625118.772051 6795479 random_forest.cc:812] Training of tree  197/200 (tree index:197) done accuracy:0.733333 logloss:0.543325\n",
      "I0000 00:00:1729625118.772109 6795482 random_forest.cc:812] Training of tree  200/200 (tree index:194) done accuracy:0.741667 logloss:0.542373\n",
      "I0000 00:00:1729625118.772168 6795468 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.542373\n",
      "I0000 00:00:1729625118.772710 6795468 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjp1g41su with prefix eb55c9ccd00e44bd\n",
      "I0000 00:00:1729625118.775370 6795468 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625118.776122 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.542373\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  16\n",
      "2  15  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:18.781936: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpjp1g41su/model/ with prefix eb55c9ccd00e44bd\n",
      "I0000 00:00:1729625118.787850 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4606 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:18.787872: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptu_jhyzc as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145602. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022619\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625119.085278 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625119.085289 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625119.085293 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625119.085357 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625119.085361 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625119.085413 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.085426 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.085432 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.085437 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.085467 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625119.085486 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625119.085623 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625119.085647 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptu_jhyzc/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625119.085714 6795537 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625119.085822 6795537 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625119.086566 6795553 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.675 logloss:11.7142\n",
      "I0000 00:00:1729625119.086829 6795549 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.721739 logloss:3.75113\n",
      "I0000 00:00:1729625119.087058 6795549 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.816667 logloss:0.415806\n",
      "I0000 00:00:1729625119.087249 6795549 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.791667 logloss:0.425635\n",
      "I0000 00:00:1729625119.087459 6795549 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.758333 logloss:0.442655\n",
      "I0000 00:00:1729625119.087640 6795550 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.8 logloss:0.441056\n",
      "I0000 00:00:1729625119.087883 6795547 random_forest.cc:812] Training of tree  61/200 (tree index:63) done accuracy:0.783333 logloss:0.43095\n",
      "I0000 00:00:1729625119.088051 6795553 random_forest.cc:812] Training of tree  71/200 (tree index:71) done accuracy:0.783333 logloss:0.443263\n",
      "I0000 00:00:1729625119.088248 6795546 random_forest.cc:812] Training of tree  81/200 (tree index:82) done accuracy:0.8 logloss:0.449642\n",
      "I0000 00:00:1729625119.088382 6795547 random_forest.cc:812] Training of tree  91/200 (tree index:89) done accuracy:0.8 logloss:0.44655\n",
      "I0000 00:00:1729625119.088630 6795549 random_forest.cc:812] Training of tree  101/200 (tree index:94) done accuracy:0.8 logloss:0.451059\n",
      "I0000 00:00:1729625119.088817 6795547 random_forest.cc:812] Training of tree  111/200 (tree index:111) done accuracy:0.791667 logloss:0.452155\n",
      "I0000 00:00:1729625119.088968 6795548 random_forest.cc:812] Training of tree  122/200 (tree index:121) done accuracy:0.8 logloss:0.457793\n",
      "I0000 00:00:1729625119.089167 6795548 random_forest.cc:812] Training of tree  133/200 (tree index:132) done accuracy:0.791667 logloss:0.446685\n",
      "I0000 00:00:1729625119.089327 6795547 random_forest.cc:812] Training of tree  143/200 (tree index:141) done accuracy:0.791667 logloss:0.447012\n",
      "I0000 00:00:1729625119.089552 6795546 random_forest.cc:812] Training of tree  153/200 (tree index:155) done accuracy:0.791667 logloss:0.445569\n",
      "I0000 00:00:1729625119.089715 6795551 random_forest.cc:812] Training of tree  163/200 (tree index:163) done accuracy:0.783333 logloss:0.448133\n",
      "I0000 00:00:1729625119.089877 6795548 random_forest.cc:812] Training of tree  173/200 (tree index:173) done accuracy:0.791667 logloss:0.448298\n",
      "I0000 00:00:1729625119.090049 6795553 random_forest.cc:812] Training of tree  183/200 (tree index:182) done accuracy:0.783333 logloss:0.455511\n",
      "I0000 00:00:1729625119.090193 6795546 random_forest.cc:812] Training of tree  193/200 (tree index:192) done accuracy:0.783333 logloss:0.455839\n",
      "I0000 00:00:1729625119.090316 6795552 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.783333 logloss:0.458263\n",
      "I0000 00:00:1729625119.090393 6795537 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.458263\n",
      "I0000 00:00:1729625119.090856 6795537 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptu_jhyzc with prefix 49c006b557a748d4\n",
      "I0000 00:00:1729625119.093205 6795537 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625119.093907 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.458263\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:19.100464: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptu_jhyzc/model/ with prefix 49c006b557a748d4\n",
      "I0000 00:00:1729625119.105818 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4132 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:19.105834: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_h0guoai as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.207252. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.026379\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': -1, 'min_examples': 5, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppqkhxhqo as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625119.453144 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625119.453159 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625119.453164 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625119.453231 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625119.453235 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625119.453285 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.453297 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.453303 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.453308 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.453338 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625119.453355 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625119.453506 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625119.453529 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_h0guoai/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625119.453607 6795614 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625119.453711 6795614 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625119.454323 6795628 random_forest.cc:812] Training of tree  1/200 (tree index:2) done accuracy:0.609756 logloss:14.0658\n",
      "I0000 00:00:1729625119.454540 6795626 random_forest.cc:812] Training of tree  11/200 (tree index:9) done accuracy:0.681035 logloss:4.63756\n",
      "I0000 00:00:1729625119.454829 6795629 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.733333 logloss:2.21871\n",
      "I0000 00:00:1729625119.455263 6795627 random_forest.cc:812] Training of tree  32/200 (tree index:34) done accuracy:0.75 logloss:1.06939\n",
      "I0000 00:00:1729625119.455694 6795626 random_forest.cc:812] Training of tree  42/200 (tree index:38) done accuracy:0.775 logloss:0.774978\n",
      "I0000 00:00:1729625119.456006 6795627 random_forest.cc:812] Training of tree  52/200 (tree index:51) done accuracy:0.791667 logloss:0.470773\n",
      "I0000 00:00:1729625119.456303 6795623 random_forest.cc:812] Training of tree  62/200 (tree index:64) done accuracy:0.775 logloss:0.483697\n",
      "I0000 00:00:1729625119.456585 6795625 random_forest.cc:812] Training of tree  72/200 (tree index:73) done accuracy:0.783333 logloss:0.484757\n",
      "I0000 00:00:1729625119.456771 6795628 random_forest.cc:812] Training of tree  82/200 (tree index:82) done accuracy:0.783333 logloss:0.478512\n",
      "I0000 00:00:1729625119.456967 6795629 random_forest.cc:812] Training of tree  92/200 (tree index:91) done accuracy:0.775 logloss:0.478526\n",
      "I0000 00:00:1729625119.457152 6795627 random_forest.cc:812] Training of tree  102/200 (tree index:101) done accuracy:0.783333 logloss:0.477781\n",
      "I0000 00:00:1729625119.457372 6795627 random_forest.cc:812] Training of tree  112/200 (tree index:111) done accuracy:0.775 logloss:0.481853\n",
      "I0000 00:00:1729625119.457563 6795630 random_forest.cc:812] Training of tree  122/200 (tree index:123) done accuracy:0.775 logloss:0.487193\n",
      "I0000 00:00:1729625119.457746 6795630 random_forest.cc:812] Training of tree  132/200 (tree index:134) done accuracy:0.775 logloss:0.485995\n",
      "I0000 00:00:1729625119.457932 6795625 random_forest.cc:812] Training of tree  142/200 (tree index:141) done accuracy:0.775 logloss:0.490229\n",
      "I0000 00:00:1729625119.458167 6795623 random_forest.cc:812] Training of tree  152/200 (tree index:144) done accuracy:0.766667 logloss:0.492181\n",
      "I0000 00:00:1729625119.458385 6795625 random_forest.cc:812] Training of tree  162/200 (tree index:162) done accuracy:0.766667 logloss:0.493499\n",
      "I0000 00:00:1729625119.458600 6795624 random_forest.cc:812] Training of tree  172/200 (tree index:165) done accuracy:0.766667 logloss:0.494129\n",
      "I0000 00:00:1729625119.458852 6795624 random_forest.cc:812] Training of tree  182/200 (tree index:182) done accuracy:0.766667 logloss:0.495045\n",
      "I0000 00:00:1729625119.459095 6795630 random_forest.cc:812] Training of tree  192/200 (tree index:193) done accuracy:0.766667 logloss:0.497234\n",
      "I0000 00:00:1729625119.459319 6795625 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.766667 logloss:0.489188\n",
      "I0000 00:00:1729625119.459487 6795614 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.489188\n",
      "I0000 00:00:1729625119.460124 6795614 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_h0guoai with prefix c340afe7adfe40eb\n",
      "I0000 00:00:1729625119.462865 6795614 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625119.463705 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.489188\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  12\n",
      "2  16  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:19.470936: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_h0guoai/model/ with prefix c340afe7adfe40eb\n",
      "I0000 00:00:1729625119.476546 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 4372 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:19.476578: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144507. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021366\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp703lcky3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625119.778989 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625119.779000 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625119.779007 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625119.779070 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625119.779075 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625119.779119 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.779129 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.779134 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.779139 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625119.779166 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625119.779184 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625119.779323 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625119.779347 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppqkhxhqo/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625119.779411 6795689 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625119.779525 6795689 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625119.780117 6795704 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625119.780253 6795703 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.716667 logloss:1.9796\n",
      "I0000 00:00:1729625119.780454 6795701 random_forest.cc:812] Training of tree  22/200 (tree index:20) done accuracy:0.725 logloss:0.795852\n",
      "I0000 00:00:1729625119.780696 6795698 random_forest.cc:812] Training of tree  33/200 (tree index:32) done accuracy:0.7 logloss:0.520494\n",
      "I0000 00:00:1729625119.780907 6795700 random_forest.cc:812] Training of tree  43/200 (tree index:43) done accuracy:0.666667 logloss:0.574779\n",
      "I0000 00:00:1729625119.781108 6795699 random_forest.cc:812] Training of tree  56/200 (tree index:54) done accuracy:0.691667 logloss:0.563247\n",
      "I0000 00:00:1729625119.781300 6795699 random_forest.cc:812] Training of tree  66/200 (tree index:66) done accuracy:0.725 logloss:0.543542\n",
      "I0000 00:00:1729625119.781439 6795703 random_forest.cc:812] Training of tree  77/200 (tree index:77) done accuracy:0.725 logloss:0.547702\n",
      "I0000 00:00:1729625119.781612 6795705 random_forest.cc:812] Training of tree  87/200 (tree index:89) done accuracy:0.716667 logloss:0.535908\n",
      "I0000 00:00:1729625119.781765 6795704 random_forest.cc:812] Training of tree  97/200 (tree index:98) done accuracy:0.7 logloss:0.540026\n",
      "I0000 00:00:1729625119.781970 6795700 random_forest.cc:812] Training of tree  108/200 (tree index:109) done accuracy:0.716667 logloss:0.538843\n",
      "I0000 00:00:1729625119.782166 6795700 random_forest.cc:812] Training of tree  118/200 (tree index:118) done accuracy:0.725 logloss:0.530421\n",
      "I0000 00:00:1729625119.782343 6795699 random_forest.cc:812] Training of tree  128/200 (tree index:117) done accuracy:0.725 logloss:0.532853\n",
      "I0000 00:00:1729625119.782601 6795701 random_forest.cc:812] Training of tree  140/200 (tree index:139) done accuracy:0.75 logloss:0.529507\n",
      "I0000 00:00:1729625119.782849 6795698 random_forest.cc:812] Training of tree  150/200 (tree index:151) done accuracy:0.733333 logloss:0.522389\n",
      "I0000 00:00:1729625119.783102 6795704 random_forest.cc:812] Training of tree  160/200 (tree index:161) done accuracy:0.725 logloss:0.529248\n",
      "I0000 00:00:1729625119.783250 6795698 random_forest.cc:812] Training of tree  170/200 (tree index:171) done accuracy:0.741667 logloss:0.528268\n",
      "I0000 00:00:1729625119.783402 6795699 random_forest.cc:812] Training of tree  180/200 (tree index:179) done accuracy:0.741667 logloss:0.523877\n",
      "I0000 00:00:1729625119.783592 6795704 random_forest.cc:812] Training of tree  191/200 (tree index:190) done accuracy:0.733333 logloss:0.519547\n",
      "I0000 00:00:1729625119.783785 6795702 random_forest.cc:812] Training of tree  200/200 (tree index:193) done accuracy:0.733333 logloss:0.518974\n",
      "I0000 00:00:1729625119.783882 6795689 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.518974\n",
      "I0000 00:00:1729625119.784331 6795689 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppqkhxhqo with prefix 5e7b85f4e5c44c26\n",
      "I0000 00:00:1729625119.786744 6795689 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625119.787408 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.518974\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:19.793402: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmppqkhxhqo/model/ with prefix 5e7b85f4e5c44c26\n",
      "I0000 00:00:1729625119.798273 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3776 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:19.798294: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.140696. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021845\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdx6xa55a as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625120.074697 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625120.074709 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625120.074714 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625120.074776 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625120.074781 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625120.074826 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.074835 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.074841 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.074846 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.074876 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625120.074894 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625120.075049 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625120.075072 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp703lcky3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625120.075128 6795758 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625120.075243 6795758 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625120.075876 6795774 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.641509 logloss:12.9213\n",
      "I0000 00:00:1729625120.075997 6795773 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.658333 logloss:2.57554\n",
      "I0000 00:00:1729625120.076229 6795767 random_forest.cc:812] Training of tree  22/200 (tree index:13) done accuracy:0.708333 logloss:1.18273\n",
      "I0000 00:00:1729625120.076379 6795773 random_forest.cc:812] Training of tree  32/200 (tree index:31) done accuracy:0.675 logloss:0.597018\n",
      "I0000 00:00:1729625120.076570 6795769 random_forest.cc:812] Training of tree  42/200 (tree index:41) done accuracy:0.683333 logloss:0.580718\n",
      "I0000 00:00:1729625120.076712 6795768 random_forest.cc:812] Training of tree  52/200 (tree index:52) done accuracy:0.691667 logloss:0.563846\n",
      "I0000 00:00:1729625120.076864 6795767 random_forest.cc:812] Training of tree  62/200 (tree index:62) done accuracy:0.733333 logloss:0.562112\n",
      "I0000 00:00:1729625120.077008 6795774 random_forest.cc:812] Training of tree  72/200 (tree index:70) done accuracy:0.741667 logloss:0.565982\n",
      "I0000 00:00:1729625120.077192 6795771 random_forest.cc:812] Training of tree  83/200 (tree index:81) done accuracy:0.741667 logloss:0.563863\n",
      "I0000 00:00:1729625120.077433 6795773 random_forest.cc:812] Training of tree  93/200 (tree index:92) done accuracy:0.725 logloss:0.561854\n",
      "I0000 00:00:1729625120.077570 6795771 random_forest.cc:812] Training of tree  103/200 (tree index:103) done accuracy:0.741667 logloss:0.555571\n",
      "I0000 00:00:1729625120.077703 6795774 random_forest.cc:812] Training of tree  113/200 (tree index:113) done accuracy:0.741667 logloss:0.552201\n",
      "I0000 00:00:1729625120.077859 6795771 random_forest.cc:812] Training of tree  123/200 (tree index:124) done accuracy:0.75 logloss:0.554537\n",
      "I0000 00:00:1729625120.078035 6795773 random_forest.cc:812] Training of tree  133/200 (tree index:126) done accuracy:0.75 logloss:0.552278\n",
      "I0000 00:00:1729625120.078202 6795769 random_forest.cc:812] Training of tree  143/200 (tree index:143) done accuracy:0.758333 logloss:0.554113\n",
      "I0000 00:00:1729625120.078382 6795774 random_forest.cc:812] Training of tree  153/200 (tree index:152) done accuracy:0.766667 logloss:0.551593\n",
      "I0000 00:00:1729625120.078524 6795772 random_forest.cc:812] Training of tree  163/200 (tree index:164) done accuracy:0.766667 logloss:0.54735\n",
      "I0000 00:00:1729625120.078648 6795771 random_forest.cc:812] Training of tree  174/200 (tree index:173) done accuracy:0.775 logloss:0.547472\n",
      "I0000 00:00:1729625120.078800 6795772 random_forest.cc:812] Training of tree  184/200 (tree index:184) done accuracy:0.783333 logloss:0.545045\n",
      "I0000 00:00:1729625120.078993 6795769 random_forest.cc:812] Training of tree  194/200 (tree index:181) done accuracy:0.775 logloss:0.540342\n",
      "I0000 00:00:1729625120.079090 6795774 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.775 logloss:0.541575\n",
      "I0000 00:00:1729625120.079124 6795758 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.541575\n",
      "I0000 00:00:1729625120.079589 6795758 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp703lcky3 with prefix 6a6c4d179b774026\n",
      "I0000 00:00:1729625120.081876 6795758 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625120.082581 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.541575\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:20.089264: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp703lcky3/model/ with prefix 6a6c4d179b774026\n",
      "I0000 00:00:1729625120.094561 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3862 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:20.094581: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.138998. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.020789\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625120.372090 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625120.372099 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625120.372108 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625120.372172 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625120.372176 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625120.372220 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.372229 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.372234 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.372239 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.372265 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625120.372283 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625120.372454 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625120.372478 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdx6xa55a/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625120.372533 6795830 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625120.372711 6795830 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625120.373256 6795841 random_forest.cc:812] Training of tree  1/200 (tree index:2) done accuracy:0.632653 logloss:13.2405\n",
      "I0000 00:00:1729625120.373445 6795844 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.663866 logloss:3.4605\n",
      "I0000 00:00:1729625120.373608 6795842 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.666667 logloss:1.46624\n",
      "I0000 00:00:1729625120.373783 6795845 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.683333 logloss:0.593987\n",
      "I0000 00:00:1729625120.374037 6795840 random_forest.cc:812] Training of tree  41/200 (tree index:42) done accuracy:0.733333 logloss:0.557509\n",
      "I0000 00:00:1729625120.374159 6795839 random_forest.cc:812] Training of tree  51/200 (tree index:51) done accuracy:0.741667 logloss:0.552428\n",
      "I0000 00:00:1729625120.374339 6795845 random_forest.cc:812] Training of tree  61/200 (tree index:61) done accuracy:0.766667 logloss:0.54449\n",
      "I0000 00:00:1729625120.374507 6795841 random_forest.cc:812] Training of tree  72/200 (tree index:73) done accuracy:0.783333 logloss:0.546994\n",
      "I0000 00:00:1729625120.374683 6795845 random_forest.cc:812] Training of tree  82/200 (tree index:81) done accuracy:0.783333 logloss:0.536861\n",
      "I0000 00:00:1729625120.374884 6795846 random_forest.cc:812] Training of tree  92/200 (tree index:91) done accuracy:0.775 logloss:0.529173\n",
      "I0000 00:00:1729625120.375111 6795842 random_forest.cc:812] Training of tree  105/200 (tree index:104) done accuracy:0.791667 logloss:0.529486\n",
      "I0000 00:00:1729625120.375335 6795843 random_forest.cc:812] Training of tree  115/200 (tree index:116) done accuracy:0.791667 logloss:0.520595\n",
      "I0000 00:00:1729625120.375478 6795845 random_forest.cc:812] Training of tree  125/200 (tree index:125) done accuracy:0.775 logloss:0.522198\n",
      "I0000 00:00:1729625120.375637 6795846 random_forest.cc:812] Training of tree  135/200 (tree index:137) done accuracy:0.775 logloss:0.518047\n",
      "I0000 00:00:1729625120.375783 6795845 random_forest.cc:812] Training of tree  146/200 (tree index:145) done accuracy:0.766667 logloss:0.521253\n",
      "I0000 00:00:1729625120.376024 6795846 random_forest.cc:812] Training of tree  156/200 (tree index:154) done accuracy:0.775 logloss:0.522995\n",
      "I0000 00:00:1729625120.376145 6795843 random_forest.cc:812] Training of tree  166/200 (tree index:165) done accuracy:0.775 logloss:0.526066\n",
      "I0000 00:00:1729625120.376342 6795842 random_forest.cc:812] Training of tree  176/200 (tree index:173) done accuracy:0.783333 logloss:0.526593\n",
      "I0000 00:00:1729625120.376537 6795842 random_forest.cc:812] Training of tree  186/200 (tree index:185) done accuracy:0.783333 logloss:0.527061\n",
      "I0000 00:00:1729625120.376706 6795843 random_forest.cc:812] Training of tree  196/200 (tree index:182) done accuracy:0.783333 logloss:0.523611\n",
      "I0000 00:00:1729625120.376756 6795839 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.783333 logloss:0.52462\n",
      "I0000 00:00:1729625120.376825 6795830 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.52462\n",
      "I0000 00:00:1729625120.377266 6795830 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdx6xa55a with prefix cfd4216a19c445d2\n",
      "I0000 00:00:1729625120.379615 6795830 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625120.380258 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.52462\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  15\n",
      "2  11  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:20.385565: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdx6xa55a/model/ with prefix cfd4216a19c445d2\n",
      "I0000 00:00:1729625120.390869 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3900 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:20.390889: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxph3b5pv as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146982. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.024919\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625120.950676 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625120.950695 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625120.950699 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625120.950766 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625120.950774 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625120.950819 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.950830 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.950837 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.950843 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625120.950870 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625120.950888 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625120.951031 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625120.951056 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxph3b5pv/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625120.951115 6795905 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625120.951232 6795905 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625120.951747 6795917 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625120.951941 6795916 random_forest.cc:812] Training of tree  14/200 (tree index:12) done accuracy:0.697479 logloss:2.23226\n",
      "I0000 00:00:1729625120.952112 6795920 random_forest.cc:812] Training of tree  24/200 (tree index:23) done accuracy:0.775 logloss:1.33821\n",
      "I0000 00:00:1729625120.952279 6795921 random_forest.cc:812] Training of tree  34/200 (tree index:32) done accuracy:0.758333 logloss:1.30715\n",
      "I0000 00:00:1729625120.952475 6795918 random_forest.cc:812] Training of tree  44/200 (tree index:43) done accuracy:0.775 logloss:0.48833\n",
      "I0000 00:00:1729625120.952626 6795914 random_forest.cc:812] Training of tree  54/200 (tree index:54) done accuracy:0.766667 logloss:0.493118\n",
      "I0000 00:00:1729625120.952826 6795914 random_forest.cc:812] Training of tree  64/200 (tree index:63) done accuracy:0.783333 logloss:0.485298\n",
      "I0000 00:00:1729625120.953019 6795919 random_forest.cc:812] Training of tree  75/200 (tree index:71) done accuracy:0.766667 logloss:0.48251\n",
      "I0000 00:00:1729625120.953291 6795915 random_forest.cc:812] Training of tree  85/200 (tree index:87) done accuracy:0.775 logloss:0.476377\n",
      "I0000 00:00:1729625120.953483 6795914 random_forest.cc:812] Training of tree  95/200 (tree index:84) done accuracy:0.766667 logloss:0.474091\n",
      "I0000 00:00:1729625120.953699 6795918 random_forest.cc:812] Training of tree  106/200 (tree index:107) done accuracy:0.775 logloss:0.475217\n",
      "I0000 00:00:1729625120.954017 6795921 random_forest.cc:812] Training of tree  118/200 (tree index:118) done accuracy:0.8 logloss:0.477899\n",
      "I0000 00:00:1729625120.954280 6795920 random_forest.cc:812] Training of tree  128/200 (tree index:127) done accuracy:0.8 logloss:0.48401\n",
      "I0000 00:00:1729625120.954492 6795921 random_forest.cc:812] Training of tree  138/200 (tree index:139) done accuracy:0.783333 logloss:0.480013\n",
      "I0000 00:00:1729625120.954692 6795921 random_forest.cc:812] Training of tree  148/200 (tree index:148) done accuracy:0.783333 logloss:0.47512\n",
      "I0000 00:00:1729625120.954928 6795917 random_forest.cc:812] Training of tree  158/200 (tree index:157) done accuracy:0.783333 logloss:0.479615\n",
      "I0000 00:00:1729625120.955096 6795920 random_forest.cc:812] Training of tree  168/200 (tree index:167) done accuracy:0.775 logloss:0.475708\n",
      "I0000 00:00:1729625120.955295 6795921 random_forest.cc:812] Training of tree  178/200 (tree index:179) done accuracy:0.783333 logloss:0.477673\n",
      "I0000 00:00:1729625120.955460 6795915 random_forest.cc:812] Training of tree  188/200 (tree index:185) done accuracy:0.775 logloss:0.479036\n",
      "I0000 00:00:1729625120.955597 6795918 random_forest.cc:812] Training of tree  198/200 (tree index:191) done accuracy:0.775 logloss:0.479168\n",
      "I0000 00:00:1729625120.955651 6795914 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.783333 logloss:0.479409\n",
      "I0000 00:00:1729625120.955755 6795905 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.479409\n",
      "I0000 00:00:1729625120.956277 6795905 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxph3b5pv with prefix 403cb0d4c1d641ba\n",
      "I0000 00:00:1729625120.959174 6795905 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625120.959920 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.479409\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:20.967513: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxph3b5pv/model/ with prefix 403cb0d4c1d641ba\n",
      "I0000 00:00:1729625120.973069 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3526 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:20.973093: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9x8crfot as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146576. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022590\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625121.276453 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625121.276463 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625121.276467 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625121.276531 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625121.276537 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625121.276582 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.276592 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.276597 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.276602 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.276629 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625121.276648 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625121.276783 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625121.276805 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9x8crfot/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625121.276874 6795988 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625121.276971 6795988 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625121.277451 6796004 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.641509 logloss:12.9213\n",
      "I0000 00:00:1729625121.277632 6796003 random_forest.cc:812] Training of tree  12/200 (tree index:11) done accuracy:0.833333 logloss:1.52752\n",
      "I0000 00:00:1729625121.277809 6796002 random_forest.cc:812] Training of tree  22/200 (tree index:23) done accuracy:0.741667 logloss:0.74842\n",
      "I0000 00:00:1729625121.277980 6796002 random_forest.cc:812] Training of tree  32/200 (tree index:29) done accuracy:0.766667 logloss:0.726456\n",
      "I0000 00:00:1729625121.278184 6795999 random_forest.cc:812] Training of tree  42/200 (tree index:43) done accuracy:0.766667 logloss:0.756765\n",
      "I0000 00:00:1729625121.278332 6796004 random_forest.cc:812] Training of tree  52/200 (tree index:51) done accuracy:0.766667 logloss:0.471133\n",
      "I0000 00:00:1729625121.278549 6796000 random_forest.cc:812] Training of tree  63/200 (tree index:62) done accuracy:0.783333 logloss:0.464383\n",
      "I0000 00:00:1729625121.278777 6796004 random_forest.cc:812] Training of tree  73/200 (tree index:73) done accuracy:0.775 logloss:0.476468\n",
      "I0000 00:00:1729625121.278938 6796002 random_forest.cc:812] Training of tree  83/200 (tree index:82) done accuracy:0.783333 logloss:0.461872\n",
      "I0000 00:00:1729625121.279081 6795997 random_forest.cc:812] Training of tree  93/200 (tree index:92) done accuracy:0.791667 logloss:0.451581\n",
      "I0000 00:00:1729625121.279242 6796001 random_forest.cc:812] Training of tree  103/200 (tree index:101) done accuracy:0.775 logloss:0.458954\n",
      "I0000 00:00:1729625121.279438 6795998 random_forest.cc:812] Training of tree  113/200 (tree index:113) done accuracy:0.775 logloss:0.460356\n",
      "I0000 00:00:1729625121.279640 6796000 random_forest.cc:812] Training of tree  126/200 (tree index:126) done accuracy:0.783333 logloss:0.462839\n",
      "I0000 00:00:1729625121.279838 6795999 random_forest.cc:812] Training of tree  136/200 (tree index:136) done accuracy:0.791667 logloss:0.458734\n",
      "I0000 00:00:1729625121.279991 6795998 random_forest.cc:812] Training of tree  146/200 (tree index:147) done accuracy:0.791667 logloss:0.468277\n",
      "I0000 00:00:1729625121.280159 6796002 random_forest.cc:812] Training of tree  156/200 (tree index:157) done accuracy:0.775 logloss:0.473321\n",
      "I0000 00:00:1729625121.280363 6796002 random_forest.cc:812] Training of tree  169/200 (tree index:169) done accuracy:0.783333 logloss:0.473506\n",
      "I0000 00:00:1729625121.280581 6795999 random_forest.cc:812] Training of tree  180/200 (tree index:178) done accuracy:0.775 logloss:0.472039\n",
      "I0000 00:00:1729625121.280792 6796002 random_forest.cc:812] Training of tree  190/200 (tree index:191) done accuracy:0.775 logloss:0.475593\n",
      "I0000 00:00:1729625121.280979 6795997 random_forest.cc:812] Training of tree  200/200 (tree index:198) done accuracy:0.766667 logloss:0.475475\n",
      "I0000 00:00:1729625121.281075 6795988 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.475475\n",
      "I0000 00:00:1729625121.281531 6795988 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9x8crfot with prefix 5db90c5ca1b44a72\n",
      "I0000 00:00:1729625121.283990 6795988 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625121.284725 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.475475\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:21.290697: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9x8crfot/model/ with prefix 5db90c5ca1b44a72\n",
      "I0000 00:00:1729625121.296407 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3668 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:21.296434: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': -1, 'min_examples': 10, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp4woz_nz as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.140738. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021254\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625121.580757 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625121.580769 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625121.580773 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625121.580838 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625121.580846 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625121.580891 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.580900 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.580906 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.580911 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.580939 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625121.580955 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625121.581090 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625121.581116 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp4woz_nz/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625121.581171 6796057 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625121.581267 6796057 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625121.581849 6796072 random_forest.cc:812] Training of tree  1/200 (tree index:5) done accuracy:0.659091 logloss:12.2876\n",
      "I0000 00:00:1729625121.582039 6796072 random_forest.cc:812] Training of tree  12/200 (tree index:12) done accuracy:0.672414 logloss:4.96701\n",
      "I0000 00:00:1729625121.582284 6796066 random_forest.cc:812] Training of tree  22/200 (tree index:20) done accuracy:0.733333 logloss:1.42481\n",
      "I0000 00:00:1729625121.582426 6796067 random_forest.cc:812] Training of tree  32/200 (tree index:31) done accuracy:0.766667 logloss:1.0888\n",
      "I0000 00:00:1729625121.582635 6796066 random_forest.cc:812] Training of tree  42/200 (tree index:43) done accuracy:0.775 logloss:1.09885\n",
      "I0000 00:00:1729625121.582747 6796066 random_forest.cc:812] Training of tree  52/200 (tree index:49) done accuracy:0.741667 logloss:0.824546\n",
      "I0000 00:00:1729625121.582983 6796068 random_forest.cc:812] Training of tree  64/200 (tree index:63) done accuracy:0.758333 logloss:0.804099\n",
      "I0000 00:00:1729625121.583194 6796068 random_forest.cc:812] Training of tree  75/200 (tree index:75) done accuracy:0.741667 logloss:0.805241\n",
      "I0000 00:00:1729625121.583381 6796066 random_forest.cc:812] Training of tree  85/200 (tree index:87) done accuracy:0.725 logloss:0.814676\n",
      "I0000 00:00:1729625121.583546 6796073 random_forest.cc:812] Training of tree  97/200 (tree index:96) done accuracy:0.708333 logloss:0.809509\n",
      "I0000 00:00:1729625121.583781 6796071 random_forest.cc:812] Training of tree  107/200 (tree index:107) done accuracy:0.716667 logloss:0.547169\n",
      "I0000 00:00:1729625121.583898 6796068 random_forest.cc:812] Training of tree  117/200 (tree index:116) done accuracy:0.708333 logloss:0.55049\n",
      "I0000 00:00:1729625121.584072 6796071 random_forest.cc:812] Training of tree  127/200 (tree index:128) done accuracy:0.708333 logloss:0.545254\n",
      "I0000 00:00:1729625121.584217 6796070 random_forest.cc:812] Training of tree  137/200 (tree index:126) done accuracy:0.708333 logloss:0.550578\n",
      "I0000 00:00:1729625121.584414 6796070 random_forest.cc:812] Training of tree  147/200 (tree index:144) done accuracy:0.708333 logloss:0.554641\n",
      "I0000 00:00:1729625121.584537 6796066 random_forest.cc:812] Training of tree  157/200 (tree index:153) done accuracy:0.716667 logloss:0.558176\n",
      "I0000 00:00:1729625121.584704 6796070 random_forest.cc:812] Training of tree  167/200 (tree index:167) done accuracy:0.716667 logloss:0.557718\n",
      "I0000 00:00:1729625121.584887 6796071 random_forest.cc:812] Training of tree  177/200 (tree index:173) done accuracy:0.716667 logloss:0.546912\n",
      "I0000 00:00:1729625121.585034 6796069 random_forest.cc:812] Training of tree  187/200 (tree index:186) done accuracy:0.691667 logloss:0.548528\n",
      "I0000 00:00:1729625121.585220 6796073 random_forest.cc:812] Training of tree  197/200 (tree index:187) done accuracy:0.7 logloss:0.547143\n",
      "I0000 00:00:1729625121.585269 6796070 random_forest.cc:812] Training of tree  200/200 (tree index:195) done accuracy:0.708333 logloss:0.548091\n",
      "I0000 00:00:1729625121.585302 6796057 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.548091\n",
      "I0000 00:00:1729625121.585696 6796057 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp4woz_nz with prefix 766c10d60e5b4580\n",
      "I0000 00:00:1729625121.588211 6796057 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625121.588844 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.548091\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  18\n",
      "2  17  45\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:21.595317: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp4woz_nz/model/ with prefix 766c10d60e5b4580\n",
      "I0000 00:00:1729625121.599952 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3054 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:21.599976: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpof7c02a8 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143755. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.019824\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625121.882589 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625121.882600 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625121.882608 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625121.882677 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625121.882681 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625121.882727 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.882738 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.882744 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.882749 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625121.882776 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625121.882794 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625121.882949 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625121.882973 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpof7c02a8/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625121.883035 6796125 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625121.883132 6796125 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625121.883706 6796135 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.772727 logloss:8.19174\n",
      "I0000 00:00:1729625121.883849 6796137 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.733333 logloss:5.10793\n",
      "I0000 00:00:1729625121.884004 6796135 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.766667 logloss:1.0836\n",
      "I0000 00:00:1729625121.884129 6796141 random_forest.cc:812] Training of tree  31/200 (tree index:29) done accuracy:0.75 logloss:1.07775\n",
      "I0000 00:00:1729625121.884334 6796138 random_forest.cc:812] Training of tree  42/200 (tree index:40) done accuracy:0.758333 logloss:0.798498\n",
      "I0000 00:00:1729625121.884517 6796141 random_forest.cc:812] Training of tree  52/200 (tree index:53) done accuracy:0.766667 logloss:0.535644\n",
      "I0000 00:00:1729625121.884685 6796140 random_forest.cc:812] Training of tree  62/200 (tree index:58) done accuracy:0.758333 logloss:0.539379\n",
      "I0000 00:00:1729625121.884818 6796141 random_forest.cc:812] Training of tree  72/200 (tree index:71) done accuracy:0.783333 logloss:0.529914\n",
      "I0000 00:00:1729625121.884973 6796135 random_forest.cc:812] Training of tree  82/200 (tree index:68) done accuracy:0.766667 logloss:0.528302\n",
      "I0000 00:00:1729625121.885139 6796140 random_forest.cc:812] Training of tree  92/200 (tree index:93) done accuracy:0.766667 logloss:0.531301\n",
      "I0000 00:00:1729625121.885287 6796135 random_forest.cc:812] Training of tree  102/200 (tree index:102) done accuracy:0.775 logloss:0.527314\n",
      "I0000 00:00:1729625121.885426 6796137 random_forest.cc:812] Training of tree  112/200 (tree index:115) done accuracy:0.766667 logloss:0.524034\n",
      "I0000 00:00:1729625121.885598 6796141 random_forest.cc:812] Training of tree  122/200 (tree index:123) done accuracy:0.758333 logloss:0.529871\n",
      "I0000 00:00:1729625121.885753 6796136 random_forest.cc:812] Training of tree  132/200 (tree index:134) done accuracy:0.741667 logloss:0.526107\n",
      "I0000 00:00:1729625121.885932 6796137 random_forest.cc:812] Training of tree  142/200 (tree index:142) done accuracy:0.741667 logloss:0.530602\n",
      "I0000 00:00:1729625121.886113 6796139 random_forest.cc:812] Training of tree  152/200 (tree index:143) done accuracy:0.766667 logloss:0.533763\n",
      "I0000 00:00:1729625121.886256 6796141 random_forest.cc:812] Training of tree  163/200 (tree index:163) done accuracy:0.758333 logloss:0.537076\n",
      "I0000 00:00:1729625121.886413 6796138 random_forest.cc:812] Training of tree  173/200 (tree index:168) done accuracy:0.75 logloss:0.536476\n",
      "I0000 00:00:1729625121.886615 6796139 random_forest.cc:812] Training of tree  183/200 (tree index:181) done accuracy:0.75 logloss:0.53489\n",
      "I0000 00:00:1729625121.886791 6796138 random_forest.cc:812] Training of tree  193/200 (tree index:192) done accuracy:0.758333 logloss:0.540886\n",
      "I0000 00:00:1729625121.886891 6796134 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.775 logloss:0.544829\n",
      "I0000 00:00:1729625121.886958 6796125 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.544829\n",
      "I0000 00:00:1729625121.887323 6796125 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpof7c02a8 with prefix bd9aaf812eae4387\n",
      "I0000 00:00:1729625121.889387 6796125 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625121.890083 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.544829\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:21.895974: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpof7c02a8/model/ with prefix bd9aaf812eae4387\n",
      "I0000 00:00:1729625121.900398 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3088 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:21.900425: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr5k3qnm5 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.142885. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021476\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625122.185059 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625122.185069 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625122.185073 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625122.185140 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625122.185145 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625122.185191 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.185201 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.185207 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.185212 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.185240 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625122.185258 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625122.185397 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625122.185417 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr5k3qnm5/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625122.185472 6796193 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625122.185557 6796193 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625122.186122 6796209 random_forest.cc:812] Training of tree  1/200 (tree index:2) done accuracy:0.682927 logloss:11.4285\n",
      "I0000 00:00:1729625122.186274 6796202 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.7 logloss:2.79269\n",
      "I0000 00:00:1729625122.186429 6796207 random_forest.cc:812] Training of tree  21/200 (tree index:13) done accuracy:0.708333 logloss:0.831119\n",
      "I0000 00:00:1729625122.186683 6796207 random_forest.cc:812] Training of tree  34/200 (tree index:33) done accuracy:0.716667 logloss:0.858951\n",
      "I0000 00:00:1729625122.186921 6796207 random_forest.cc:812] Training of tree  45/200 (tree index:45) done accuracy:0.65 logloss:0.599408\n",
      "I0000 00:00:1729625122.187134 6796207 random_forest.cc:812] Training of tree  55/200 (tree index:56) done accuracy:0.658333 logloss:0.594801\n",
      "I0000 00:00:1729625122.187279 6796208 random_forest.cc:812] Training of tree  65/200 (tree index:60) done accuracy:0.708333 logloss:0.589169\n",
      "I0000 00:00:1729625122.187508 6796209 random_forest.cc:812] Training of tree  75/200 (tree index:66) done accuracy:0.725 logloss:0.598354\n",
      "I0000 00:00:1729625122.187655 6796205 random_forest.cc:812] Training of tree  86/200 (tree index:85) done accuracy:0.741667 logloss:0.59068\n",
      "I0000 00:00:1729625122.187842 6796202 random_forest.cc:812] Training of tree  96/200 (tree index:96) done accuracy:0.733333 logloss:0.587389\n",
      "I0000 00:00:1729625122.188016 6796209 random_forest.cc:812] Training of tree  106/200 (tree index:105) done accuracy:0.725 logloss:0.588931\n",
      "I0000 00:00:1729625122.188216 6796209 random_forest.cc:812] Training of tree  116/200 (tree index:118) done accuracy:0.716667 logloss:0.584457\n",
      "I0000 00:00:1729625122.188387 6796206 random_forest.cc:812] Training of tree  126/200 (tree index:127) done accuracy:0.725 logloss:0.58578\n",
      "I0000 00:00:1729625122.188526 6796207 random_forest.cc:812] Training of tree  136/200 (tree index:135) done accuracy:0.716667 logloss:0.585299\n",
      "I0000 00:00:1729625122.188709 6796206 random_forest.cc:812] Training of tree  146/200 (tree index:145) done accuracy:0.7 logloss:0.585748\n",
      "I0000 00:00:1729625122.188855 6796203 random_forest.cc:812] Training of tree  157/200 (tree index:157) done accuracy:0.716667 logloss:0.57973\n",
      "I0000 00:00:1729625122.189038 6796204 random_forest.cc:812] Training of tree  167/200 (tree index:165) done accuracy:0.725 logloss:0.577021\n",
      "I0000 00:00:1729625122.189235 6796205 random_forest.cc:812] Training of tree  177/200 (tree index:158) done accuracy:0.725 logloss:0.570101\n",
      "I0000 00:00:1729625122.189358 6796203 random_forest.cc:812] Training of tree  187/200 (tree index:186) done accuracy:0.716667 logloss:0.570438\n",
      "I0000 00:00:1729625122.189524 6796207 random_forest.cc:812] Training of tree  197/200 (tree index:197) done accuracy:0.716667 logloss:0.570365\n",
      "I0000 00:00:1729625122.189582 6796209 random_forest.cc:812] Training of tree  200/200 (tree index:195) done accuracy:0.716667 logloss:0.569787\n",
      "I0000 00:00:1729625122.189624 6796193 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.569787\n",
      "I0000 00:00:1729625122.190046 6796193 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr5k3qnm5 with prefix 335d27317ede41f5\n",
      "I0000 00:00:1729625122.192248 6796193 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625122.192938 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.569787\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  17  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:22.200265: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpr5k3qnm5/model/ with prefix 335d27317ede41f5\n",
      "I0000 00:00:1729625122.204595 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3078 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:22.204620: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpimzthfdd as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.140969. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.019799\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625122.486961 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625122.486971 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625122.486975 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625122.487036 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625122.487041 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625122.487086 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.487098 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.487104 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.487109 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.487137 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625122.487156 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625122.487285 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625122.487321 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpimzthfdd/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625122.487360 6796281 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625122.487470 6796281 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625122.487971 6796295 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.674419 logloss:11.7351\n",
      "I0000 00:00:1729625122.488165 6796293 random_forest.cc:812] Training of tree  12/200 (tree index:10) done accuracy:0.709402 logloss:3.16473\n",
      "I0000 00:00:1729625122.488410 6796293 random_forest.cc:812] Training of tree  22/200 (tree index:22) done accuracy:0.725 logloss:0.801859\n",
      "I0000 00:00:1729625122.488578 6796294 random_forest.cc:812] Training of tree  32/200 (tree index:31) done accuracy:0.725 logloss:0.784707\n",
      "I0000 00:00:1729625122.488847 6796292 random_forest.cc:812] Training of tree  42/200 (tree index:42) done accuracy:0.725 logloss:0.781879\n",
      "I0000 00:00:1729625122.489032 6796290 random_forest.cc:812] Training of tree  52/200 (tree index:53) done accuracy:0.75 logloss:0.497936\n",
      "I0000 00:00:1729625122.489240 6796290 random_forest.cc:812] Training of tree  62/200 (tree index:63) done accuracy:0.775 logloss:0.493006\n",
      "I0000 00:00:1729625122.489492 6796294 random_forest.cc:812] Training of tree  72/200 (tree index:60) done accuracy:0.75 logloss:0.489321\n",
      "I0000 00:00:1729625122.489727 6796293 random_forest.cc:812] Training of tree  84/200 (tree index:83) done accuracy:0.775 logloss:0.493559\n",
      "I0000 00:00:1729625122.489953 6796297 random_forest.cc:812] Training of tree  94/200 (tree index:93) done accuracy:0.783333 logloss:0.482318\n",
      "I0000 00:00:1729625122.490133 6796297 random_forest.cc:812] Training of tree  104/200 (tree index:105) done accuracy:0.791667 logloss:0.474325\n",
      "I0000 00:00:1729625122.490369 6796294 random_forest.cc:812] Training of tree  115/200 (tree index:117) done accuracy:0.775 logloss:0.469654\n",
      "I0000 00:00:1729625122.490544 6796294 random_forest.cc:812] Training of tree  125/200 (tree index:125) done accuracy:0.8 logloss:0.466936\n",
      "I0000 00:00:1729625122.490721 6796291 random_forest.cc:812] Training of tree  135/200 (tree index:135) done accuracy:0.791667 logloss:0.468993\n",
      "I0000 00:00:1729625122.490847 6796294 random_forest.cc:812] Training of tree  146/200 (tree index:145) done accuracy:0.791667 logloss:0.47551\n",
      "I0000 00:00:1729625122.491025 6796292 random_forest.cc:812] Training of tree  156/200 (tree index:147) done accuracy:0.791667 logloss:0.47843\n",
      "I0000 00:00:1729625122.491170 6796291 random_forest.cc:812] Training of tree  166/200 (tree index:165) done accuracy:0.783333 logloss:0.476056\n",
      "I0000 00:00:1729625122.491348 6796290 random_forest.cc:812] Training of tree  176/200 (tree index:178) done accuracy:0.8 logloss:0.48263\n",
      "I0000 00:00:1729625122.491473 6796296 random_forest.cc:812] Training of tree  186/200 (tree index:185) done accuracy:0.791667 logloss:0.479946\n",
      "I0000 00:00:1729625122.491664 6796295 random_forest.cc:812] Training of tree  196/200 (tree index:196) done accuracy:0.783333 logloss:0.480696\n",
      "I0000 00:00:1729625122.491747 6796296 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.791667 logloss:0.481198\n",
      "I0000 00:00:1729625122.491805 6796281 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.481198\n",
      "I0000 00:00:1729625122.492137 6796281 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpimzthfdd with prefix 64f0946649494adc\n",
      "I0000 00:00:1729625122.494116 6796281 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625122.494770 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.481198\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  11  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:22.500639: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpimzthfdd/model/ with prefix 64f0946649494adc\n",
      "I0000 00:00:1729625122.504680 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2908 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:22.504766: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpddp0h4_c as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.151725. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.020213\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625122.802022 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625122.802033 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625122.802038 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625122.802103 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625122.802110 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625122.802152 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.802162 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.802168 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.802173 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625122.802200 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625122.802217 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625122.802354 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625122.802379 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpddp0h4_c/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625122.802441 6796351 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625122.802536 6796351 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625122.803059 6796361 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625122.803193 6796363 random_forest.cc:812] Training of tree  11/200 (tree index:6) done accuracy:0.747899 logloss:3.32652\n",
      "I0000 00:00:1729625122.803401 6796363 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.733333 logloss:1.06843\n",
      "I0000 00:00:1729625122.803527 6796365 random_forest.cc:812] Training of tree  31/200 (tree index:29) done accuracy:0.741667 logloss:0.788357\n",
      "I0000 00:00:1729625122.803673 6796361 random_forest.cc:812] Training of tree  42/200 (tree index:42) done accuracy:0.75 logloss:0.781558\n",
      "I0000 00:00:1729625122.803862 6796361 random_forest.cc:812] Training of tree  52/200 (tree index:52) done accuracy:0.775 logloss:0.482316\n",
      "I0000 00:00:1729625122.803989 6796366 random_forest.cc:812] Training of tree  62/200 (tree index:63) done accuracy:0.775 logloss:0.484973\n",
      "I0000 00:00:1729625122.804164 6796365 random_forest.cc:812] Training of tree  72/200 (tree index:73) done accuracy:0.775 logloss:0.488935\n",
      "I0000 00:00:1729625122.804365 6796362 random_forest.cc:812] Training of tree  82/200 (tree index:57) done accuracy:0.766667 logloss:0.489293\n",
      "I0000 00:00:1729625122.804577 6796363 random_forest.cc:812] Training of tree  92/200 (tree index:91) done accuracy:0.766667 logloss:0.494881\n",
      "I0000 00:00:1729625122.804878 6796367 random_forest.cc:812] Training of tree  102/200 (tree index:95) done accuracy:0.766667 logloss:0.494376\n",
      "I0000 00:00:1729625122.805060 6796366 random_forest.cc:812] Training of tree  112/200 (tree index:107) done accuracy:0.758333 logloss:0.495016\n",
      "I0000 00:00:1729625122.805361 6796365 random_forest.cc:812] Training of tree  124/200 (tree index:125) done accuracy:0.766667 logloss:0.493611\n",
      "I0000 00:00:1729625122.805567 6796361 random_forest.cc:812] Training of tree  134/200 (tree index:134) done accuracy:0.758333 logloss:0.492246\n",
      "I0000 00:00:1729625122.805744 6796364 random_forest.cc:812] Training of tree  144/200 (tree index:145) done accuracy:0.741667 logloss:0.496164\n",
      "I0000 00:00:1729625122.805941 6796363 random_forest.cc:812] Training of tree  154/200 (tree index:155) done accuracy:0.758333 logloss:0.496524\n",
      "I0000 00:00:1729625122.806182 6796363 random_forest.cc:812] Training of tree  164/200 (tree index:166) done accuracy:0.75 logloss:0.496183\n",
      "I0000 00:00:1729625122.806333 6796365 random_forest.cc:812] Training of tree  174/200 (tree index:174) done accuracy:0.758333 logloss:0.497678\n",
      "I0000 00:00:1729625122.806513 6796366 random_forest.cc:812] Training of tree  185/200 (tree index:185) done accuracy:0.75 logloss:0.495876\n",
      "I0000 00:00:1729625122.806719 6796364 random_forest.cc:812] Training of tree  195/200 (tree index:195) done accuracy:0.75 logloss:0.496793\n",
      "I0000 00:00:1729625122.806793 6796367 random_forest.cc:812] Training of tree  200/200 (tree index:194) done accuracy:0.758333 logloss:0.494298\n",
      "I0000 00:00:1729625122.806862 6796351 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.494298\n",
      "I0000 00:00:1729625122.807210 6796351 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpddp0h4_c with prefix 3ca7221c7c3e4f73\n",
      "I0000 00:00:1729625122.809277 6796351 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625122.809920 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.494298\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  15  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:22.815679: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpddp0h4_c/model/ with prefix 3ca7221c7c3e4f73\n",
      "I0000 00:00:1729625122.819998 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 3012 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:22.820028: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': -1, 'min_examples': 10, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9j6_xcc5 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.149256. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018497\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625123.155347 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625123.155360 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625123.155365 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625123.155475 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625123.155487 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625123.155533 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.155546 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.155552 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.155557 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.155584 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625123.155603 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625123.155802 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625123.155868 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9j6_xcc5/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625123.155914 6796420 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625123.156007 6796420 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625123.156576 6796430 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.773585 logloss:8.16083\n",
      "I0000 00:00:1729625123.156755 6796436 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.725 logloss:2.80262\n",
      "I0000 00:00:1729625123.156933 6796432 random_forest.cc:812] Training of tree  22/200 (tree index:23) done accuracy:0.775 logloss:1.65839\n",
      "I0000 00:00:1729625123.157134 6796432 random_forest.cc:812] Training of tree  32/200 (tree index:31) done accuracy:0.766667 logloss:1.11626\n",
      "I0000 00:00:1729625123.157266 6796429 random_forest.cc:812] Training of tree  42/200 (tree index:40) done accuracy:0.758333 logloss:0.835584\n",
      "I0000 00:00:1729625123.157439 6796429 random_forest.cc:812] Training of tree  52/200 (tree index:52) done accuracy:0.733333 logloss:0.55929\n",
      "I0000 00:00:1729625123.157606 6796434 random_forest.cc:812] Training of tree  63/200 (tree index:59) done accuracy:0.716667 logloss:0.552103\n",
      "I0000 00:00:1729625123.157757 6796432 random_forest.cc:812] Training of tree  73/200 (tree index:71) done accuracy:0.675 logloss:0.554972\n",
      "I0000 00:00:1729625123.157908 6796431 random_forest.cc:812] Training of tree  83/200 (tree index:83) done accuracy:0.7 logloss:0.547393\n",
      "I0000 00:00:1729625123.158041 6796433 random_forest.cc:812] Training of tree  93/200 (tree index:94) done accuracy:0.7 logloss:0.552821\n",
      "I0000 00:00:1729625123.158177 6796429 random_forest.cc:812] Training of tree  104/200 (tree index:103) done accuracy:0.708333 logloss:0.557377\n",
      "I0000 00:00:1729625123.158325 6796436 random_forest.cc:812] Training of tree  114/200 (tree index:114) done accuracy:0.733333 logloss:0.554212\n",
      "I0000 00:00:1729625123.158461 6796430 random_forest.cc:812] Training of tree  125/200 (tree index:125) done accuracy:0.733333 logloss:0.557091\n",
      "I0000 00:00:1729625123.158591 6796429 random_forest.cc:812] Training of tree  135/200 (tree index:134) done accuracy:0.7 logloss:0.549951\n",
      "I0000 00:00:1729625123.158718 6796436 random_forest.cc:812] Training of tree  145/200 (tree index:145) done accuracy:0.7 logloss:0.550576\n",
      "I0000 00:00:1729625123.158819 6796429 random_forest.cc:812] Training of tree  155/200 (tree index:155) done accuracy:0.725 logloss:0.549087\n",
      "I0000 00:00:1729625123.158971 6796436 random_forest.cc:812] Training of tree  167/200 (tree index:167) done accuracy:0.7 logloss:0.55313\n",
      "I0000 00:00:1729625123.159131 6796434 random_forest.cc:812] Training of tree  178/200 (tree index:178) done accuracy:0.708333 logloss:0.548061\n",
      "I0000 00:00:1729625123.159252 6796430 random_forest.cc:812] Training of tree  188/200 (tree index:188) done accuracy:0.716667 logloss:0.545365\n",
      "I0000 00:00:1729625123.159381 6796431 random_forest.cc:812] Training of tree  199/200 (tree index:196) done accuracy:0.708333 logloss:0.54368\n",
      "I0000 00:00:1729625123.159425 6796429 random_forest.cc:812] Training of tree  200/200 (tree index:194) done accuracy:0.7 logloss:0.546815\n",
      "I0000 00:00:1729625123.159527 6796420 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.546815\n",
      "I0000 00:00:1729625123.159834 6796420 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9j6_xcc5 with prefix 917be83c6685438c\n",
      "I0000 00:00:1729625123.161734 6796420 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625123.162373 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.546815\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  19  43\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:23.167951: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp9j6_xcc5/model/ with prefix 917be83c6685438c\n",
      "I0000 00:00:1729625123.171268 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2516 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:23.171285: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpt7jf7ouo as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146868. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018529\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625123.458456 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625123.458465 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625123.458471 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625123.458543 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625123.458549 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625123.458603 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.458613 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.458619 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.458624 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.458651 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625123.458668 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625123.458828 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625123.458853 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpt7jf7ouo/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625123.458915 6796493 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625123.459009 6796493 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625123.459538 6796502 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.510638 logloss:17.6384\n",
      "I0000 00:00:1729625123.459679 6796505 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.694915 logloss:3.73124\n",
      "I0000 00:00:1729625123.459865 6796507 random_forest.cc:812] Training of tree  21/200 (tree index:21) done accuracy:0.708333 logloss:1.7044\n",
      "I0000 00:00:1729625123.459999 6796509 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.725 logloss:0.583065\n",
      "I0000 00:00:1729625123.460133 6796504 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.733333 logloss:0.576381\n",
      "I0000 00:00:1729625123.460259 6796508 random_forest.cc:812] Training of tree  51/200 (tree index:51) done accuracy:0.708333 logloss:0.584738\n",
      "I0000 00:00:1729625123.460396 6796509 random_forest.cc:812] Training of tree  61/200 (tree index:63) done accuracy:0.725 logloss:0.568022\n",
      "I0000 00:00:1729625123.460598 6796503 random_forest.cc:812] Training of tree  71/200 (tree index:68) done accuracy:0.758333 logloss:0.57294\n",
      "I0000 00:00:1729625123.460707 6796503 random_forest.cc:812] Training of tree  81/200 (tree index:78) done accuracy:0.741667 logloss:0.565392\n",
      "I0000 00:00:1729625123.460858 6796502 random_forest.cc:812] Training of tree  91/200 (tree index:93) done accuracy:0.741667 logloss:0.563524\n",
      "I0000 00:00:1729625123.460979 6796503 random_forest.cc:812] Training of tree  101/200 (tree index:100) done accuracy:0.758333 logloss:0.557614\n",
      "I0000 00:00:1729625123.461148 6796506 random_forest.cc:812] Training of tree  112/200 (tree index:113) done accuracy:0.758333 logloss:0.555785\n",
      "I0000 00:00:1729625123.461322 6796509 random_forest.cc:812] Training of tree  122/200 (tree index:122) done accuracy:0.758333 logloss:0.557098\n",
      "I0000 00:00:1729625123.461446 6796507 random_forest.cc:812] Training of tree  132/200 (tree index:131) done accuracy:0.766667 logloss:0.56048\n",
      "I0000 00:00:1729625123.461589 6796508 random_forest.cc:812] Training of tree  142/200 (tree index:142) done accuracy:0.783333 logloss:0.558298\n",
      "I0000 00:00:1729625123.461749 6796503 random_forest.cc:812] Training of tree  155/200 (tree index:155) done accuracy:0.775 logloss:0.559813\n",
      "I0000 00:00:1729625123.461965 6796506 random_forest.cc:812] Training of tree  165/200 (tree index:166) done accuracy:0.766667 logloss:0.564531\n",
      "I0000 00:00:1729625123.462101 6796507 random_forest.cc:812] Training of tree  175/200 (tree index:173) done accuracy:0.775 logloss:0.5635\n",
      "I0000 00:00:1729625123.462262 6796504 random_forest.cc:812] Training of tree  186/200 (tree index:185) done accuracy:0.775 logloss:0.56004\n",
      "I0000 00:00:1729625123.462453 6796503 random_forest.cc:812] Training of tree  198/200 (tree index:196) done accuracy:0.783333 logloss:0.558533\n",
      "I0000 00:00:1729625123.462543 6796506 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.783333 logloss:0.558912\n",
      "I0000 00:00:1729625123.462579 6796493 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.558912\n",
      "I0000 00:00:1729625123.462897 6796493 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpt7jf7ouo with prefix b0eb77bc0e414337\n",
      "I0000 00:00:1729625123.464891 6796493 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625123.465505 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.558912\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:23.471751: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpt7jf7ouo/model/ with prefix b0eb77bc0e414337\n",
      "I0000 00:00:1729625123.475093 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2536 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:23.475107: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx63m2bo0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146290. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018432\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625123.760848 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625123.760869 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625123.760874 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625123.760940 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625123.760948 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625123.760991 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.761001 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.761007 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.761013 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625123.761041 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625123.761060 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625123.761196 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625123.761221 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx63m2bo0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625123.761294 6796573 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625123.761390 6796573 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625123.761957 6796586 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625123.762112 6796589 random_forest.cc:812] Training of tree  11/200 (tree index:3) done accuracy:0.633333 logloss:3.45838\n",
      "I0000 00:00:1729625123.762282 6796582 random_forest.cc:812] Training of tree  21/200 (tree index:19) done accuracy:0.641667 logloss:1.19259\n",
      "I0000 00:00:1729625123.762421 6796584 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.666667 logloss:0.887454\n",
      "I0000 00:00:1729625123.762600 6796584 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.733333 logloss:0.590228\n",
      "I0000 00:00:1729625123.762749 6796589 random_forest.cc:812] Training of tree  51/200 (tree index:42) done accuracy:0.708333 logloss:0.591465\n",
      "I0000 00:00:1729625123.762873 6796589 random_forest.cc:812] Training of tree  61/200 (tree index:58) done accuracy:0.691667 logloss:0.585648\n",
      "I0000 00:00:1729625123.763018 6796584 random_forest.cc:812] Training of tree  71/200 (tree index:72) done accuracy:0.7 logloss:0.582171\n",
      "I0000 00:00:1729625123.763138 6796583 random_forest.cc:812] Training of tree  81/200 (tree index:81) done accuracy:0.691667 logloss:0.573673\n",
      "I0000 00:00:1729625123.763294 6796585 random_forest.cc:812] Training of tree  91/200 (tree index:82) done accuracy:0.7 logloss:0.563329\n",
      "I0000 00:00:1729625123.763448 6796587 random_forest.cc:812] Training of tree  101/200 (tree index:100) done accuracy:0.683333 logloss:0.566905\n",
      "I0000 00:00:1729625123.763583 6796588 random_forest.cc:812] Training of tree  111/200 (tree index:111) done accuracy:0.7 logloss:0.560611\n",
      "I0000 00:00:1729625123.763737 6796588 random_forest.cc:812] Training of tree  122/200 (tree index:123) done accuracy:0.683333 logloss:0.559008\n",
      "I0000 00:00:1729625123.763903 6796583 random_forest.cc:812] Training of tree  132/200 (tree index:126) done accuracy:0.691667 logloss:0.552297\n",
      "I0000 00:00:1729625123.764029 6796586 random_forest.cc:812] Training of tree  142/200 (tree index:141) done accuracy:0.691667 logloss:0.552352\n",
      "I0000 00:00:1729625123.764252 6796583 random_forest.cc:812] Training of tree  152/200 (tree index:153) done accuracy:0.7 logloss:0.554721\n",
      "I0000 00:00:1729625123.764388 6796582 random_forest.cc:812] Training of tree  162/200 (tree index:163) done accuracy:0.708333 logloss:0.553292\n",
      "I0000 00:00:1729625123.764541 6796587 random_forest.cc:812] Training of tree  172/200 (tree index:171) done accuracy:0.725 logloss:0.561214\n",
      "I0000 00:00:1729625123.764659 6796584 random_forest.cc:812] Training of tree  182/200 (tree index:182) done accuracy:0.733333 logloss:0.565173\n",
      "I0000 00:00:1729625123.764788 6796586 random_forest.cc:812] Training of tree  192/200 (tree index:195) done accuracy:0.733333 logloss:0.566733\n",
      "I0000 00:00:1729625123.764883 6796586 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.733333 logloss:0.569845\n",
      "I0000 00:00:1729625123.764984 6796573 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.569845\n",
      "I0000 00:00:1729625123.765347 6796573 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx63m2bo0 with prefix 9f4cfa0bdcd948b2\n",
      "I0000 00:00:1729625123.767495 6796573 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625123.768269 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.569845\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  35  19\n",
      "2  13  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:23.773893: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx63m2bo0/model/ with prefix 9f4cfa0bdcd948b2\n",
      "I0000 00:00:1729625123.777415 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2558 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:23.777451: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpnbhzagl9 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.190464. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625124.107694 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625124.107707 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625124.107711 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625124.107775 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625124.107781 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625124.107822 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.107832 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.107837 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.107842 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.107867 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625124.107885 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625124.108013 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625124.108037 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpnbhzagl9/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625124.108080 6796643 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625124.108182 6796643 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625124.108663 6796654 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625124.108814 6796654 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.675 logloss:2.84725\n",
      "I0000 00:00:1729625124.108940 6796657 random_forest.cc:812] Training of tree  21/200 (tree index:14) done accuracy:0.725 logloss:1.07897\n",
      "I0000 00:00:1729625124.109082 6796659 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.716667 logloss:0.810849\n",
      "I0000 00:00:1729625124.109241 6796654 random_forest.cc:812] Training of tree  41/200 (tree index:45) done accuracy:0.758333 logloss:0.516834\n",
      "I0000 00:00:1729625124.109372 6796658 random_forest.cc:812] Training of tree  53/200 (tree index:53) done accuracy:0.766667 logloss:0.525041\n",
      "I0000 00:00:1729625124.109574 6796655 random_forest.cc:812] Training of tree  64/200 (tree index:63) done accuracy:0.75 logloss:0.517674\n",
      "I0000 00:00:1729625124.109743 6796655 random_forest.cc:812] Training of tree  74/200 (tree index:75) done accuracy:0.758333 logloss:0.519574\n",
      "I0000 00:00:1729625124.109851 6796657 random_forest.cc:812] Training of tree  84/200 (tree index:83) done accuracy:0.733333 logloss:0.520416\n",
      "I0000 00:00:1729625124.109993 6796653 random_forest.cc:812] Training of tree  94/200 (tree index:96) done accuracy:0.775 logloss:0.514088\n",
      "I0000 00:00:1729625124.110158 6796658 random_forest.cc:812] Training of tree  106/200 (tree index:105) done accuracy:0.775 logloss:0.512954\n",
      "I0000 00:00:1729625124.110336 6796654 random_forest.cc:812] Training of tree  116/200 (tree index:116) done accuracy:0.775 logloss:0.509702\n",
      "I0000 00:00:1729625124.110488 6796659 random_forest.cc:812] Training of tree  126/200 (tree index:128) done accuracy:0.775 logloss:0.502636\n",
      "I0000 00:00:1729625124.110659 6796652 random_forest.cc:812] Training of tree  136/200 (tree index:135) done accuracy:0.775 logloss:0.49873\n",
      "I0000 00:00:1729625124.110776 6796655 random_forest.cc:812] Training of tree  147/200 (tree index:146) done accuracy:0.783333 logloss:0.495896\n",
      "I0000 00:00:1729625124.110928 6796655 random_forest.cc:812] Training of tree  157/200 (tree index:158) done accuracy:0.775 logloss:0.496085\n",
      "I0000 00:00:1729625124.111050 6796658 random_forest.cc:812] Training of tree  167/200 (tree index:165) done accuracy:0.783333 logloss:0.495874\n",
      "I0000 00:00:1729625124.111264 6796653 random_forest.cc:812] Training of tree  177/200 (tree index:178) done accuracy:0.775 logloss:0.501348\n",
      "I0000 00:00:1729625124.111445 6796652 random_forest.cc:812] Training of tree  189/200 (tree index:188) done accuracy:0.766667 logloss:0.503348\n",
      "I0000 00:00:1729625124.111637 6796652 random_forest.cc:812] Training of tree  199/200 (tree index:198) done accuracy:0.766667 logloss:0.501845\n",
      "I0000 00:00:1729625124.111660 6796653 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.766667 logloss:0.501334\n",
      "I0000 00:00:1729625124.111738 6796643 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.501334\n",
      "I0000 00:00:1729625124.112045 6796643 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpnbhzagl9 with prefix b926f66c69a0487c\n",
      "I0000 00:00:1729625124.113857 6796643 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625124.114549 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.501334\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  16\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.018317\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpaswp8w_2 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 20:25:24.120548: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpnbhzagl9/model/ with prefix b926f66c69a0487c\n",
      "I0000 00:00:1729625124.123997 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2434 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:24.124025: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147489. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017287\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': -1, 'min_examples': 20, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0xj24nxv as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625124.405525 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625124.405536 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625124.405541 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625124.405608 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625124.405613 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625124.405661 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.405670 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.405675 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.405681 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.405743 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625124.405771 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625124.405910 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625124.405938 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpaswp8w_2/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625124.406003 6796715 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625124.406109 6796715 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625124.406670 6796725 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.735849 logloss:9.52096\n",
      "I0000 00:00:1729625124.406860 6796727 random_forest.cc:812] Training of tree  11/200 (tree index:2) done accuracy:0.741667 logloss:1.63157\n",
      "I0000 00:00:1729625124.407001 6796725 random_forest.cc:812] Training of tree  22/200 (tree index:21) done accuracy:0.725 logloss:0.79411\n",
      "I0000 00:00:1729625124.407257 6796729 random_forest.cc:812] Training of tree  34/200 (tree index:34) done accuracy:0.733333 logloss:0.491365\n",
      "I0000 00:00:1729625124.407421 6796730 random_forest.cc:812] Training of tree  45/200 (tree index:41) done accuracy:0.775 logloss:0.520932\n",
      "I0000 00:00:1729625124.407603 6796730 random_forest.cc:812] Training of tree  57/200 (tree index:57) done accuracy:0.766667 logloss:0.515215\n",
      "I0000 00:00:1729625124.407779 6796727 random_forest.cc:812] Training of tree  67/200 (tree index:66) done accuracy:0.75 logloss:0.52225\n",
      "I0000 00:00:1729625124.407949 6796727 random_forest.cc:812] Training of tree  79/200 (tree index:78) done accuracy:0.775 logloss:0.524501\n",
      "I0000 00:00:1729625124.408142 6796724 random_forest.cc:812] Training of tree  89/200 (tree index:88) done accuracy:0.775 logloss:0.518651\n",
      "I0000 00:00:1729625124.408295 6796728 random_forest.cc:812] Training of tree  101/200 (tree index:100) done accuracy:0.775 logloss:0.516495\n",
      "I0000 00:00:1729625124.408492 6796724 random_forest.cc:812] Training of tree  111/200 (tree index:110) done accuracy:0.775 logloss:0.518573\n",
      "I0000 00:00:1729625124.408699 6796731 random_forest.cc:812] Training of tree  121/200 (tree index:121) done accuracy:0.775 logloss:0.513812\n",
      "I0000 00:00:1729625124.408830 6796725 random_forest.cc:812] Training of tree  131/200 (tree index:130) done accuracy:0.775 logloss:0.51168\n",
      "I0000 00:00:1729625124.409001 6796725 random_forest.cc:812] Training of tree  141/200 (tree index:140) done accuracy:0.775 logloss:0.513336\n",
      "I0000 00:00:1729625124.409160 6796727 random_forest.cc:812] Training of tree  151/200 (tree index:150) done accuracy:0.775 logloss:0.5115\n",
      "I0000 00:00:1729625124.409305 6796729 random_forest.cc:812] Training of tree  161/200 (tree index:161) done accuracy:0.783333 logloss:0.51294\n",
      "I0000 00:00:1729625124.409439 6796725 random_forest.cc:812] Training of tree  171/200 (tree index:171) done accuracy:0.791667 logloss:0.512066\n",
      "I0000 00:00:1729625124.409570 6796724 random_forest.cc:812] Training of tree  181/200 (tree index:183) done accuracy:0.783333 logloss:0.511679\n",
      "I0000 00:00:1729625124.409734 6796727 random_forest.cc:812] Training of tree  193/200 (tree index:193) done accuracy:0.783333 logloss:0.512533\n",
      "I0000 00:00:1729625124.409836 6796727 random_forest.cc:812] Training of tree  200/200 (tree index:198) done accuracy:0.766667 logloss:0.516313\n",
      "I0000 00:00:1729625124.409887 6796715 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.516313\n",
      "I0000 00:00:1729625124.410188 6796715 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpaswp8w_2 with prefix 004b214fd6734198\n",
      "I0000 00:00:1729625124.412059 6796715 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625124.412771 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.516313\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  16\n",
      "2  12  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:24.417640: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpaswp8w_2/model/ with prefix 004b214fd6734198\n",
      "I0000 00:00:1729625124.420956 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 2486 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:24.420978: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.149569. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015561\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0u3och7u as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625124.706641 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625124.706651 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625124.706655 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625124.706722 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625124.706726 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625124.706771 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.706781 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.706786 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.706791 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625124.706819 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625124.706836 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625124.706992 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625124.707019 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0xj24nxv/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625124.707080 6796785 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625124.707184 6796785 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625124.707704 6796801 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.454545 logloss:19.6602\n",
      "I0000 00:00:1729625124.707885 6796796 random_forest.cc:812] Training of tree  11/200 (tree index:9) done accuracy:0.641667 logloss:4.00572\n",
      "I0000 00:00:1729625124.708049 6796796 random_forest.cc:812] Training of tree  23/200 (tree index:22) done accuracy:0.758333 logloss:2.23005\n",
      "I0000 00:00:1729625124.708291 6796796 random_forest.cc:812] Training of tree  35/200 (tree index:35) done accuracy:0.758333 logloss:1.40421\n",
      "I0000 00:00:1729625124.708449 6796796 random_forest.cc:812] Training of tree  45/200 (tree index:46) done accuracy:0.708333 logloss:1.41312\n",
      "I0000 00:00:1729625124.708616 6796801 random_forest.cc:812] Training of tree  55/200 (tree index:54) done accuracy:0.708333 logloss:1.4085\n",
      "I0000 00:00:1729625124.708777 6796797 random_forest.cc:812] Training of tree  65/200 (tree index:65) done accuracy:0.7 logloss:0.833135\n",
      "I0000 00:00:1729625124.708884 6796796 random_forest.cc:812] Training of tree  75/200 (tree index:74) done accuracy:0.708333 logloss:0.837632\n",
      "I0000 00:00:1729625124.709032 6796797 random_forest.cc:812] Training of tree  85/200 (tree index:85) done accuracy:0.708333 logloss:0.850319\n",
      "I0000 00:00:1729625124.709143 6796798 random_forest.cc:812] Training of tree  95/200 (tree index:95) done accuracy:0.708333 logloss:0.584558\n",
      "I0000 00:00:1729625124.709271 6796794 random_forest.cc:812] Training of tree  106/200 (tree index:105) done accuracy:0.708333 logloss:0.589138\n",
      "I0000 00:00:1729625124.709426 6796800 random_forest.cc:812] Training of tree  116/200 (tree index:117) done accuracy:0.716667 logloss:0.591405\n",
      "I0000 00:00:1729625124.709552 6796797 random_forest.cc:812] Training of tree  126/200 (tree index:128) done accuracy:0.708333 logloss:0.585937\n",
      "I0000 00:00:1729625124.709694 6796794 random_forest.cc:812] Training of tree  136/200 (tree index:136) done accuracy:0.708333 logloss:0.582815\n",
      "I0000 00:00:1729625124.709827 6796797 random_forest.cc:812] Training of tree  147/200 (tree index:146) done accuracy:0.7 logloss:0.581643\n",
      "I0000 00:00:1729625124.710040 6796797 random_forest.cc:812] Training of tree  157/200 (tree index:156) done accuracy:0.716667 logloss:0.581241\n",
      "I0000 00:00:1729625124.710188 6796799 random_forest.cc:812] Training of tree  169/200 (tree index:169) done accuracy:0.716667 logloss:0.57914\n",
      "I0000 00:00:1729625124.710364 6796796 random_forest.cc:812] Training of tree  180/200 (tree index:181) done accuracy:0.716667 logloss:0.571055\n",
      "I0000 00:00:1729625124.710490 6796799 random_forest.cc:812] Training of tree  190/200 (tree index:190) done accuracy:0.708333 logloss:0.572119\n",
      "I0000 00:00:1729625124.710669 6796797 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.725 logloss:0.573817\n",
      "I0000 00:00:1729625124.710755 6796785 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.573817\n",
      "I0000 00:00:1729625124.711012 6796785 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0xj24nxv with prefix be0880ebef9d4e4e\n",
      "I0000 00:00:1729625124.712760 6796785 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625124.713336 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.573817\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  18\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:24.718159: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0xj24nxv/model/ with prefix be0880ebef9d4e4e\n",
      "I0000 00:00:1729625124.720347 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1636 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:24.720362: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143430. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016854\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp_ome7b6 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625125.001814 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625125.001823 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625125.001829 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625125.001902 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625125.001907 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625125.001954 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.001965 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.001970 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.001975 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.002004 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625125.002021 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625125.002179 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625125.002204 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0u3och7u/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625125.002287 6796859 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625125.002375 6796859 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625125.002882 6796872 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.675 logloss:11.7142\n",
      "I0000 00:00:1729625125.002989 6796875 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.666667 logloss:5.84991\n",
      "I0000 00:00:1729625125.003148 6796872 random_forest.cc:812] Training of tree  21/200 (tree index:19) done accuracy:0.658333 logloss:2.02877\n",
      "I0000 00:00:1729625125.003300 6796873 random_forest.cc:812] Training of tree  31/200 (tree index:25) done accuracy:0.658333 logloss:0.902322\n",
      "I0000 00:00:1729625125.003441 6796871 random_forest.cc:812] Training of tree  42/200 (tree index:40) done accuracy:0.708333 logloss:0.904118\n",
      "I0000 00:00:1729625125.003592 6796871 random_forest.cc:812] Training of tree  52/200 (tree index:53) done accuracy:0.716667 logloss:0.616897\n",
      "I0000 00:00:1729625125.003756 6796875 random_forest.cc:812] Training of tree  62/200 (tree index:57) done accuracy:0.708333 logloss:0.614829\n",
      "I0000 00:00:1729625125.003924 6796872 random_forest.cc:812] Training of tree  72/200 (tree index:71) done accuracy:0.725 logloss:0.613407\n",
      "I0000 00:00:1729625125.004080 6796873 random_forest.cc:812] Training of tree  82/200 (tree index:75) done accuracy:0.733333 logloss:0.609234\n",
      "I0000 00:00:1729625125.004208 6796869 random_forest.cc:812] Training of tree  92/200 (tree index:82) done accuracy:0.733333 logloss:0.599817\n",
      "I0000 00:00:1729625125.004348 6796869 random_forest.cc:812] Training of tree  102/200 (tree index:105) done accuracy:0.741667 logloss:0.588148\n",
      "I0000 00:00:1729625125.004499 6796869 random_forest.cc:812] Training of tree  112/200 (tree index:113) done accuracy:0.733333 logloss:0.595591\n",
      "I0000 00:00:1729625125.004680 6796874 random_forest.cc:812] Training of tree  125/200 (tree index:122) done accuracy:0.725 logloss:0.597679\n",
      "I0000 00:00:1729625125.004835 6796874 random_forest.cc:812] Training of tree  135/200 (tree index:135) done accuracy:0.75 logloss:0.596365\n",
      "I0000 00:00:1729625125.004969 6796870 random_forest.cc:812] Training of tree  145/200 (tree index:146) done accuracy:0.766667 logloss:0.601622\n",
      "I0000 00:00:1729625125.005079 6796871 random_forest.cc:812] Training of tree  156/200 (tree index:156) done accuracy:0.75 logloss:0.606207\n",
      "I0000 00:00:1729625125.005237 6796871 random_forest.cc:812] Training of tree  166/200 (tree index:165) done accuracy:0.75 logloss:0.60373\n",
      "I0000 00:00:1729625125.005379 6796873 random_forest.cc:812] Training of tree  176/200 (tree index:175) done accuracy:0.766667 logloss:0.603579\n",
      "I0000 00:00:1729625125.005568 6796869 random_forest.cc:812] Training of tree  187/200 (tree index:187) done accuracy:0.758333 logloss:0.600449\n",
      "I0000 00:00:1729625125.005716 6796869 random_forest.cc:812] Training of tree  197/200 (tree index:197) done accuracy:0.775 logloss:0.60165\n",
      "I0000 00:00:1729625125.005761 6796875 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.766667 logloss:0.600679\n",
      "I0000 00:00:1729625125.005831 6796859 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.600679\n",
      "I0000 00:00:1729625125.006103 6796859 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0u3och7u with prefix f1f55c9744d94794\n",
      "I0000 00:00:1729625125.007493 6796859 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625125.008146 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.600679\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  17\n",
      "2  11  56\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:25.014522: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp0u3och7u/model/ with prefix f1f55c9744d94794\n",
      "I0000 00:00:1729625125.016802 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1628 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:25.016823: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146252. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015647\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpptm3t2f2 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625125.300542 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625125.300552 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625125.300556 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625125.300620 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625125.300625 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625125.300673 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.300685 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.300691 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.300697 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.300726 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625125.300745 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625125.300890 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625125.300911 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp_ome7b6/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625125.300981 6796929 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625125.301082 6796929 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625125.301637 6796942 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.386364 logloss:22.1177\n",
      "I0000 00:00:1729625125.301771 6796941 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.672269 logloss:3.1742\n",
      "I0000 00:00:1729625125.301888 6796942 random_forest.cc:812] Training of tree  21/200 (tree index:23) done accuracy:0.675 logloss:0.892596\n",
      "I0000 00:00:1729625125.302030 6796945 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.691667 logloss:0.610856\n",
      "I0000 00:00:1729625125.302171 6796939 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.7 logloss:0.592231\n",
      "I0000 00:00:1729625125.302310 6796939 random_forest.cc:812] Training of tree  52/200 (tree index:48) done accuracy:0.716667 logloss:0.600075\n",
      "I0000 00:00:1729625125.302475 6796944 random_forest.cc:812] Training of tree  62/200 (tree index:60) done accuracy:0.716667 logloss:0.600562\n",
      "I0000 00:00:1729625125.302595 6796943 random_forest.cc:812] Training of tree  72/200 (tree index:71) done accuracy:0.716667 logloss:0.606368\n",
      "I0000 00:00:1729625125.302702 6796945 random_forest.cc:812] Training of tree  82/200 (tree index:83) done accuracy:0.733333 logloss:0.599659\n",
      "I0000 00:00:1729625125.302817 6796943 random_forest.cc:812] Training of tree  92/200 (tree index:93) done accuracy:0.733333 logloss:0.590734\n",
      "I0000 00:00:1729625125.302938 6796942 random_forest.cc:812] Training of tree  102/200 (tree index:103) done accuracy:0.725 logloss:0.581765\n",
      "I0000 00:00:1729625125.303094 6796938 random_forest.cc:812] Training of tree  115/200 (tree index:115) done accuracy:0.716667 logloss:0.585237\n",
      "I0000 00:00:1729625125.303284 6796944 random_forest.cc:812] Training of tree  125/200 (tree index:125) done accuracy:0.7 logloss:0.58741\n",
      "I0000 00:00:1729625125.303388 6796945 random_forest.cc:812] Training of tree  135/200 (tree index:135) done accuracy:0.691667 logloss:0.58837\n",
      "I0000 00:00:1729625125.303600 6796940 random_forest.cc:812] Training of tree  145/200 (tree index:140) done accuracy:0.683333 logloss:0.593243\n",
      "I0000 00:00:1729625125.303701 6796941 random_forest.cc:812] Training of tree  155/200 (tree index:154) done accuracy:0.7 logloss:0.594302\n",
      "I0000 00:00:1729625125.303857 6796940 random_forest.cc:812] Training of tree  165/200 (tree index:166) done accuracy:0.716667 logloss:0.592252\n",
      "I0000 00:00:1729625125.303969 6796941 random_forest.cc:812] Training of tree  175/200 (tree index:173) done accuracy:0.741667 logloss:0.586345\n",
      "I0000 00:00:1729625125.304089 6796944 random_forest.cc:812] Training of tree  185/200 (tree index:184) done accuracy:0.716667 logloss:0.587822\n",
      "I0000 00:00:1729625125.304223 6796941 random_forest.cc:812] Training of tree  195/200 (tree index:196) done accuracy:0.7 logloss:0.590433\n",
      "I0000 00:00:1729625125.304289 6796939 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.716667 logloss:0.589941\n",
      "I0000 00:00:1729625125.304339 6796929 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.589941\n",
      "I0000 00:00:1729625125.304559 6796929 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp_ome7b6 with prefix 1169b4ac33934e83\n",
      "I0000 00:00:1729625125.306148 6796929 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625125.306863 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.589941\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  32  22\n",
      "2  12  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:25.312085: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpp_ome7b6/model/ with prefix 1169b4ac33934e83\n",
      "I0000 00:00:1729625125.314344 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1622 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:25.314359: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143457. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014341\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7yhue2n7 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625125.593554 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625125.593563 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625125.593567 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625125.593633 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625125.593638 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625125.593691 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.593705 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.593710 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.593715 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.593742 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625125.593761 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625125.593895 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625125.593920 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpptm3t2f2/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625125.593978 6797001 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625125.594086 6797001 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625125.594550 6797017 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625125.594686 6797016 random_forest.cc:812] Training of tree  13/200 (tree index:10) done accuracy:0.65 logloss:3.67921\n",
      "I0000 00:00:1729625125.594849 6797011 random_forest.cc:812] Training of tree  23/200 (tree index:24) done accuracy:0.741667 logloss:1.92459\n",
      "I0000 00:00:1729625125.594952 6797010 random_forest.cc:812] Training of tree  33/200 (tree index:31) done accuracy:0.75 logloss:1.08537\n",
      "I0000 00:00:1729625125.595055 6797016 random_forest.cc:812] Training of tree  43/200 (tree index:43) done accuracy:0.708333 logloss:0.814128\n",
      "I0000 00:00:1729625125.595194 6797015 random_forest.cc:812] Training of tree  53/200 (tree index:51) done accuracy:0.708333 logloss:0.534831\n",
      "I0000 00:00:1729625125.595300 6797016 random_forest.cc:812] Training of tree  63/200 (tree index:63) done accuracy:0.75 logloss:0.517433\n",
      "I0000 00:00:1729625125.595432 6797011 random_forest.cc:812] Training of tree  73/200 (tree index:74) done accuracy:0.733333 logloss:0.507922\n",
      "I0000 00:00:1729625125.595612 6797016 random_forest.cc:812] Training of tree  85/200 (tree index:85) done accuracy:0.75 logloss:0.513696\n",
      "I0000 00:00:1729625125.595764 6797014 random_forest.cc:812] Training of tree  96/200 (tree index:95) done accuracy:0.75 logloss:0.512692\n",
      "I0000 00:00:1729625125.595963 6797016 random_forest.cc:812] Training of tree  106/200 (tree index:105) done accuracy:0.775 logloss:0.506151\n",
      "I0000 00:00:1729625125.596134 6797012 random_forest.cc:812] Training of tree  119/200 (tree index:119) done accuracy:0.791667 logloss:0.501805\n",
      "I0000 00:00:1729625125.596308 6797017 random_forest.cc:812] Training of tree  129/200 (tree index:128) done accuracy:0.783333 logloss:0.510679\n",
      "I0000 00:00:1729625125.596429 6797010 random_forest.cc:812] Training of tree  139/200 (tree index:138) done accuracy:0.8 logloss:0.510387\n",
      "I0000 00:00:1729625125.596530 6797017 random_forest.cc:812] Training of tree  149/200 (tree index:149) done accuracy:0.783333 logloss:0.513672\n",
      "I0000 00:00:1729625125.596651 6797014 random_forest.cc:812] Training of tree  159/200 (tree index:160) done accuracy:0.783333 logloss:0.516085\n",
      "I0000 00:00:1729625125.596762 6797012 random_forest.cc:812] Training of tree  169/200 (tree index:169) done accuracy:0.783333 logloss:0.516091\n",
      "I0000 00:00:1729625125.596881 6797011 random_forest.cc:812] Training of tree  179/200 (tree index:177) done accuracy:0.8 logloss:0.512128\n",
      "I0000 00:00:1729625125.596997 6797013 random_forest.cc:812] Training of tree  189/200 (tree index:190) done accuracy:0.8 logloss:0.512868\n",
      "I0000 00:00:1729625125.597103 6797012 random_forest.cc:812] Training of tree  199/200 (tree index:195) done accuracy:0.8 logloss:0.511748\n",
      "I0000 00:00:1729625125.597140 6797010 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.8 logloss:0.51219\n",
      "I0000 00:00:1729625125.597255 6797001 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.51219\n",
      "I0000 00:00:1729625125.597453 6797001 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpptm3t2f2 with prefix a0bbe6d038f542ae\n",
      "I0000 00:00:1729625125.598934 6797001 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625125.599613 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.51219\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:25.604254: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpptm3t2f2/model/ with prefix a0bbe6d038f542ae\n",
      "I0000 00:00:1729625125.606391 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1584 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:25.606405: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.200534. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015816\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 200, 'max_depth': -1, 'min_examples': 20, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps88o0e1c as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625125.939057 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625125.939066 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625125.939070 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625125.939135 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625125.939141 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625125.939184 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.939194 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.939199 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.939204 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625125.939230 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625125.939249 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625125.939378 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625125.939401 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7yhue2n7/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625125.939455 6797072 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625125.939540 6797072 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625125.940059 6797083 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625125.940238 6797084 random_forest.cc:812] Training of tree  11/200 (tree index:12) done accuracy:0.726496 logloss:4.61168\n",
      "I0000 00:00:1729625125.940391 6797085 random_forest.cc:812] Training of tree  21/200 (tree index:20) done accuracy:0.683333 logloss:1.72833\n",
      "I0000 00:00:1729625125.940523 6797081 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.716667 logloss:0.88224\n",
      "I0000 00:00:1729625125.940681 6797082 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.725 logloss:0.866103\n",
      "I0000 00:00:1729625125.940836 6797085 random_forest.cc:812] Training of tree  51/200 (tree index:50) done accuracy:0.733333 logloss:0.852625\n",
      "I0000 00:00:1729625125.941079 6797085 random_forest.cc:812] Training of tree  61/200 (tree index:57) done accuracy:0.758333 logloss:0.846573\n",
      "I0000 00:00:1729625125.941287 6797086 random_forest.cc:812] Training of tree  72/200 (tree index:71) done accuracy:0.758333 logloss:0.838068\n",
      "I0000 00:00:1729625125.941542 6797084 random_forest.cc:812] Training of tree  82/200 (tree index:81) done accuracy:0.733333 logloss:0.842603\n",
      "I0000 00:00:1729625125.941687 6797084 random_forest.cc:812] Training of tree  93/200 (tree index:93) done accuracy:0.716667 logloss:0.838955\n",
      "I0000 00:00:1729625125.941890 6797088 random_forest.cc:812] Training of tree  103/200 (tree index:103) done accuracy:0.725 logloss:0.835829\n",
      "I0000 00:00:1729625125.942047 6797081 random_forest.cc:812] Training of tree  113/200 (tree index:115) done accuracy:0.741667 logloss:0.834428\n",
      "I0000 00:00:1729625125.942196 6797085 random_forest.cc:812] Training of tree  123/200 (tree index:122) done accuracy:0.758333 logloss:0.827985\n",
      "I0000 00:00:1729625125.942324 6797085 random_forest.cc:812] Training of tree  133/200 (tree index:134) done accuracy:0.775 logloss:0.558241\n",
      "I0000 00:00:1729625125.942438 6797086 random_forest.cc:812] Training of tree  143/200 (tree index:142) done accuracy:0.766667 logloss:0.563802\n",
      "I0000 00:00:1729625125.942586 6797086 random_forest.cc:812] Training of tree  153/200 (tree index:153) done accuracy:0.758333 logloss:0.567493\n",
      "I0000 00:00:1729625125.942759 6797084 random_forest.cc:812] Training of tree  163/200 (tree index:157) done accuracy:0.75 logloss:0.568619\n",
      "I0000 00:00:1729625125.942887 6797087 random_forest.cc:812] Training of tree  173/200 (tree index:172) done accuracy:0.758333 logloss:0.567028\n",
      "I0000 00:00:1729625125.943075 6797083 random_forest.cc:812] Training of tree  186/200 (tree index:185) done accuracy:0.75 logloss:0.556842\n",
      "I0000 00:00:1729625125.943229 6797083 random_forest.cc:812] Training of tree  196/200 (tree index:196) done accuracy:0.75 logloss:0.550528\n",
      "I0000 00:00:1729625125.943300 6797081 random_forest.cc:812] Training of tree  200/200 (tree index:190) done accuracy:0.766667 logloss:0.551084\n",
      "I0000 00:00:1729625125.943377 6797072 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.551084\n",
      "I0000 00:00:1729625125.943566 6797072 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7yhue2n7 with prefix 91ee56cf97f64469\n",
      "I0000 00:00:1729625125.944884 6797072 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625125.945711 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.551084\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  18\n",
      "2  10  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:25.950883: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7yhue2n7/model/ with prefix 91ee56cf97f64469\n",
      "I0000 00:00:1729625125.953046 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1606 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:25.953064: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.149672. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.015082\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpa_6_pujk as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625126.252762 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625126.252781 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625126.252785 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625126.252850 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625126.252856 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625126.252899 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.252908 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.252914 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.252918 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.252976 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625126.253008 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625126.253168 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625126.253211 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps88o0e1c/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625126.253277 6797143 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625126.253426 6797143 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625126.254064 6797156 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.531915 logloss:16.8715\n",
      "I0000 00:00:1729625126.254192 6797156 random_forest.cc:812] Training of tree  11/200 (tree index:13) done accuracy:0.683333 logloss:2.61087\n",
      "I0000 00:00:1729625126.254319 6797153 random_forest.cc:812] Training of tree  21/200 (tree index:12) done accuracy:0.675 logloss:1.1663\n",
      "I0000 00:00:1729625126.254423 6797155 random_forest.cc:812] Training of tree  31/200 (tree index:31) done accuracy:0.683333 logloss:0.869163\n",
      "I0000 00:00:1729625126.254569 6797159 random_forest.cc:812] Training of tree  41/200 (tree index:42) done accuracy:0.708333 logloss:0.596877\n",
      "I0000 00:00:1729625126.254663 6797157 random_forest.cc:812] Training of tree  51/200 (tree index:51) done accuracy:0.691667 logloss:0.604588\n",
      "I0000 00:00:1729625126.254780 6797155 random_forest.cc:812] Training of tree  62/200 (tree index:57) done accuracy:0.7 logloss:0.594285\n",
      "I0000 00:00:1729625126.254926 6797155 random_forest.cc:812] Training of tree  72/200 (tree index:71) done accuracy:0.683333 logloss:0.58675\n",
      "I0000 00:00:1729625126.255019 6797157 random_forest.cc:812] Training of tree  82/200 (tree index:82) done accuracy:0.7 logloss:0.580241\n",
      "I0000 00:00:1729625126.255111 6797152 random_forest.cc:812] Training of tree  92/200 (tree index:92) done accuracy:0.691667 logloss:0.584562\n",
      "I0000 00:00:1729625126.255236 6797159 random_forest.cc:812] Training of tree  102/200 (tree index:91) done accuracy:0.683333 logloss:0.591092\n",
      "I0000 00:00:1729625126.255338 6797154 random_forest.cc:812] Training of tree  112/200 (tree index:111) done accuracy:0.683333 logloss:0.581791\n",
      "I0000 00:00:1729625126.255483 6797159 random_forest.cc:812] Training of tree  122/200 (tree index:122) done accuracy:0.7 logloss:0.571486\n",
      "I0000 00:00:1729625126.255587 6797153 random_forest.cc:812] Training of tree  133/200 (tree index:131) done accuracy:0.725 logloss:0.575432\n",
      "I0000 00:00:1729625126.255734 6797157 random_forest.cc:812] Training of tree  143/200 (tree index:138) done accuracy:0.7 logloss:0.577722\n",
      "I0000 00:00:1729625126.255854 6797157 random_forest.cc:812] Training of tree  153/200 (tree index:153) done accuracy:0.716667 logloss:0.579426\n",
      "I0000 00:00:1729625126.255947 6797156 random_forest.cc:812] Training of tree  163/200 (tree index:161) done accuracy:0.725 logloss:0.577031\n",
      "I0000 00:00:1729625126.256081 6797152 random_forest.cc:812] Training of tree  173/200 (tree index:173) done accuracy:0.716667 logloss:0.57489\n",
      "I0000 00:00:1729625126.256181 6797156 random_forest.cc:812] Training of tree  184/200 (tree index:184) done accuracy:0.716667 logloss:0.572292\n",
      "I0000 00:00:1729625126.256300 6797156 random_forest.cc:812] Training of tree  194/200 (tree index:190) done accuracy:0.725 logloss:0.570959\n",
      "I0000 00:00:1729625126.256386 6797159 random_forest.cc:812] Training of tree  200/200 (tree index:197) done accuracy:0.716667 logloss:0.573964\n",
      "I0000 00:00:1729625126.256415 6797143 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.573964\n",
      "I0000 00:00:1729625126.256581 6797143 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps88o0e1c with prefix 223680ac56cb4ee5\n",
      "I0000 00:00:1729625126.257738 6797143 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625126.258482 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.573964\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:26.264241: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps88o0e1c/model/ with prefix 223680ac56cb4ee5\n",
      "I0000 00:00:1729625126.266047 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1304 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:26.266061: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144104. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014600\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3nkhxaph as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625126.545972 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625126.545982 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625126.545986 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625126.546048 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625126.546052 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625126.546096 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.546108 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.546114 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.546119 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.546146 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625126.546191 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625126.546325 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625126.546350 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpa_6_pujk/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625126.546425 6797211 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625126.546528 6797211 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625126.547057 6797220 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.433962 logloss:20.4021\n",
      "I0000 00:00:1729625126.547207 6797227 random_forest.cc:812] Training of tree  11/200 (tree index:9) done accuracy:0.644068 logloss:5.85658\n",
      "I0000 00:00:1729625126.547343 6797221 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.708333 logloss:1.74088\n",
      "I0000 00:00:1729625126.547565 6797224 random_forest.cc:812] Training of tree  31/200 (tree index:32) done accuracy:0.733333 logloss:0.893059\n",
      "I0000 00:00:1729625126.547751 6797223 random_forest.cc:812] Training of tree  41/200 (tree index:43) done accuracy:0.741667 logloss:0.890696\n",
      "I0000 00:00:1729625126.547897 6797221 random_forest.cc:812] Training of tree  51/200 (tree index:42) done accuracy:0.691667 logloss:0.617818\n",
      "I0000 00:00:1729625126.548013 6797222 random_forest.cc:812] Training of tree  62/200 (tree index:61) done accuracy:0.708333 logloss:0.608516\n",
      "I0000 00:00:1729625126.548137 6797222 random_forest.cc:812] Training of tree  72/200 (tree index:67) done accuracy:0.708333 logloss:0.607823\n",
      "I0000 00:00:1729625126.548287 6797224 random_forest.cc:812] Training of tree  82/200 (tree index:81) done accuracy:0.7 logloss:0.607048\n",
      "I0000 00:00:1729625126.548495 6797226 random_forest.cc:812] Training of tree  92/200 (tree index:92) done accuracy:0.716667 logloss:0.610879\n",
      "I0000 00:00:1729625126.548601 6797221 random_forest.cc:812] Training of tree  102/200 (tree index:100) done accuracy:0.733333 logloss:0.611607\n",
      "I0000 00:00:1729625126.548735 6797223 random_forest.cc:812] Training of tree  112/200 (tree index:113) done accuracy:0.733333 logloss:0.60463\n",
      "I0000 00:00:1729625126.548886 6797226 random_forest.cc:812] Training of tree  124/200 (tree index:124) done accuracy:0.733333 logloss:0.607286\n",
      "I0000 00:00:1729625126.549070 6797227 random_forest.cc:812] Training of tree  135/200 (tree index:135) done accuracy:0.708333 logloss:0.606684\n",
      "I0000 00:00:1729625126.549249 6797227 random_forest.cc:812] Training of tree  146/200 (tree index:145) done accuracy:0.733333 logloss:0.605942\n",
      "I0000 00:00:1729625126.549401 6797222 random_forest.cc:812] Training of tree  158/200 (tree index:157) done accuracy:0.758333 logloss:0.60702\n",
      "I0000 00:00:1729625126.549535 6797223 random_forest.cc:812] Training of tree  168/200 (tree index:166) done accuracy:0.725 logloss:0.604693\n",
      "I0000 00:00:1729625126.549643 6797223 random_forest.cc:812] Training of tree  178/200 (tree index:175) done accuracy:0.741667 logloss:0.600439\n",
      "I0000 00:00:1729625126.549796 6797220 random_forest.cc:812] Training of tree  191/200 (tree index:191) done accuracy:0.75 logloss:0.600607\n",
      "I0000 00:00:1729625126.549953 6797224 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.75 logloss:0.601305\n",
      "I0000 00:00:1729625126.550082 6797211 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.601305\n",
      "I0000 00:00:1729625126.550246 6797211 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpa_6_pujk with prefix e713f6a5c4e447f1\n",
      "I0000 00:00:1729625126.551636 6797211 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625126.552214 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.601305\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  34  19\n",
      "2  11  56\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:26.557089: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpa_6_pujk/model/ with prefix e713f6a5c4e447f1\n",
      "I0000 00:00:1729625126.558972 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1298 node(s), and 18 input feature(s).\n",
      "2024-10-22 20:25:26.558991: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.169010. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016447\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdmynwewa as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625126.862485 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625126.862496 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625126.862500 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625126.862561 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625126.862566 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625126.862608 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.862620 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.862626 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.862630 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625126.862657 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625126.862674 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625126.862806 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625126.862827 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3nkhxaph/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625126.862928 6797287 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625126.863111 6797287 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625126.863739 6797303 random_forest.cc:812] Training of tree  1/200 (tree index:3) done accuracy:0.45283 logloss:19.722\n",
      "I0000 00:00:1729625126.863916 6797300 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.618644 logloss:5.30382\n",
      "I0000 00:00:1729625126.864102 6797302 random_forest.cc:812] Training of tree  22/200 (tree index:19) done accuracy:0.625 logloss:1.18987\n",
      "I0000 00:00:1729625126.864314 6797296 random_forest.cc:812] Training of tree  32/200 (tree index:30) done accuracy:0.708333 logloss:0.598858\n",
      "I0000 00:00:1729625126.864613 6797301 random_forest.cc:812] Training of tree  43/200 (tree index:43) done accuracy:0.7 logloss:0.602411\n",
      "I0000 00:00:1729625126.864867 6797296 random_forest.cc:812] Training of tree  53/200 (tree index:53) done accuracy:0.675 logloss:0.618043\n",
      "I0000 00:00:1729625126.865004 6797296 random_forest.cc:812] Training of tree  64/200 (tree index:63) done accuracy:0.716667 logloss:0.598594\n",
      "I0000 00:00:1729625126.865282 6797298 random_forest.cc:812] Training of tree  75/200 (tree index:75) done accuracy:0.708333 logloss:0.602609\n",
      "I0000 00:00:1729625126.865451 6797302 random_forest.cc:812] Training of tree  85/200 (tree index:84) done accuracy:0.716667 logloss:0.605162\n",
      "I0000 00:00:1729625126.865660 6797298 random_forest.cc:812] Training of tree  96/200 (tree index:95) done accuracy:0.7 logloss:0.613467\n",
      "I0000 00:00:1729625126.865889 6797300 random_forest.cc:812] Training of tree  107/200 (tree index:103) done accuracy:0.708333 logloss:0.608663\n",
      "I0000 00:00:1729625126.866019 6797299 random_forest.cc:812] Training of tree  117/200 (tree index:117) done accuracy:0.7 logloss:0.611064\n",
      "I0000 00:00:1729625126.866157 6797301 random_forest.cc:812] Training of tree  127/200 (tree index:126) done accuracy:0.708333 logloss:0.613978\n",
      "I0000 00:00:1729625126.866319 6797296 random_forest.cc:812] Training of tree  137/200 (tree index:129) done accuracy:0.716667 logloss:0.61146\n",
      "I0000 00:00:1729625126.866467 6797301 random_forest.cc:812] Training of tree  147/200 (tree index:148) done accuracy:0.708333 logloss:0.614016\n",
      "I0000 00:00:1729625126.866641 6797303 random_forest.cc:812] Training of tree  158/200 (tree index:157) done accuracy:0.716667 logloss:0.607795\n",
      "I0000 00:00:1729625126.866781 6797301 random_forest.cc:812] Training of tree  168/200 (tree index:169) done accuracy:0.691667 logloss:0.609631\n",
      "I0000 00:00:1729625126.866924 6797303 random_forest.cc:812] Training of tree  180/200 (tree index:180) done accuracy:0.683333 logloss:0.61339\n",
      "I0000 00:00:1729625126.867078 6797303 random_forest.cc:812] Training of tree  190/200 (tree index:191) done accuracy:0.691667 logloss:0.612246\n",
      "I0000 00:00:1729625126.867207 6797301 random_forest.cc:812] Training of tree  200/200 (tree index:193) done accuracy:0.675 logloss:0.61671\n",
      "I0000 00:00:1729625126.867277 6797287 random_forest.cc:892] Final OOB metrics: accuracy:0.675 logloss:0.61671\n",
      "I0000 00:00:1729625126.867503 6797287 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3nkhxaph with prefix b2d9df5fb4974d23\n",
      "I0000 00:00:1729625126.869220 6797287 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625126.869999 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.675  CI95[W][0.597764 0.745608]\n",
      "LogLoss: : 0.61671\n",
      "ErrorRate: : 0.325\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  29  25\n",
      "2  14  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:26.875483: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3nkhxaph/model/ with prefix b2d9df5fb4974d23\n",
      "I0000 00:00:1729625126.877238 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1280 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:26.877256: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.148212. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014215\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfo7lsgzl as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625127.168508 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625127.168520 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625127.168525 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625127.168596 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625127.168600 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625127.168644 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.168654 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.168688 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.168715 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.168760 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625127.168793 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625127.168930 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625127.168955 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdmynwewa/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625127.169030 6797355 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625127.169124 6797355 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625127.169690 6797368 random_forest.cc:812] Training of tree  1/200 (tree index:1) done accuracy:0.574468 logloss:15.3377\n",
      "I0000 00:00:1729625127.169885 6797369 random_forest.cc:812] Training of tree  11/200 (tree index:13) done accuracy:0.655462 logloss:2.90602\n",
      "I0000 00:00:1729625127.170014 6797369 random_forest.cc:812] Training of tree  21/200 (tree index:22) done accuracy:0.708333 logloss:1.71799\n",
      "I0000 00:00:1729625127.170156 6797371 random_forest.cc:812] Training of tree  32/200 (tree index:31) done accuracy:0.725 logloss:1.1401\n",
      "I0000 00:00:1729625127.170301 6797364 random_forest.cc:812] Training of tree  42/200 (tree index:39) done accuracy:0.733333 logloss:0.586388\n",
      "I0000 00:00:1729625127.170457 6797370 random_forest.cc:812] Training of tree  52/200 (tree index:51) done accuracy:0.741667 logloss:0.573888\n",
      "I0000 00:00:1729625127.170588 6797369 random_forest.cc:812] Training of tree  62/200 (tree index:61) done accuracy:0.725 logloss:0.569449\n",
      "I0000 00:00:1729625127.170718 6797368 random_forest.cc:812] Training of tree  72/200 (tree index:71) done accuracy:0.725 logloss:0.576795\n",
      "I0000 00:00:1729625127.170832 6797368 random_forest.cc:812] Training of tree  83/200 (tree index:82) done accuracy:0.716667 logloss:0.56368\n",
      "I0000 00:00:1729625127.171019 6797370 random_forest.cc:812] Training of tree  93/200 (tree index:93) done accuracy:0.741667 logloss:0.559248\n",
      "I0000 00:00:1729625127.171225 6797367 random_forest.cc:812] Training of tree  103/200 (tree index:102) done accuracy:0.733333 logloss:0.554957\n",
      "I0000 00:00:1729625127.171395 6797367 random_forest.cc:812] Training of tree  113/200 (tree index:116) done accuracy:0.741667 logloss:0.555644\n",
      "I0000 00:00:1729625127.171502 6797371 random_forest.cc:812] Training of tree  123/200 (tree index:124) done accuracy:0.741667 logloss:0.562423\n",
      "I0000 00:00:1729625127.171639 6797370 random_forest.cc:812] Training of tree  134/200 (tree index:134) done accuracy:0.733333 logloss:0.550919\n",
      "I0000 00:00:1729625127.171789 6797366 random_forest.cc:812] Training of tree  145/200 (tree index:144) done accuracy:0.741667 logloss:0.546605\n",
      "I0000 00:00:1729625127.171911 6797366 random_forest.cc:812] Training of tree  155/200 (tree index:155) done accuracy:0.75 logloss:0.543627\n",
      "I0000 00:00:1729625127.172043 6797371 random_forest.cc:812] Training of tree  165/200 (tree index:159) done accuracy:0.75 logloss:0.548423\n",
      "I0000 00:00:1729625127.172165 6797369 random_forest.cc:812] Training of tree  175/200 (tree index:174) done accuracy:0.733333 logloss:0.54767\n",
      "I0000 00:00:1729625127.172288 6797367 random_forest.cc:812] Training of tree  185/200 (tree index:185) done accuracy:0.733333 logloss:0.546663\n",
      "I0000 00:00:1729625127.172430 6797371 random_forest.cc:812] Training of tree  195/200 (tree index:189) done accuracy:0.741667 logloss:0.544661\n",
      "I0000 00:00:1729625127.172452 6797365 random_forest.cc:812] Training of tree  200/200 (tree index:195) done accuracy:0.741667 logloss:0.544295\n",
      "I0000 00:00:1729625127.172593 6797355 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.544295\n",
      "I0000 00:00:1729625127.172769 6797355 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdmynwewa with prefix 5f753e5f9e56483a\n",
      "I0000 00:00:1729625127.174082 6797355 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625127.174782 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.544295\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  19\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:27.179236: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdmynwewa/model/ with prefix 5f753e5f9e56483a\n",
      "I0000 00:00:1729625127.181062 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1306 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:27.181078: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.140690. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.014517\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 20, 'min_examples': 5, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfil5k41a as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625127.455553 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625127.455563 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625127.455567 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625127.455631 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625127.455637 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625127.455681 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.455691 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.455697 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.455703 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.455757 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625127.455782 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625127.455919 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625127.455950 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfo7lsgzl/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625127.456037 6797425 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625127.456230 6797425 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625127.456794 6797435 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625127.456923 6797441 random_forest.cc:812] Training of tree  11/200 (tree index:10) done accuracy:0.694915 logloss:3.45695\n",
      "I0000 00:00:1729625127.457098 6797437 random_forest.cc:812] Training of tree  21/200 (tree index:23) done accuracy:0.741667 logloss:1.71116\n",
      "I0000 00:00:1729625127.457294 6797435 random_forest.cc:812] Training of tree  31/200 (tree index:30) done accuracy:0.733333 logloss:1.13831\n",
      "I0000 00:00:1729625127.457384 6797436 random_forest.cc:812] Training of tree  41/200 (tree index:40) done accuracy:0.708333 logloss:0.862847\n",
      "I0000 00:00:1729625127.457550 6797440 random_forest.cc:812] Training of tree  52/200 (tree index:52) done accuracy:0.675 logloss:0.870144\n",
      "I0000 00:00:1729625127.457691 6797437 random_forest.cc:812] Training of tree  62/200 (tree index:63) done accuracy:0.683333 logloss:0.591143\n",
      "I0000 00:00:1729625127.457804 6797439 random_forest.cc:812] Training of tree  72/200 (tree index:72) done accuracy:0.725 logloss:0.585212\n",
      "I0000 00:00:1729625127.457973 6797439 random_forest.cc:812] Training of tree  82/200 (tree index:82) done accuracy:0.708333 logloss:0.582164\n",
      "I0000 00:00:1729625127.458231 6797438 random_forest.cc:812] Training of tree  92/200 (tree index:91) done accuracy:0.725 logloss:0.577291\n",
      "I0000 00:00:1729625127.458408 6797437 random_forest.cc:812] Training of tree  102/200 (tree index:101) done accuracy:0.7 logloss:0.584214\n",
      "I0000 00:00:1729625127.458542 6797441 random_forest.cc:812] Training of tree  112/200 (tree index:113) done accuracy:0.75 logloss:0.5798\n",
      "I0000 00:00:1729625127.458640 6797435 random_forest.cc:812] Training of tree  123/200 (tree index:122) done accuracy:0.716667 logloss:0.577116\n",
      "I0000 00:00:1729625127.458789 6797439 random_forest.cc:812] Training of tree  133/200 (tree index:130) done accuracy:0.708333 logloss:0.575294\n",
      "I0000 00:00:1729625127.458921 6797441 random_forest.cc:812] Training of tree  143/200 (tree index:141) done accuracy:0.708333 logloss:0.573054\n",
      "I0000 00:00:1729625127.459037 6797436 random_forest.cc:812] Training of tree  153/200 (tree index:153) done accuracy:0.733333 logloss:0.575592\n",
      "I0000 00:00:1729625127.459148 6797441 random_forest.cc:812] Training of tree  163/200 (tree index:163) done accuracy:0.725 logloss:0.578337\n",
      "I0000 00:00:1729625127.459247 6797435 random_forest.cc:812] Training of tree  173/200 (tree index:173) done accuracy:0.708333 logloss:0.575887\n",
      "I0000 00:00:1729625127.459358 6797440 random_forest.cc:812] Training of tree  184/200 (tree index:184) done accuracy:0.708333 logloss:0.582071\n",
      "I0000 00:00:1729625127.459531 6797435 random_forest.cc:812] Training of tree  194/200 (tree index:193) done accuracy:0.708333 logloss:0.575056\n",
      "I0000 00:00:1729625127.459640 6797440 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.708333 logloss:0.575424\n",
      "I0000 00:00:1729625127.459707 6797425 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.575424\n",
      "I0000 00:00:1729625127.459866 6797425 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfo7lsgzl with prefix 1e1199fb2fac4f2a\n",
      "I0000 00:00:1729625127.461229 6797425 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625127.461809 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.575424\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  19\n",
      "2  16  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:27.466797: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfo7lsgzl/model/ with prefix 1e1199fb2fac4f2a\n",
      "I0000 00:00:1729625127.468585 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 1278 node(s), and 19 input feature(s).\n",
      "I0000 00:00:1729625127.468599 6784195 abstract_model.cc:1323] Engine \"RandomForestOptPred\" built\n",
      "2024-10-22 20:25:27.468604: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.186985. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.028305\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpj1qa37tn as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625127.788162 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625127.788176 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625127.788181 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625127.788248 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625127.788254 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625127.788299 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.788308 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.788314 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.788319 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625127.788347 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625127.788365 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625127.788494 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625127.788520 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfil5k41a/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625127.788579 6797494 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625127.788678 6797494 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625127.789258 6797504 random_forest.cc:812] Training of tree  1/300 (tree index:5) done accuracy:0.568182 logloss:15.5643\n",
      "I0000 00:00:1729625127.789430 6797503 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.731092 logloss:3.41992\n",
      "I0000 00:00:1729625127.789664 6797507 random_forest.cc:812] Training of tree  21/300 (tree index:14) done accuracy:0.725 logloss:1.13193\n",
      "I0000 00:00:1729625127.789846 6797503 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.683333 logloss:1.16517\n",
      "I0000 00:00:1729625127.790060 6797508 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.741667 logloss:0.847442\n",
      "I0000 00:00:1729625127.790262 6797508 random_forest.cc:812] Training of tree  51/300 (tree index:53) done accuracy:0.733333 logloss:0.543026\n",
      "I0000 00:00:1729625127.790466 6797507 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.766667 logloss:0.530349\n",
      "I0000 00:00:1729625127.790627 6797503 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.75 logloss:0.523379\n",
      "I0000 00:00:1729625127.790814 6797504 random_forest.cc:812] Training of tree  81/300 (tree index:81) done accuracy:0.741667 logloss:0.524534\n",
      "I0000 00:00:1729625127.790998 6797507 random_forest.cc:812] Training of tree  91/300 (tree index:91) done accuracy:0.75 logloss:0.522916\n",
      "I0000 00:00:1729625127.791162 6797506 random_forest.cc:812] Training of tree  101/300 (tree index:102) done accuracy:0.758333 logloss:0.525901\n",
      "I0000 00:00:1729625127.791325 6797507 random_forest.cc:812] Training of tree  112/300 (tree index:111) done accuracy:0.733333 logloss:0.532159\n",
      "I0000 00:00:1729625127.791558 6797510 random_forest.cc:812] Training of tree  122/300 (tree index:123) done accuracy:0.75 logloss:0.520497\n",
      "I0000 00:00:1729625127.791740 6797503 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.75 logloss:0.524163\n",
      "I0000 00:00:1729625127.791912 6797506 random_forest.cc:812] Training of tree  142/300 (tree index:142) done accuracy:0.75 logloss:0.531537\n",
      "I0000 00:00:1729625127.792074 6797505 random_forest.cc:812] Training of tree  152/300 (tree index:152) done accuracy:0.716667 logloss:0.539032\n",
      "I0000 00:00:1729625127.792209 6797504 random_forest.cc:812] Training of tree  162/300 (tree index:163) done accuracy:0.733333 logloss:0.534169\n",
      "I0000 00:00:1729625127.792398 6797508 random_forest.cc:812] Training of tree  172/300 (tree index:172) done accuracy:0.741667 logloss:0.533506\n",
      "I0000 00:00:1729625127.792610 6797507 random_forest.cc:812] Training of tree  182/300 (tree index:181) done accuracy:0.733333 logloss:0.525007\n",
      "I0000 00:00:1729625127.792818 6797506 random_forest.cc:812] Training of tree  192/300 (tree index:191) done accuracy:0.741667 logloss:0.522633\n",
      "I0000 00:00:1729625127.792993 6797510 random_forest.cc:812] Training of tree  202/300 (tree index:203) done accuracy:0.75 logloss:0.517876\n",
      "I0000 00:00:1729625127.793124 6797506 random_forest.cc:812] Training of tree  212/300 (tree index:212) done accuracy:0.741667 logloss:0.521971\n",
      "I0000 00:00:1729625127.793304 6797510 random_forest.cc:812] Training of tree  222/300 (tree index:222) done accuracy:0.716667 logloss:0.526479\n",
      "I0000 00:00:1729625127.793460 6797503 random_forest.cc:812] Training of tree  232/300 (tree index:232) done accuracy:0.708333 logloss:0.530534\n",
      "I0000 00:00:1729625127.793610 6797506 random_forest.cc:812] Training of tree  242/300 (tree index:242) done accuracy:0.708333 logloss:0.530519\n",
      "I0000 00:00:1729625127.793813 6797508 random_forest.cc:812] Training of tree  252/300 (tree index:231) done accuracy:0.716667 logloss:0.529006\n",
      "I0000 00:00:1729625127.793999 6797507 random_forest.cc:812] Training of tree  263/300 (tree index:263) done accuracy:0.7 logloss:0.527253\n",
      "I0000 00:00:1729625127.794174 6797510 random_forest.cc:812] Training of tree  273/300 (tree index:271) done accuracy:0.7 logloss:0.527399\n",
      "I0000 00:00:1729625127.794360 6797506 random_forest.cc:812] Training of tree  283/300 (tree index:286) done accuracy:0.708333 logloss:0.526026\n",
      "I0000 00:00:1729625127.794557 6797503 random_forest.cc:812] Training of tree  293/300 (tree index:283) done accuracy:0.691667 logloss:0.524399\n",
      "I0000 00:00:1729625127.794716 6797503 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.708333 logloss:0.52502\n",
      "I0000 00:00:1729625127.794821 6797494 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.52502\n",
      "I0000 00:00:1729625127.795523 6797494 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfil5k41a with prefix b11af07ccb2a47f2\n",
      "I0000 00:00:1729625127.798735 6797494 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625127.799350 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.52502\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  44  14\n",
      "2  21  41\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:27.805437: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfil5k41a/model/ with prefix b11af07ccb2a47f2\n",
      "I0000 00:00:1729625127.813782 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6548 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:27.813807: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.140940. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.029771\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqb7_0yiw as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625128.088201 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625128.088210 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625128.088222 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625128.088284 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625128.088289 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625128.088333 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.088343 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.088348 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.088353 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.088383 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625128.088400 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625128.088536 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625128.088563 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpj1qa37tn/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625128.088621 6797562 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625128.088704 6797562 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625128.089321 6797578 random_forest.cc:812] Training of tree  1/300 (tree index:4) done accuracy:0.729167 logloss:9.76182\n",
      "I0000 00:00:1729625128.089523 6797575 random_forest.cc:812] Training of tree  11/300 (tree index:1) done accuracy:0.672269 logloss:4.03093\n",
      "I0000 00:00:1729625128.089713 6797572 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.7 logloss:0.823294\n",
      "I0000 00:00:1729625128.089866 6797573 random_forest.cc:812] Training of tree  31/300 (tree index:32) done accuracy:0.741667 logloss:0.788612\n",
      "I0000 00:00:1729625128.090097 6797577 random_forest.cc:812] Training of tree  41/300 (tree index:23) done accuracy:0.733333 logloss:0.801315\n",
      "I0000 00:00:1729625128.090260 6797573 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.741667 logloss:0.520791\n",
      "I0000 00:00:1729625128.090445 6797576 random_forest.cc:812] Training of tree  62/300 (tree index:60) done accuracy:0.741667 logloss:0.516156\n",
      "I0000 00:00:1729625128.090673 6797571 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.741667 logloss:0.514921\n",
      "I0000 00:00:1729625128.090876 6797578 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.741667 logloss:0.504447\n",
      "I0000 00:00:1729625128.091023 6797576 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.766667 logloss:0.491436\n",
      "I0000 00:00:1729625128.091215 6797578 random_forest.cc:812] Training of tree  102/300 (tree index:102) done accuracy:0.766667 logloss:0.49143\n",
      "I0000 00:00:1729625128.091393 6797574 random_forest.cc:812] Training of tree  112/300 (tree index:113) done accuracy:0.766667 logloss:0.500042\n",
      "I0000 00:00:1729625128.091595 6797576 random_forest.cc:812] Training of tree  122/300 (tree index:121) done accuracy:0.783333 logloss:0.490805\n",
      "I0000 00:00:1729625128.091799 6797571 random_forest.cc:812] Training of tree  133/300 (tree index:133) done accuracy:0.783333 logloss:0.491167\n",
      "I0000 00:00:1729625128.091989 6797572 random_forest.cc:812] Training of tree  143/300 (tree index:141) done accuracy:0.775 logloss:0.492891\n",
      "I0000 00:00:1729625128.092143 6797571 random_forest.cc:812] Training of tree  153/300 (tree index:152) done accuracy:0.766667 logloss:0.493984\n",
      "I0000 00:00:1729625128.092324 6797574 random_forest.cc:812] Training of tree  163/300 (tree index:163) done accuracy:0.766667 logloss:0.495176\n",
      "I0000 00:00:1729625128.092479 6797572 random_forest.cc:812] Training of tree  173/300 (tree index:174) done accuracy:0.766667 logloss:0.492395\n",
      "I0000 00:00:1729625128.092675 6797577 random_forest.cc:812] Training of tree  183/300 (tree index:173) done accuracy:0.758333 logloss:0.494201\n",
      "I0000 00:00:1729625128.092869 6797576 random_forest.cc:812] Training of tree  193/300 (tree index:193) done accuracy:0.766667 logloss:0.499905\n",
      "I0000 00:00:1729625128.093045 6797573 random_forest.cc:812] Training of tree  203/300 (tree index:205) done accuracy:0.766667 logloss:0.494841\n",
      "I0000 00:00:1729625128.093192 6797574 random_forest.cc:812] Training of tree  213/300 (tree index:208) done accuracy:0.766667 logloss:0.498496\n",
      "I0000 00:00:1729625128.093396 6797578 random_forest.cc:812] Training of tree  223/300 (tree index:223) done accuracy:0.758333 logloss:0.502274\n",
      "I0000 00:00:1729625128.093576 6797577 random_forest.cc:812] Training of tree  233/300 (tree index:220) done accuracy:0.758333 logloss:0.498741\n",
      "I0000 00:00:1729625128.093746 6797575 random_forest.cc:812] Training of tree  243/300 (tree index:243) done accuracy:0.75 logloss:0.498098\n",
      "I0000 00:00:1729625128.093916 6797578 random_forest.cc:812] Training of tree  254/300 (tree index:253) done accuracy:0.75 logloss:0.499676\n",
      "I0000 00:00:1729625128.094144 6797574 random_forest.cc:812] Training of tree  264/300 (tree index:266) done accuracy:0.758333 logloss:0.499659\n",
      "I0000 00:00:1729625128.094320 6797576 random_forest.cc:812] Training of tree  274/300 (tree index:275) done accuracy:0.766667 logloss:0.497996\n",
      "I0000 00:00:1729625128.094515 6797571 random_forest.cc:812] Training of tree  285/300 (tree index:284) done accuracy:0.775 logloss:0.498521\n",
      "I0000 00:00:1729625128.094771 6797571 random_forest.cc:812] Training of tree  297/300 (tree index:298) done accuracy:0.783333 logloss:0.497752\n",
      "I0000 00:00:1729625128.094796 6797574 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.783333 logloss:0.497367\n",
      "I0000 00:00:1729625128.094877 6797562 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.497367\n",
      "I0000 00:00:1729625128.095555 6797562 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpj1qa37tn with prefix 996081cafa2041c1\n",
      "I0000 00:00:1729625128.098693 6797562 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625128.099394 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.497367\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:28.106759: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpj1qa37tn/model/ with prefix 996081cafa2041c1\n",
      "I0000 00:00:1729625128.115373 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6732 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:28.115401: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144487. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.030332\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpexh9cy8d as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625128.390784 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625128.390795 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625128.390799 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625128.390862 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625128.390868 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625128.390912 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.390924 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.390929 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.390934 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.390961 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625128.390996 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625128.391153 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625128.391181 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqb7_0yiw/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625128.391237 6797643 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625128.391340 6797643 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625128.391940 6797659 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.590909 logloss:14.7451\n",
      "I0000 00:00:1729625128.392102 6797657 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.694915 logloss:3.12149\n",
      "I0000 00:00:1729625128.392333 6797652 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.7 logloss:1.1437\n",
      "I0000 00:00:1729625128.392507 6797657 random_forest.cc:812] Training of tree  31/300 (tree index:28) done accuracy:0.666667 logloss:0.584431\n",
      "I0000 00:00:1729625128.392688 6797653 random_forest.cc:812] Training of tree  41/300 (tree index:42) done accuracy:0.733333 logloss:0.566887\n",
      "I0000 00:00:1729625128.392869 6797652 random_forest.cc:812] Training of tree  51/300 (tree index:34) done accuracy:0.716667 logloss:0.553276\n",
      "I0000 00:00:1729625128.393046 6797654 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.758333 logloss:0.544113\n",
      "I0000 00:00:1729625128.393274 6797653 random_forest.cc:812] Training of tree  71/300 (tree index:71) done accuracy:0.733333 logloss:0.545191\n",
      "I0000 00:00:1729625128.393488 6797654 random_forest.cc:812] Training of tree  81/300 (tree index:84) done accuracy:0.741667 logloss:0.545526\n",
      "I0000 00:00:1729625128.393625 6797655 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.733333 logloss:0.539126\n",
      "I0000 00:00:1729625128.393868 6797658 random_forest.cc:812] Training of tree  101/300 (tree index:92) done accuracy:0.725 logloss:0.53699\n",
      "I0000 00:00:1729625128.394025 6797656 random_forest.cc:812] Training of tree  111/300 (tree index:111) done accuracy:0.725 logloss:0.536312\n",
      "I0000 00:00:1729625128.394213 6797658 random_forest.cc:812] Training of tree  122/300 (tree index:121) done accuracy:0.725 logloss:0.54441\n",
      "I0000 00:00:1729625128.394422 6797653 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.725 logloss:0.543786\n",
      "I0000 00:00:1729625128.394618 6797655 random_forest.cc:812] Training of tree  142/300 (tree index:144) done accuracy:0.716667 logloss:0.54042\n",
      "I0000 00:00:1729625128.394805 6797652 random_forest.cc:812] Training of tree  152/300 (tree index:155) done accuracy:0.725 logloss:0.543208\n",
      "I0000 00:00:1729625128.394982 6797659 random_forest.cc:812] Training of tree  162/300 (tree index:163) done accuracy:0.733333 logloss:0.543378\n",
      "I0000 00:00:1729625128.395123 6797652 random_forest.cc:812] Training of tree  172/300 (tree index:170) done accuracy:0.733333 logloss:0.540729\n",
      "I0000 00:00:1729625128.395274 6797658 random_forest.cc:812] Training of tree  182/300 (tree index:182) done accuracy:0.733333 logloss:0.539176\n",
      "I0000 00:00:1729625128.395525 6797654 random_forest.cc:812] Training of tree  192/300 (tree index:191) done accuracy:0.741667 logloss:0.541733\n",
      "I0000 00:00:1729625128.395719 6797653 random_forest.cc:812] Training of tree  202/300 (tree index:201) done accuracy:0.725 logloss:0.5442\n",
      "I0000 00:00:1729625128.395878 6797655 random_forest.cc:812] Training of tree  212/300 (tree index:214) done accuracy:0.733333 logloss:0.542268\n",
      "I0000 00:00:1729625128.396078 6797652 random_forest.cc:812] Training of tree  222/300 (tree index:224) done accuracy:0.741667 logloss:0.539371\n",
      "I0000 00:00:1729625128.396236 6797656 random_forest.cc:812] Training of tree  232/300 (tree index:233) done accuracy:0.733333 logloss:0.539694\n",
      "I0000 00:00:1729625128.396420 6797655 random_forest.cc:812] Training of tree  242/300 (tree index:243) done accuracy:0.733333 logloss:0.542154\n",
      "I0000 00:00:1729625128.396609 6797659 random_forest.cc:812] Training of tree  252/300 (tree index:251) done accuracy:0.725 logloss:0.540426\n",
      "I0000 00:00:1729625128.396769 6797653 random_forest.cc:812] Training of tree  262/300 (tree index:264) done accuracy:0.716667 logloss:0.539275\n",
      "I0000 00:00:1729625128.396942 6797654 random_forest.cc:812] Training of tree  272/300 (tree index:273) done accuracy:0.733333 logloss:0.535667\n",
      "I0000 00:00:1729625128.397171 6797652 random_forest.cc:812] Training of tree  282/300 (tree index:277) done accuracy:0.741667 logloss:0.532736\n",
      "I0000 00:00:1729625128.397333 6797655 random_forest.cc:812] Training of tree  292/300 (tree index:291) done accuracy:0.741667 logloss:0.529492\n",
      "I0000 00:00:1729625128.397457 6797657 random_forest.cc:812] Training of tree  300/300 (tree index:293) done accuracy:0.741667 logloss:0.530101\n",
      "I0000 00:00:1729625128.397485 6797643 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.530101\n",
      "I0000 00:00:1729625128.398330 6797643 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqb7_0yiw with prefix 198ec0a050814989\n",
      "I0000 00:00:1729625128.402044 6797643 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625128.402716 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.530101\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  14  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:28.409644: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqb7_0yiw/model/ with prefix 198ec0a050814989\n",
      "I0000 00:00:1729625128.418562 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6878 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:28.418580: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143660. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.028282\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpenuxpl5j as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625128.695753 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625128.695766 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625128.695770 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625128.695834 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625128.695839 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625128.695884 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.695893 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.695899 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.695903 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625128.695931 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625128.695948 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625128.696097 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625128.696123 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpexh9cy8d/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625128.696176 6797711 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625128.696289 6797711 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625128.696889 6797720 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.756098 logloss:8.79113\n",
      "I0000 00:00:1729625128.697059 6797720 random_forest.cc:812] Training of tree  11/300 (tree index:8) done accuracy:0.747899 logloss:2.17768\n",
      "I0000 00:00:1729625128.697256 6797723 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.8 logloss:0.706617\n",
      "I0000 00:00:1729625128.697482 6797724 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.808333 logloss:0.427189\n",
      "I0000 00:00:1729625128.697700 6797727 random_forest.cc:812] Training of tree  41/300 (tree index:32) done accuracy:0.8 logloss:0.440838\n",
      "I0000 00:00:1729625128.697842 6797720 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.808333 logloss:0.439944\n",
      "I0000 00:00:1729625128.698065 6797722 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.791667 logloss:0.441948\n",
      "I0000 00:00:1729625128.698258 6797720 random_forest.cc:812] Training of tree  71/300 (tree index:71) done accuracy:0.758333 logloss:0.452511\n",
      "I0000 00:00:1729625128.698457 6797721 random_forest.cc:812] Training of tree  81/300 (tree index:81) done accuracy:0.791667 logloss:0.456226\n",
      "I0000 00:00:1729625128.698642 6797725 random_forest.cc:812] Training of tree  91/300 (tree index:91) done accuracy:0.791667 logloss:0.449815\n",
      "I0000 00:00:1729625128.698844 6797721 random_forest.cc:812] Training of tree  101/300 (tree index:100) done accuracy:0.8 logloss:0.452413\n",
      "I0000 00:00:1729625128.699126 6797725 random_forest.cc:812] Training of tree  113/300 (tree index:113) done accuracy:0.8 logloss:0.45161\n",
      "I0000 00:00:1729625128.699450 6797720 random_forest.cc:812] Training of tree  123/300 (tree index:124) done accuracy:0.808333 logloss:0.452624\n",
      "I0000 00:00:1729625128.699790 6797727 random_forest.cc:812] Training of tree  133/300 (tree index:129) done accuracy:0.8 logloss:0.448035\n",
      "I0000 00:00:1729625128.700057 6797723 random_forest.cc:812] Training of tree  143/300 (tree index:143) done accuracy:0.791667 logloss:0.449144\n",
      "I0000 00:00:1729625128.700393 6797721 random_forest.cc:812] Training of tree  154/300 (tree index:155) done accuracy:0.791667 logloss:0.44525\n",
      "I0000 00:00:1729625128.700597 6797721 random_forest.cc:812] Training of tree  166/300 (tree index:165) done accuracy:0.791667 logloss:0.44696\n",
      "I0000 00:00:1729625128.700834 6797722 random_forest.cc:812] Training of tree  176/300 (tree index:175) done accuracy:0.8 logloss:0.449518\n",
      "I0000 00:00:1729625128.701021 6797722 random_forest.cc:812] Training of tree  186/300 (tree index:187) done accuracy:0.783333 logloss:0.454935\n",
      "I0000 00:00:1729625128.701243 6797724 random_forest.cc:812] Training of tree  196/300 (tree index:194) done accuracy:0.783333 logloss:0.456837\n",
      "I0000 00:00:1729625128.701488 6797722 random_forest.cc:812] Training of tree  209/300 (tree index:206) done accuracy:0.783333 logloss:0.456151\n",
      "I0000 00:00:1729625128.701703 6797725 random_forest.cc:812] Training of tree  219/300 (tree index:222) done accuracy:0.783333 logloss:0.4553\n",
      "I0000 00:00:1729625128.701838 6797726 random_forest.cc:812] Training of tree  229/300 (tree index:229) done accuracy:0.783333 logloss:0.455284\n",
      "I0000 00:00:1729625128.701992 6797720 random_forest.cc:812] Training of tree  239/300 (tree index:239) done accuracy:0.791667 logloss:0.451315\n",
      "I0000 00:00:1729625128.702228 6797721 random_forest.cc:812] Training of tree  249/300 (tree index:240) done accuracy:0.783333 logloss:0.453974\n",
      "I0000 00:00:1729625128.702365 6797722 random_forest.cc:812] Training of tree  259/300 (tree index:258) done accuracy:0.783333 logloss:0.453563\n",
      "I0000 00:00:1729625128.702604 6797721 random_forest.cc:812] Training of tree  269/300 (tree index:270) done accuracy:0.791667 logloss:0.454328\n",
      "I0000 00:00:1729625128.702761 6797723 random_forest.cc:812] Training of tree  279/300 (tree index:278) done accuracy:0.791667 logloss:0.45666\n",
      "I0000 00:00:1729625128.702958 6797722 random_forest.cc:812] Training of tree  289/300 (tree index:291) done accuracy:0.791667 logloss:0.456564\n",
      "I0000 00:00:1729625128.703155 6797720 random_forest.cc:812] Training of tree  299/300 (tree index:299) done accuracy:0.791667 logloss:0.457244\n",
      "I0000 00:00:1729625128.703205 6797724 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.791667 logloss:0.457814\n",
      "I0000 00:00:1729625128.703254 6797711 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.457814\n",
      "I0000 00:00:1729625128.703897 6797711 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpexh9cy8d with prefix a6171aa6bda64639\n",
      "I0000 00:00:1729625128.706731 6797711 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625128.707506 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.457814\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  11  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:28.713547: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpexh9cy8d/model/ with prefix a6171aa6bda64639\n",
      "I0000 00:00:1729625128.721537 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6178 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:28.721557: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147591. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.030311\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 20, 'min_examples': 5, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpkd8m3x51 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625129.009622 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625129.009636 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625129.009639 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625129.009709 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625129.009715 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625129.009758 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.009768 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.009774 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.009779 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.009805 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625129.009824 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625129.009957 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625129.009981 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpenuxpl5j/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625129.010042 6797802 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625129.010147 6797802 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625129.010730 6797817 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.609756 logloss:14.0658\n",
      "I0000 00:00:1729625129.010930 6797813 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.705882 logloss:4.22461\n",
      "I0000 00:00:1729625129.011188 6797812 random_forest.cc:812] Training of tree  21/300 (tree index:11) done accuracy:0.741667 logloss:1.92478\n",
      "I0000 00:00:1729625129.011389 6797818 random_forest.cc:812] Training of tree  31/300 (tree index:32) done accuracy:0.733333 logloss:1.63352\n",
      "I0000 00:00:1729625129.011596 6797818 random_forest.cc:812] Training of tree  42/300 (tree index:43) done accuracy:0.791667 logloss:0.781059\n",
      "I0000 00:00:1729625129.011764 6797811 random_forest.cc:812] Training of tree  52/300 (tree index:47) done accuracy:0.783333 logloss:0.478885\n",
      "I0000 00:00:1729625129.011950 6797813 random_forest.cc:812] Training of tree  62/300 (tree index:63) done accuracy:0.775 logloss:0.485842\n",
      "I0000 00:00:1729625129.012125 6797816 random_forest.cc:812] Training of tree  72/300 (tree index:59) done accuracy:0.783333 logloss:0.483813\n",
      "I0000 00:00:1729625129.012333 6797812 random_forest.cc:812] Training of tree  84/300 (tree index:83) done accuracy:0.775 logloss:0.488272\n",
      "I0000 00:00:1729625129.012504 6797816 random_forest.cc:812] Training of tree  94/300 (tree index:93) done accuracy:0.783333 logloss:0.477661\n",
      "I0000 00:00:1729625129.012682 6797813 random_forest.cc:812] Training of tree  104/300 (tree index:104) done accuracy:0.791667 logloss:0.481761\n",
      "I0000 00:00:1729625129.012885 6797812 random_forest.cc:812] Training of tree  114/300 (tree index:113) done accuracy:0.783333 logloss:0.490356\n",
      "I0000 00:00:1729625129.013114 6797815 random_forest.cc:812] Training of tree  124/300 (tree index:126) done accuracy:0.783333 logloss:0.488987\n",
      "I0000 00:00:1729625129.013387 6797813 random_forest.cc:812] Training of tree  134/300 (tree index:125) done accuracy:0.775 logloss:0.490597\n",
      "I0000 00:00:1729625129.013676 6797816 random_forest.cc:812] Training of tree  144/300 (tree index:141) done accuracy:0.775 logloss:0.496435\n",
      "I0000 00:00:1729625129.013955 6797814 random_forest.cc:812] Training of tree  154/300 (tree index:153) done accuracy:0.775 logloss:0.494954\n",
      "I0000 00:00:1729625129.014268 6797814 random_forest.cc:812] Training of tree  164/300 (tree index:165) done accuracy:0.766667 logloss:0.497289\n",
      "I0000 00:00:1729625129.014535 6797811 random_forest.cc:812] Training of tree  174/300 (tree index:169) done accuracy:0.766667 logloss:0.495557\n",
      "I0000 00:00:1729625129.014755 6797811 random_forest.cc:812] Training of tree  184/300 (tree index:186) done accuracy:0.766667 logloss:0.496688\n",
      "I0000 00:00:1729625129.015064 6797817 random_forest.cc:812] Training of tree  194/300 (tree index:194) done accuracy:0.766667 logloss:0.492939\n",
      "I0000 00:00:1729625129.015316 6797814 random_forest.cc:812] Training of tree  204/300 (tree index:200) done accuracy:0.766667 logloss:0.48776\n",
      "I0000 00:00:1729625129.015534 6797811 random_forest.cc:812] Training of tree  214/300 (tree index:213) done accuracy:0.766667 logloss:0.489705\n",
      "I0000 00:00:1729625129.015757 6797815 random_forest.cc:812] Training of tree  224/300 (tree index:224) done accuracy:0.783333 logloss:0.485488\n",
      "I0000 00:00:1729625129.015970 6797816 random_forest.cc:812] Training of tree  234/300 (tree index:226) done accuracy:0.775 logloss:0.4836\n",
      "I0000 00:00:1729625129.016171 6797818 random_forest.cc:812] Training of tree  244/300 (tree index:243) done accuracy:0.766667 logloss:0.481804\n",
      "I0000 00:00:1729625129.016357 6797811 random_forest.cc:812] Training of tree  254/300 (tree index:255) done accuracy:0.766667 logloss:0.481716\n",
      "I0000 00:00:1729625129.016531 6797814 random_forest.cc:812] Training of tree  264/300 (tree index:264) done accuracy:0.766667 logloss:0.480377\n",
      "I0000 00:00:1729625129.016725 6797815 random_forest.cc:812] Training of tree  274/300 (tree index:275) done accuracy:0.775 logloss:0.479912\n",
      "I0000 00:00:1729625129.016925 6797814 random_forest.cc:812] Training of tree  284/300 (tree index:286) done accuracy:0.766667 logloss:0.479802\n",
      "I0000 00:00:1729625129.017068 6797816 random_forest.cc:812] Training of tree  294/300 (tree index:295) done accuracy:0.783333 logloss:0.476787\n",
      "I0000 00:00:1729625129.017258 6797817 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.783333 logloss:0.475578\n",
      "I0000 00:00:1729625129.017326 6797802 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.475578\n",
      "I0000 00:00:1729625129.018034 6797802 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpenuxpl5j with prefix 5afc8d4d12d949d9\n",
      "I0000 00:00:1729625129.021392 6797802 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625129.022399 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.475578\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  12\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:29.028934: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpenuxpl5j/model/ with prefix 5afc8d4d12d949d9\n",
      "I0000 00:00:1729625129.037289 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6562 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:29.037311: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.142857. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.026076\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbg7znqaj as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625129.316171 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625129.316186 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625129.316190 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625129.316253 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625129.316259 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625129.316301 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.316310 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.316315 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.316321 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.316347 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625129.316364 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625129.316490 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625129.316512 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpkd8m3x51/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625129.316574 6797882 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625129.316668 6797882 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625129.317209 6797892 random_forest.cc:812] Training of tree  1/300 (tree index:4) done accuracy:0.642857 logloss:12.8727\n",
      "I0000 00:00:1729625129.317335 6797891 random_forest.cc:812] Training of tree  12/300 (tree index:10) done accuracy:0.658333 logloss:3.14869\n",
      "I0000 00:00:1729625129.317561 6797892 random_forest.cc:812] Training of tree  22/300 (tree index:17) done accuracy:0.716667 logloss:0.809986\n",
      "I0000 00:00:1729625129.317706 6797896 random_forest.cc:812] Training of tree  32/300 (tree index:31) done accuracy:0.733333 logloss:0.52422\n",
      "I0000 00:00:1729625129.317894 6797892 random_forest.cc:812] Training of tree  42/300 (tree index:43) done accuracy:0.658333 logloss:0.577632\n",
      "I0000 00:00:1729625129.318058 6797893 random_forest.cc:812] Training of tree  53/300 (tree index:52) done accuracy:0.7 logloss:0.560281\n",
      "I0000 00:00:1729625129.318305 6797897 random_forest.cc:812] Training of tree  63/300 (tree index:64) done accuracy:0.708333 logloss:0.537801\n",
      "I0000 00:00:1729625129.318476 6797892 random_forest.cc:812] Training of tree  73/300 (tree index:73) done accuracy:0.683333 logloss:0.544503\n",
      "I0000 00:00:1729625129.318656 6797896 random_forest.cc:812] Training of tree  83/300 (tree index:82) done accuracy:0.725 logloss:0.541205\n",
      "I0000 00:00:1729625129.318774 6797896 random_forest.cc:812] Training of tree  93/300 (tree index:90) done accuracy:0.7 logloss:0.538744\n",
      "I0000 00:00:1729625129.318952 6797892 random_forest.cc:812] Training of tree  103/300 (tree index:103) done accuracy:0.733333 logloss:0.537106\n",
      "I0000 00:00:1729625129.319111 6797897 random_forest.cc:812] Training of tree  115/300 (tree index:112) done accuracy:0.725 logloss:0.539459\n",
      "I0000 00:00:1729625129.319312 6797898 random_forest.cc:812] Training of tree  125/300 (tree index:124) done accuracy:0.733333 logloss:0.534994\n",
      "I0000 00:00:1729625129.319549 6797895 random_forest.cc:812] Training of tree  135/300 (tree index:134) done accuracy:0.741667 logloss:0.529891\n",
      "I0000 00:00:1729625129.319687 6797896 random_forest.cc:812] Training of tree  145/300 (tree index:146) done accuracy:0.733333 logloss:0.528001\n",
      "I0000 00:00:1729625129.319845 6797893 random_forest.cc:812] Training of tree  155/300 (tree index:154) done accuracy:0.733333 logloss:0.526271\n",
      "I0000 00:00:1729625129.319995 6797898 random_forest.cc:812] Training of tree  165/300 (tree index:164) done accuracy:0.725 logloss:0.531322\n",
      "I0000 00:00:1729625129.320172 6797894 random_forest.cc:812] Training of tree  175/300 (tree index:172) done accuracy:0.741667 logloss:0.525449\n",
      "I0000 00:00:1729625129.320304 6797895 random_forest.cc:812] Training of tree  185/300 (tree index:184) done accuracy:0.741667 logloss:0.52153\n",
      "I0000 00:00:1729625129.320475 6797894 random_forest.cc:812] Training of tree  195/300 (tree index:195) done accuracy:0.741667 logloss:0.519201\n",
      "I0000 00:00:1729625129.320612 6797892 random_forest.cc:812] Training of tree  205/300 (tree index:205) done accuracy:0.725 logloss:0.519402\n",
      "I0000 00:00:1729625129.320805 6797894 random_forest.cc:812] Training of tree  215/300 (tree index:209) done accuracy:0.716667 logloss:0.516466\n",
      "I0000 00:00:1729625129.320953 6797898 random_forest.cc:812] Training of tree  225/300 (tree index:224) done accuracy:0.716667 logloss:0.516744\n",
      "I0000 00:00:1729625129.321089 6797896 random_forest.cc:812] Training of tree  235/300 (tree index:234) done accuracy:0.741667 logloss:0.513899\n",
      "I0000 00:00:1729625129.321236 6797891 random_forest.cc:812] Training of tree  245/300 (tree index:245) done accuracy:0.741667 logloss:0.511004\n",
      "I0000 00:00:1729625129.321365 6797898 random_forest.cc:812] Training of tree  255/300 (tree index:254) done accuracy:0.741667 logloss:0.511563\n",
      "I0000 00:00:1729625129.321573 6797891 random_forest.cc:812] Training of tree  265/300 (tree index:265) done accuracy:0.733333 logloss:0.511675\n",
      "I0000 00:00:1729625129.321719 6797895 random_forest.cc:812] Training of tree  275/300 (tree index:274) done accuracy:0.733333 logloss:0.511264\n",
      "I0000 00:00:1729625129.321893 6797895 random_forest.cc:812] Training of tree  285/300 (tree index:285) done accuracy:0.733333 logloss:0.509393\n",
      "I0000 00:00:1729625129.322059 6797893 random_forest.cc:812] Training of tree  295/300 (tree index:295) done accuracy:0.741667 logloss:0.512183\n",
      "I0000 00:00:1729625129.322156 6797896 random_forest.cc:812] Training of tree  300/300 (tree index:296) done accuracy:0.741667 logloss:0.510612\n",
      "I0000 00:00:1729625129.322197 6797882 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.510612\n",
      "I0000 00:00:1729625129.322781 6797882 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpkd8m3x51 with prefix 0546a004c8404afd\n",
      "I0000 00:00:1729625129.326375 6797882 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625129.326953 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.510612\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  16\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:29.332772: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpkd8m3x51/model/ with prefix 0546a004c8404afd\n",
      "I0000 00:00:1729625129.339915 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5638 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:29.339930: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.142548. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027261\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpffxj7uf3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625129.657601 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625129.657612 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625129.657617 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625129.657680 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625129.657685 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625129.657730 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.657740 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.657745 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.657750 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.657780 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625129.657797 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625129.657937 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625129.657960 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbg7znqaj/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625129.658022 6797955 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625129.658107 6797955 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625129.658729 6797970 random_forest.cc:812] Training of tree  1/300 (tree index:4) done accuracy:0.660714 logloss:12.2291\n",
      "I0000 00:00:1729625129.658921 6797966 random_forest.cc:812] Training of tree  13/300 (tree index:12) done accuracy:0.630252 logloss:2.87922\n",
      "I0000 00:00:1729625129.659134 6797970 random_forest.cc:812] Training of tree  24/300 (tree index:23) done accuracy:0.708333 logloss:1.17553\n",
      "I0000 00:00:1729625129.659395 6797970 random_forest.cc:812] Training of tree  34/300 (tree index:34) done accuracy:0.708333 logloss:0.590032\n",
      "I0000 00:00:1729625129.659581 6797964 random_forest.cc:812] Training of tree  44/300 (tree index:44) done accuracy:0.7 logloss:0.575842\n",
      "I0000 00:00:1729625129.659829 6797967 random_forest.cc:812] Training of tree  54/300 (tree index:55) done accuracy:0.725 logloss:0.559634\n",
      "I0000 00:00:1729625129.659979 6797964 random_forest.cc:812] Training of tree  66/300 (tree index:63) done accuracy:0.708333 logloss:0.564031\n",
      "I0000 00:00:1729625129.660187 6797966 random_forest.cc:812] Training of tree  76/300 (tree index:74) done accuracy:0.716667 logloss:0.567563\n",
      "I0000 00:00:1729625129.660336 6797965 random_forest.cc:812] Training of tree  86/300 (tree index:87) done accuracy:0.741667 logloss:0.564383\n",
      "I0000 00:00:1729625129.660492 6797969 random_forest.cc:812] Training of tree  96/300 (tree index:96) done accuracy:0.725 logloss:0.565329\n",
      "I0000 00:00:1729625129.660741 6797968 random_forest.cc:812] Training of tree  106/300 (tree index:105) done accuracy:0.741667 logloss:0.555172\n",
      "I0000 00:00:1729625129.660877 6797969 random_forest.cc:812] Training of tree  116/300 (tree index:116) done accuracy:0.75 logloss:0.553209\n",
      "I0000 00:00:1729625129.661031 6797967 random_forest.cc:812] Training of tree  126/300 (tree index:125) done accuracy:0.766667 logloss:0.551008\n",
      "I0000 00:00:1729625129.661217 6797968 random_forest.cc:812] Training of tree  136/300 (tree index:137) done accuracy:0.758333 logloss:0.553262\n",
      "I0000 00:00:1729625129.661358 6797970 random_forest.cc:812] Training of tree  146/300 (tree index:145) done accuracy:0.758333 logloss:0.554312\n",
      "I0000 00:00:1729625129.661514 6797966 random_forest.cc:812] Training of tree  156/300 (tree index:157) done accuracy:0.766667 logloss:0.554263\n",
      "I0000 00:00:1729625129.661642 6797965 random_forest.cc:812] Training of tree  166/300 (tree index:150) done accuracy:0.766667 logloss:0.548255\n",
      "I0000 00:00:1729625129.661843 6797968 random_forest.cc:812] Training of tree  177/300 (tree index:175) done accuracy:0.783333 logloss:0.544478\n",
      "I0000 00:00:1729625129.662047 6797965 random_forest.cc:812] Training of tree  187/300 (tree index:177) done accuracy:0.783333 logloss:0.541088\n",
      "I0000 00:00:1729625129.662217 6797970 random_forest.cc:812] Training of tree  197/300 (tree index:198) done accuracy:0.783333 logloss:0.541046\n",
      "I0000 00:00:1729625129.662423 6797966 random_forest.cc:812] Training of tree  207/300 (tree index:200) done accuracy:0.775 logloss:0.543491\n",
      "I0000 00:00:1729625129.662584 6797967 random_forest.cc:812] Training of tree  217/300 (tree index:219) done accuracy:0.783333 logloss:0.540819\n",
      "I0000 00:00:1729625129.662733 6797966 random_forest.cc:812] Training of tree  227/300 (tree index:227) done accuracy:0.775 logloss:0.542125\n",
      "I0000 00:00:1729625129.662886 6797964 random_forest.cc:812] Training of tree  237/300 (tree index:238) done accuracy:0.766667 logloss:0.538598\n",
      "I0000 00:00:1729625129.663028 6797970 random_forest.cc:812] Training of tree  247/300 (tree index:248) done accuracy:0.758333 logloss:0.538037\n",
      "I0000 00:00:1729625129.663154 6797969 random_forest.cc:812] Training of tree  257/300 (tree index:256) done accuracy:0.758333 logloss:0.535906\n",
      "I0000 00:00:1729625129.663364 6797969 random_forest.cc:812] Training of tree  267/300 (tree index:268) done accuracy:0.775 logloss:0.531674\n",
      "I0000 00:00:1729625129.663549 6797964 random_forest.cc:812] Training of tree  278/300 (tree index:276) done accuracy:0.783333 logloss:0.531718\n",
      "I0000 00:00:1729625129.663831 6797971 random_forest.cc:812] Training of tree  289/300 (tree index:287) done accuracy:0.766667 logloss:0.532363\n",
      "I0000 00:00:1729625129.664031 6797967 random_forest.cc:812] Training of tree  299/300 (tree index:298) done accuracy:0.775 logloss:0.53087\n",
      "I0000 00:00:1729625129.664109 6797968 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.766667 logloss:0.530043\n",
      "I0000 00:00:1729625129.664194 6797955 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.530043\n",
      "I0000 00:00:1729625129.664879 6797955 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbg7znqaj with prefix 5167a540ffb440eb\n",
      "I0000 00:00:1729625129.668222 6797955 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625129.668818 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.530043\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  13  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:29.674876: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbg7znqaj/model/ with prefix 5167a540ffb440eb\n",
      "I0000 00:00:1729625129.682307 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5776 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:29.682325: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.150718. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.029283\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpuifodlda as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625129.971976 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625129.971989 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625129.971995 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625129.972061 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625129.972066 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625129.972109 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.972119 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.972125 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.972130 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625129.972157 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625129.972194 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625129.972328 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625129.972355 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpffxj7uf3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625129.972397 6798028 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625129.972477 6798028 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625129.973035 6798044 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.660377 logloss:12.2412\n",
      "I0000 00:00:1729625129.973228 6798043 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.672269 logloss:4.04903\n",
      "I0000 00:00:1729625129.973432 6798044 random_forest.cc:812] Training of tree  21/300 (tree index:24) done accuracy:0.666667 logloss:1.17433\n",
      "I0000 00:00:1729625129.973615 6798037 random_forest.cc:812] Training of tree  31/300 (tree index:25) done accuracy:0.666667 logloss:0.591551\n",
      "I0000 00:00:1729625129.973827 6798040 random_forest.cc:812] Training of tree  41/300 (tree index:41) done accuracy:0.725 logloss:0.56724\n",
      "I0000 00:00:1729625129.974099 6798040 random_forest.cc:812] Training of tree  53/300 (tree index:54) done accuracy:0.741667 logloss:0.553902\n",
      "I0000 00:00:1729625129.974400 6798037 random_forest.cc:812] Training of tree  66/300 (tree index:65) done accuracy:0.758333 logloss:0.540691\n",
      "I0000 00:00:1729625129.974631 6798044 random_forest.cc:812] Training of tree  76/300 (tree index:75) done accuracy:0.791667 logloss:0.542554\n",
      "I0000 00:00:1729625129.974844 6798040 random_forest.cc:812] Training of tree  87/300 (tree index:83) done accuracy:0.775 logloss:0.532178\n",
      "I0000 00:00:1729625129.975080 6798039 random_forest.cc:812] Training of tree  98/300 (tree index:98) done accuracy:0.791667 logloss:0.532441\n",
      "I0000 00:00:1729625129.975375 6798043 random_forest.cc:812] Training of tree  108/300 (tree index:108) done accuracy:0.8 logloss:0.526092\n",
      "I0000 00:00:1729625129.975634 6798037 random_forest.cc:812] Training of tree  118/300 (tree index:114) done accuracy:0.775 logloss:0.525673\n",
      "I0000 00:00:1729625129.975849 6798039 random_forest.cc:812] Training of tree  128/300 (tree index:127) done accuracy:0.775 logloss:0.521942\n",
      "I0000 00:00:1729625129.976052 6798039 random_forest.cc:812] Training of tree  138/300 (tree index:138) done accuracy:0.775 logloss:0.518271\n",
      "I0000 00:00:1729625129.976239 6798044 random_forest.cc:812] Training of tree  148/300 (tree index:148) done accuracy:0.766667 logloss:0.521679\n",
      "I0000 00:00:1729625129.976475 6798043 random_forest.cc:812] Training of tree  158/300 (tree index:159) done accuracy:0.766667 logloss:0.523625\n",
      "I0000 00:00:1729625129.976723 6798042 random_forest.cc:812] Training of tree  168/300 (tree index:160) done accuracy:0.775 logloss:0.52689\n",
      "I0000 00:00:1729625129.976896 6798037 random_forest.cc:812] Training of tree  178/300 (tree index:177) done accuracy:0.775 logloss:0.526407\n",
      "I0000 00:00:1729625129.977110 6798041 random_forest.cc:812] Training of tree  188/300 (tree index:189) done accuracy:0.783333 logloss:0.526367\n",
      "I0000 00:00:1729625129.977235 6798042 random_forest.cc:812] Training of tree  198/300 (tree index:197) done accuracy:0.783333 logloss:0.523638\n",
      "I0000 00:00:1729625129.977407 6798040 random_forest.cc:812] Training of tree  208/300 (tree index:207) done accuracy:0.783333 logloss:0.522946\n",
      "I0000 00:00:1729625129.977535 6798039 random_forest.cc:812] Training of tree  218/300 (tree index:219) done accuracy:0.783333 logloss:0.520439\n",
      "I0000 00:00:1729625129.977710 6798042 random_forest.cc:812] Training of tree  228/300 (tree index:227) done accuracy:0.783333 logloss:0.521124\n",
      "I0000 00:00:1729625129.977970 6798038 random_forest.cc:812] Training of tree  240/300 (tree index:238) done accuracy:0.783333 logloss:0.519292\n",
      "I0000 00:00:1729625129.978151 6798037 random_forest.cc:812] Training of tree  250/300 (tree index:250) done accuracy:0.783333 logloss:0.520045\n",
      "I0000 00:00:1729625129.978316 6798043 random_forest.cc:812] Training of tree  260/300 (tree index:260) done accuracy:0.783333 logloss:0.519332\n",
      "I0000 00:00:1729625129.978448 6798043 random_forest.cc:812] Training of tree  270/300 (tree index:267) done accuracy:0.783333 logloss:0.519839\n",
      "I0000 00:00:1729625129.978610 6798041 random_forest.cc:812] Training of tree  280/300 (tree index:279) done accuracy:0.783333 logloss:0.521414\n",
      "I0000 00:00:1729625129.978808 6798037 random_forest.cc:812] Training of tree  290/300 (tree index:289) done accuracy:0.783333 logloss:0.519344\n",
      "I0000 00:00:1729625129.978954 6798043 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.791667 logloss:0.519838\n",
      "I0000 00:00:1729625129.979077 6798028 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.519838\n",
      "I0000 00:00:1729625129.979732 6798028 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpffxj7uf3 with prefix 1d20e56352bb47e2\n",
      "I0000 00:00:1729625129.983253 6798028 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625129.984059 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.519838\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  14\n",
      "2  11  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:29.990825: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpffxj7uf3/model/ with prefix 1d20e56352bb47e2\n",
      "I0000 00:00:1729625129.998723 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5828 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:29.998750: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147316. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027482\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx6_ryolf as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625130.288237 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625130.288250 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625130.288255 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625130.288322 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625130.288327 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625130.288370 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.288380 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.288385 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.288390 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.288418 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625130.288435 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625130.288572 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625130.288596 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpuifodlda/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625130.288678 6798101 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625130.288767 6798101 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625130.289351 6798115 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.509434 logloss:17.6818\n",
      "I0000 00:00:1729625130.289561 6798117 random_forest.cc:812] Training of tree  11/300 (tree index:14) done accuracy:0.7 logloss:2.79404\n",
      "I0000 00:00:1729625130.289742 6798112 random_forest.cc:812] Training of tree  21/300 (tree index:23) done accuracy:0.766667 logloss:1.35314\n",
      "I0000 00:00:1729625130.289962 6798114 random_forest.cc:812] Training of tree  31/300 (tree index:33) done accuracy:0.75 logloss:1.02857\n",
      "I0000 00:00:1729625130.290175 6798117 random_forest.cc:812] Training of tree  41/300 (tree index:37) done accuracy:0.758333 logloss:0.765698\n",
      "I0000 00:00:1729625130.290400 6798114 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.766667 logloss:0.487535\n",
      "I0000 00:00:1729625130.290664 6798117 random_forest.cc:812] Training of tree  61/300 (tree index:59) done accuracy:0.766667 logloss:0.481307\n",
      "I0000 00:00:1729625130.290932 6798110 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.783333 logloss:0.47957\n",
      "I0000 00:00:1729625130.291382 6798113 random_forest.cc:812] Training of tree  81/300 (tree index:79) done accuracy:0.766667 logloss:0.484196\n",
      "I0000 00:00:1729625130.291766 6798117 random_forest.cc:812] Training of tree  91/300 (tree index:94) done accuracy:0.758333 logloss:0.47672\n",
      "I0000 00:00:1729625130.291960 6798111 random_forest.cc:812] Training of tree  101/300 (tree index:101) done accuracy:0.783333 logloss:0.47358\n",
      "I0000 00:00:1729625130.292198 6798115 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.783333 logloss:0.480207\n",
      "I0000 00:00:1729625130.292368 6798114 random_forest.cc:812] Training of tree  121/300 (tree index:111) done accuracy:0.8 logloss:0.481937\n",
      "I0000 00:00:1729625130.292592 6798112 random_forest.cc:812] Training of tree  131/300 (tree index:131) done accuracy:0.791667 logloss:0.47993\n",
      "I0000 00:00:1729625130.292766 6798114 random_forest.cc:812] Training of tree  141/300 (tree index:132) done accuracy:0.783333 logloss:0.476239\n",
      "I0000 00:00:1729625130.292978 6798110 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.783333 logloss:0.477278\n",
      "I0000 00:00:1729625130.293168 6798113 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.783333 logloss:0.476992\n",
      "I0000 00:00:1729625130.293360 6798115 random_forest.cc:812] Training of tree  171/300 (tree index:165) done accuracy:0.775 logloss:0.478575\n",
      "I0000 00:00:1729625130.293511 6798115 random_forest.cc:812] Training of tree  181/300 (tree index:177) done accuracy:0.775 logloss:0.479099\n",
      "I0000 00:00:1729625130.293738 6798113 random_forest.cc:812] Training of tree  191/300 (tree index:192) done accuracy:0.766667 logloss:0.481613\n",
      "I0000 00:00:1729625130.293897 6798117 random_forest.cc:812] Training of tree  202/300 (tree index:201) done accuracy:0.775 logloss:0.481364\n",
      "I0000 00:00:1729625130.294136 6798113 random_forest.cc:812] Training of tree  212/300 (tree index:211) done accuracy:0.783333 logloss:0.478593\n",
      "I0000 00:00:1729625130.294336 6798115 random_forest.cc:812] Training of tree  222/300 (tree index:225) done accuracy:0.775 logloss:0.476915\n",
      "I0000 00:00:1729625130.294454 6798111 random_forest.cc:812] Training of tree  232/300 (tree index:230) done accuracy:0.783333 logloss:0.474335\n",
      "I0000 00:00:1729625130.294621 6798116 random_forest.cc:812] Training of tree  242/300 (tree index:241) done accuracy:0.783333 logloss:0.472936\n",
      "I0000 00:00:1729625130.294849 6798114 random_forest.cc:812] Training of tree  254/300 (tree index:253) done accuracy:0.783333 logloss:0.471259\n",
      "I0000 00:00:1729625130.295063 6798110 random_forest.cc:812] Training of tree  264/300 (tree index:267) done accuracy:0.783333 logloss:0.475435\n",
      "I0000 00:00:1729625130.295299 6798115 random_forest.cc:812] Training of tree  274/300 (tree index:275) done accuracy:0.783333 logloss:0.476052\n",
      "I0000 00:00:1729625130.295637 6798116 random_forest.cc:812] Training of tree  284/300 (tree index:283) done accuracy:0.8 logloss:0.475357\n",
      "I0000 00:00:1729625130.295768 6798112 random_forest.cc:812] Training of tree  294/300 (tree index:294) done accuracy:0.8 logloss:0.475903\n",
      "I0000 00:00:1729625130.295940 6798111 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.8 logloss:0.474312\n",
      "I0000 00:00:1729625130.296003 6798101 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.474312\n",
      "I0000 00:00:1729625130.296655 6798101 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpuifodlda with prefix a55678febbfa4db6\n",
      "I0000 00:00:1729625130.299418 6798101 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625130.300235 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.474312\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:30.306589: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpuifodlda/model/ with prefix a55678febbfa4db6\n",
      "I0000 00:00:1729625130.313306 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5290 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:30.313323: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.185628. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.030544\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 20, 'min_examples': 10, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwz4tjzt7 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625130.631916 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625130.631929 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625130.631934 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625130.632003 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625130.632007 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625130.632052 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.632061 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.632067 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.632072 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.632098 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625130.632117 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625130.632251 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625130.632276 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx6_ryolf/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625130.632338 6798236 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625130.632456 6798236 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625130.633013 6798249 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.641509 logloss:12.9213\n",
      "I0000 00:00:1729625130.633200 6798250 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.756303 logloss:2.1808\n",
      "I0000 00:00:1729625130.633427 6798251 random_forest.cc:812] Training of tree  21/300 (tree index:23) done accuracy:0.733333 logloss:1.04455\n",
      "I0000 00:00:1729625130.633827 6798249 random_forest.cc:812] Training of tree  31/300 (tree index:28) done accuracy:0.758333 logloss:0.755156\n",
      "I0000 00:00:1729625130.634106 6798250 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.775 logloss:0.493349\n",
      "I0000 00:00:1729625130.634521 6798250 random_forest.cc:812] Training of tree  51/300 (tree index:51) done accuracy:0.791667 logloss:0.481846\n",
      "I0000 00:00:1729625130.634940 6798249 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.791667 logloss:0.470513\n",
      "I0000 00:00:1729625130.635273 6798246 random_forest.cc:812] Training of tree  71/300 (tree index:72) done accuracy:0.775 logloss:0.478383\n",
      "I0000 00:00:1729625130.635566 6798251 random_forest.cc:812] Training of tree  81/300 (tree index:82) done accuracy:0.783333 logloss:0.469034\n",
      "I0000 00:00:1729625130.635718 6798248 random_forest.cc:812] Training of tree  91/300 (tree index:91) done accuracy:0.783333 logloss:0.455131\n",
      "I0000 00:00:1729625130.635888 6798248 random_forest.cc:812] Training of tree  101/300 (tree index:102) done accuracy:0.775 logloss:0.461302\n",
      "I0000 00:00:1729625130.636093 6798249 random_forest.cc:812] Training of tree  111/300 (tree index:105) done accuracy:0.775 logloss:0.457638\n",
      "I0000 00:00:1729625130.636274 6798245 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.8 logloss:0.467788\n",
      "I0000 00:00:1729625130.636494 6798246 random_forest.cc:812] Training of tree  131/300 (tree index:131) done accuracy:0.783333 logloss:0.460962\n",
      "I0000 00:00:1729625130.636637 6798247 random_forest.cc:812] Training of tree  142/300 (tree index:140) done accuracy:0.783333 logloss:0.468078\n",
      "I0000 00:00:1729625130.636883 6798246 random_forest.cc:812] Training of tree  152/300 (tree index:152) done accuracy:0.783333 logloss:0.47248\n",
      "I0000 00:00:1729625130.637115 6798250 random_forest.cc:812] Training of tree  162/300 (tree index:161) done accuracy:0.783333 logloss:0.473921\n",
      "I0000 00:00:1729625130.637377 6798250 random_forest.cc:812] Training of tree  172/300 (tree index:172) done accuracy:0.783333 logloss:0.475256\n",
      "I0000 00:00:1729625130.637597 6798251 random_forest.cc:812] Training of tree  182/300 (tree index:183) done accuracy:0.783333 logloss:0.475132\n",
      "I0000 00:00:1729625130.637820 6798247 random_forest.cc:812] Training of tree  192/300 (tree index:193) done accuracy:0.783333 logloss:0.472288\n",
      "I0000 00:00:1729625130.638058 6798250 random_forest.cc:812] Training of tree  202/300 (tree index:202) done accuracy:0.766667 logloss:0.476187\n",
      "I0000 00:00:1729625130.638210 6798245 random_forest.cc:812] Training of tree  212/300 (tree index:195) done accuracy:0.766667 logloss:0.477039\n",
      "I0000 00:00:1729625130.638362 6798250 random_forest.cc:812] Training of tree  222/300 (tree index:220) done accuracy:0.766667 logloss:0.475545\n",
      "I0000 00:00:1729625130.638543 6798250 random_forest.cc:812] Training of tree  234/300 (tree index:233) done accuracy:0.775 logloss:0.473809\n",
      "I0000 00:00:1729625130.638810 6798245 random_forest.cc:812] Training of tree  245/300 (tree index:247) done accuracy:0.766667 logloss:0.472627\n",
      "I0000 00:00:1729625130.639018 6798246 random_forest.cc:812] Training of tree  255/300 (tree index:256) done accuracy:0.783333 logloss:0.473671\n",
      "I0000 00:00:1729625130.639311 6798248 random_forest.cc:812] Training of tree  265/300 (tree index:262) done accuracy:0.775 logloss:0.47692\n",
      "I0000 00:00:1729625130.639484 6798245 random_forest.cc:812] Training of tree  275/300 (tree index:273) done accuracy:0.766667 logloss:0.478663\n",
      "I0000 00:00:1729625130.639663 6798245 random_forest.cc:812] Training of tree  285/300 (tree index:285) done accuracy:0.775 logloss:0.478074\n",
      "I0000 00:00:1729625130.639887 6798247 random_forest.cc:812] Training of tree  295/300 (tree index:297) done accuracy:0.775 logloss:0.477918\n",
      "I0000 00:00:1729625130.639966 6798246 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.775 logloss:0.476714\n",
      "I0000 00:00:1729625130.640123 6798236 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.476714\n",
      "I0000 00:00:1729625130.640831 6798236 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx6_ryolf with prefix e81029b98baf4c75\n",
      "I0000 00:00:1729625130.644451 6798236 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625130.645323 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.476714\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  13  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:30.652386: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx6_ryolf/model/ with prefix e81029b98baf4c75\n",
      "I0000 00:00:1729625130.659869 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5552 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:30.659893: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.157802. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.026086\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw56oobm6 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625130.964781 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625130.964791 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625130.964795 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625130.964890 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625130.964904 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625130.964951 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.964975 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.964991 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.964998 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625130.965029 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625130.965048 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625130.965180 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625130.965208 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwz4tjzt7/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625130.965253 6798337 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625130.965427 6798337 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625130.965989 6798353 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625130.966218 6798353 random_forest.cc:812] Training of tree  11/300 (tree index:8) done accuracy:0.672269 logloss:4.56804\n",
      "I0000 00:00:1729625130.966374 6798352 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.758333 logloss:1.7049\n",
      "I0000 00:00:1729625130.966514 6798348 random_forest.cc:812] Training of tree  31/300 (tree index:33) done accuracy:0.758333 logloss:1.11063\n",
      "I0000 00:00:1729625130.966684 6798351 random_forest.cc:812] Training of tree  41/300 (tree index:42) done accuracy:0.741667 logloss:0.831637\n",
      "I0000 00:00:1729625130.966820 6798352 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.733333 logloss:0.815908\n",
      "I0000 00:00:1729625130.966990 6798351 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.75 logloss:0.804373\n",
      "I0000 00:00:1729625130.967175 6798349 random_forest.cc:812] Training of tree  72/300 (tree index:66) done accuracy:0.725 logloss:0.805481\n",
      "I0000 00:00:1729625130.967385 6798353 random_forest.cc:812] Training of tree  82/300 (tree index:84) done accuracy:0.716667 logloss:0.815081\n",
      "I0000 00:00:1729625130.967533 6798348 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.708333 logloss:0.81547\n",
      "I0000 00:00:1729625130.967749 6798348 random_forest.cc:812] Training of tree  103/300 (tree index:102) done accuracy:0.725 logloss:0.540599\n",
      "I0000 00:00:1729625130.967996 6798346 random_forest.cc:812] Training of tree  113/300 (tree index:113) done accuracy:0.708333 logloss:0.550002\n",
      "I0000 00:00:1729625130.968254 6798347 random_forest.cc:812] Training of tree  124/300 (tree index:122) done accuracy:0.691667 logloss:0.549661\n",
      "I0000 00:00:1729625130.968679 6798349 random_forest.cc:812] Training of tree  134/300 (tree index:136) done accuracy:0.7 logloss:0.552615\n",
      "I0000 00:00:1729625130.968887 6798349 random_forest.cc:812] Training of tree  144/300 (tree index:144) done accuracy:0.708333 logloss:0.554246\n",
      "I0000 00:00:1729625130.969088 6798353 random_forest.cc:812] Training of tree  154/300 (tree index:153) done accuracy:0.708333 logloss:0.559805\n",
      "I0000 00:00:1729625130.969293 6798350 random_forest.cc:812] Training of tree  164/300 (tree index:164) done accuracy:0.716667 logloss:0.555663\n",
      "I0000 00:00:1729625130.969454 6798351 random_forest.cc:812] Training of tree  174/300 (tree index:174) done accuracy:0.716667 logloss:0.546372\n",
      "I0000 00:00:1729625130.969641 6798347 random_forest.cc:812] Training of tree  184/300 (tree index:184) done accuracy:0.708333 logloss:0.547201\n",
      "I0000 00:00:1729625130.969803 6798348 random_forest.cc:812] Training of tree  194/300 (tree index:192) done accuracy:0.7 logloss:0.547691\n",
      "I0000 00:00:1729625130.969988 6798346 random_forest.cc:812] Training of tree  204/300 (tree index:204) done accuracy:0.7 logloss:0.549225\n",
      "I0000 00:00:1729625130.970139 6798349 random_forest.cc:812] Training of tree  214/300 (tree index:214) done accuracy:0.7 logloss:0.550555\n",
      "I0000 00:00:1729625130.970287 6798353 random_forest.cc:812] Training of tree  224/300 (tree index:224) done accuracy:0.691667 logloss:0.553487\n",
      "I0000 00:00:1729625130.970461 6798348 random_forest.cc:812] Training of tree  235/300 (tree index:233) done accuracy:0.691667 logloss:0.554152\n",
      "I0000 00:00:1729625130.970638 6798352 random_forest.cc:812] Training of tree  245/300 (tree index:246) done accuracy:0.7 logloss:0.550615\n",
      "I0000 00:00:1729625130.970792 6798349 random_forest.cc:812] Training of tree  255/300 (tree index:255) done accuracy:0.708333 logloss:0.550857\n",
      "I0000 00:00:1729625130.970953 6798346 random_forest.cc:812] Training of tree  265/300 (tree index:263) done accuracy:0.708333 logloss:0.552374\n",
      "I0000 00:00:1729625130.971122 6798350 random_forest.cc:812] Training of tree  275/300 (tree index:275) done accuracy:0.708333 logloss:0.551008\n",
      "I0000 00:00:1729625130.971265 6798349 random_forest.cc:812] Training of tree  285/300 (tree index:285) done accuracy:0.708333 logloss:0.549065\n",
      "I0000 00:00:1729625130.971450 6798348 random_forest.cc:812] Training of tree  295/300 (tree index:297) done accuracy:0.708333 logloss:0.545119\n",
      "I0000 00:00:1729625130.971517 6798347 random_forest.cc:812] Training of tree  300/300 (tree index:291) done accuracy:0.708333 logloss:0.545719\n",
      "I0000 00:00:1729625130.971624 6798337 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.545719\n",
      "I0000 00:00:1729625130.972160 6798337 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwz4tjzt7 with prefix 1999176f6cfd4533\n",
      "I0000 00:00:1729625130.974685 6798337 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625130.975578 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.545719\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  16  46\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:30.982475: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwz4tjzt7/model/ with prefix 1999176f6cfd4533\n",
      "I0000 00:00:1729625130.988542 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4562 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:30.988558: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.489391. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027607\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphtlgmwxa as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625131.615017 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625131.615029 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625131.615033 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625131.615099 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625131.615105 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625131.615152 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625131.615163 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625131.615169 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625131.615175 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625131.615202 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625131.615221 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625131.615371 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625131.615397 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw56oobm6/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625131.615457 6798408 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625131.615612 6798408 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625131.616140 6798418 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.772727 logloss:8.19174\n",
      "I0000 00:00:1729625131.616282 6798420 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.697479 logloss:4.86184\n",
      "I0000 00:00:1729625131.616448 6798418 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.758333 logloss:1.0904\n",
      "I0000 00:00:1729625131.616626 6798417 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.758333 logloss:1.07114\n",
      "I0000 00:00:1729625131.616789 6798419 random_forest.cc:812] Training of tree  41/300 (tree index:43) done accuracy:0.758333 logloss:1.09341\n",
      "I0000 00:00:1729625131.616950 6798421 random_forest.cc:812] Training of tree  51/300 (tree index:49) done accuracy:0.75 logloss:0.536932\n",
      "I0000 00:00:1729625131.617089 6798423 random_forest.cc:812] Training of tree  61/300 (tree index:62) done accuracy:0.791667 logloss:0.531378\n",
      "I0000 00:00:1729625131.617247 6798423 random_forest.cc:812] Training of tree  71/300 (tree index:67) done accuracy:0.775 logloss:0.532857\n",
      "I0000 00:00:1729625131.617522 6798423 random_forest.cc:812] Training of tree  82/300 (tree index:81) done accuracy:0.775 logloss:0.536467\n",
      "I0000 00:00:1729625131.617773 6798424 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.758333 logloss:0.528087\n",
      "I0000 00:00:1729625131.617979 6798424 random_forest.cc:812] Training of tree  102/300 (tree index:102) done accuracy:0.791667 logloss:0.526627\n",
      "I0000 00:00:1729625131.618148 6798419 random_forest.cc:812] Training of tree  112/300 (tree index:112) done accuracy:0.758333 logloss:0.527416\n",
      "I0000 00:00:1729625131.618291 6798421 random_forest.cc:812] Training of tree  122/300 (tree index:121) done accuracy:0.758333 logloss:0.525272\n",
      "I0000 00:00:1729625131.618448 6798420 random_forest.cc:812] Training of tree  132/300 (tree index:133) done accuracy:0.741667 logloss:0.524979\n",
      "I0000 00:00:1729625131.618658 6798423 random_forest.cc:812] Training of tree  142/300 (tree index:143) done accuracy:0.758333 logloss:0.531127\n",
      "I0000 00:00:1729625131.618787 6798421 random_forest.cc:812] Training of tree  152/300 (tree index:152) done accuracy:0.75 logloss:0.535567\n",
      "I0000 00:00:1729625131.618926 6798418 random_forest.cc:812] Training of tree  162/300 (tree index:161) done accuracy:0.75 logloss:0.538437\n",
      "I0000 00:00:1729625131.619145 6798419 random_forest.cc:812] Training of tree  175/300 (tree index:174) done accuracy:0.75 logloss:0.53649\n",
      "I0000 00:00:1729625131.619379 6798419 random_forest.cc:812] Training of tree  185/300 (tree index:188) done accuracy:0.75 logloss:0.536635\n",
      "I0000 00:00:1729625131.619529 6798424 random_forest.cc:812] Training of tree  195/300 (tree index:195) done accuracy:0.75 logloss:0.543057\n",
      "I0000 00:00:1729625131.619678 6798421 random_forest.cc:812] Training of tree  205/300 (tree index:205) done accuracy:0.775 logloss:0.545496\n",
      "I0000 00:00:1729625131.619864 6798418 random_forest.cc:812] Training of tree  216/300 (tree index:214) done accuracy:0.775 logloss:0.54465\n",
      "I0000 00:00:1729625131.620045 6798424 random_forest.cc:812] Training of tree  226/300 (tree index:226) done accuracy:0.766667 logloss:0.543757\n",
      "I0000 00:00:1729625131.620202 6798421 random_forest.cc:812] Training of tree  237/300 (tree index:237) done accuracy:0.775 logloss:0.544386\n",
      "I0000 00:00:1729625131.620355 6798418 random_forest.cc:812] Training of tree  247/300 (tree index:246) done accuracy:0.758333 logloss:0.547146\n",
      "I0000 00:00:1729625131.620527 6798419 random_forest.cc:812] Training of tree  257/300 (tree index:256) done accuracy:0.775 logloss:0.544529\n",
      "I0000 00:00:1729625131.620686 6798423 random_forest.cc:812] Training of tree  267/300 (tree index:267) done accuracy:0.766667 logloss:0.548662\n",
      "I0000 00:00:1729625131.620858 6798418 random_forest.cc:812] Training of tree  277/300 (tree index:278) done accuracy:0.775 logloss:0.546675\n",
      "I0000 00:00:1729625131.621036 6798424 random_forest.cc:812] Training of tree  287/300 (tree index:288) done accuracy:0.766667 logloss:0.545608\n",
      "I0000 00:00:1729625131.621183 6798419 random_forest.cc:812] Training of tree  298/300 (tree index:297) done accuracy:0.775 logloss:0.545843\n",
      "I0000 00:00:1729625131.621262 6798421 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.775 logloss:0.547206\n",
      "I0000 00:00:1729625131.621306 6798408 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.547206\n",
      "I0000 00:00:1729625131.622140 6798408 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw56oobm6 with prefix f99ac58fe9c9449a\n",
      "I0000 00:00:1729625131.625258 6798408 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625131.626010 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.547206\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:31.633614: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw56oobm6/model/ with prefix f99ac58fe9c9449a\n",
      "I0000 00:00:1729625131.640010 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4612 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:31.640027: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.199736. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027466\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp56xjtx5z as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625131.985775 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625131.985785 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625131.985790 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625131.985856 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625131.985863 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625131.985910 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625131.985919 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625131.985925 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625131.985931 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625131.985963 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625131.985981 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625131.986122 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625131.986146 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphtlgmwxa/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625131.986208 6798477 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625131.986310 6798477 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625131.986781 6798486 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.682927 logloss:11.4285\n",
      "I0000 00:00:1729625131.986945 6798492 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.7 logloss:1.91318\n",
      "I0000 00:00:1729625131.987089 6798486 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.65 logloss:0.881203\n",
      "I0000 00:00:1729625131.987232 6798487 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.7 logloss:0.867745\n",
      "I0000 00:00:1729625131.987424 6798491 random_forest.cc:812] Training of tree  41/300 (tree index:45) done accuracy:0.666667 logloss:0.870187\n",
      "I0000 00:00:1729625131.987562 6798489 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.65 logloss:0.602838\n",
      "I0000 00:00:1729625131.987780 6798493 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.675 logloss:0.588995\n",
      "I0000 00:00:1729625131.987942 6798486 random_forest.cc:812] Training of tree  72/300 (tree index:73) done accuracy:0.7 logloss:0.594506\n",
      "I0000 00:00:1729625131.988089 6798488 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.716667 logloss:0.5908\n",
      "I0000 00:00:1729625131.988264 6798493 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.725 logloss:0.589983\n",
      "I0000 00:00:1729625131.988502 6798486 random_forest.cc:812] Training of tree  105/300 (tree index:105) done accuracy:0.725 logloss:0.585773\n",
      "I0000 00:00:1729625131.988725 6798492 random_forest.cc:812] Training of tree  115/300 (tree index:117) done accuracy:0.716667 logloss:0.583075\n",
      "I0000 00:00:1729625131.988901 6798489 random_forest.cc:812] Training of tree  125/300 (tree index:119) done accuracy:0.716667 logloss:0.586018\n",
      "I0000 00:00:1729625131.989102 6798488 random_forest.cc:812] Training of tree  135/300 (tree index:134) done accuracy:0.725 logloss:0.581736\n",
      "I0000 00:00:1729625131.989380 6798493 random_forest.cc:812] Training of tree  146/300 (tree index:148) done accuracy:0.716667 logloss:0.583123\n",
      "I0000 00:00:1729625131.989518 6798489 random_forest.cc:812] Training of tree  156/300 (tree index:157) done accuracy:0.716667 logloss:0.579925\n",
      "I0000 00:00:1729625131.989684 6798488 random_forest.cc:812] Training of tree  166/300 (tree index:167) done accuracy:0.725 logloss:0.57723\n",
      "I0000 00:00:1729625131.989787 6798488 random_forest.cc:812] Training of tree  176/300 (tree index:173) done accuracy:0.725 logloss:0.575087\n",
      "I0000 00:00:1729625131.989974 6798489 random_forest.cc:812] Training of tree  186/300 (tree index:183) done accuracy:0.716667 logloss:0.570438\n",
      "I0000 00:00:1729625131.990175 6798491 random_forest.cc:812] Training of tree  196/300 (tree index:189) done accuracy:0.716667 logloss:0.571307\n",
      "I0000 00:00:1729625131.990364 6798486 random_forest.cc:812] Training of tree  207/300 (tree index:204) done accuracy:0.716667 logloss:0.566148\n",
      "I0000 00:00:1729625131.990521 6798490 random_forest.cc:812] Training of tree  217/300 (tree index:216) done accuracy:0.708333 logloss:0.563541\n",
      "I0000 00:00:1729625131.990722 6798489 random_forest.cc:812] Training of tree  227/300 (tree index:223) done accuracy:0.716667 logloss:0.562894\n",
      "I0000 00:00:1729625131.990890 6798490 random_forest.cc:812] Training of tree  237/300 (tree index:236) done accuracy:0.716667 logloss:0.567938\n",
      "I0000 00:00:1729625131.991071 6798486 random_forest.cc:812] Training of tree  247/300 (tree index:248) done accuracy:0.725 logloss:0.565685\n",
      "I0000 00:00:1729625131.991210 6798486 random_forest.cc:812] Training of tree  257/300 (tree index:254) done accuracy:0.716667 logloss:0.564404\n",
      "I0000 00:00:1729625131.991407 6798486 random_forest.cc:812] Training of tree  267/300 (tree index:268) done accuracy:0.716667 logloss:0.563801\n",
      "I0000 00:00:1729625131.991561 6798491 random_forest.cc:812] Training of tree  278/300 (tree index:273) done accuracy:0.7 logloss:0.564882\n",
      "I0000 00:00:1729625131.991786 6798486 random_forest.cc:812] Training of tree  288/300 (tree index:288) done accuracy:0.716667 logloss:0.563206\n",
      "I0000 00:00:1729625131.991955 6798488 random_forest.cc:812] Training of tree  298/300 (tree index:297) done accuracy:0.725 logloss:0.561359\n",
      "I0000 00:00:1729625131.991999 6798491 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.725 logloss:0.562004\n",
      "I0000 00:00:1729625131.992080 6798477 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.562004\n",
      "I0000 00:00:1729625131.992646 6798477 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphtlgmwxa with prefix 646bb0d1bb4340ea\n",
      "I0000 00:00:1729625131.996295 6798477 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625131.997128 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.562004\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  16  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:32.004057: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmphtlgmwxa/model/ with prefix 646bb0d1bb4340ea\n",
      "I0000 00:00:1729625132.010653 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4626 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:32.010673: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.151190. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.025262\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk1s1y9g3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625132.299188 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625132.299198 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625132.299202 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625132.299272 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625132.299277 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625132.299326 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.299336 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.299342 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.299347 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.299379 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625132.299399 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625132.299558 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625132.299581 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp56xjtx5z/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625132.299632 6798544 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625132.299724 6798544 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625132.300198 6798554 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.674419 logloss:11.7351\n",
      "I0000 00:00:1729625132.300350 6798556 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.70339 logloss:2.25794\n",
      "I0000 00:00:1729625132.300574 6798557 random_forest.cc:812] Training of tree  24/300 (tree index:22) done accuracy:0.75 logloss:0.780478\n",
      "I0000 00:00:1729625132.300808 6798553 random_forest.cc:812] Training of tree  34/300 (tree index:34) done accuracy:0.758333 logloss:0.772623\n",
      "I0000 00:00:1729625132.300976 6798554 random_forest.cc:812] Training of tree  44/300 (tree index:43) done accuracy:0.725 logloss:0.776396\n",
      "I0000 00:00:1729625132.301140 6798560 random_forest.cc:812] Training of tree  54/300 (tree index:56) done accuracy:0.733333 logloss:0.48183\n",
      "I0000 00:00:1729625132.301273 6798554 random_forest.cc:812] Training of tree  64/300 (tree index:63) done accuracy:0.775 logloss:0.496502\n",
      "I0000 00:00:1729625132.301418 6798560 random_forest.cc:812] Training of tree  74/300 (tree index:74) done accuracy:0.758333 logloss:0.494978\n",
      "I0000 00:00:1729625132.301547 6798554 random_forest.cc:812] Training of tree  84/300 (tree index:84) done accuracy:0.775 logloss:0.487822\n",
      "I0000 00:00:1729625132.301711 6798559 random_forest.cc:812] Training of tree  94/300 (tree index:95) done accuracy:0.783333 logloss:0.482636\n",
      "I0000 00:00:1729625132.301864 6798560 random_forest.cc:812] Training of tree  104/300 (tree index:104) done accuracy:0.808333 logloss:0.473799\n",
      "I0000 00:00:1729625132.302106 6798556 random_forest.cc:812] Training of tree  114/300 (tree index:118) done accuracy:0.8 logloss:0.467465\n",
      "I0000 00:00:1729625132.302272 6798557 random_forest.cc:812] Training of tree  124/300 (tree index:124) done accuracy:0.783333 logloss:0.465218\n",
      "I0000 00:00:1729625132.302442 6798553 random_forest.cc:812] Training of tree  134/300 (tree index:135) done accuracy:0.791667 logloss:0.469883\n",
      "I0000 00:00:1729625132.302623 6798556 random_forest.cc:812] Training of tree  144/300 (tree index:145) done accuracy:0.791667 logloss:0.47751\n",
      "I0000 00:00:1729625132.302787 6798556 random_forest.cc:812] Training of tree  154/300 (tree index:155) done accuracy:0.791667 logloss:0.478437\n",
      "I0000 00:00:1729625132.302977 6798555 random_forest.cc:812] Training of tree  164/300 (tree index:165) done accuracy:0.791667 logloss:0.478063\n",
      "I0000 00:00:1729625132.303114 6798556 random_forest.cc:812] Training of tree  174/300 (tree index:176) done accuracy:0.8 logloss:0.474893\n",
      "I0000 00:00:1729625132.303296 6798558 random_forest.cc:812] Training of tree  186/300 (tree index:185) done accuracy:0.791667 logloss:0.482909\n",
      "I0000 00:00:1729625132.303518 6798558 random_forest.cc:812] Training of tree  196/300 (tree index:198) done accuracy:0.8 logloss:0.479998\n",
      "I0000 00:00:1729625132.303729 6798553 random_forest.cc:812] Training of tree  206/300 (tree index:208) done accuracy:0.791667 logloss:0.478565\n",
      "I0000 00:00:1729625132.303932 6798556 random_forest.cc:812] Training of tree  216/300 (tree index:219) done accuracy:0.791667 logloss:0.47348\n",
      "I0000 00:00:1729625132.304080 6798557 random_forest.cc:812] Training of tree  226/300 (tree index:229) done accuracy:0.8 logloss:0.478531\n",
      "I0000 00:00:1729625132.304272 6798560 random_forest.cc:812] Training of tree  236/300 (tree index:221) done accuracy:0.8 logloss:0.478899\n",
      "I0000 00:00:1729625132.304446 6798554 random_forest.cc:812] Training of tree  246/300 (tree index:245) done accuracy:0.808333 logloss:0.477898\n",
      "I0000 00:00:1729625132.304611 6798554 random_forest.cc:812] Training of tree  256/300 (tree index:257) done accuracy:0.808333 logloss:0.479351\n",
      "I0000 00:00:1729625132.304828 6798556 random_forest.cc:812] Training of tree  266/300 (tree index:256) done accuracy:0.8 logloss:0.481281\n",
      "I0000 00:00:1729625132.304985 6798555 random_forest.cc:812] Training of tree  277/300 (tree index:278) done accuracy:0.8 logloss:0.481491\n",
      "I0000 00:00:1729625132.305219 6798555 random_forest.cc:812] Training of tree  287/300 (tree index:284) done accuracy:0.8 logloss:0.480917\n",
      "I0000 00:00:1729625132.305425 6798560 random_forest.cc:812] Training of tree  297/300 (tree index:297) done accuracy:0.8 logloss:0.479932\n",
      "I0000 00:00:1729625132.305446 6798554 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.8 logloss:0.479951\n",
      "I0000 00:00:1729625132.305555 6798544 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.479951\n",
      "I0000 00:00:1729625132.306016 6798544 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp56xjtx5z with prefix 654a210dee2f4945\n",
      "I0000 00:00:1729625132.308482 6798544 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625132.309659 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.479951\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:32.315468: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp56xjtx5z/model/ with prefix 654a210dee2f4945\n",
      "I0000 00:00:1729625132.321703 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4352 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:32.321727: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.149289. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.024375\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 20, 'min_examples': 10, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptms1zh57 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625132.610953 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625132.610963 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625132.610966 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625132.611032 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625132.611037 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625132.611081 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.611090 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.611096 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.611101 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.611128 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625132.611147 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625132.611287 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625132.611308 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk1s1y9g3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625132.611370 6798613 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625132.611460 6798613 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625132.611996 6798624 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.725 logloss:9.912\n",
      "I0000 00:00:1729625132.612252 6798622 random_forest.cc:812] Training of tree  11/300 (tree index:9) done accuracy:0.773109 logloss:2.74265\n",
      "I0000 00:00:1729625132.612479 6798624 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.741667 logloss:1.07646\n",
      "I0000 00:00:1729625132.612621 6798628 random_forest.cc:812] Training of tree  31/300 (tree index:29) done accuracy:0.725 logloss:0.791864\n",
      "I0000 00:00:1729625132.612790 6798624 random_forest.cc:812] Training of tree  41/300 (tree index:41) done accuracy:0.766667 logloss:0.498543\n",
      "I0000 00:00:1729625132.612933 6798628 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.75 logloss:0.491969\n",
      "I0000 00:00:1729625132.613075 6798625 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.758333 logloss:0.479993\n",
      "I0000 00:00:1729625132.613277 6798627 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.775 logloss:0.492625\n",
      "I0000 00:00:1729625132.613450 6798624 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.766667 logloss:0.490216\n",
      "I0000 00:00:1729625132.613647 6798629 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.758333 logloss:0.491319\n",
      "I0000 00:00:1729625132.613793 6798624 random_forest.cc:812] Training of tree  102/300 (tree index:101) done accuracy:0.766667 logloss:0.493052\n",
      "I0000 00:00:1729625132.613943 6798623 random_forest.cc:812] Training of tree  113/300 (tree index:110) done accuracy:0.766667 logloss:0.49558\n",
      "I0000 00:00:1729625132.614186 6798626 random_forest.cc:812] Training of tree  123/300 (tree index:124) done accuracy:0.775 logloss:0.495977\n",
      "I0000 00:00:1729625132.614304 6798622 random_forest.cc:812] Training of tree  133/300 (tree index:133) done accuracy:0.75 logloss:0.492706\n",
      "I0000 00:00:1729625132.614514 6798623 random_forest.cc:812] Training of tree  144/300 (tree index:146) done accuracy:0.75 logloss:0.496653\n",
      "I0000 00:00:1729625132.614765 6798624 random_forest.cc:812] Training of tree  155/300 (tree index:153) done accuracy:0.741667 logloss:0.500042\n",
      "I0000 00:00:1729625132.615017 6798627 random_forest.cc:812] Training of tree  167/300 (tree index:166) done accuracy:0.75 logloss:0.497989\n",
      "I0000 00:00:1729625132.615182 6798629 random_forest.cc:812] Training of tree  177/300 (tree index:178) done accuracy:0.75 logloss:0.495086\n",
      "I0000 00:00:1729625132.615332 6798627 random_forest.cc:812] Training of tree  187/300 (tree index:185) done accuracy:0.75 logloss:0.49627\n",
      "I0000 00:00:1729625132.615512 6798628 random_forest.cc:812] Training of tree  197/300 (tree index:196) done accuracy:0.75 logloss:0.495283\n",
      "I0000 00:00:1729625132.615677 6798629 random_forest.cc:812] Training of tree  207/300 (tree index:198) done accuracy:0.75 logloss:0.490509\n",
      "I0000 00:00:1729625132.615802 6798624 random_forest.cc:812] Training of tree  217/300 (tree index:216) done accuracy:0.758333 logloss:0.487828\n",
      "I0000 00:00:1729625132.616000 6798629 random_forest.cc:812] Training of tree  227/300 (tree index:227) done accuracy:0.758333 logloss:0.488453\n",
      "I0000 00:00:1729625132.616203 6798622 random_forest.cc:812] Training of tree  237/300 (tree index:236) done accuracy:0.741667 logloss:0.490979\n",
      "I0000 00:00:1729625132.616374 6798623 random_forest.cc:812] Training of tree  247/300 (tree index:246) done accuracy:0.758333 logloss:0.491017\n",
      "I0000 00:00:1729625132.616507 6798622 random_forest.cc:812] Training of tree  257/300 (tree index:258) done accuracy:0.741667 logloss:0.493366\n",
      "I0000 00:00:1729625132.616690 6798625 random_forest.cc:812] Training of tree  267/300 (tree index:266) done accuracy:0.75 logloss:0.491574\n",
      "I0000 00:00:1729625132.616898 6798627 random_forest.cc:812] Training of tree  277/300 (tree index:276) done accuracy:0.758333 logloss:0.491378\n",
      "I0000 00:00:1729625132.617046 6798626 random_forest.cc:812] Training of tree  287/300 (tree index:288) done accuracy:0.766667 logloss:0.492754\n",
      "I0000 00:00:1729625132.617198 6798625 random_forest.cc:812] Training of tree  297/300 (tree index:298) done accuracy:0.758333 logloss:0.489841\n",
      "I0000 00:00:1729625132.617247 6798622 random_forest.cc:812] Training of tree  300/300 (tree index:295) done accuracy:0.75 logloss:0.489819\n",
      "I0000 00:00:1729625132.617326 6798613 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.489819\n",
      "I0000 00:00:1729625132.617833 6798613 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk1s1y9g3 with prefix 45199c753afe477f\n",
      "I0000 00:00:1729625132.620289 6798613 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625132.620871 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.489819\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  16\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:32.627077: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk1s1y9g3/model/ with prefix 45199c753afe477f\n",
      "I0000 00:00:1729625132.632911 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4508 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:32.632935: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.148738. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022421\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpswkg08yo as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625132.916969 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625132.916983 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625132.916987 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625132.917051 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625132.917056 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625132.917101 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.917111 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.917116 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.917121 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625132.917148 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625132.917168 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625132.917300 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625132.917324 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptms1zh57/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625132.917373 6798681 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625132.917476 6798681 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625132.917989 6798693 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625132.918166 6798696 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.747899 logloss:2.22807\n",
      "I0000 00:00:1729625132.918325 6798697 random_forest.cc:812] Training of tree  22/300 (tree index:21) done accuracy:0.741667 logloss:1.95011\n",
      "I0000 00:00:1729625132.918522 6798696 random_forest.cc:812] Training of tree  32/300 (tree index:32) done accuracy:0.783333 logloss:1.37934\n",
      "I0000 00:00:1729625132.918704 6798696 random_forest.cc:812] Training of tree  42/300 (tree index:40) done accuracy:0.741667 logloss:0.839011\n",
      "I0000 00:00:1729625132.918845 6798692 random_forest.cc:812] Training of tree  52/300 (tree index:47) done accuracy:0.75 logloss:0.561426\n",
      "I0000 00:00:1729625132.918991 6798691 random_forest.cc:812] Training of tree  62/300 (tree index:62) done accuracy:0.733333 logloss:0.54733\n",
      "I0000 00:00:1729625132.919124 6798695 random_forest.cc:812] Training of tree  72/300 (tree index:73) done accuracy:0.691667 logloss:0.550363\n",
      "I0000 00:00:1729625132.919221 6798696 random_forest.cc:812] Training of tree  82/300 (tree index:80) done accuracy:0.691667 logloss:0.549548\n",
      "I0000 00:00:1729625132.919364 6798695 random_forest.cc:812] Training of tree  92/300 (tree index:90) done accuracy:0.708333 logloss:0.553636\n",
      "I0000 00:00:1729625132.919505 6798693 random_forest.cc:812] Training of tree  102/300 (tree index:101) done accuracy:0.708333 logloss:0.557936\n",
      "I0000 00:00:1729625132.919779 6798697 random_forest.cc:812] Training of tree  116/300 (tree index:110) done accuracy:0.7 logloss:0.552712\n",
      "I0000 00:00:1729625132.919980 6798690 random_forest.cc:812] Training of tree  126/300 (tree index:125) done accuracy:0.716667 logloss:0.554588\n",
      "I0000 00:00:1729625132.920131 6798693 random_forest.cc:812] Training of tree  136/300 (tree index:137) done accuracy:0.7 logloss:0.550092\n",
      "I0000 00:00:1729625132.920282 6798692 random_forest.cc:812] Training of tree  146/300 (tree index:145) done accuracy:0.716667 logloss:0.551274\n",
      "I0000 00:00:1729625132.920430 6798693 random_forest.cc:812] Training of tree  156/300 (tree index:157) done accuracy:0.716667 logloss:0.54737\n",
      "I0000 00:00:1729625132.920612 6798692 random_forest.cc:812] Training of tree  168/300 (tree index:167) done accuracy:0.708333 logloss:0.550764\n",
      "I0000 00:00:1729625132.920868 6798697 random_forest.cc:812] Training of tree  178/300 (tree index:177) done accuracy:0.708333 logloss:0.549087\n",
      "I0000 00:00:1729625132.921018 6798690 random_forest.cc:812] Training of tree  188/300 (tree index:189) done accuracy:0.708333 logloss:0.545581\n",
      "I0000 00:00:1729625132.921130 6798693 random_forest.cc:812] Training of tree  198/300 (tree index:197) done accuracy:0.708333 logloss:0.544035\n",
      "I0000 00:00:1729625132.921297 6798691 random_forest.cc:812] Training of tree  208/300 (tree index:207) done accuracy:0.691667 logloss:0.549171\n",
      "I0000 00:00:1729625132.921448 6798696 random_forest.cc:812] Training of tree  218/300 (tree index:219) done accuracy:0.7 logloss:0.547688\n",
      "I0000 00:00:1729625132.921615 6798693 random_forest.cc:812] Training of tree  229/300 (tree index:230) done accuracy:0.7 logloss:0.547324\n",
      "I0000 00:00:1729625132.921770 6798690 random_forest.cc:812] Training of tree  239/300 (tree index:238) done accuracy:0.716667 logloss:0.546319\n",
      "I0000 00:00:1729625132.921925 6798694 random_forest.cc:812] Training of tree  249/300 (tree index:251) done accuracy:0.7 logloss:0.547849\n",
      "I0000 00:00:1729625132.922069 6798693 random_forest.cc:812] Training of tree  260/300 (tree index:248) done accuracy:0.725 logloss:0.548708\n",
      "I0000 00:00:1729625132.922212 6798697 random_forest.cc:812] Training of tree  270/300 (tree index:269) done accuracy:0.716667 logloss:0.548756\n",
      "I0000 00:00:1729625132.922377 6798693 random_forest.cc:812] Training of tree  280/300 (tree index:279) done accuracy:0.725 logloss:0.546622\n",
      "I0000 00:00:1729625132.922567 6798690 random_forest.cc:812] Training of tree  290/300 (tree index:289) done accuracy:0.716667 logloss:0.544403\n",
      "I0000 00:00:1729625132.922701 6798697 random_forest.cc:812] Training of tree  300/300 (tree index:295) done accuracy:0.725 logloss:0.54404\n",
      "I0000 00:00:1729625132.922832 6798681 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.54404\n",
      "I0000 00:00:1729625132.923250 6798681 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptms1zh57 with prefix 83ad0a723a9a404c\n",
      "I0000 00:00:1729625132.925424 6798681 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625132.926071 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.54404\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  16  46\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:32.932155: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptms1zh57/model/ with prefix 83ad0a723a9a404c\n",
      "I0000 00:00:1729625132.937207 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3792 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:32.937234: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147087. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021940\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk_chf_la as temporary training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625133.219041 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625133.219055 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625133.219060 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625133.219123 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625133.219128 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625133.219173 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.219182 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.219188 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.219193 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.219220 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625133.219240 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625133.219373 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625133.219396 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpswkg08yo/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625133.219453 6798748 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625133.219575 6798748 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625133.220137 6798764 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.773585 logloss:8.16083\n",
      "I0000 00:00:1729625133.220278 6798759 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.666667 logloss:3.65956\n",
      "I0000 00:00:1729625133.220415 6798761 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.7 logloss:1.43498\n",
      "I0000 00:00:1729625133.220556 6798764 random_forest.cc:812] Training of tree  31/300 (tree index:29) done accuracy:0.691667 logloss:1.14013\n",
      "I0000 00:00:1729625133.220742 6798762 random_forest.cc:812] Training of tree  41/300 (tree index:39) done accuracy:0.708333 logloss:0.584166\n",
      "I0000 00:00:1729625133.220873 6798757 random_forest.cc:812] Training of tree  51/300 (tree index:51) done accuracy:0.708333 logloss:0.581682\n",
      "I0000 00:00:1729625133.221060 6798760 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.716667 logloss:0.576607\n",
      "I0000 00:00:1729625133.221253 6798761 random_forest.cc:812] Training of tree  72/300 (tree index:71) done accuracy:0.733333 logloss:0.573703\n",
      "I0000 00:00:1729625133.221418 6798761 random_forest.cc:812] Training of tree  82/300 (tree index:83) done accuracy:0.733333 logloss:0.571323\n",
      "I0000 00:00:1729625133.221570 6798763 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.741667 logloss:0.562623\n",
      "I0000 00:00:1729625133.221694 6798764 random_forest.cc:812] Training of tree  102/300 (tree index:100) done accuracy:0.758333 logloss:0.556554\n",
      "I0000 00:00:1729625133.221859 6798763 random_forest.cc:812] Training of tree  112/300 (tree index:111) done accuracy:0.766667 logloss:0.555326\n",
      "I0000 00:00:1729625133.222033 6798759 random_forest.cc:812] Training of tree  122/300 (tree index:121) done accuracy:0.766667 logloss:0.559748\n",
      "I0000 00:00:1729625133.222201 6798758 random_forest.cc:812] Training of tree  133/300 (tree index:133) done accuracy:0.766667 logloss:0.561488\n",
      "I0000 00:00:1729625133.222344 6798760 random_forest.cc:812] Training of tree  143/300 (tree index:143) done accuracy:0.775 logloss:0.560264\n",
      "I0000 00:00:1729625133.222491 6798764 random_forest.cc:812] Training of tree  153/300 (tree index:153) done accuracy:0.758333 logloss:0.559417\n",
      "I0000 00:00:1729625133.222617 6798763 random_forest.cc:812] Training of tree  163/300 (tree index:163) done accuracy:0.758333 logloss:0.565573\n",
      "I0000 00:00:1729625133.222774 6798759 random_forest.cc:812] Training of tree  173/300 (tree index:172) done accuracy:0.766667 logloss:0.566309\n",
      "I0000 00:00:1729625133.222907 6798757 random_forest.cc:812] Training of tree  183/300 (tree index:181) done accuracy:0.775 logloss:0.560308\n",
      "I0000 00:00:1729625133.223079 6798757 random_forest.cc:812] Training of tree  194/300 (tree index:195) done accuracy:0.783333 logloss:0.559479\n",
      "I0000 00:00:1729625133.223216 6798757 random_forest.cc:812] Training of tree  204/300 (tree index:200) done accuracy:0.783333 logloss:0.558943\n",
      "I0000 00:00:1729625133.223368 6798759 random_forest.cc:812] Training of tree  214/300 (tree index:214) done accuracy:0.766667 logloss:0.561502\n",
      "I0000 00:00:1729625133.223510 6798762 random_forest.cc:812] Training of tree  226/300 (tree index:226) done accuracy:0.766667 logloss:0.560277\n",
      "I0000 00:00:1729625133.223723 6798759 random_forest.cc:812] Training of tree  236/300 (tree index:235) done accuracy:0.766667 logloss:0.557568\n",
      "I0000 00:00:1729625133.223846 6798763 random_forest.cc:812] Training of tree  246/300 (tree index:247) done accuracy:0.758333 logloss:0.558132\n",
      "I0000 00:00:1729625133.223986 6798760 random_forest.cc:812] Training of tree  256/300 (tree index:257) done accuracy:0.791667 logloss:0.554803\n",
      "I0000 00:00:1729625133.224108 6798764 random_forest.cc:812] Training of tree  266/300 (tree index:265) done accuracy:0.791667 logloss:0.554097\n",
      "I0000 00:00:1729625133.224238 6798762 random_forest.cc:812] Training of tree  276/300 (tree index:276) done accuracy:0.8 logloss:0.550124\n",
      "I0000 00:00:1729625133.224425 6798764 random_forest.cc:812] Training of tree  288/300 (tree index:288) done accuracy:0.783333 logloss:0.551599\n",
      "I0000 00:00:1729625133.224605 6798759 random_forest.cc:812] Training of tree  298/300 (tree index:298) done accuracy:0.791667 logloss:0.550623\n",
      "I0000 00:00:1729625133.224646 6798760 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.791667 logloss:0.551257\n",
      "I0000 00:00:1729625133.224742 6798748 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.551257\n",
      "I0000 00:00:1729625133.225172 6798748 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpswkg08yo with prefix de2ccbe526e54aa1\n",
      "I0000 00:00:1729625133.227550 6798748 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625133.228162 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.551257\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  11  56\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:33.233495: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpswkg08yo/model/ with prefix de2ccbe526e54aa1\n",
      "I0000 00:00:1729625133.238484 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3804 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:33.238518: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.159919. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021469\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625133.583023 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625133.583032 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625133.583036 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625133.583098 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625133.583102 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625133.583146 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.583155 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.583161 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.583166 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.583193 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625133.583210 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625133.583350 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625133.583379 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk_chf_la/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625133.583435 6798821 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625133.583533 6798821 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625133.584101 6798831 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625133.584253 6798835 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.638655 logloss:2.57489\n",
      "I0000 00:00:1729625133.584398 6798837 random_forest.cc:812] Training of tree  21/300 (tree index:19) done accuracy:0.675 logloss:1.4588\n",
      "I0000 00:00:1729625133.584536 6798833 random_forest.cc:812] Training of tree  31/300 (tree index:29) done accuracy:0.7 logloss:1.14715\n",
      "I0000 00:00:1729625133.584714 6798835 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.733333 logloss:0.590228\n",
      "I0000 00:00:1729625133.584870 6798831 random_forest.cc:812] Training of tree  51/300 (tree index:51) done accuracy:0.708333 logloss:0.587034\n",
      "I0000 00:00:1729625133.585037 6798835 random_forest.cc:812] Training of tree  62/300 (tree index:60) done accuracy:0.691667 logloss:0.587056\n",
      "I0000 00:00:1729625133.585191 6798832 random_forest.cc:812] Training of tree  72/300 (tree index:71) done accuracy:0.708333 logloss:0.581286\n",
      "I0000 00:00:1729625133.585378 6798831 random_forest.cc:812] Training of tree  82/300 (tree index:81) done accuracy:0.675 logloss:0.572776\n",
      "I0000 00:00:1729625133.585524 6798837 random_forest.cc:812] Training of tree  93/300 (tree index:83) done accuracy:0.691667 logloss:0.563891\n",
      "I0000 00:00:1729625133.585666 6798835 random_forest.cc:812] Training of tree  103/300 (tree index:101) done accuracy:0.7 logloss:0.566199\n",
      "I0000 00:00:1729625133.585834 6798830 random_forest.cc:812] Training of tree  115/300 (tree index:106) done accuracy:0.691667 logloss:0.561185\n",
      "I0000 00:00:1729625133.586047 6798832 random_forest.cc:812] Training of tree  125/300 (tree index:129) done accuracy:0.691667 logloss:0.554602\n",
      "I0000 00:00:1729625133.586195 6798832 random_forest.cc:812] Training of tree  135/300 (tree index:136) done accuracy:0.7 logloss:0.550044\n",
      "I0000 00:00:1729625133.586421 6798836 random_forest.cc:812] Training of tree  147/300 (tree index:146) done accuracy:0.683333 logloss:0.551808\n",
      "I0000 00:00:1729625133.586596 6798831 random_forest.cc:812] Training of tree  157/300 (tree index:156) done accuracy:0.708333 logloss:0.556273\n",
      "I0000 00:00:1729625133.586715 6798836 random_forest.cc:812] Training of tree  167/300 (tree index:166) done accuracy:0.725 logloss:0.56049\n",
      "I0000 00:00:1729625133.586848 6798835 random_forest.cc:812] Training of tree  177/300 (tree index:179) done accuracy:0.733333 logloss:0.566457\n",
      "I0000 00:00:1729625133.587022 6798836 random_forest.cc:812] Training of tree  187/300 (tree index:185) done accuracy:0.733333 logloss:0.568441\n",
      "I0000 00:00:1729625133.587175 6798834 random_forest.cc:812] Training of tree  199/300 (tree index:198) done accuracy:0.741667 logloss:0.568156\n",
      "I0000 00:00:1729625133.587337 6798833 random_forest.cc:812] Training of tree  209/300 (tree index:209) done accuracy:0.733333 logloss:0.563825\n",
      "I0000 00:00:1729625133.587492 6798830 random_forest.cc:812] Training of tree  219/300 (tree index:219) done accuracy:0.733333 logloss:0.563182\n",
      "I0000 00:00:1729625133.587647 6798837 random_forest.cc:812] Training of tree  229/300 (tree index:232) done accuracy:0.741667 logloss:0.561441\n",
      "I0000 00:00:1729625133.587790 6798836 random_forest.cc:812] Training of tree  239/300 (tree index:239) done accuracy:0.75 logloss:0.560453\n",
      "I0000 00:00:1729625133.587906 6798830 random_forest.cc:812] Training of tree  249/300 (tree index:249) done accuracy:0.758333 logloss:0.558398\n",
      "I0000 00:00:1729625133.588049 6798834 random_forest.cc:812] Training of tree  259/300 (tree index:258) done accuracy:0.75 logloss:0.559611\n",
      "I0000 00:00:1729625133.588181 6798835 random_forest.cc:812] Training of tree  269/300 (tree index:270) done accuracy:0.75 logloss:0.559782\n",
      "I0000 00:00:1729625133.588329 6798831 random_forest.cc:812] Training of tree  279/300 (tree index:278) done accuracy:0.741667 logloss:0.55783\n",
      "I0000 00:00:1729625133.588438 6798833 random_forest.cc:812] Training of tree  289/300 (tree index:288) done accuracy:0.741667 logloss:0.558049\n",
      "I0000 00:00:1729625133.588663 6798830 random_forest.cc:812] Training of tree  299/300 (tree index:298) done accuracy:0.741667 logloss:0.559875\n",
      "I0000 00:00:1729625133.588688 6798837 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.75 logloss:0.560293\n",
      "I0000 00:00:1729625133.588775 6798821 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.560293\n",
      "I0000 00:00:1729625133.589198 6798821 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk_chf_la with prefix 07cd5111c9ed46d6\n",
      "I0000 00:00:1729625133.591393 6798821 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625133.592030 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.560293\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  18\n",
      "2  12  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:33.597492: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpk_chf_la/model/ with prefix 07cd5111c9ed46d6\n",
      "I0000 00:00:1729625133.602406 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3854 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:33.602421: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpiue_zuhm as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147030. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021102\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625133.885998 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625133.886012 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625133.886016 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625133.886087 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625133.886092 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625133.886138 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.886150 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.886156 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.886162 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625133.886193 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625133.886212 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625133.886357 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625133.886379 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpiue_zuhm/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625133.886440 6798890 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625133.886565 6798890 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625133.887094 6798906 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625133.887227 6798902 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.714286 logloss:5.09963\n",
      "I0000 00:00:1729625133.887408 6798901 random_forest.cc:812] Training of tree  21/300 (tree index:19) done accuracy:0.733333 logloss:1.08541\n",
      "I0000 00:00:1729625133.887538 6798906 random_forest.cc:812] Training of tree  32/300 (tree index:32) done accuracy:0.741667 logloss:0.790313\n",
      "I0000 00:00:1729625133.887685 6798900 random_forest.cc:812] Training of tree  42/300 (tree index:42) done accuracy:0.75 logloss:0.522023\n",
      "I0000 00:00:1729625133.887822 6798904 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.758333 logloss:0.518074\n",
      "I0000 00:00:1729625133.887931 6798905 random_forest.cc:812] Training of tree  62/300 (tree index:62) done accuracy:0.75 logloss:0.51777\n",
      "I0000 00:00:1729625133.888067 6798899 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.758333 logloss:0.520271\n",
      "I0000 00:00:1729625133.888202 6798902 random_forest.cc:812] Training of tree  82/300 (tree index:73) done accuracy:0.75 logloss:0.523182\n",
      "I0000 00:00:1729625133.888353 6798903 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.75 logloss:0.514622\n",
      "I0000 00:00:1729625133.888491 6798902 random_forest.cc:812] Training of tree  102/300 (tree index:102) done accuracy:0.783333 logloss:0.512599\n",
      "I0000 00:00:1729625133.888633 6798905 random_forest.cc:812] Training of tree  112/300 (tree index:112) done accuracy:0.783333 logloss:0.512619\n",
      "I0000 00:00:1729625133.888790 6798902 random_forest.cc:812] Training of tree  123/300 (tree index:123) done accuracy:0.775 logloss:0.510804\n",
      "I0000 00:00:1729625133.888937 6798901 random_forest.cc:812] Training of tree  133/300 (tree index:133) done accuracy:0.775 logloss:0.498658\n",
      "I0000 00:00:1729625133.889079 6798906 random_forest.cc:812] Training of tree  143/300 (tree index:146) done accuracy:0.775 logloss:0.497496\n",
      "I0000 00:00:1729625133.889206 6798901 random_forest.cc:812] Training of tree  153/300 (tree index:152) done accuracy:0.775 logloss:0.501052\n",
      "I0000 00:00:1729625133.889349 6798903 random_forest.cc:812] Training of tree  164/300 (tree index:164) done accuracy:0.783333 logloss:0.499029\n",
      "I0000 00:00:1729625133.889461 6798900 random_forest.cc:812] Training of tree  174/300 (tree index:173) done accuracy:0.783333 logloss:0.502292\n",
      "I0000 00:00:1729625133.889608 6798904 random_forest.cc:812] Training of tree  184/300 (tree index:183) done accuracy:0.766667 logloss:0.503519\n",
      "I0000 00:00:1729625133.889746 6798906 random_forest.cc:812] Training of tree  194/300 (tree index:193) done accuracy:0.775 logloss:0.500387\n",
      "I0000 00:00:1729625133.889875 6798902 random_forest.cc:812] Training of tree  204/300 (tree index:203) done accuracy:0.775 logloss:0.501234\n",
      "I0000 00:00:1729625133.890022 6798905 random_forest.cc:812] Training of tree  214/300 (tree index:205) done accuracy:0.783333 logloss:0.499274\n",
      "I0000 00:00:1729625133.890133 6798899 random_forest.cc:812] Training of tree  224/300 (tree index:224) done accuracy:0.766667 logloss:0.499483\n",
      "I0000 00:00:1729625133.890271 6798902 random_forest.cc:812] Training of tree  234/300 (tree index:234) done accuracy:0.775 logloss:0.499158\n",
      "I0000 00:00:1729625133.890389 6798905 random_forest.cc:812] Training of tree  244/300 (tree index:245) done accuracy:0.766667 logloss:0.497503\n",
      "I0000 00:00:1729625133.890549 6798905 random_forest.cc:812] Training of tree  254/300 (tree index:255) done accuracy:0.775 logloss:0.496392\n",
      "I0000 00:00:1729625133.890697 6798904 random_forest.cc:812] Training of tree  264/300 (tree index:265) done accuracy:0.775 logloss:0.496181\n",
      "I0000 00:00:1729625133.890888 6798906 random_forest.cc:812] Training of tree  274/300 (tree index:273) done accuracy:0.783333 logloss:0.495004\n",
      "I0000 00:00:1729625133.891025 6798901 random_forest.cc:812] Training of tree  285/300 (tree index:282) done accuracy:0.783333 logloss:0.494784\n",
      "I0000 00:00:1729625133.891254 6798904 random_forest.cc:812] Training of tree  297/300 (tree index:297) done accuracy:0.775 logloss:0.496043\n",
      "I0000 00:00:1729625133.891278 6798899 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.775 logloss:0.496349\n",
      "I0000 00:00:1729625133.891402 6798890 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.496349\n",
      "I0000 00:00:1729625133.891799 6798890 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpiue_zuhm with prefix 2b902eb877e4454d\n",
      "I0000 00:00:1729625133.894104 6798890 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625133.894646 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.496349\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  15\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:33.900070: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpiue_zuhm/model/ with prefix 2b902eb877e4454d\n",
      "I0000 00:00:1729625133.904851 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3648 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:33.904874: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbmjuekoq as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.158944. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022678\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625134.271742 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625134.271752 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625134.271756 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625134.271818 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625134.271824 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625134.271869 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.271879 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.271884 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.271890 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.271918 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625134.271936 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625134.272065 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625134.272091 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbmjuekoq/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625134.272146 6798965 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625134.272244 6798965 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625134.272852 6798974 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.673469 logloss:11.7694\n",
      "I0000 00:00:1729625134.273041 6798979 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.741667 logloss:1.62514\n",
      "I0000 00:00:1729625134.273169 6798978 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.733333 logloss:0.790687\n",
      "I0000 00:00:1729625134.273375 6798976 random_forest.cc:812] Training of tree  32/300 (tree index:31) done accuracy:0.75 logloss:0.773334\n",
      "I0000 00:00:1729625134.273565 6798979 random_forest.cc:812] Training of tree  42/300 (tree index:41) done accuracy:0.783333 logloss:0.506511\n",
      "I0000 00:00:1729625134.273788 6798974 random_forest.cc:812] Training of tree  54/300 (tree index:53) done accuracy:0.766667 logloss:0.515285\n",
      "I0000 00:00:1729625134.274020 6798980 random_forest.cc:812] Training of tree  66/300 (tree index:65) done accuracy:0.75 logloss:0.517435\n",
      "I0000 00:00:1729625134.274187 6798975 random_forest.cc:812] Training of tree  76/300 (tree index:77) done accuracy:0.766667 logloss:0.527972\n",
      "I0000 00:00:1729625134.274355 6798977 random_forest.cc:812] Training of tree  86/300 (tree index:89) done accuracy:0.766667 logloss:0.519678\n",
      "I0000 00:00:1729625134.274513 6798977 random_forest.cc:812] Training of tree  96/300 (tree index:97) done accuracy:0.775 logloss:0.511295\n",
      "I0000 00:00:1729625134.274731 6798981 random_forest.cc:812] Training of tree  106/300 (tree index:108) done accuracy:0.775 logloss:0.520822\n",
      "I0000 00:00:1729625134.274907 6798980 random_forest.cc:812] Training of tree  116/300 (tree index:116) done accuracy:0.775 logloss:0.515924\n",
      "I0000 00:00:1729625134.275032 6798980 random_forest.cc:812] Training of tree  126/300 (tree index:122) done accuracy:0.775 logloss:0.51359\n",
      "I0000 00:00:1729625134.275205 6798980 random_forest.cc:812] Training of tree  136/300 (tree index:136) done accuracy:0.783333 logloss:0.508081\n",
      "I0000 00:00:1729625134.275383 6798975 random_forest.cc:812] Training of tree  146/300 (tree index:140) done accuracy:0.783333 logloss:0.51481\n",
      "I0000 00:00:1729625134.275547 6798977 random_forest.cc:812] Training of tree  156/300 (tree index:156) done accuracy:0.775 logloss:0.516038\n",
      "I0000 00:00:1729625134.275727 6798977 random_forest.cc:812] Training of tree  167/300 (tree index:167) done accuracy:0.783333 logloss:0.515366\n",
      "I0000 00:00:1729625134.275915 6798975 random_forest.cc:812] Training of tree  177/300 (tree index:176) done accuracy:0.783333 logloss:0.512121\n",
      "I0000 00:00:1729625134.276092 6798974 random_forest.cc:812] Training of tree  187/300 (tree index:181) done accuracy:0.783333 logloss:0.51343\n",
      "I0000 00:00:1729625134.276264 6798975 random_forest.cc:812] Training of tree  197/300 (tree index:197) done accuracy:0.783333 logloss:0.515489\n",
      "I0000 00:00:1729625134.276437 6798975 random_forest.cc:812] Training of tree  207/300 (tree index:207) done accuracy:0.775 logloss:0.51585\n",
      "I0000 00:00:1729625134.276605 6798975 random_forest.cc:812] Training of tree  217/300 (tree index:218) done accuracy:0.783333 logloss:0.515913\n",
      "I0000 00:00:1729625134.276737 6798974 random_forest.cc:812] Training of tree  227/300 (tree index:227) done accuracy:0.783333 logloss:0.515756\n",
      "I0000 00:00:1729625134.276941 6798974 random_forest.cc:812] Training of tree  237/300 (tree index:236) done accuracy:0.783333 logloss:0.512318\n",
      "I0000 00:00:1729625134.277115 6798979 random_forest.cc:812] Training of tree  247/300 (tree index:246) done accuracy:0.783333 logloss:0.512866\n",
      "I0000 00:00:1729625134.277378 6798981 random_forest.cc:812] Training of tree  258/300 (tree index:259) done accuracy:0.783333 logloss:0.514019\n",
      "I0000 00:00:1729625134.277549 6798974 random_forest.cc:812] Training of tree  268/300 (tree index:271) done accuracy:0.783333 logloss:0.516441\n",
      "I0000 00:00:1729625134.277731 6798980 random_forest.cc:812] Training of tree  278/300 (tree index:279) done accuracy:0.783333 logloss:0.517018\n",
      "I0000 00:00:1729625134.277925 6798981 random_forest.cc:812] Training of tree  288/300 (tree index:289) done accuracy:0.783333 logloss:0.517603\n",
      "I0000 00:00:1729625134.278166 6798976 random_forest.cc:812] Training of tree  299/300 (tree index:299) done accuracy:0.783333 logloss:0.516903\n",
      "I0000 00:00:1729625134.278220 6798978 random_forest.cc:812] Training of tree  300/300 (tree index:297) done accuracy:0.783333 logloss:0.516345\n",
      "I0000 00:00:1729625134.278266 6798965 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.516345\n",
      "I0000 00:00:1729625134.278741 6798965 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbmjuekoq with prefix 38fd5e17f4f547a5\n",
      "I0000 00:00:1729625134.281061 6798965 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625134.282021 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.516345\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  12  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:34.287475: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpbmjuekoq/model/ with prefix 38fd5e17f4f547a5\n",
      "I0000 00:00:1729625134.292435 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3744 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:34.292454: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 20, 'min_examples': 20, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf7vlbew2 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.150177. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017920\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625134.579386 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625134.579397 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625134.579402 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625134.579468 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625134.579473 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625134.579518 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.579529 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.579535 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.579540 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.579568 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625134.579586 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625134.579726 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625134.579750 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf7vlbew2/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625134.579843 6799037 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625134.579963 6799037 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625134.580561 6799052 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.454545 logloss:19.6602\n",
      "I0000 00:00:1729625134.580703 6799049 random_forest.cc:812] Training of tree  12/300 (tree index:4) done accuracy:0.680672 logloss:3.69948\n",
      "I0000 00:00:1729625134.580841 6799052 random_forest.cc:812] Training of tree  22/300 (tree index:24) done accuracy:0.741667 logloss:2.22558\n",
      "I0000 00:00:1729625134.580948 6799049 random_forest.cc:812] Training of tree  32/300 (tree index:33) done accuracy:0.733333 logloss:1.41117\n",
      "I0000 00:00:1729625134.581082 6799051 random_forest.cc:812] Training of tree  42/300 (tree index:43) done accuracy:0.741667 logloss:1.40601\n",
      "I0000 00:00:1729625134.581236 6799047 random_forest.cc:812] Training of tree  52/300 (tree index:54) done accuracy:0.7 logloss:1.13687\n",
      "I0000 00:00:1729625134.581399 6799051 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.708333 logloss:0.84275\n",
      "I0000 00:00:1729625134.581523 6799046 random_forest.cc:812] Training of tree  72/300 (tree index:71) done accuracy:0.725 logloss:0.838697\n",
      "I0000 00:00:1729625134.581651 6799052 random_forest.cc:812] Training of tree  83/300 (tree index:82) done accuracy:0.716667 logloss:0.851041\n",
      "I0000 00:00:1729625134.581804 6799053 random_forest.cc:812] Training of tree  93/300 (tree index:90) done accuracy:0.7 logloss:0.584986\n",
      "I0000 00:00:1729625134.581915 6799048 random_forest.cc:812] Training of tree  103/300 (tree index:105) done accuracy:0.716667 logloss:0.583891\n",
      "I0000 00:00:1729625134.582029 6799046 random_forest.cc:812] Training of tree  114/300 (tree index:113) done accuracy:0.708333 logloss:0.591388\n",
      "I0000 00:00:1729625134.582220 6799051 random_forest.cc:812] Training of tree  124/300 (tree index:117) done accuracy:0.7 logloss:0.586981\n",
      "I0000 00:00:1729625134.582324 6799052 random_forest.cc:812] Training of tree  134/300 (tree index:133) done accuracy:0.7 logloss:0.589658\n",
      "I0000 00:00:1729625134.582462 6799049 random_forest.cc:812] Training of tree  144/300 (tree index:144) done accuracy:0.691667 logloss:0.584428\n",
      "I0000 00:00:1729625134.582568 6799048 random_forest.cc:812] Training of tree  154/300 (tree index:153) done accuracy:0.708333 logloss:0.582439\n",
      "I0000 00:00:1729625134.582691 6799047 random_forest.cc:812] Training of tree  164/300 (tree index:164) done accuracy:0.725 logloss:0.57789\n",
      "I0000 00:00:1729625134.582794 6799049 random_forest.cc:812] Training of tree  174/300 (tree index:174) done accuracy:0.716667 logloss:0.570387\n",
      "I0000 00:00:1729625134.582928 6799050 random_forest.cc:812] Training of tree  185/300 (tree index:186) done accuracy:0.716667 logloss:0.569435\n",
      "I0000 00:00:1729625134.583045 6799052 random_forest.cc:812] Training of tree  195/300 (tree index:194) done accuracy:0.708333 logloss:0.570964\n",
      "I0000 00:00:1729625134.583174 6799047 random_forest.cc:812] Training of tree  205/300 (tree index:204) done accuracy:0.716667 logloss:0.573709\n",
      "I0000 00:00:1729625134.583277 6799053 random_forest.cc:812] Training of tree  215/300 (tree index:214) done accuracy:0.725 logloss:0.576234\n",
      "I0000 00:00:1729625134.583399 6799050 random_forest.cc:812] Training of tree  225/300 (tree index:224) done accuracy:0.733333 logloss:0.57704\n",
      "I0000 00:00:1729625134.583502 6799053 random_forest.cc:812] Training of tree  235/300 (tree index:235) done accuracy:0.716667 logloss:0.575751\n",
      "I0000 00:00:1729625134.583644 6799047 random_forest.cc:812] Training of tree  245/300 (tree index:245) done accuracy:0.725 logloss:0.573546\n",
      "I0000 00:00:1729625134.583771 6799047 random_forest.cc:812] Training of tree  255/300 (tree index:251) done accuracy:0.733333 logloss:0.573161\n",
      "I0000 00:00:1729625134.583879 6799051 random_forest.cc:812] Training of tree  265/300 (tree index:265) done accuracy:0.725 logloss:0.576739\n",
      "I0000 00:00:1729625134.583998 6799048 random_forest.cc:812] Training of tree  275/300 (tree index:275) done accuracy:0.725 logloss:0.574979\n",
      "I0000 00:00:1729625134.584105 6799046 random_forest.cc:812] Training of tree  285/300 (tree index:285) done accuracy:0.725 logloss:0.574907\n",
      "I0000 00:00:1729625134.584223 6799053 random_forest.cc:812] Training of tree  295/300 (tree index:295) done accuracy:0.741667 logloss:0.577926\n",
      "I0000 00:00:1729625134.584278 6799051 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.75 logloss:0.575814\n",
      "I0000 00:00:1729625134.584359 6799037 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.575814\n",
      "I0000 00:00:1729625134.584656 6799037 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf7vlbew2 with prefix 01eb4c81d8c44043\n",
      "I0000 00:00:1729625134.586473 6799037 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625134.587074 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.575814\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  13  49\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:34.592310: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf7vlbew2/model/ with prefix 01eb4c81d8c44043\n",
      "I0000 00:00:1729625134.595535 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2456 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:34.595553: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp94lri4ks as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.149915. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.020555\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625134.928868 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625134.928881 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625134.928886 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625134.928950 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625134.928957 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625134.929001 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.929012 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.929019 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.929024 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625134.929053 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625134.929072 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625134.929206 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625134.929231 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp94lri4ks/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625134.929300 6799105 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625134.929396 6799105 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625134.929946 6799114 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.675 logloss:11.7142\n",
      "I0000 00:00:1729625134.930094 6799119 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.655462 logloss:5.21629\n",
      "I0000 00:00:1729625134.930242 6799119 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.683333 logloss:2.03229\n",
      "I0000 00:00:1729625134.930404 6799120 random_forest.cc:812] Training of tree  32/300 (tree index:30) done accuracy:0.675 logloss:1.18114\n",
      "I0000 00:00:1729625134.930611 6799116 random_forest.cc:812] Training of tree  42/300 (tree index:43) done accuracy:0.725 logloss:0.611391\n",
      "I0000 00:00:1729625134.930806 6799118 random_forest.cc:812] Training of tree  52/300 (tree index:51) done accuracy:0.691667 logloss:0.623919\n",
      "I0000 00:00:1729625134.930966 6799117 random_forest.cc:812] Training of tree  62/300 (tree index:60) done accuracy:0.691667 logloss:0.625872\n",
      "I0000 00:00:1729625134.931113 6799117 random_forest.cc:812] Training of tree  72/300 (tree index:71) done accuracy:0.716667 logloss:0.612218\n",
      "I0000 00:00:1729625134.931261 6799117 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.725 logloss:0.615457\n",
      "I0000 00:00:1729625134.931397 6799117 random_forest.cc:812] Training of tree  92/300 (tree index:92) done accuracy:0.75 logloss:0.595879\n",
      "I0000 00:00:1729625134.931552 6799114 random_forest.cc:812] Training of tree  102/300 (tree index:101) done accuracy:0.758333 logloss:0.586367\n",
      "I0000 00:00:1729625134.931744 6799117 random_forest.cc:812] Training of tree  112/300 (tree index:113) done accuracy:0.733333 logloss:0.595308\n",
      "I0000 00:00:1729625134.931926 6799119 random_forest.cc:812] Training of tree  122/300 (tree index:122) done accuracy:0.75 logloss:0.590375\n",
      "I0000 00:00:1729625134.932164 6799119 random_forest.cc:812] Training of tree  133/300 (tree index:134) done accuracy:0.75 logloss:0.591508\n",
      "I0000 00:00:1729625134.932363 6799116 random_forest.cc:812] Training of tree  143/300 (tree index:144) done accuracy:0.758333 logloss:0.603869\n",
      "I0000 00:00:1729625134.932546 6799114 random_forest.cc:812] Training of tree  153/300 (tree index:153) done accuracy:0.75 logloss:0.605288\n",
      "I0000 00:00:1729625134.932726 6799120 random_forest.cc:812] Training of tree  163/300 (tree index:164) done accuracy:0.75 logloss:0.603396\n",
      "I0000 00:00:1729625134.932918 6799117 random_forest.cc:812] Training of tree  173/300 (tree index:162) done accuracy:0.75 logloss:0.598999\n",
      "I0000 00:00:1729625134.933147 6799121 random_forest.cc:812] Training of tree  183/300 (tree index:184) done accuracy:0.758333 logloss:0.599671\n",
      "I0000 00:00:1729625134.933372 6799120 random_forest.cc:812] Training of tree  193/300 (tree index:194) done accuracy:0.775 logloss:0.599296\n",
      "I0000 00:00:1729625134.933608 6799114 random_forest.cc:812] Training of tree  203/300 (tree index:202) done accuracy:0.766667 logloss:0.599666\n",
      "I0000 00:00:1729625134.933712 6799117 random_forest.cc:812] Training of tree  213/300 (tree index:211) done accuracy:0.766667 logloss:0.59864\n",
      "I0000 00:00:1729625134.933847 6799117 random_forest.cc:812] Training of tree  223/300 (tree index:225) done accuracy:0.758333 logloss:0.59949\n",
      "I0000 00:00:1729625134.934095 6799114 random_forest.cc:812] Training of tree  233/300 (tree index:233) done accuracy:0.758333 logloss:0.595603\n",
      "I0000 00:00:1729625134.934352 6799115 random_forest.cc:812] Training of tree  243/300 (tree index:243) done accuracy:0.766667 logloss:0.595222\n",
      "I0000 00:00:1729625134.934571 6799119 random_forest.cc:812] Training of tree  253/300 (tree index:255) done accuracy:0.775 logloss:0.592035\n",
      "I0000 00:00:1729625134.934710 6799119 random_forest.cc:812] Training of tree  263/300 (tree index:264) done accuracy:0.775 logloss:0.59123\n",
      "I0000 00:00:1729625134.934880 6799120 random_forest.cc:812] Training of tree  273/300 (tree index:272) done accuracy:0.775 logloss:0.587987\n",
      "I0000 00:00:1729625134.935178 6799116 random_forest.cc:812] Training of tree  283/300 (tree index:283) done accuracy:0.775 logloss:0.586985\n",
      "I0000 00:00:1729625134.935333 6799116 random_forest.cc:812] Training of tree  293/300 (tree index:294) done accuracy:0.791667 logloss:0.582556\n",
      "I0000 00:00:1729625134.935479 6799115 random_forest.cc:812] Training of tree  300/300 (tree index:295) done accuracy:0.775 logloss:0.582626\n",
      "I0000 00:00:1729625134.935598 6799105 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.582626\n",
      "I0000 00:00:1729625134.935915 6799105 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp94lri4ks with prefix f955e2220d3e4205\n",
      "I0000 00:00:1729625134.937715 6799105 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625134.938513 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.582626\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  17\n",
      "2  10  57\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:34.944220: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp94lri4ks/model/ with prefix f955e2220d3e4205\n",
      "I0000 00:00:1729625134.947388 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2434 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:34.947417: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfwrymdke as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.183061. Found 120 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625135.278639 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625135.278654 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625135.278666 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625135.278732 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625135.278738 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625135.278782 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.278792 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.278797 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.278802 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.278829 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625135.278848 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625135.278996 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625135.279021 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfwrymdke/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625135.279126 6799172 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625135.279214 6799172 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625135.279812 6799182 random_forest.cc:812] Training of tree  2/300 (tree index:2) done accuracy:0.658537 logloss:12.3076\n",
      "I0000 00:00:1729625135.279951 6799183 random_forest.cc:812] Training of tree  12/300 (tree index:11) done accuracy:0.591667 logloss:3.18355\n",
      "I0000 00:00:1729625135.280074 6799181 random_forest.cc:812] Training of tree  22/300 (tree index:21) done accuracy:0.641667 logloss:0.879846\n",
      "I0000 00:00:1729625135.280188 6799187 random_forest.cc:812] Training of tree  32/300 (tree index:33) done accuracy:0.691667 logloss:0.603191\n",
      "I0000 00:00:1729625135.280304 6799182 random_forest.cc:812] Training of tree  43/300 (tree index:43) done accuracy:0.691667 logloss:0.62619\n",
      "I0000 00:00:1729625135.280477 6799181 random_forest.cc:812] Training of tree  53/300 (tree index:52) done accuracy:0.691667 logloss:0.605742\n",
      "I0000 00:00:1729625135.280606 6799186 random_forest.cc:812] Training of tree  64/300 (tree index:63) done accuracy:0.708333 logloss:0.597845\n",
      "I0000 00:00:1729625135.280809 6799184 random_forest.cc:812] Training of tree  74/300 (tree index:68) done accuracy:0.716667 logloss:0.600445\n",
      "I0000 00:00:1729625135.280954 6799187 random_forest.cc:812] Training of tree  84/300 (tree index:83) done accuracy:0.716667 logloss:0.598954\n",
      "I0000 00:00:1729625135.281100 6799187 random_forest.cc:812] Training of tree  94/300 (tree index:94) done accuracy:0.725 logloss:0.584421\n",
      "I0000 00:00:1729625135.281239 6799187 random_forest.cc:812] Training of tree  104/300 (tree index:104) done accuracy:0.716667 logloss:0.586427\n",
      "I0000 00:00:1729625135.281425 6799182 random_forest.cc:812] Training of tree  114/300 (tree index:109) done accuracy:0.716667 logloss:0.583035\n",
      "I0000 00:00:1729625135.281572 6799187 random_forest.cc:812] Training of tree  124/300 (tree index:125) done accuracy:0.708333 logloss:0.587961\n",
      "I0000 00:00:1729625135.281689 6799182 random_forest.cc:812] Training of tree  134/300 (tree index:134) done accuracy:0.7 logloss:0.58988\n",
      "I0000 00:00:1729625135.281803 6799183 random_forest.cc:812] Training of tree  144/300 (tree index:143) done accuracy:0.683333 logloss:0.593332\n",
      "I0000 00:00:1729625135.281928 6799184 random_forest.cc:812] Training of tree  154/300 (tree index:155) done accuracy:0.7 logloss:0.594479\n",
      "I0000 00:00:1729625135.282041 6799188 random_forest.cc:812] Training of tree  164/300 (tree index:162) done accuracy:0.708333 logloss:0.589432\n",
      "I0000 00:00:1729625135.282141 6799187 random_forest.cc:812] Training of tree  174/300 (tree index:174) done accuracy:0.7 logloss:0.589534\n",
      "I0000 00:00:1729625135.282275 6799185 random_forest.cc:812] Training of tree  184/300 (tree index:183) done accuracy:0.725 logloss:0.586896\n",
      "I0000 00:00:1729625135.282419 6799183 random_forest.cc:812] Training of tree  194/300 (tree index:197) done accuracy:0.725 logloss:0.586666\n",
      "I0000 00:00:1729625135.282520 6799188 random_forest.cc:812] Training of tree  204/300 (tree index:202) done accuracy:0.708333 logloss:0.590495\n",
      "I0000 00:00:1729625135.282687 6799185 random_forest.cc:812] Training of tree  216/300 (tree index:215) done accuracy:0.725 logloss:0.595001\n",
      "I0000 00:00:1729625135.282845 6799186 random_forest.cc:812] Training of tree  227/300 (tree index:225) done accuracy:0.708333 logloss:0.591731\n",
      "I0000 00:00:1729625135.282990 6799187 random_forest.cc:812] Training of tree  237/300 (tree index:229) done accuracy:0.716667 logloss:0.592866\n",
      "I0000 00:00:1729625135.283090 6799188 random_forest.cc:812] Training of tree  247/300 (tree index:247) done accuracy:0.75 logloss:0.58879\n",
      "I0000 00:00:1729625135.283214 6799187 random_forest.cc:812] Training of tree  257/300 (tree index:255) done accuracy:0.733333 logloss:0.588441\n",
      "I0000 00:00:1729625135.283360 6799181 random_forest.cc:812] Training of tree  267/300 (tree index:270) done accuracy:0.741667 logloss:0.589018\n",
      "I0000 00:00:1729625135.283468 6799184 random_forest.cc:812] Training of tree  277/300 (tree index:276) done accuracy:0.716667 logloss:0.591809\n",
      "I0000 00:00:1729625135.283610 6799185 random_forest.cc:812] Training of tree  287/300 (tree index:281) done accuracy:0.716667 logloss:0.593477\n",
      "I0000 00:00:1729625135.283768 6799186 random_forest.cc:812] Training of tree  299/300 (tree index:298) done accuracy:0.733333 logloss:0.591359\n",
      "I0000 00:00:1729625135.283803 6799188 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.716667 logloss:0.592224\n",
      "I0000 00:00:1729625135.283894 6799172 random_forest.cc:892] Final OOB metrics: accuracy:0.716667 logloss:0.592224\n",
      "I0000 00:00:1729625135.284184 6799172 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfwrymdke with prefix 5b2fdaa2fd8d45c6\n",
      "I0000 00:00:1729625135.286207 6799172 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625135.287018 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.716667  CI95[W][0.641252 0.783854]\n",
      "LogLoss: : 0.592224\n",
      "ErrorRate: : 0.283333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  34  20\n",
      "2  14  52\n",
      "Total: 120\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.020644\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpe08p4kst as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 20:25:35.293727: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfwrymdke/model/ with prefix 5b2fdaa2fd8d45c6\n",
      "I0000 00:00:1729625135.297071 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2434 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:35.297090: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145818. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018062\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6pewiara as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625135.572611 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625135.572623 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625135.572626 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625135.572690 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625135.572695 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625135.572737 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.572746 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.572752 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.572757 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.572782 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625135.572800 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625135.572925 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625135.572949 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpe08p4kst/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625135.572997 6799240 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625135.573148 6799240 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625135.573640 6799252 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625135.573768 6799250 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.716667 logloss:2.78367\n",
      "I0000 00:00:1729625135.573946 6799254 random_forest.cc:812] Training of tree  21/300 (tree index:19) done accuracy:0.75 logloss:1.93109\n",
      "I0000 00:00:1729625135.574073 6799249 random_forest.cc:812] Training of tree  31/300 (tree index:32) done accuracy:0.75 logloss:1.09202\n",
      "I0000 00:00:1729625135.574210 6799255 random_forest.cc:812] Training of tree  42/300 (tree index:31) done accuracy:0.741667 logloss:1.08649\n",
      "I0000 00:00:1729625135.574401 6799255 random_forest.cc:812] Training of tree  54/300 (tree index:53) done accuracy:0.733333 logloss:0.544006\n",
      "I0000 00:00:1729625135.574542 6799253 random_forest.cc:812] Training of tree  64/300 (tree index:61) done accuracy:0.741667 logloss:0.52649\n",
      "I0000 00:00:1729625135.574701 6799249 random_forest.cc:812] Training of tree  74/300 (tree index:76) done accuracy:0.75 logloss:0.516807\n",
      "I0000 00:00:1729625135.574826 6799255 random_forest.cc:812] Training of tree  86/300 (tree index:85) done accuracy:0.75 logloss:0.514185\n",
      "I0000 00:00:1729625135.574959 6799255 random_forest.cc:812] Training of tree  96/300 (tree index:96) done accuracy:0.758333 logloss:0.508377\n",
      "I0000 00:00:1729625135.575099 6799250 random_forest.cc:812] Training of tree  107/300 (tree index:106) done accuracy:0.758333 logloss:0.509899\n",
      "I0000 00:00:1729625135.575224 6799254 random_forest.cc:812] Training of tree  117/300 (tree index:116) done accuracy:0.775 logloss:0.508344\n",
      "I0000 00:00:1729625135.575351 6799252 random_forest.cc:812] Training of tree  128/300 (tree index:128) done accuracy:0.791667 logloss:0.511648\n",
      "I0000 00:00:1729625135.575492 6799255 random_forest.cc:812] Training of tree  138/300 (tree index:137) done accuracy:0.808333 logloss:0.511813\n",
      "I0000 00:00:1729625135.575620 6799249 random_forest.cc:812] Training of tree  148/300 (tree index:148) done accuracy:0.808333 logloss:0.511059\n",
      "I0000 00:00:1729625135.575765 6799249 random_forest.cc:812] Training of tree  158/300 (tree index:158) done accuracy:0.791667 logloss:0.514131\n",
      "I0000 00:00:1729625135.575875 6799250 random_forest.cc:812] Training of tree  168/300 (tree index:169) done accuracy:0.775 logloss:0.515068\n",
      "I0000 00:00:1729625135.575975 6799255 random_forest.cc:812] Training of tree  178/300 (tree index:161) done accuracy:0.8 logloss:0.51341\n",
      "I0000 00:00:1729625135.576120 6799253 random_forest.cc:812] Training of tree  188/300 (tree index:188) done accuracy:0.8 logloss:0.513531\n",
      "I0000 00:00:1729625135.576223 6799251 random_forest.cc:812] Training of tree  198/300 (tree index:196) done accuracy:0.808333 logloss:0.509584\n",
      "I0000 00:00:1729625135.576362 6799251 random_forest.cc:812] Training of tree  208/300 (tree index:203) done accuracy:0.8 logloss:0.504661\n",
      "I0000 00:00:1729625135.576478 6799250 random_forest.cc:812] Training of tree  218/300 (tree index:216) done accuracy:0.8 logloss:0.50899\n",
      "I0000 00:00:1729625135.576591 6799252 random_forest.cc:812] Training of tree  228/300 (tree index:229) done accuracy:0.8 logloss:0.51172\n",
      "I0000 00:00:1729625135.576742 6799249 random_forest.cc:812] Training of tree  238/300 (tree index:239) done accuracy:0.791667 logloss:0.511748\n",
      "I0000 00:00:1729625135.576852 6799256 random_forest.cc:812] Training of tree  248/300 (tree index:241) done accuracy:0.783333 logloss:0.511292\n",
      "I0000 00:00:1729625135.576965 6799252 random_forest.cc:812] Training of tree  258/300 (tree index:258) done accuracy:0.8 logloss:0.509266\n",
      "I0000 00:00:1729625135.577083 6799251 random_forest.cc:812] Training of tree  268/300 (tree index:268) done accuracy:0.8 logloss:0.51005\n",
      "I0000 00:00:1729625135.577184 6799253 random_forest.cc:812] Training of tree  278/300 (tree index:278) done accuracy:0.8 logloss:0.509254\n",
      "I0000 00:00:1729625135.577318 6799255 random_forest.cc:812] Training of tree  288/300 (tree index:287) done accuracy:0.8 logloss:0.510227\n",
      "I0000 00:00:1729625135.577436 6799254 random_forest.cc:812] Training of tree  298/300 (tree index:296) done accuracy:0.8 logloss:0.510176\n",
      "I0000 00:00:1729625135.577494 6799255 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.8 logloss:0.511\n",
      "I0000 00:00:1729625135.577587 6799240 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.511\n",
      "I0000 00:00:1729625135.577880 6799240 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpe08p4kst with prefix 37c495f9f88f4b1d\n",
      "I0000 00:00:1729625135.579624 6799240 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625135.580379 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.511\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  15\n",
      "2   9  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:35.585815: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpe08p4kst/model/ with prefix 37c495f9f88f4b1d\n",
      "I0000 00:00:1729625135.588891 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2394 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:35.588907: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147384. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018744\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 20, 'min_examples': 20, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpsgv4wh8w as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625135.869235 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625135.869245 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625135.869249 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625135.869314 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625135.869319 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625135.869365 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.869375 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.869380 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.869385 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625135.869411 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625135.869431 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625135.869563 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625135.869590 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6pewiara/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625135.869662 6799308 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625135.869777 6799308 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625135.870372 6799319 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625135.870503 6799323 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.726496 logloss:3.98918\n",
      "I0000 00:00:1729625135.870629 6799322 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.716667 logloss:1.43621\n",
      "I0000 00:00:1729625135.870739 6799319 random_forest.cc:812] Training of tree  31/300 (tree index:31) done accuracy:0.725 logloss:0.867135\n",
      "I0000 00:00:1729625135.870891 6799322 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.741667 logloss:0.878963\n",
      "I0000 00:00:1729625135.870993 6799318 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.733333 logloss:0.852625\n",
      "I0000 00:00:1729625135.871173 6799322 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.758333 logloss:0.838816\n",
      "I0000 00:00:1729625135.871309 6799317 random_forest.cc:812] Training of tree  73/300 (tree index:72) done accuracy:0.75 logloss:0.832323\n",
      "I0000 00:00:1729625135.871492 6799324 random_forest.cc:812] Training of tree  83/300 (tree index:81) done accuracy:0.741667 logloss:0.841319\n",
      "I0000 00:00:1729625135.871612 6799321 random_forest.cc:812] Training of tree  93/300 (tree index:93) done accuracy:0.733333 logloss:0.836919\n",
      "I0000 00:00:1729625135.871784 6799320 random_forest.cc:812] Training of tree  103/300 (tree index:98) done accuracy:0.741667 logloss:0.840958\n",
      "I0000 00:00:1729625135.871956 6799324 random_forest.cc:812] Training of tree  114/300 (tree index:113) done accuracy:0.733333 logloss:0.835361\n",
      "I0000 00:00:1729625135.872111 6799319 random_forest.cc:812] Training of tree  125/300 (tree index:122) done accuracy:0.75 logloss:0.834506\n",
      "I0000 00:00:1729625135.872300 6799321 random_forest.cc:812] Training of tree  136/300 (tree index:136) done accuracy:0.758333 logloss:0.828725\n",
      "I0000 00:00:1729625135.872482 6799318 random_forest.cc:812] Training of tree  147/300 (tree index:147) done accuracy:0.758333 logloss:0.565005\n",
      "I0000 00:00:1729625135.872634 6799317 random_forest.cc:812] Training of tree  157/300 (tree index:158) done accuracy:0.75 logloss:0.572849\n",
      "I0000 00:00:1729625135.872738 6799320 random_forest.cc:812] Training of tree  167/300 (tree index:168) done accuracy:0.758333 logloss:0.567666\n",
      "I0000 00:00:1729625135.872872 6799322 random_forest.cc:812] Training of tree  177/300 (tree index:177) done accuracy:0.775 logloss:0.557352\n",
      "I0000 00:00:1729625135.873023 6799322 random_forest.cc:812] Training of tree  187/300 (tree index:186) done accuracy:0.75 logloss:0.556883\n",
      "I0000 00:00:1729625135.873156 6799317 random_forest.cc:812] Training of tree  197/300 (tree index:197) done accuracy:0.758333 logloss:0.55356\n",
      "I0000 00:00:1729625135.873280 6799321 random_forest.cc:812] Training of tree  207/300 (tree index:207) done accuracy:0.75 logloss:0.548479\n",
      "I0000 00:00:1729625135.873408 6799318 random_forest.cc:812] Training of tree  217/300 (tree index:218) done accuracy:0.766667 logloss:0.549352\n",
      "I0000 00:00:1729625135.873532 6799322 random_forest.cc:812] Training of tree  227/300 (tree index:227) done accuracy:0.75 logloss:0.5513\n",
      "I0000 00:00:1729625135.873665 6799320 random_forest.cc:812] Training of tree  237/300 (tree index:237) done accuracy:0.766667 logloss:0.552152\n",
      "I0000 00:00:1729625135.873798 6799322 random_forest.cc:812] Training of tree  247/300 (tree index:248) done accuracy:0.741667 logloss:0.553163\n",
      "I0000 00:00:1729625135.873957 6799324 random_forest.cc:812] Training of tree  258/300 (tree index:258) done accuracy:0.741667 logloss:0.553373\n",
      "I0000 00:00:1729625135.874124 6799318 random_forest.cc:812] Training of tree  268/300 (tree index:267) done accuracy:0.733333 logloss:0.55608\n",
      "I0000 00:00:1729625135.874262 6799320 random_forest.cc:812] Training of tree  278/300 (tree index:275) done accuracy:0.75 logloss:0.552595\n",
      "I0000 00:00:1729625135.874417 6799322 random_forest.cc:812] Training of tree  288/300 (tree index:292) done accuracy:0.766667 logloss:0.55212\n",
      "I0000 00:00:1729625135.874573 6799321 random_forest.cc:812] Training of tree  298/300 (tree index:298) done accuracy:0.766667 logloss:0.55025\n",
      "I0000 00:00:1729625135.874612 6799320 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.766667 logloss:0.549098\n",
      "I0000 00:00:1729625135.874661 6799308 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.549098\n",
      "I0000 00:00:1729625135.874943 6799308 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6pewiara with prefix 5e101e42118949f3\n",
      "I0000 00:00:1729625135.876728 6799308 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625135.877415 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.549098\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  18\n",
      "2  10  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:35.883109: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp6pewiara/model/ with prefix 5e101e42118949f3\n",
      "I0000 00:00:1729625135.886224 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2424 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:35.886238: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146244. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016081\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2tvf58zb as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625136.164206 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625136.164217 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625136.164225 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625136.164289 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625136.164299 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625136.164341 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.164351 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.164356 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.164361 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.164388 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625136.164406 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625136.164535 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625136.164559 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpsgv4wh8w/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625136.164618 6799378 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625136.164716 6799378 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625136.165207 6799394 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.716981 logloss:10.201\n",
      "I0000 00:00:1729625136.165297 6799392 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.661017 logloss:5.56696\n",
      "I0000 00:00:1729625136.165493 6799387 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.675 logloss:1.1663\n",
      "I0000 00:00:1729625136.165589 6799389 random_forest.cc:812] Training of tree  32/300 (tree index:31) done accuracy:0.683333 logloss:0.877119\n",
      "I0000 00:00:1729625136.165718 6799389 random_forest.cc:812] Training of tree  43/300 (tree index:44) done accuracy:0.691667 logloss:0.601493\n",
      "I0000 00:00:1729625136.165840 6799389 random_forest.cc:812] Training of tree  53/300 (tree index:52) done accuracy:0.708333 logloss:0.599963\n",
      "I0000 00:00:1729625136.165960 6799389 random_forest.cc:812] Training of tree  63/300 (tree index:65) done accuracy:0.683333 logloss:0.589124\n",
      "I0000 00:00:1729625136.166067 6799388 random_forest.cc:812] Training of tree  74/300 (tree index:73) done accuracy:0.683333 logloss:0.58761\n",
      "I0000 00:00:1729625136.166234 6799389 random_forest.cc:812] Training of tree  84/300 (tree index:83) done accuracy:0.7 logloss:0.584955\n",
      "I0000 00:00:1729625136.166362 6799393 random_forest.cc:812] Training of tree  94/300 (tree index:93) done accuracy:0.675 logloss:0.585795\n",
      "I0000 00:00:1729625136.166475 6799387 random_forest.cc:812] Training of tree  104/300 (tree index:105) done accuracy:0.683333 logloss:0.582751\n",
      "I0000 00:00:1729625136.166626 6799392 random_forest.cc:812] Training of tree  116/300 (tree index:115) done accuracy:0.708333 logloss:0.57364\n",
      "I0000 00:00:1729625136.166731 6799389 random_forest.cc:812] Training of tree  126/300 (tree index:125) done accuracy:0.725 logloss:0.572991\n",
      "I0000 00:00:1729625136.166827 6799390 random_forest.cc:812] Training of tree  136/300 (tree index:136) done accuracy:0.708333 logloss:0.575109\n",
      "I0000 00:00:1729625136.166925 6799392 random_forest.cc:812] Training of tree  146/300 (tree index:145) done accuracy:0.725 logloss:0.578748\n",
      "I0000 00:00:1729625136.167043 6799391 random_forest.cc:812] Training of tree  156/300 (tree index:157) done accuracy:0.725 logloss:0.575159\n",
      "I0000 00:00:1729625136.167139 6799390 random_forest.cc:812] Training of tree  166/300 (tree index:166) done accuracy:0.716667 logloss:0.579097\n",
      "I0000 00:00:1729625136.167233 6799390 random_forest.cc:812] Training of tree  177/300 (tree index:172) done accuracy:0.716667 logloss:0.572547\n",
      "I0000 00:00:1729625136.167338 6799387 random_forest.cc:812] Training of tree  187/300 (tree index:185) done accuracy:0.716667 logloss:0.573819\n",
      "I0000 00:00:1729625136.167453 6799389 random_forest.cc:812] Training of tree  197/300 (tree index:197) done accuracy:0.716667 logloss:0.572499\n",
      "I0000 00:00:1729625136.167549 6799390 random_forest.cc:812] Training of tree  207/300 (tree index:208) done accuracy:0.708333 logloss:0.575433\n",
      "I0000 00:00:1729625136.167662 6799393 random_forest.cc:812] Training of tree  218/300 (tree index:217) done accuracy:0.716667 logloss:0.575853\n",
      "I0000 00:00:1729625136.167782 6799393 random_forest.cc:812] Training of tree  228/300 (tree index:228) done accuracy:0.708333 logloss:0.57489\n",
      "I0000 00:00:1729625136.167924 6799387 random_forest.cc:812] Training of tree  238/300 (tree index:237) done accuracy:0.725 logloss:0.573602\n",
      "I0000 00:00:1729625136.168085 6799387 random_forest.cc:812] Training of tree  248/300 (tree index:246) done accuracy:0.716667 logloss:0.573412\n",
      "I0000 00:00:1729625136.168182 6799389 random_forest.cc:812] Training of tree  258/300 (tree index:258) done accuracy:0.716667 logloss:0.576759\n",
      "I0000 00:00:1729625136.168292 6799390 random_forest.cc:812] Training of tree  268/300 (tree index:268) done accuracy:0.733333 logloss:0.574209\n",
      "I0000 00:00:1729625136.168387 6799387 random_forest.cc:812] Training of tree  278/300 (tree index:278) done accuracy:0.716667 logloss:0.574608\n",
      "I0000 00:00:1729625136.168477 6799393 random_forest.cc:812] Training of tree  288/300 (tree index:285) done accuracy:0.716667 logloss:0.573816\n",
      "I0000 00:00:1729625136.168617 6799393 random_forest.cc:812] Training of tree  299/300 (tree index:299) done accuracy:0.725 logloss:0.57505\n",
      "I0000 00:00:1729625136.168655 6799391 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.725 logloss:0.573882\n",
      "I0000 00:00:1729625136.168691 6799378 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.573882\n",
      "I0000 00:00:1729625136.168916 6799378 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpsgv4wh8w with prefix 94b06d8343744c20\n",
      "I0000 00:00:1729625136.170493 6799378 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625136.171121 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.573882\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  14  48\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:36.175824: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpsgv4wh8w/model/ with prefix 94b06d8343744c20\n",
      "I0000 00:00:1729625136.178434 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1944 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:36.178451: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145239. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017162\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp924fzlby as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625136.455126 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625136.455138 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625136.455142 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625136.455205 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625136.455210 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625136.455256 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.455266 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.455272 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.455277 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.455304 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625136.455321 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625136.455475 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625136.455499 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2tvf58zb/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625136.455559 6799446 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625136.455641 6799446 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625136.456218 6799455 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.574468 logloss:15.3377\n",
      "I0000 00:00:1729625136.456374 6799457 random_forest.cc:812] Training of tree  16/300 (tree index:15) done accuracy:0.641667 logloss:2.90056\n",
      "I0000 00:00:1729625136.456597 6799459 random_forest.cc:812] Training of tree  29/300 (tree index:28) done accuracy:0.7 logloss:1.17436\n",
      "I0000 00:00:1729625136.456730 6799459 random_forest.cc:812] Training of tree  39/300 (tree index:39) done accuracy:0.733333 logloss:0.887944\n",
      "I0000 00:00:1729625136.456869 6799458 random_forest.cc:812] Training of tree  49/300 (tree index:50) done accuracy:0.741667 logloss:0.606435\n",
      "I0000 00:00:1729625136.456980 6799459 random_forest.cc:812] Training of tree  59/300 (tree index:58) done accuracy:0.716667 logloss:0.612993\n",
      "I0000 00:00:1729625136.457078 6799461 random_forest.cc:812] Training of tree  69/300 (tree index:70) done accuracy:0.7 logloss:0.615975\n",
      "I0000 00:00:1729625136.457174 6799455 random_forest.cc:812] Training of tree  79/300 (tree index:80) done accuracy:0.691667 logloss:0.596654\n",
      "I0000 00:00:1729625136.457305 6799459 random_forest.cc:812] Training of tree  89/300 (tree index:89) done accuracy:0.741667 logloss:0.597237\n",
      "I0000 00:00:1729625136.457464 6799462 random_forest.cc:812] Training of tree  99/300 (tree index:98) done accuracy:0.733333 logloss:0.610046\n",
      "I0000 00:00:1729625136.457562 6799455 random_forest.cc:812] Training of tree  110/300 (tree index:110) done accuracy:0.741667 logloss:0.612675\n",
      "I0000 00:00:1729625136.457689 6799455 random_forest.cc:812] Training of tree  121/300 (tree index:123) done accuracy:0.741667 logloss:0.602721\n",
      "I0000 00:00:1729625136.457822 6799462 random_forest.cc:812] Training of tree  133/300 (tree index:133) done accuracy:0.733333 logloss:0.606778\n",
      "I0000 00:00:1729625136.458005 6799455 random_forest.cc:812] Training of tree  143/300 (tree index:142) done accuracy:0.741667 logloss:0.603452\n",
      "I0000 00:00:1729625136.458142 6799462 random_forest.cc:812] Training of tree  154/300 (tree index:153) done accuracy:0.741667 logloss:0.60281\n",
      "I0000 00:00:1729625136.458258 6799460 random_forest.cc:812] Training of tree  164/300 (tree index:163) done accuracy:0.75 logloss:0.605689\n",
      "I0000 00:00:1729625136.458382 6799459 random_forest.cc:812] Training of tree  175/300 (tree index:162) done accuracy:0.733333 logloss:0.604744\n",
      "I0000 00:00:1729625136.458513 6799460 random_forest.cc:812] Training of tree  185/300 (tree index:184) done accuracy:0.741667 logloss:0.601714\n",
      "I0000 00:00:1729625136.458675 6799460 random_forest.cc:812] Training of tree  195/300 (tree index:199) done accuracy:0.758333 logloss:0.600211\n",
      "I0000 00:00:1729625136.458793 6799457 random_forest.cc:812] Training of tree  205/300 (tree index:200) done accuracy:0.758333 logloss:0.602193\n",
      "I0000 00:00:1729625136.458909 6799455 random_forest.cc:812] Training of tree  215/300 (tree index:215) done accuracy:0.766667 logloss:0.600488\n",
      "I0000 00:00:1729625136.459052 6799460 random_forest.cc:812] Training of tree  225/300 (tree index:225) done accuracy:0.75 logloss:0.598921\n",
      "I0000 00:00:1729625136.459186 6799457 random_forest.cc:812] Training of tree  235/300 (tree index:237) done accuracy:0.766667 logloss:0.598437\n",
      "I0000 00:00:1729625136.459308 6799458 random_forest.cc:812] Training of tree  246/300 (tree index:245) done accuracy:0.766667 logloss:0.598921\n",
      "I0000 00:00:1729625136.459492 6799457 random_forest.cc:812] Training of tree  256/300 (tree index:256) done accuracy:0.758333 logloss:0.599429\n",
      "I0000 00:00:1729625136.459613 6799456 random_forest.cc:812] Training of tree  266/300 (tree index:265) done accuracy:0.758333 logloss:0.599263\n",
      "I0000 00:00:1729625136.459749 6799461 random_forest.cc:812] Training of tree  277/300 (tree index:275) done accuracy:0.758333 logloss:0.59839\n",
      "I0000 00:00:1729625136.459878 6799458 random_forest.cc:812] Training of tree  287/300 (tree index:286) done accuracy:0.75 logloss:0.596598\n",
      "I0000 00:00:1729625136.459995 6799460 random_forest.cc:812] Training of tree  297/300 (tree index:298) done accuracy:0.758333 logloss:0.594987\n",
      "I0000 00:00:1729625136.460044 6799457 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.758333 logloss:0.595347\n",
      "I0000 00:00:1729625136.460111 6799446 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.595347\n",
      "I0000 00:00:1729625136.460344 6799446 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2tvf58zb with prefix e68d8d9580ae40ce\n",
      "I0000 00:00:1729625136.462080 6799446 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625136.462713 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.595347\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  17\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:36.467993: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2tvf58zb/model/ with prefix e68d8d9580ae40ce\n",
      "I0000 00:00:1729625136.470547 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1954 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:36.470567: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145293. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017875\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqn8w53xy as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625136.748695 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625136.748707 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625136.748711 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625136.748772 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625136.748776 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625136.748818 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.748830 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.748835 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.748840 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625136.748868 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625136.748886 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625136.749048 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625136.749072 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp924fzlby/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625136.749130 6799513 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625136.749231 6799513 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625136.749858 6799529 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625136.749998 6799525 random_forest.cc:812] Training of tree  13/300 (tree index:6) done accuracy:0.647059 logloss:3.18763\n",
      "I0000 00:00:1729625136.750166 6799529 random_forest.cc:812] Training of tree  23/300 (tree index:25) done accuracy:0.65 logloss:0.887245\n",
      "I0000 00:00:1729625136.750290 6799529 random_forest.cc:812] Training of tree  33/300 (tree index:34) done accuracy:0.716667 logloss:0.866767\n",
      "I0000 00:00:1729625136.750475 6799525 random_forest.cc:812] Training of tree  43/300 (tree index:22) done accuracy:0.708333 logloss:0.596515\n",
      "I0000 00:00:1729625136.750745 6799524 random_forest.cc:812] Training of tree  56/300 (tree index:55) done accuracy:0.7 logloss:0.606989\n",
      "I0000 00:00:1729625136.750939 6799522 random_forest.cc:812] Training of tree  66/300 (tree index:64) done accuracy:0.7 logloss:0.605646\n",
      "I0000 00:00:1729625136.751049 6799527 random_forest.cc:812] Training of tree  76/300 (tree index:76) done accuracy:0.725 logloss:0.605756\n",
      "I0000 00:00:1729625136.751145 6799528 random_forest.cc:812] Training of tree  87/300 (tree index:86) done accuracy:0.708333 logloss:0.610657\n",
      "I0000 00:00:1729625136.751279 6799523 random_forest.cc:812] Training of tree  98/300 (tree index:98) done accuracy:0.7 logloss:0.60439\n",
      "I0000 00:00:1729625136.751423 6799526 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.708333 logloss:0.609057\n",
      "I0000 00:00:1729625136.751570 6799523 random_forest.cc:812] Training of tree  122/300 (tree index:122) done accuracy:0.7 logloss:0.610941\n",
      "I0000 00:00:1729625136.751709 6799524 random_forest.cc:812] Training of tree  133/300 (tree index:135) done accuracy:0.708333 logloss:0.6154\n",
      "I0000 00:00:1729625136.751854 6799527 random_forest.cc:812] Training of tree  143/300 (tree index:144) done accuracy:0.716667 logloss:0.608428\n",
      "I0000 00:00:1729625136.751939 6799525 random_forest.cc:812] Training of tree  153/300 (tree index:152) done accuracy:0.708333 logloss:0.606958\n",
      "I0000 00:00:1729625136.752051 6799528 random_forest.cc:812] Training of tree  163/300 (tree index:164) done accuracy:0.708333 logloss:0.609809\n",
      "I0000 00:00:1729625136.752157 6799523 random_forest.cc:812] Training of tree  173/300 (tree index:158) done accuracy:0.691667 logloss:0.612644\n",
      "I0000 00:00:1729625136.752291 6799529 random_forest.cc:812] Training of tree  183/300 (tree index:182) done accuracy:0.691667 logloss:0.611262\n",
      "I0000 00:00:1729625136.752386 6799525 random_forest.cc:812] Training of tree  193/300 (tree index:192) done accuracy:0.691667 logloss:0.610502\n",
      "I0000 00:00:1729625136.752544 6799525 random_forest.cc:812] Training of tree  203/300 (tree index:203) done accuracy:0.691667 logloss:0.61365\n",
      "I0000 00:00:1729625136.752666 6799526 random_forest.cc:812] Training of tree  213/300 (tree index:214) done accuracy:0.683333 logloss:0.611877\n",
      "I0000 00:00:1729625136.752785 6799526 random_forest.cc:812] Training of tree  223/300 (tree index:224) done accuracy:0.683333 logloss:0.60848\n",
      "I0000 00:00:1729625136.752916 6799526 random_forest.cc:812] Training of tree  233/300 (tree index:233) done accuracy:0.708333 logloss:0.606799\n",
      "I0000 00:00:1729625136.753029 6799526 random_forest.cc:812] Training of tree  243/300 (tree index:245) done accuracy:0.7 logloss:0.604566\n",
      "I0000 00:00:1729625136.753124 6799523 random_forest.cc:812] Training of tree  254/300 (tree index:251) done accuracy:0.7 logloss:0.605427\n",
      "I0000 00:00:1729625136.753250 6799523 random_forest.cc:812] Training of tree  265/300 (tree index:264) done accuracy:0.7 logloss:0.604896\n",
      "I0000 00:00:1729625136.753357 6799522 random_forest.cc:812] Training of tree  275/300 (tree index:274) done accuracy:0.7 logloss:0.605721\n",
      "I0000 00:00:1729625136.753538 6799525 random_forest.cc:812] Training of tree  286/300 (tree index:286) done accuracy:0.7 logloss:0.605679\n",
      "I0000 00:00:1729625136.753694 6799523 random_forest.cc:812] Training of tree  297/300 (tree index:297) done accuracy:0.7 logloss:0.603872\n",
      "I0000 00:00:1729625136.753752 6799524 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.708333 logloss:0.604209\n",
      "I0000 00:00:1729625136.753870 6799513 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.604209\n",
      "I0000 00:00:1729625136.754123 6799513 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp924fzlby with prefix c06741a219714aff\n",
      "I0000 00:00:1729625136.755837 6799513 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625136.756593 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.604209\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  32  22\n",
      "2  13  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:36.762520: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp924fzlby/model/ with prefix c06741a219714aff\n",
      "I0000 00:00:1729625136.765033 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1928 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:36.765050: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146560. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.057146\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq9z907le as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625137.043636 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625137.043645 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625137.043653 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625137.043715 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625137.043720 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625137.043766 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.043776 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.043781 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.043786 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.043814 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625137.043831 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625137.043964 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625137.043991 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqn8w53xy/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625137.044046 6799603 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625137.044152 6799603 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625137.044720 6799619 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625137.044847 6799618 random_forest.cc:812] Training of tree  12/300 (tree index:11) done accuracy:0.655462 logloss:4.92165\n",
      "I0000 00:00:1729625137.045011 6799613 random_forest.cc:812] Training of tree  23/300 (tree index:22) done accuracy:0.675 logloss:1.45999\n",
      "I0000 00:00:1729625137.045166 6799614 random_forest.cc:812] Training of tree  33/300 (tree index:32) done accuracy:0.725 logloss:0.860697\n",
      "I0000 00:00:1729625137.045399 6799615 random_forest.cc:812] Training of tree  43/300 (tree index:42) done accuracy:0.716667 logloss:0.595424\n",
      "I0000 00:00:1729625137.045549 6799615 random_forest.cc:812] Training of tree  53/300 (tree index:52) done accuracy:0.733333 logloss:0.573836\n",
      "I0000 00:00:1729625137.045695 6799613 random_forest.cc:812] Training of tree  63/300 (tree index:64) done accuracy:0.708333 logloss:0.575261\n",
      "I0000 00:00:1729625137.045784 6799619 random_forest.cc:812] Training of tree  73/300 (tree index:74) done accuracy:0.708333 logloss:0.569589\n",
      "I0000 00:00:1729625137.045924 6799618 random_forest.cc:812] Training of tree  83/300 (tree index:84) done accuracy:0.725 logloss:0.564535\n",
      "I0000 00:00:1729625137.046009 6799613 random_forest.cc:812] Training of tree  93/300 (tree index:93) done accuracy:0.741667 logloss:0.561303\n",
      "I0000 00:00:1729625137.046092 6799612 random_forest.cc:812] Training of tree  103/300 (tree index:89) done accuracy:0.741667 logloss:0.556495\n",
      "I0000 00:00:1729625137.046262 6799616 random_forest.cc:812] Training of tree  113/300 (tree index:114) done accuracy:0.741667 logloss:0.553983\n",
      "I0000 00:00:1729625137.046411 6799615 random_forest.cc:812] Training of tree  124/300 (tree index:124) done accuracy:0.733333 logloss:0.554997\n",
      "I0000 00:00:1729625137.046575 6799617 random_forest.cc:812] Training of tree  134/300 (tree index:133) done accuracy:0.733333 logloss:0.549042\n",
      "I0000 00:00:1729625137.046704 6799617 random_forest.cc:812] Training of tree  144/300 (tree index:146) done accuracy:0.75 logloss:0.542799\n",
      "I0000 00:00:1729625137.047227 6799619 random_forest.cc:812] Training of tree  154/300 (tree index:157) done accuracy:0.741667 logloss:0.550414\n",
      "I0000 00:00:1729625137.048356 6799618 random_forest.cc:812] Training of tree  164/300 (tree index:168) done accuracy:0.741667 logloss:0.547114\n",
      "I0000 00:00:1729625137.048725 6799618 random_forest.cc:812] Training of tree  174/300 (tree index:178) done accuracy:0.741667 logloss:0.549518\n",
      "I0000 00:00:1729625137.049103 6799618 random_forest.cc:812] Training of tree  184/300 (tree index:188) done accuracy:0.741667 logloss:0.548506\n",
      "I0000 00:00:1729625137.049945 6799614 random_forest.cc:812] Training of tree  194/300 (tree index:159) done accuracy:0.758333 logloss:0.545318\n",
      "I0000 00:00:1729625137.055846 6799613 random_forest.cc:812] Training of tree  204/300 (tree index:207) done accuracy:0.741667 logloss:0.544775\n",
      "I0000 00:00:1729625137.057327 6799613 random_forest.cc:812] Training of tree  214/300 (tree index:217) done accuracy:0.741667 logloss:0.541284\n",
      "I0000 00:00:1729625137.058979 6799612 random_forest.cc:812] Training of tree  224/300 (tree index:229) done accuracy:0.75 logloss:0.536664\n",
      "I0000 00:00:1729625137.064724 6799614 random_forest.cc:812] Training of tree  234/300 (tree index:238) done accuracy:0.766667 logloss:0.533998\n",
      "I0000 00:00:1729625137.067204 6799619 random_forest.cc:812] Training of tree  244/300 (tree index:249) done accuracy:0.766667 logloss:0.532903\n",
      "I0000 00:00:1729625137.072933 6799614 random_forest.cc:812] Training of tree  254/300 (tree index:259) done accuracy:0.758333 logloss:0.536588\n",
      "I0000 00:00:1729625137.079389 6799614 random_forest.cc:812] Training of tree  264/300 (tree index:269) done accuracy:0.758333 logloss:0.534898\n",
      "I0000 00:00:1729625137.084358 6799614 random_forest.cc:812] Training of tree  274/300 (tree index:278) done accuracy:0.758333 logloss:0.532418\n",
      "I0000 00:00:1729625137.084657 6799618 random_forest.cc:812] Training of tree  284/300 (tree index:280) done accuracy:0.758333 logloss:0.529543\n",
      "I0000 00:00:1729625137.084804 6799616 random_forest.cc:812] Training of tree  294/300 (tree index:294) done accuracy:0.775 logloss:0.529894\n",
      "I0000 00:00:1729625137.084906 6799616 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.775 logloss:0.529773\n",
      "I0000 00:00:1729625137.085094 6799603 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.529773\n",
      "I0000 00:00:1729625137.085358 6799603 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqn8w53xy with prefix 06414f57f2ec4135\n",
      "I0000 00:00:1729625137.087008 6799603 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625137.087948 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.529773\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  17\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:37.096099: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqn8w53xy/model/ with prefix 06414f57f2ec4135\n",
      "I0000 00:00:1729625137.098911 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1950 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:37.098939: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144851. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016552\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 30, 'min_examples': 5, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxkgfqv3v as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625137.374732 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625137.374742 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625137.374746 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625137.374811 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625137.374817 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625137.374861 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.374871 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.374876 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.374881 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.374912 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625137.374930 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625137.375068 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625137.375090 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq9z907le/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625137.375138 6799671 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625137.375221 6799671 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625137.375689 6799681 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625137.375788 6799680 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.705882 logloss:4.56324\n",
      "I0000 00:00:1729625137.375946 6799686 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.683333 logloss:1.16317\n",
      "I0000 00:00:1729625137.376080 6799681 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.733333 logloss:1.14385\n",
      "I0000 00:00:1729625137.376190 6799685 random_forest.cc:812] Training of tree  41/300 (tree index:42) done accuracy:0.716667 logloss:0.86857\n",
      "I0000 00:00:1729625137.376293 6799684 random_forest.cc:812] Training of tree  52/300 (tree index:49) done accuracy:0.675 logloss:0.601562\n",
      "I0000 00:00:1729625137.376422 6799682 random_forest.cc:812] Training of tree  62/300 (tree index:60) done accuracy:0.708333 logloss:0.581136\n",
      "I0000 00:00:1729625137.376547 6799682 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.708333 logloss:0.588499\n",
      "I0000 00:00:1729625137.376747 6799685 random_forest.cc:812] Training of tree  82/300 (tree index:81) done accuracy:0.716667 logloss:0.577831\n",
      "I0000 00:00:1729625137.376849 6799683 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.708333 logloss:0.58496\n",
      "I0000 00:00:1729625137.376990 6799683 random_forest.cc:812] Training of tree  103/300 (tree index:102) done accuracy:0.7 logloss:0.588018\n",
      "I0000 00:00:1729625137.377147 6799686 random_forest.cc:812] Training of tree  113/300 (tree index:113) done accuracy:0.733333 logloss:0.578217\n",
      "I0000 00:00:1729625137.377282 6799686 random_forest.cc:812] Training of tree  123/300 (tree index:124) done accuracy:0.716667 logloss:0.57956\n",
      "I0000 00:00:1729625137.377371 6799682 random_forest.cc:812] Training of tree  133/300 (tree index:132) done accuracy:0.716667 logloss:0.575046\n",
      "I0000 00:00:1729625137.377530 6799684 random_forest.cc:812] Training of tree  143/300 (tree index:144) done accuracy:0.708333 logloss:0.57548\n",
      "I0000 00:00:1729625137.377635 6799680 random_forest.cc:812] Training of tree  153/300 (tree index:154) done accuracy:0.708333 logloss:0.578499\n",
      "I0000 00:00:1729625137.377717 6799681 random_forest.cc:812] Training of tree  163/300 (tree index:162) done accuracy:0.708333 logloss:0.579517\n",
      "I0000 00:00:1729625137.377869 6799680 random_forest.cc:812] Training of tree  173/300 (tree index:174) done accuracy:0.716667 logloss:0.580047\n",
      "I0000 00:00:1729625137.377987 6799684 random_forest.cc:812] Training of tree  183/300 (tree index:183) done accuracy:0.7 logloss:0.577403\n",
      "I0000 00:00:1729625137.378109 6799683 random_forest.cc:812] Training of tree  193/300 (tree index:193) done accuracy:0.708333 logloss:0.574758\n",
      "I0000 00:00:1729625137.378193 6799687 random_forest.cc:812] Training of tree  203/300 (tree index:202) done accuracy:0.708333 logloss:0.575092\n",
      "I0000 00:00:1729625137.378286 6799681 random_forest.cc:812] Training of tree  213/300 (tree index:213) done accuracy:0.7 logloss:0.57559\n",
      "I0000 00:00:1729625137.378374 6799687 random_forest.cc:812] Training of tree  223/300 (tree index:222) done accuracy:0.716667 logloss:0.571846\n",
      "I0000 00:00:1729625137.378500 6799681 random_forest.cc:812] Training of tree  233/300 (tree index:233) done accuracy:0.725 logloss:0.570055\n",
      "I0000 00:00:1729625137.378610 6799681 random_forest.cc:812] Training of tree  244/300 (tree index:245) done accuracy:0.725 logloss:0.568083\n",
      "I0000 00:00:1729625137.378718 6799680 random_forest.cc:812] Training of tree  254/300 (tree index:254) done accuracy:0.725 logloss:0.569623\n",
      "I0000 00:00:1729625137.378861 6799681 random_forest.cc:812] Training of tree  264/300 (tree index:264) done accuracy:0.716667 logloss:0.569557\n",
      "I0000 00:00:1729625137.378987 6799680 random_forest.cc:812] Training of tree  275/300 (tree index:275) done accuracy:0.725 logloss:0.567861\n",
      "I0000 00:00:1729625137.379132 6799687 random_forest.cc:812] Training of tree  285/300 (tree index:284) done accuracy:0.733333 logloss:0.567758\n",
      "I0000 00:00:1729625137.379226 6799686 random_forest.cc:812] Training of tree  295/300 (tree index:295) done accuracy:0.733333 logloss:0.567144\n",
      "I0000 00:00:1729625137.379301 6799686 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.733333 logloss:0.562626\n",
      "I0000 00:00:1729625137.379435 6799671 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.562626\n",
      "I0000 00:00:1729625137.379673 6799671 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq9z907le with prefix 2afe9b93cb804a47\n",
      "I0000 00:00:1729625137.381352 6799671 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625137.381978 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.562626\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  19\n",
      "2  13  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:37.387240: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq9z907le/model/ with prefix 2afe9b93cb804a47\n",
      "I0000 00:00:1729625137.389778 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1930 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:37.389791: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144903. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.030143\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5cuovqwb as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625137.666452 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625137.666461 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625137.666465 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625137.666539 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625137.666545 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625137.666593 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.666603 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.666609 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.666614 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.666643 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625137.666660 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625137.666796 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625137.666822 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxkgfqv3v/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625137.666883 6799740 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625137.666981 6799740 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625137.667459 6799750 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.55814 logloss:15.9263\n",
      "I0000 00:00:1729625137.667673 6799752 random_forest.cc:812] Training of tree  12/300 (tree index:12) done accuracy:0.714286 logloss:3.99004\n",
      "I0000 00:00:1729625137.667841 6799749 random_forest.cc:812] Training of tree  22/300 (tree index:21) done accuracy:0.716667 logloss:1.13837\n",
      "I0000 00:00:1729625137.668012 6799756 random_forest.cc:812] Training of tree  33/300 (tree index:29) done accuracy:0.733333 logloss:0.855726\n",
      "I0000 00:00:1729625137.668199 6799749 random_forest.cc:812] Training of tree  43/300 (tree index:40) done accuracy:0.75 logloss:0.832591\n",
      "I0000 00:00:1729625137.668428 6799754 random_forest.cc:812] Training of tree  53/300 (tree index:55) done accuracy:0.733333 logloss:0.54955\n",
      "I0000 00:00:1729625137.668555 6799750 random_forest.cc:812] Training of tree  63/300 (tree index:61) done accuracy:0.758333 logloss:0.526745\n",
      "I0000 00:00:1729625137.668755 6799749 random_forest.cc:812] Training of tree  73/300 (tree index:74) done accuracy:0.758333 logloss:0.529499\n",
      "I0000 00:00:1729625137.668891 6799751 random_forest.cc:812] Training of tree  83/300 (tree index:84) done accuracy:0.741667 logloss:0.526739\n",
      "I0000 00:00:1729625137.669054 6799754 random_forest.cc:812] Training of tree  93/300 (tree index:93) done accuracy:0.75 logloss:0.523707\n",
      "I0000 00:00:1729625137.669301 6799752 random_forest.cc:812] Training of tree  103/300 (tree index:102) done accuracy:0.75 logloss:0.523808\n",
      "I0000 00:00:1729625137.669432 6799754 random_forest.cc:812] Training of tree  113/300 (tree index:111) done accuracy:0.733333 logloss:0.531353\n",
      "I0000 00:00:1729625137.669603 6799751 random_forest.cc:812] Training of tree  123/300 (tree index:123) done accuracy:0.75 logloss:0.521672\n",
      "I0000 00:00:1729625137.669845 6799756 random_forest.cc:812] Training of tree  133/300 (tree index:129) done accuracy:0.75 logloss:0.52672\n",
      "I0000 00:00:1729625137.670138 6799755 random_forest.cc:812] Training of tree  143/300 (tree index:142) done accuracy:0.741667 logloss:0.535129\n",
      "I0000 00:00:1729625137.670388 6799749 random_forest.cc:812] Training of tree  153/300 (tree index:151) done accuracy:0.725 logloss:0.539496\n",
      "I0000 00:00:1729625137.670612 6799753 random_forest.cc:812] Training of tree  164/300 (tree index:163) done accuracy:0.741667 logloss:0.533687\n",
      "I0000 00:00:1729625137.670813 6799753 random_forest.cc:812] Training of tree  174/300 (tree index:173) done accuracy:0.741667 logloss:0.532076\n",
      "I0000 00:00:1729625137.671059 6799754 random_forest.cc:812] Training of tree  186/300 (tree index:184) done accuracy:0.75 logloss:0.525318\n",
      "I0000 00:00:1729625137.671265 6799752 random_forest.cc:812] Training of tree  196/300 (tree index:199) done accuracy:0.75 logloss:0.520786\n",
      "I0000 00:00:1729625137.671419 6799756 random_forest.cc:812] Training of tree  206/300 (tree index:205) done accuracy:0.733333 logloss:0.519465\n",
      "I0000 00:00:1729625137.671605 6799752 random_forest.cc:812] Training of tree  216/300 (tree index:212) done accuracy:0.716667 logloss:0.523219\n",
      "I0000 00:00:1729625137.671782 6799755 random_forest.cc:812] Training of tree  227/300 (tree index:218) done accuracy:0.716667 logloss:0.52691\n",
      "I0000 00:00:1729625137.672008 6799755 random_forest.cc:812] Training of tree  238/300 (tree index:237) done accuracy:0.716667 logloss:0.529391\n",
      "I0000 00:00:1729625137.672226 6799755 random_forest.cc:812] Training of tree  248/300 (tree index:247) done accuracy:0.7 logloss:0.530526\n",
      "I0000 00:00:1729625137.672418 6799752 random_forest.cc:812] Training of tree  258/300 (tree index:258) done accuracy:0.708333 logloss:0.528125\n",
      "I0000 00:00:1729625137.672582 6799754 random_forest.cc:812] Training of tree  268/300 (tree index:270) done accuracy:0.708333 logloss:0.526499\n",
      "I0000 00:00:1729625137.672765 6799749 random_forest.cc:812] Training of tree  279/300 (tree index:277) done accuracy:0.7 logloss:0.527202\n",
      "I0000 00:00:1729625137.672989 6799756 random_forest.cc:812] Training of tree  289/300 (tree index:291) done accuracy:0.7 logloss:0.524602\n",
      "I0000 00:00:1729625137.673151 6799750 random_forest.cc:812] Training of tree  299/300 (tree index:285) done accuracy:0.7 logloss:0.525246\n",
      "I0000 00:00:1729625137.673177 6799755 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.708333 logloss:0.524504\n",
      "I0000 00:00:1729625137.673234 6799740 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.524504\n",
      "I0000 00:00:1729625137.673936 6799740 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxkgfqv3v with prefix ced3a7a900804ab4\n",
      "I0000 00:00:1729625137.677896 6799740 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625137.678660 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.524504\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  44  14\n",
      "2  21  41\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:37.685154: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpxkgfqv3v/model/ with prefix ced3a7a900804ab4\n",
      "I0000 00:00:1729625137.693550 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6548 node(s), and 19 input feature(s).\n",
      "I0000 00:00:1729625137.693566 6784195 abstract_model.cc:1323] Engine \"RandomForestOptPred\" built\n",
      "2024-10-22 20:25:37.693572: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143010. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.029584\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_orabve3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625137.978104 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625137.978117 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625137.978121 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625137.978184 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625137.978190 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625137.978234 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.978244 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.978249 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.978254 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625137.978281 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625137.978300 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625137.978437 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625137.978464 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5cuovqwb/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625137.978521 6799811 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625137.978605 6799811 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625137.979154 6799822 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625137.979306 6799826 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.672269 logloss:5.19579\n",
      "I0000 00:00:1729625137.979564 6799822 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.691667 logloss:0.838158\n",
      "I0000 00:00:1729625137.979733 6799820 random_forest.cc:812] Training of tree  31/300 (tree index:32) done accuracy:0.75 logloss:0.771127\n",
      "I0000 00:00:1729625137.979920 6799821 random_forest.cc:812] Training of tree  41/300 (tree index:41) done accuracy:0.733333 logloss:0.516096\n",
      "I0000 00:00:1729625137.980126 6799824 random_forest.cc:812] Training of tree  51/300 (tree index:51) done accuracy:0.741667 logloss:0.522929\n",
      "I0000 00:00:1729625137.980307 6799826 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.733333 logloss:0.515879\n",
      "I0000 00:00:1729625137.980492 6799825 random_forest.cc:812] Training of tree  71/300 (tree index:73) done accuracy:0.733333 logloss:0.507853\n",
      "I0000 00:00:1729625137.980712 6799823 random_forest.cc:812] Training of tree  84/300 (tree index:71) done accuracy:0.741667 logloss:0.504442\n",
      "I0000 00:00:1729625137.980906 6799821 random_forest.cc:812] Training of tree  94/300 (tree index:93) done accuracy:0.766667 logloss:0.489975\n",
      "I0000 00:00:1729625137.981093 6799827 random_forest.cc:812] Training of tree  104/300 (tree index:105) done accuracy:0.766667 logloss:0.495452\n",
      "I0000 00:00:1729625137.981235 6799824 random_forest.cc:812] Training of tree  114/300 (tree index:115) done accuracy:0.766667 logloss:0.494221\n",
      "I0000 00:00:1729625137.981417 6799827 random_forest.cc:812] Training of tree  124/300 (tree index:124) done accuracy:0.775 logloss:0.495995\n",
      "I0000 00:00:1729625137.981589 6799824 random_forest.cc:812] Training of tree  134/300 (tree index:121) done accuracy:0.766667 logloss:0.493996\n",
      "I0000 00:00:1729625137.981811 6799823 random_forest.cc:812] Training of tree  144/300 (tree index:144) done accuracy:0.775 logloss:0.492826\n",
      "I0000 00:00:1729625137.981980 6799821 random_forest.cc:812] Training of tree  154/300 (tree index:153) done accuracy:0.766667 logloss:0.494805\n",
      "I0000 00:00:1729625137.982202 6799821 random_forest.cc:812] Training of tree  164/300 (tree index:165) done accuracy:0.766667 logloss:0.495499\n",
      "I0000 00:00:1729625137.982392 6799821 random_forest.cc:812] Training of tree  174/300 (tree index:174) done accuracy:0.775 logloss:0.494195\n",
      "I0000 00:00:1729625137.982647 6799826 random_forest.cc:812] Training of tree  184/300 (tree index:185) done accuracy:0.758333 logloss:0.497169\n",
      "I0000 00:00:1729625137.982820 6799827 random_forest.cc:812] Training of tree  194/300 (tree index:194) done accuracy:0.758333 logloss:0.500274\n",
      "I0000 00:00:1729625137.982970 6799826 random_forest.cc:812] Training of tree  204/300 (tree index:203) done accuracy:0.766667 logloss:0.497066\n",
      "I0000 00:00:1729625137.983156 6799821 random_forest.cc:812] Training of tree  214/300 (tree index:214) done accuracy:0.758333 logloss:0.499509\n",
      "I0000 00:00:1729625137.983307 6799825 random_forest.cc:812] Training of tree  224/300 (tree index:225) done accuracy:0.758333 logloss:0.49849\n",
      "I0000 00:00:1729625137.983466 6799825 random_forest.cc:812] Training of tree  234/300 (tree index:231) done accuracy:0.758333 logloss:0.501372\n",
      "I0000 00:00:1729625137.983671 6799821 random_forest.cc:812] Training of tree  244/300 (tree index:243) done accuracy:0.75 logloss:0.497866\n",
      "I0000 00:00:1729625137.983842 6799823 random_forest.cc:812] Training of tree  254/300 (tree index:245) done accuracy:0.758333 logloss:0.498609\n",
      "I0000 00:00:1729625137.984033 6799823 random_forest.cc:812] Training of tree  264/300 (tree index:268) done accuracy:0.758333 logloss:0.496126\n",
      "I0000 00:00:1729625137.984221 6799822 random_forest.cc:812] Training of tree  274/300 (tree index:263) done accuracy:0.766667 logloss:0.497593\n",
      "I0000 00:00:1729625137.984407 6799824 random_forest.cc:812] Training of tree  284/300 (tree index:282) done accuracy:0.775 logloss:0.499239\n",
      "I0000 00:00:1729625137.984583 6799825 random_forest.cc:812] Training of tree  294/300 (tree index:294) done accuracy:0.775 logloss:0.496572\n",
      "I0000 00:00:1729625137.984680 6799823 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.783333 logloss:0.496164\n",
      "I0000 00:00:1729625137.984781 6799811 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.496164\n",
      "I0000 00:00:1729625137.985570 6799811 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5cuovqwb with prefix 86eea43c8c0c4c0c\n",
      "I0000 00:00:1729625137.989288 6799811 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625137.990114 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.496164\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:37.996625: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5cuovqwb/model/ with prefix 86eea43c8c0c4c0c\n",
      "I0000 00:00:1729625138.005132 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6732 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:38.005147: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.165916. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.040969\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpmwv8l2gu as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625138.328899 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625138.328914 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625138.328922 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625138.328990 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625138.328997 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625138.329042 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.329053 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.329058 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.329063 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.329092 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625138.329111 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625138.329262 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625138.329309 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_orabve3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625138.329398 6799879 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625138.329509 6799879 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625138.330152 6799888 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.697674 logloss:10.8969\n",
      "I0000 00:00:1729625138.330363 6799893 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.683333 logloss:3.40886\n",
      "I0000 00:00:1729625138.330602 6799894 random_forest.cc:812] Training of tree  21/300 (tree index:13) done accuracy:0.675 logloss:0.596124\n",
      "I0000 00:00:1729625138.330823 6799889 random_forest.cc:812] Training of tree  31/300 (tree index:31) done accuracy:0.666667 logloss:0.585593\n",
      "I0000 00:00:1729625138.331039 6799890 random_forest.cc:812] Training of tree  41/300 (tree index:41) done accuracy:0.75 logloss:0.550963\n",
      "I0000 00:00:1729625138.331217 6799888 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.725 logloss:0.543258\n",
      "I0000 00:00:1729625138.331425 6799888 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.75 logloss:0.545256\n",
      "I0000 00:00:1729625138.331661 6799894 random_forest.cc:812] Training of tree  71/300 (tree index:72) done accuracy:0.733333 logloss:0.542341\n",
      "I0000 00:00:1729625138.331858 6799890 random_forest.cc:812] Training of tree  81/300 (tree index:81) done accuracy:0.741667 logloss:0.544302\n",
      "I0000 00:00:1729625138.332153 6799888 random_forest.cc:812] Training of tree  91/300 (tree index:94) done accuracy:0.725 logloss:0.535412\n",
      "I0000 00:00:1729625138.332403 6799889 random_forest.cc:812] Training of tree  101/300 (tree index:99) done accuracy:0.725 logloss:0.537631\n",
      "I0000 00:00:1729625138.333346 6799892 random_forest.cc:812] Training of tree  111/300 (tree index:114) done accuracy:0.725 logloss:0.534471\n",
      "I0000 00:00:1729625138.334603 6799892 random_forest.cc:812] Training of tree  121/300 (tree index:125) done accuracy:0.708333 logloss:0.539242\n",
      "I0000 00:00:1729625138.335101 6799892 random_forest.cc:812] Training of tree  131/300 (tree index:133) done accuracy:0.733333 logloss:0.537842\n",
      "I0000 00:00:1729625138.335712 6799893 random_forest.cc:812] Training of tree  141/300 (tree index:142) done accuracy:0.725 logloss:0.538071\n",
      "I0000 00:00:1729625138.336866 6799889 random_forest.cc:812] Training of tree  151/300 (tree index:153) done accuracy:0.725 logloss:0.54209\n",
      "I0000 00:00:1729625138.337452 6799889 random_forest.cc:812] Training of tree  161/300 (tree index:163) done accuracy:0.741667 logloss:0.535203\n",
      "I0000 00:00:1729625138.337990 6799889 random_forest.cc:812] Training of tree  171/300 (tree index:173) done accuracy:0.725 logloss:0.537866\n",
      "I0000 00:00:1729625138.338737 6799893 random_forest.cc:812] Training of tree  181/300 (tree index:181) done accuracy:0.733333 logloss:0.53838\n",
      "I0000 00:00:1729625138.339358 6799894 random_forest.cc:812] Training of tree  191/300 (tree index:193) done accuracy:0.741667 logloss:0.541052\n",
      "I0000 00:00:1729625138.339873 6799895 random_forest.cc:812] Training of tree  201/300 (tree index:203) done accuracy:0.741667 logloss:0.539884\n",
      "I0000 00:00:1729625138.340234 6799894 random_forest.cc:812] Training of tree  211/300 (tree index:212) done accuracy:0.741667 logloss:0.540704\n",
      "I0000 00:00:1729625138.340662 6799894 random_forest.cc:812] Training of tree  221/300 (tree index:222) done accuracy:0.75 logloss:0.539979\n",
      "I0000 00:00:1729625138.341091 6799894 random_forest.cc:812] Training of tree  231/300 (tree index:232) done accuracy:0.75 logloss:0.541761\n",
      "I0000 00:00:1729625138.341555 6799889 random_forest.cc:812] Training of tree  241/300 (tree index:244) done accuracy:0.733333 logloss:0.540775\n",
      "I0000 00:00:1729625138.341803 6799890 random_forest.cc:812] Training of tree  251/300 (tree index:252) done accuracy:0.733333 logloss:0.541076\n",
      "I0000 00:00:1729625138.342192 6799892 random_forest.cc:812] Training of tree  261/300 (tree index:255) done accuracy:0.725 logloss:0.537959\n",
      "I0000 00:00:1729625138.342462 6799888 random_forest.cc:812] Training of tree  271/300 (tree index:272) done accuracy:0.741667 logloss:0.535668\n",
      "I0000 00:00:1729625138.342701 6799892 random_forest.cc:812] Training of tree  281/300 (tree index:283) done accuracy:0.733333 logloss:0.532821\n",
      "I0000 00:00:1729625138.342962 6799893 random_forest.cc:812] Training of tree  291/300 (tree index:292) done accuracy:0.733333 logloss:0.531542\n",
      "I0000 00:00:1729625138.343231 6799889 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.741667 logloss:0.530101\n",
      "I0000 00:00:1729625138.343347 6799879 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.530101\n",
      "I0000 00:00:1729625138.344173 6799879 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_orabve3 with prefix 487391e759084924\n",
      "I0000 00:00:1729625138.347825 6799879 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625138.348697 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.530101\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  14  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:38.355968: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_orabve3/model/ with prefix 487391e759084924\n",
      "I0000 00:00:1729625138.364697 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6878 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:38.364718: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146969. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.028344\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpi7so_rv0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625138.642071 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625138.642087 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625138.642091 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625138.642156 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625138.642161 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625138.642205 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.642217 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.642223 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.642245 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.642278 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625138.642330 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625138.642466 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625138.642495 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpmwv8l2gu/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625138.642547 6799947 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625138.642639 6799947 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625138.643262 6799957 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.651163 logloss:12.5734\n",
      "I0000 00:00:1729625138.643441 6799959 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.739496 logloss:1.57545\n",
      "I0000 00:00:1729625138.643629 6799956 random_forest.cc:812] Training of tree  21/300 (tree index:23) done accuracy:0.8 logloss:0.421838\n",
      "I0000 00:00:1729625138.643756 6799957 random_forest.cc:812] Training of tree  31/300 (tree index:31) done accuracy:0.808333 logloss:0.420732\n",
      "I0000 00:00:1729625138.643954 6799956 random_forest.cc:812] Training of tree  41/300 (tree index:42) done accuracy:0.783333 logloss:0.441171\n",
      "I0000 00:00:1729625138.644079 6799963 random_forest.cc:812] Training of tree  51/300 (tree index:52) done accuracy:0.791667 logloss:0.434703\n",
      "I0000 00:00:1729625138.644297 6799959 random_forest.cc:812] Training of tree  64/300 (tree index:63) done accuracy:0.791667 logloss:0.433733\n",
      "I0000 00:00:1729625138.644492 6799960 random_forest.cc:812] Training of tree  74/300 (tree index:74) done accuracy:0.775 logloss:0.452822\n",
      "I0000 00:00:1729625138.644665 6799959 random_forest.cc:812] Training of tree  84/300 (tree index:83) done accuracy:0.8 logloss:0.449958\n",
      "I0000 00:00:1729625138.644797 6799962 random_forest.cc:812] Training of tree  94/300 (tree index:94) done accuracy:0.8 logloss:0.449283\n",
      "I0000 00:00:1729625138.644988 6799961 random_forest.cc:812] Training of tree  104/300 (tree index:100) done accuracy:0.8 logloss:0.454491\n",
      "I0000 00:00:1729625138.645128 6799959 random_forest.cc:812] Training of tree  114/300 (tree index:114) done accuracy:0.791667 logloss:0.451086\n",
      "I0000 00:00:1729625138.645291 6799957 random_forest.cc:812] Training of tree  124/300 (tree index:124) done accuracy:0.8 logloss:0.450234\n",
      "I0000 00:00:1729625138.645431 6799962 random_forest.cc:812] Training of tree  134/300 (tree index:133) done accuracy:0.791667 logloss:0.446819\n",
      "I0000 00:00:1729625138.645622 6799957 random_forest.cc:812] Training of tree  144/300 (tree index:146) done accuracy:0.791667 logloss:0.448004\n",
      "I0000 00:00:1729625138.645788 6799958 random_forest.cc:812] Training of tree  155/300 (tree index:155) done accuracy:0.791667 logloss:0.444372\n",
      "I0000 00:00:1729625138.645965 6799958 random_forest.cc:812] Training of tree  165/300 (tree index:166) done accuracy:0.8 logloss:0.446828\n",
      "I0000 00:00:1729625138.646125 6799956 random_forest.cc:812] Training of tree  175/300 (tree index:174) done accuracy:0.791667 logloss:0.449793\n",
      "I0000 00:00:1729625138.646294 6799958 random_forest.cc:812] Training of tree  185/300 (tree index:184) done accuracy:0.783333 logloss:0.456656\n",
      "I0000 00:00:1729625138.646446 6799957 random_forest.cc:812] Training of tree  195/300 (tree index:196) done accuracy:0.783333 logloss:0.455001\n",
      "I0000 00:00:1729625138.646575 6799958 random_forest.cc:812] Training of tree  205/300 (tree index:205) done accuracy:0.783333 logloss:0.456856\n",
      "I0000 00:00:1729625138.646730 6799956 random_forest.cc:812] Training of tree  215/300 (tree index:215) done accuracy:0.783333 logloss:0.456412\n",
      "I0000 00:00:1729625138.646897 6799962 random_forest.cc:812] Training of tree  225/300 (tree index:223) done accuracy:0.783333 logloss:0.454511\n",
      "I0000 00:00:1729625138.647052 6799956 random_forest.cc:812] Training of tree  235/300 (tree index:235) done accuracy:0.783333 logloss:0.454642\n",
      "I0000 00:00:1729625138.647276 6799960 random_forest.cc:812] Training of tree  245/300 (tree index:229) done accuracy:0.8 logloss:0.45331\n",
      "I0000 00:00:1729625138.647422 6799956 random_forest.cc:812] Training of tree  255/300 (tree index:254) done accuracy:0.791667 logloss:0.455895\n",
      "I0000 00:00:1729625138.647587 6799961 random_forest.cc:812] Training of tree  265/300 (tree index:264) done accuracy:0.791667 logloss:0.456212\n",
      "I0000 00:00:1729625138.647756 6799957 random_forest.cc:812] Training of tree  275/300 (tree index:276) done accuracy:0.791667 logloss:0.456864\n",
      "I0000 00:00:1729625138.647891 6799961 random_forest.cc:812] Training of tree  285/300 (tree index:284) done accuracy:0.791667 logloss:0.456155\n",
      "I0000 00:00:1729625138.648056 6799960 random_forest.cc:812] Training of tree  295/300 (tree index:293) done accuracy:0.791667 logloss:0.457415\n",
      "I0000 00:00:1729625138.648179 6799957 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.791667 logloss:0.457814\n",
      "I0000 00:00:1729625138.648253 6799947 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.457814\n",
      "I0000 00:00:1729625138.649028 6799947 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpmwv8l2gu with prefix bdabab1c95c44ae2\n",
      "I0000 00:00:1729625138.652581 6799947 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625138.653179 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.457814\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  11  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:38.659780: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpmwv8l2gu/model/ with prefix bdabab1c95c44ae2\n",
      "I0000 00:00:1729625138.667913 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6178 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:38.667936: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.142645. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.029380\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 30, 'min_examples': 5, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx29chrc7 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625138.942701 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625138.942712 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625138.942720 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625138.942782 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625138.942788 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625138.942829 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.942839 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.942845 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.942851 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625138.942877 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625138.942895 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625138.943023 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625138.943046 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpi7so_rv0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625138.943105 6800015 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625138.943208 6800015 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625138.943816 6800024 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625138.944024 6800030 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.733333 logloss:3.30099\n",
      "I0000 00:00:1729625138.944248 6800025 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.733333 logloss:1.93789\n",
      "I0000 00:00:1729625138.944424 6800024 random_forest.cc:812] Training of tree  32/300 (tree index:27) done accuracy:0.758333 logloss:1.06944\n",
      "I0000 00:00:1729625138.944579 6800028 random_forest.cc:812] Training of tree  42/300 (tree index:40) done accuracy:0.775 logloss:0.781972\n",
      "I0000 00:00:1729625138.944766 6800024 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.791667 logloss:0.477443\n",
      "I0000 00:00:1729625138.944967 6800030 random_forest.cc:812] Training of tree  62/300 (tree index:63) done accuracy:0.791667 logloss:0.480076\n",
      "I0000 00:00:1729625138.945132 6800026 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.791667 logloss:0.482045\n",
      "I0000 00:00:1729625138.945291 6800030 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.783333 logloss:0.481041\n",
      "I0000 00:00:1729625138.945463 6800027 random_forest.cc:812] Training of tree  92/300 (tree index:94) done accuracy:0.775 logloss:0.469819\n",
      "I0000 00:00:1729625138.945646 6800028 random_forest.cc:812] Training of tree  103/300 (tree index:100) done accuracy:0.775 logloss:0.479395\n",
      "I0000 00:00:1729625138.945884 6800031 random_forest.cc:812] Training of tree  115/300 (tree index:114) done accuracy:0.783333 logloss:0.481061\n",
      "I0000 00:00:1729625138.946130 6800028 random_forest.cc:812] Training of tree  125/300 (tree index:124) done accuracy:0.775 logloss:0.492975\n",
      "I0000 00:00:1729625138.946332 6800030 random_forest.cc:812] Training of tree  135/300 (tree index:136) done accuracy:0.775 logloss:0.49284\n",
      "I0000 00:00:1729625138.946572 6800030 random_forest.cc:812] Training of tree  145/300 (tree index:145) done accuracy:0.766667 logloss:0.494253\n",
      "I0000 00:00:1729625138.946729 6800029 random_forest.cc:812] Training of tree  156/300 (tree index:153) done accuracy:0.775 logloss:0.497496\n",
      "I0000 00:00:1729625138.946940 6800026 random_forest.cc:812] Training of tree  166/300 (tree index:165) done accuracy:0.766667 logloss:0.496568\n",
      "I0000 00:00:1729625138.947117 6800031 random_forest.cc:812] Training of tree  176/300 (tree index:177) done accuracy:0.766667 logloss:0.495293\n",
      "I0000 00:00:1729625138.947291 6800029 random_forest.cc:812] Training of tree  186/300 (tree index:185) done accuracy:0.766667 logloss:0.496192\n",
      "I0000 00:00:1729625138.947535 6800030 random_forest.cc:812] Training of tree  196/300 (tree index:193) done accuracy:0.766667 logloss:0.489891\n",
      "I0000 00:00:1729625138.947701 6800031 random_forest.cc:812] Training of tree  206/300 (tree index:206) done accuracy:0.766667 logloss:0.487098\n",
      "I0000 00:00:1729625138.947873 6800026 random_forest.cc:812] Training of tree  216/300 (tree index:217) done accuracy:0.766667 logloss:0.48803\n",
      "I0000 00:00:1729625138.948021 6800031 random_forest.cc:812] Training of tree  226/300 (tree index:225) done accuracy:0.775 logloss:0.485811\n",
      "I0000 00:00:1729625138.948202 6800030 random_forest.cc:812] Training of tree  236/300 (tree index:236) done accuracy:0.766667 logloss:0.485507\n",
      "I0000 00:00:1729625138.948453 6800024 random_forest.cc:812] Training of tree  247/300 (tree index:230) done accuracy:0.766667 logloss:0.481293\n",
      "I0000 00:00:1729625138.948636 6800027 random_forest.cc:812] Training of tree  258/300 (tree index:256) done accuracy:0.766667 logloss:0.480164\n",
      "I0000 00:00:1729625138.948870 6800031 random_forest.cc:812] Training of tree  269/300 (tree index:267) done accuracy:0.766667 logloss:0.480246\n",
      "I0000 00:00:1729625138.949091 6800031 random_forest.cc:812] Training of tree  279/300 (tree index:281) done accuracy:0.775 logloss:0.478984\n",
      "I0000 00:00:1729625138.949290 6800030 random_forest.cc:812] Training of tree  289/300 (tree index:280) done accuracy:0.766667 logloss:0.476992\n",
      "I0000 00:00:1729625138.949438 6800027 random_forest.cc:812] Training of tree  299/300 (tree index:298) done accuracy:0.783333 logloss:0.476271\n",
      "I0000 00:00:1729625138.949480 6800031 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.783333 logloss:0.475578\n",
      "I0000 00:00:1729625138.949510 6800015 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.475578\n",
      "I0000 00:00:1729625138.950257 6800015 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpi7so_rv0 with prefix 53e28af998ad4b9a\n",
      "I0000 00:00:1729625138.954140 6800015 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625138.954766 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.475578\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  12\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:38.961148: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpi7so_rv0/model/ with prefix 53e28af998ad4b9a\n",
      "I0000 00:00:1729625138.969448 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6562 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:38.969464: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146685. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027439\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptd0iwssk as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625139.247529 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625139.247542 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625139.247546 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625139.247622 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625139.247626 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625139.247673 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.247683 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.247688 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.247693 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.247719 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625139.247735 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625139.247866 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625139.247887 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx29chrc7/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625139.247948 6800083 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625139.248050 6800083 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625139.248771 6800094 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625139.248960 6800097 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.716667 logloss:1.97537\n",
      "I0000 00:00:1729625139.249110 6800096 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.725 logloss:0.806421\n",
      "I0000 00:00:1729625139.249310 6800094 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.7 logloss:0.521528\n",
      "I0000 00:00:1729625139.249459 6800093 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.683333 logloss:0.568998\n",
      "I0000 00:00:1729625139.249608 6800099 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.7 logloss:0.557027\n",
      "I0000 00:00:1729625139.249776 6800098 random_forest.cc:812] Training of tree  61/300 (tree index:62) done accuracy:0.675 logloss:0.556385\n",
      "I0000 00:00:1729625139.249918 6800093 random_forest.cc:812] Training of tree  71/300 (tree index:71) done accuracy:0.7 logloss:0.552085\n",
      "I0000 00:00:1729625139.250087 6800094 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.725 logloss:0.54742\n",
      "I0000 00:00:1729625139.250225 6800095 random_forest.cc:812] Training of tree  91/300 (tree index:91) done accuracy:0.7 logloss:0.544109\n",
      "I0000 00:00:1729625139.250386 6800098 random_forest.cc:812] Training of tree  101/300 (tree index:99) done accuracy:0.708333 logloss:0.539586\n",
      "I0000 00:00:1729625139.250538 6800093 random_forest.cc:812] Training of tree  111/300 (tree index:111) done accuracy:0.725 logloss:0.541426\n",
      "I0000 00:00:1729625139.250681 6800098 random_forest.cc:812] Training of tree  121/300 (tree index:119) done accuracy:0.733333 logloss:0.530728\n",
      "I0000 00:00:1729625139.250877 6800092 random_forest.cc:812] Training of tree  133/300 (tree index:131) done accuracy:0.741667 logloss:0.529579\n",
      "I0000 00:00:1729625139.251059 6800094 random_forest.cc:812] Training of tree  143/300 (tree index:143) done accuracy:0.725 logloss:0.528719\n",
      "I0000 00:00:1729625139.251244 6800096 random_forest.cc:812] Training of tree  153/300 (tree index:149) done accuracy:0.741667 logloss:0.526087\n",
      "I0000 00:00:1729625139.251359 6800092 random_forest.cc:812] Training of tree  163/300 (tree index:163) done accuracy:0.741667 logloss:0.528686\n",
      "I0000 00:00:1729625139.251621 6800094 random_forest.cc:812] Training of tree  173/300 (tree index:159) done accuracy:0.733333 logloss:0.527768\n",
      "I0000 00:00:1729625139.251801 6800097 random_forest.cc:812] Training of tree  183/300 (tree index:182) done accuracy:0.75 logloss:0.524319\n",
      "I0000 00:00:1729625139.252005 6800096 random_forest.cc:812] Training of tree  193/300 (tree index:189) done accuracy:0.733333 logloss:0.519383\n",
      "I0000 00:00:1729625139.252202 6800093 random_forest.cc:812] Training of tree  203/300 (tree index:202) done accuracy:0.725 logloss:0.519808\n",
      "I0000 00:00:1729625139.252336 6800092 random_forest.cc:812] Training of tree  213/300 (tree index:213) done accuracy:0.733333 logloss:0.518509\n",
      "I0000 00:00:1729625139.252544 6800095 random_forest.cc:812] Training of tree  224/300 (tree index:223) done accuracy:0.741667 logloss:0.516261\n",
      "I0000 00:00:1729625139.252749 6800094 random_forest.cc:812] Training of tree  234/300 (tree index:233) done accuracy:0.725 logloss:0.51397\n",
      "I0000 00:00:1729625139.252933 6800095 random_forest.cc:812] Training of tree  245/300 (tree index:244) done accuracy:0.733333 logloss:0.511985\n",
      "I0000 00:00:1729625139.253247 6800097 random_forest.cc:812] Training of tree  255/300 (tree index:255) done accuracy:0.733333 logloss:0.511881\n",
      "I0000 00:00:1729625139.253404 6800093 random_forest.cc:812] Training of tree  265/300 (tree index:264) done accuracy:0.733333 logloss:0.510967\n",
      "I0000 00:00:1729625139.253627 6800093 random_forest.cc:812] Training of tree  275/300 (tree index:270) done accuracy:0.733333 logloss:0.510666\n",
      "I0000 00:00:1729625139.253792 6800096 random_forest.cc:812] Training of tree  285/300 (tree index:286) done accuracy:0.733333 logloss:0.510251\n",
      "I0000 00:00:1729625139.253986 6800096 random_forest.cc:812] Training of tree  295/300 (tree index:296) done accuracy:0.741667 logloss:0.511203\n",
      "I0000 00:00:1729625139.254100 6800095 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.741667 logloss:0.510612\n",
      "I0000 00:00:1729625139.254161 6800083 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.510612\n",
      "I0000 00:00:1729625139.254760 6800083 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx29chrc7 with prefix 32e7481765974324\n",
      "I0000 00:00:1729625139.258124 6800083 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625139.258917 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.510612\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  16\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:39.265189: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpx29chrc7/model/ with prefix 32e7481765974324\n",
      "I0000 00:00:1729625139.272335 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5638 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:39.272358: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.188319. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.028541\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfk63riqu as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625139.599979 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625139.599993 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625139.599997 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625139.600069 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625139.600074 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625139.600121 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.600131 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.600137 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.600142 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.600175 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625139.600193 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625139.600338 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625139.600365 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptd0iwssk/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625139.600429 6800155 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625139.600526 6800155 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625139.601069 6800171 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.530612 logloss:16.9184\n",
      "I0000 00:00:1729625139.601259 6800165 random_forest.cc:812] Training of tree  11/300 (tree index:9) done accuracy:0.705882 logloss:3.42292\n",
      "I0000 00:00:1729625139.601449 6800166 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.691667 logloss:1.18513\n",
      "I0000 00:00:1729625139.601642 6800169 random_forest.cc:812] Training of tree  31/300 (tree index:33) done accuracy:0.708333 logloss:0.594724\n",
      "I0000 00:00:1729625139.601810 6800164 random_forest.cc:812] Training of tree  41/300 (tree index:32) done accuracy:0.725 logloss:0.57983\n",
      "I0000 00:00:1729625139.602023 6800171 random_forest.cc:812] Training of tree  52/300 (tree index:51) done accuracy:0.716667 logloss:0.567239\n",
      "I0000 00:00:1729625139.602215 6800171 random_forest.cc:812] Training of tree  62/300 (tree index:62) done accuracy:0.733333 logloss:0.566101\n",
      "I0000 00:00:1729625139.602372 6800170 random_forest.cc:812] Training of tree  72/300 (tree index:71) done accuracy:0.716667 logloss:0.569167\n",
      "I0000 00:00:1729625139.602598 6800166 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.741667 logloss:0.558093\n",
      "I0000 00:00:1729625139.602783 6800171 random_forest.cc:812] Training of tree  92/300 (tree index:94) done accuracy:0.725 logloss:0.558503\n",
      "I0000 00:00:1729625139.602976 6800171 random_forest.cc:812] Training of tree  102/300 (tree index:103) done accuracy:0.725 logloss:0.555597\n",
      "I0000 00:00:1729625139.603164 6800171 random_forest.cc:812] Training of tree  113/300 (tree index:112) done accuracy:0.75 logloss:0.551301\n",
      "I0000 00:00:1729625139.603387 6800166 random_forest.cc:812] Training of tree  123/300 (tree index:122) done accuracy:0.75 logloss:0.55412\n",
      "I0000 00:00:1729625139.603641 6800166 random_forest.cc:812] Training of tree  134/300 (tree index:135) done accuracy:0.758333 logloss:0.555075\n",
      "I0000 00:00:1729625139.603834 6800166 random_forest.cc:812] Training of tree  144/300 (tree index:144) done accuracy:0.75 logloss:0.554865\n",
      "I0000 00:00:1729625139.604028 6800166 random_forest.cc:812] Training of tree  155/300 (tree index:155) done accuracy:0.766667 logloss:0.550294\n",
      "I0000 00:00:1729625139.604234 6800167 random_forest.cc:812] Training of tree  165/300 (tree index:162) done accuracy:0.766667 logloss:0.546558\n",
      "I0000 00:00:1729625139.604388 6800170 random_forest.cc:812] Training of tree  175/300 (tree index:174) done accuracy:0.775 logloss:0.54679\n",
      "I0000 00:00:1729625139.604574 6800165 random_forest.cc:812] Training of tree  185/300 (tree index:175) done accuracy:0.775 logloss:0.544703\n",
      "I0000 00:00:1729625139.604722 6800167 random_forest.cc:812] Training of tree  195/300 (tree index:194) done accuracy:0.783333 logloss:0.542924\n",
      "I0000 00:00:1729625139.604895 6800167 random_forest.cc:812] Training of tree  205/300 (tree index:205) done accuracy:0.766667 logloss:0.545779\n",
      "I0000 00:00:1729625139.605111 6800168 random_forest.cc:812] Training of tree  216/300 (tree index:216) done accuracy:0.775 logloss:0.540541\n",
      "I0000 00:00:1729625139.605281 6800170 random_forest.cc:812] Training of tree  226/300 (tree index:225) done accuracy:0.775 logloss:0.540975\n",
      "I0000 00:00:1729625139.605471 6800168 random_forest.cc:812] Training of tree  236/300 (tree index:228) done accuracy:0.758333 logloss:0.542401\n",
      "I0000 00:00:1729625139.605638 6800170 random_forest.cc:812] Training of tree  246/300 (tree index:246) done accuracy:0.758333 logloss:0.539666\n",
      "I0000 00:00:1729625139.605809 6800165 random_forest.cc:812] Training of tree  257/300 (tree index:256) done accuracy:0.766667 logloss:0.535108\n",
      "I0000 00:00:1729625139.606051 6800166 random_forest.cc:812] Training of tree  269/300 (tree index:267) done accuracy:0.775 logloss:0.532275\n",
      "I0000 00:00:1729625139.606267 6800165 random_forest.cc:812] Training of tree  279/300 (tree index:278) done accuracy:0.783333 logloss:0.533111\n",
      "I0000 00:00:1729625139.606407 6800171 random_forest.cc:812] Training of tree  289/300 (tree index:287) done accuracy:0.766667 logloss:0.532977\n",
      "I0000 00:00:1729625139.606612 6800166 random_forest.cc:812] Training of tree  299/300 (tree index:299) done accuracy:0.766667 logloss:0.530753\n",
      "I0000 00:00:1729625139.606654 6800165 random_forest.cc:812] Training of tree  300/300 (tree index:294) done accuracy:0.766667 logloss:0.530043\n",
      "I0000 00:00:1729625139.606715 6800155 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.530043\n",
      "I0000 00:00:1729625139.607290 6800155 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptd0iwssk with prefix 01c19673e0ee444f\n",
      "I0000 00:00:1729625139.611060 6800155 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625139.611864 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.530043\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  13  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:39.618773: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmptd0iwssk/model/ with prefix 01c19673e0ee444f\n",
      "I0000 00:00:1729625139.626149 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5776 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:39.626166: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144093. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.028478\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7wgna6n0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625139.902374 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625139.902384 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625139.902388 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625139.902451 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625139.902456 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625139.902501 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.902511 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.902516 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.902521 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625139.902549 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625139.902566 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625139.902706 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625139.902728 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfk63riqu/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625139.902773 6800224 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625139.902869 6800224 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625139.903417 6800233 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.632653 logloss:13.2405\n",
      "I0000 00:00:1729625139.903578 6800237 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.643478 logloss:4.14664\n",
      "I0000 00:00:1729625139.903849 6800237 random_forest.cc:812] Training of tree  22/300 (tree index:21) done accuracy:0.675 logloss:1.45443\n",
      "I0000 00:00:1729625139.904005 6800235 random_forest.cc:812] Training of tree  32/300 (tree index:31) done accuracy:0.7 logloss:0.572287\n",
      "I0000 00:00:1729625139.904158 6800234 random_forest.cc:812] Training of tree  42/300 (tree index:43) done accuracy:0.716667 logloss:0.555498\n",
      "I0000 00:00:1729625139.904341 6800240 random_forest.cc:812] Training of tree  52/300 (tree index:53) done accuracy:0.741667 logloss:0.550924\n",
      "I0000 00:00:1729625139.904501 6800235 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.775 logloss:0.547802\n",
      "I0000 00:00:1729625139.904683 6800237 random_forest.cc:812] Training of tree  72/300 (tree index:71) done accuracy:0.783333 logloss:0.545729\n",
      "I0000 00:00:1729625139.904869 6800235 random_forest.cc:812] Training of tree  82/300 (tree index:80) done accuracy:0.758333 logloss:0.537339\n",
      "I0000 00:00:1729625139.905047 6800234 random_forest.cc:812] Training of tree  92/300 (tree index:94) done accuracy:0.791667 logloss:0.527838\n",
      "I0000 00:00:1729625139.905171 6800240 random_forest.cc:812] Training of tree  102/300 (tree index:100) done accuracy:0.791667 logloss:0.534435\n",
      "I0000 00:00:1729625139.905342 6800240 random_forest.cc:812] Training of tree  112/300 (tree index:114) done accuracy:0.8 logloss:0.51804\n",
      "I0000 00:00:1729625139.905546 6800240 random_forest.cc:812] Training of tree  124/300 (tree index:124) done accuracy:0.775 logloss:0.525436\n",
      "I0000 00:00:1729625139.905713 6800239 random_forest.cc:812] Training of tree  134/300 (tree index:133) done accuracy:0.775 logloss:0.521395\n",
      "I0000 00:00:1729625139.905909 6800236 random_forest.cc:812] Training of tree  144/300 (tree index:144) done accuracy:0.766667 logloss:0.519587\n",
      "I0000 00:00:1729625139.906059 6800238 random_forest.cc:812] Training of tree  154/300 (tree index:155) done accuracy:0.775 logloss:0.520758\n",
      "I0000 00:00:1729625139.906199 6800237 random_forest.cc:812] Training of tree  164/300 (tree index:164) done accuracy:0.775 logloss:0.526482\n",
      "I0000 00:00:1729625139.906385 6800240 random_forest.cc:812] Training of tree  174/300 (tree index:176) done accuracy:0.783333 logloss:0.526487\n",
      "I0000 00:00:1729625139.906573 6800238 random_forest.cc:812] Training of tree  184/300 (tree index:183) done accuracy:0.783333 logloss:0.526008\n",
      "I0000 00:00:1729625139.906792 6800239 random_forest.cc:812] Training of tree  194/300 (tree index:185) done accuracy:0.783333 logloss:0.524027\n",
      "I0000 00:00:1729625139.906960 6800238 random_forest.cc:812] Training of tree  204/300 (tree index:206) done accuracy:0.783333 logloss:0.520105\n",
      "I0000 00:00:1729625139.907125 6800237 random_forest.cc:812] Training of tree  214/300 (tree index:215) done accuracy:0.783333 logloss:0.520833\n",
      "I0000 00:00:1729625139.907291 6800235 random_forest.cc:812] Training of tree  224/300 (tree index:214) done accuracy:0.783333 logloss:0.518488\n",
      "I0000 00:00:1729625139.907560 6800234 random_forest.cc:812] Training of tree  237/300 (tree index:236) done accuracy:0.783333 logloss:0.519486\n",
      "I0000 00:00:1729625139.907750 6800236 random_forest.cc:812] Training of tree  247/300 (tree index:248) done accuracy:0.783333 logloss:0.520995\n",
      "I0000 00:00:1729625139.907906 6800240 random_forest.cc:812] Training of tree  257/300 (tree index:258) done accuracy:0.783333 logloss:0.518844\n",
      "I0000 00:00:1729625139.908081 6800240 random_forest.cc:812] Training of tree  268/300 (tree index:268) done accuracy:0.783333 logloss:0.519748\n",
      "I0000 00:00:1729625139.908267 6800240 random_forest.cc:812] Training of tree  279/300 (tree index:279) done accuracy:0.783333 logloss:0.521695\n",
      "I0000 00:00:1729625139.908460 6800240 random_forest.cc:812] Training of tree  289/300 (tree index:284) done accuracy:0.791667 logloss:0.520777\n",
      "I0000 00:00:1729625139.908661 6800233 random_forest.cc:812] Training of tree  299/300 (tree index:289) done accuracy:0.791667 logloss:0.520203\n",
      "I0000 00:00:1729625139.908715 6800239 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.791667 logloss:0.519838\n",
      "I0000 00:00:1729625139.908780 6800224 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.519838\n",
      "I0000 00:00:1729625139.909497 6800224 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfk63riqu with prefix 2c7bd4693c254e45\n",
      "I0000 00:00:1729625139.913226 6800224 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625139.914027 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.519838\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  14\n",
      "2  11  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:39.920927: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfk63riqu/model/ with prefix 2c7bd4693c254e45\n",
      "I0000 00:00:1729625139.928382 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5828 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:39.928400: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145976. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.025535\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpty29nrtc as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625140.205788 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625140.205806 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625140.205814 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625140.205885 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625140.205891 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625140.205933 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.205949 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.205955 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.205960 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.205987 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625140.206005 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625140.206137 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625140.206164 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7wgna6n0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625140.206242 6800291 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625140.206341 6800291 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625140.206948 6800307 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625140.207160 6800303 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.661017 logloss:3.13776\n",
      "I0000 00:00:1729625140.207428 6800306 random_forest.cc:812] Training of tree  21/300 (tree index:18) done accuracy:0.783333 logloss:1.33581\n",
      "I0000 00:00:1729625140.207648 6800302 random_forest.cc:812] Training of tree  31/300 (tree index:29) done accuracy:0.766667 logloss:1.03781\n",
      "I0000 00:00:1729625140.207806 6800300 random_forest.cc:812] Training of tree  42/300 (tree index:40) done accuracy:0.758333 logloss:0.757144\n",
      "I0000 00:00:1729625140.207978 6800300 random_forest.cc:812] Training of tree  52/300 (tree index:53) done accuracy:0.766667 logloss:0.494766\n",
      "I0000 00:00:1729625140.208223 6800306 random_forest.cc:812] Training of tree  62/300 (tree index:59) done accuracy:0.775 logloss:0.483303\n",
      "I0000 00:00:1729625140.208410 6800302 random_forest.cc:812] Training of tree  73/300 (tree index:72) done accuracy:0.791667 logloss:0.489266\n",
      "I0000 00:00:1729625140.208619 6800303 random_forest.cc:812] Training of tree  84/300 (tree index:84) done accuracy:0.766667 logloss:0.482732\n",
      "I0000 00:00:1729625140.208781 6800304 random_forest.cc:812] Training of tree  94/300 (tree index:94) done accuracy:0.775 logloss:0.474485\n",
      "I0000 00:00:1729625140.208929 6800301 random_forest.cc:812] Training of tree  104/300 (tree index:104) done accuracy:0.8 logloss:0.476599\n",
      "I0000 00:00:1729625140.209076 6800307 random_forest.cc:812] Training of tree  116/300 (tree index:114) done accuracy:0.783333 logloss:0.481958\n",
      "I0000 00:00:1729625140.209298 6800302 random_forest.cc:812] Training of tree  126/300 (tree index:124) done accuracy:0.791667 logloss:0.484822\n",
      "I0000 00:00:1729625140.209440 6800301 random_forest.cc:812] Training of tree  136/300 (tree index:136) done accuracy:0.791667 logloss:0.47742\n",
      "I0000 00:00:1729625140.209601 6800301 random_forest.cc:812] Training of tree  146/300 (tree index:149) done accuracy:0.791667 logloss:0.475518\n",
      "I0000 00:00:1729625140.209748 6800302 random_forest.cc:812] Training of tree  156/300 (tree index:155) done accuracy:0.783333 logloss:0.479301\n",
      "I0000 00:00:1729625140.209962 6800304 random_forest.cc:812] Training of tree  166/300 (tree index:165) done accuracy:0.783333 logloss:0.477247\n",
      "I0000 00:00:1729625140.210107 6800301 random_forest.cc:812] Training of tree  176/300 (tree index:176) done accuracy:0.775 logloss:0.479269\n",
      "I0000 00:00:1729625140.210273 6800305 random_forest.cc:812] Training of tree  186/300 (tree index:187) done accuracy:0.775 logloss:0.47976\n",
      "I0000 00:00:1729625140.210406 6800303 random_forest.cc:812] Training of tree  196/300 (tree index:194) done accuracy:0.783333 logloss:0.481359\n",
      "I0000 00:00:1729625140.210583 6800302 random_forest.cc:812] Training of tree  206/300 (tree index:206) done accuracy:0.783333 logloss:0.480036\n",
      "I0000 00:00:1729625140.210724 6800303 random_forest.cc:812] Training of tree  216/300 (tree index:216) done accuracy:0.783333 logloss:0.478012\n",
      "I0000 00:00:1729625140.210866 6800306 random_forest.cc:812] Training of tree  226/300 (tree index:227) done accuracy:0.783333 logloss:0.476438\n",
      "I0000 00:00:1729625140.211040 6800305 random_forest.cc:812] Training of tree  237/300 (tree index:224) done accuracy:0.783333 logloss:0.475365\n",
      "I0000 00:00:1729625140.211170 6800300 random_forest.cc:812] Training of tree  247/300 (tree index:246) done accuracy:0.783333 logloss:0.471028\n",
      "I0000 00:00:1729625140.211296 6800305 random_forest.cc:812] Training of tree  257/300 (tree index:257) done accuracy:0.783333 logloss:0.472076\n",
      "I0000 00:00:1729625140.211498 6800307 random_forest.cc:812] Training of tree  267/300 (tree index:267) done accuracy:0.783333 logloss:0.475373\n",
      "I0000 00:00:1729625140.211756 6800300 random_forest.cc:812] Training of tree  277/300 (tree index:279) done accuracy:0.783333 logloss:0.477199\n",
      "I0000 00:00:1729625140.211900 6800307 random_forest.cc:812] Training of tree  287/300 (tree index:286) done accuracy:0.791667 logloss:0.476857\n",
      "I0000 00:00:1729625140.212054 6800301 random_forest.cc:812] Training of tree  297/300 (tree index:297) done accuracy:0.8 logloss:0.474806\n",
      "I0000 00:00:1729625140.212110 6800305 random_forest.cc:812] Training of tree  300/300 (tree index:290) done accuracy:0.8 logloss:0.474312\n",
      "I0000 00:00:1729625140.212164 6800291 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.474312\n",
      "I0000 00:00:1729625140.212798 6800291 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7wgna6n0 with prefix 5898db10f8f04d53\n",
      "I0000 00:00:1729625140.215656 6800291 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625140.216402 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.474312\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:40.222559: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7wgna6n0/model/ with prefix 5898db10f8f04d53\n",
      "I0000 00:00:1729625140.229151 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5290 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:40.229165: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144688. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027248\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 30, 'min_examples': 10, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpks2zcivc as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625140.506165 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625140.506175 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625140.506182 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625140.506247 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625140.506251 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625140.506295 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.506304 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.506310 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.506315 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.506341 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625140.506359 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625140.506493 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625140.506515 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpty29nrtc/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625140.506578 6800359 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625140.506681 6800359 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625140.507229 6800370 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.641509 logloss:12.9213\n",
      "I0000 00:00:1729625140.507370 6800371 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.731092 logloss:1.57838\n",
      "I0000 00:00:1729625140.507513 6800375 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.766667 logloss:0.722294\n",
      "I0000 00:00:1729625140.507661 6800370 random_forest.cc:812] Training of tree  31/300 (tree index:29) done accuracy:0.766667 logloss:0.72453\n",
      "I0000 00:00:1729625140.507788 6800371 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.766667 logloss:0.478626\n",
      "I0000 00:00:1729625140.507961 6800375 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.775 logloss:0.466859\n",
      "I0000 00:00:1729625140.508112 6800371 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.775 logloss:0.474011\n",
      "I0000 00:00:1729625140.508307 6800371 random_forest.cc:812] Training of tree  73/300 (tree index:72) done accuracy:0.783333 logloss:0.474\n",
      "I0000 00:00:1729625140.508513 6800373 random_forest.cc:812] Training of tree  83/300 (tree index:82) done accuracy:0.775 logloss:0.465059\n",
      "I0000 00:00:1729625140.508662 6800375 random_forest.cc:812] Training of tree  93/300 (tree index:92) done accuracy:0.791667 logloss:0.455984\n",
      "I0000 00:00:1729625140.508826 6800373 random_forest.cc:812] Training of tree  103/300 (tree index:102) done accuracy:0.791667 logloss:0.468166\n",
      "I0000 00:00:1729625140.508981 6800372 random_forest.cc:812] Training of tree  114/300 (tree index:112) done accuracy:0.783333 logloss:0.461252\n",
      "I0000 00:00:1729625140.509179 6800370 random_forest.cc:812] Training of tree  124/300 (tree index:124) done accuracy:0.791667 logloss:0.468615\n",
      "I0000 00:00:1729625140.509358 6800368 random_forest.cc:812] Training of tree  134/300 (tree index:126) done accuracy:0.791667 logloss:0.458693\n",
      "I0000 00:00:1729625140.509520 6800372 random_forest.cc:812] Training of tree  144/300 (tree index:138) done accuracy:0.775 logloss:0.469312\n",
      "I0000 00:00:1729625140.509671 6800369 random_forest.cc:812] Training of tree  154/300 (tree index:155) done accuracy:0.775 logloss:0.47415\n",
      "I0000 00:00:1729625140.509863 6800372 random_forest.cc:812] Training of tree  164/300 (tree index:164) done accuracy:0.783333 logloss:0.474458\n",
      "I0000 00:00:1729625140.510000 6800371 random_forest.cc:812] Training of tree  174/300 (tree index:174) done accuracy:0.783333 logloss:0.473042\n",
      "I0000 00:00:1729625140.510197 6800370 random_forest.cc:812] Training of tree  184/300 (tree index:182) done accuracy:0.775 logloss:0.476801\n",
      "I0000 00:00:1729625140.510426 6800372 random_forest.cc:812] Training of tree  194/300 (tree index:195) done accuracy:0.766667 logloss:0.477082\n",
      "I0000 00:00:1729625140.510670 6800375 random_forest.cc:812] Training of tree  205/300 (tree index:206) done accuracy:0.766667 logloss:0.473904\n",
      "I0000 00:00:1729625140.510846 6800375 random_forest.cc:812] Training of tree  215/300 (tree index:216) done accuracy:0.766667 logloss:0.475626\n",
      "I0000 00:00:1729625140.510976 6800371 random_forest.cc:812] Training of tree  225/300 (tree index:224) done accuracy:0.775 logloss:0.474972\n",
      "I0000 00:00:1729625140.511244 6800375 random_forest.cc:812] Training of tree  235/300 (tree index:234) done accuracy:0.766667 logloss:0.474328\n",
      "I0000 00:00:1729625140.511404 6800372 random_forest.cc:812] Training of tree  245/300 (tree index:242) done accuracy:0.775 logloss:0.473892\n",
      "I0000 00:00:1729625140.511605 6800369 random_forest.cc:812] Training of tree  255/300 (tree index:248) done accuracy:0.775 logloss:0.475593\n",
      "I0000 00:00:1729625140.511745 6800370 random_forest.cc:812] Training of tree  265/300 (tree index:263) done accuracy:0.775 logloss:0.478128\n",
      "I0000 00:00:1729625140.511945 6800375 random_forest.cc:812] Training of tree  275/300 (tree index:279) done accuracy:0.775 logloss:0.478071\n",
      "I0000 00:00:1729625140.512152 6800372 random_forest.cc:812] Training of tree  287/300 (tree index:286) done accuracy:0.791667 logloss:0.477698\n",
      "I0000 00:00:1729625140.512345 6800369 random_forest.cc:812] Training of tree  297/300 (tree index:296) done accuracy:0.783333 logloss:0.47694\n",
      "I0000 00:00:1729625140.512432 6800375 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.775 logloss:0.476714\n",
      "I0000 00:00:1729625140.512455 6800359 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.476714\n",
      "I0000 00:00:1729625140.513124 6800359 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpty29nrtc with prefix 88e9c71a69754baa\n",
      "I0000 00:00:1729625140.516530 6800359 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625140.517227 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.476714\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  13  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:40.523920: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpty29nrtc/model/ with prefix 88e9c71a69754baa\n",
      "I0000 00:00:1729625140.531020 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5552 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:40.531037: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.185097. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023067\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp05gts_c4 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625140.850284 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625140.850297 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625140.850302 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625140.850374 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625140.850378 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625140.850421 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.850431 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.850436 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.850441 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625140.850467 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625140.850483 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625140.850618 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625140.850640 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpks2zcivc/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625140.850705 6800430 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625140.850822 6800430 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625140.851431 6800447 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.72093 logloss:10.0587\n",
      "I0000 00:00:1729625140.851588 6800441 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.706897 logloss:5.29872\n",
      "I0000 00:00:1729625140.851740 6800440 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.741667 logloss:1.70307\n",
      "I0000 00:00:1729625140.851873 6800446 random_forest.cc:812] Training of tree  31/300 (tree index:32) done accuracy:0.758333 logloss:1.09394\n",
      "I0000 00:00:1729625140.852040 6800443 random_forest.cc:812] Training of tree  42/300 (tree index:43) done accuracy:0.758333 logloss:1.09313\n",
      "I0000 00:00:1729625140.852254 6800445 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.75 logloss:0.816751\n",
      "I0000 00:00:1729625140.852389 6800443 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.733333 logloss:0.797555\n",
      "I0000 00:00:1729625140.852547 6800446 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.725 logloss:0.802421\n",
      "I0000 00:00:1729625140.852706 6800444 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.733333 logloss:0.81264\n",
      "I0000 00:00:1729625140.852858 6800442 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.716667 logloss:0.815582\n",
      "I0000 00:00:1729625140.853019 6800441 random_forest.cc:812] Training of tree  102/300 (tree index:101) done accuracy:0.725 logloss:0.542227\n",
      "I0000 00:00:1729625140.853166 6800447 random_forest.cc:812] Training of tree  112/300 (tree index:111) done accuracy:0.716667 logloss:0.551182\n",
      "I0000 00:00:1729625140.853317 6800440 random_forest.cc:812] Training of tree  122/300 (tree index:121) done accuracy:0.733333 logloss:0.548562\n",
      "I0000 00:00:1729625140.853490 6800441 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.7 logloss:0.54929\n",
      "I0000 00:00:1729625140.853645 6800445 random_forest.cc:812] Training of tree  142/300 (tree index:141) done accuracy:0.708333 logloss:0.554244\n",
      "I0000 00:00:1729625140.853851 6800447 random_forest.cc:812] Training of tree  152/300 (tree index:147) done accuracy:0.708333 logloss:0.555749\n",
      "I0000 00:00:1729625140.853997 6800444 random_forest.cc:812] Training of tree  163/300 (tree index:162) done accuracy:0.708333 logloss:0.558616\n",
      "I0000 00:00:1729625140.854196 6800442 random_forest.cc:812] Training of tree  173/300 (tree index:173) done accuracy:0.716667 logloss:0.553145\n",
      "I0000 00:00:1729625140.854350 6800447 random_forest.cc:812] Training of tree  183/300 (tree index:184) done accuracy:0.708333 logloss:0.546338\n",
      "I0000 00:00:1729625140.854504 6800441 random_forest.cc:812] Training of tree  193/300 (tree index:194) done accuracy:0.708333 logloss:0.547721\n",
      "I0000 00:00:1729625140.854642 6800442 random_forest.cc:812] Training of tree  203/300 (tree index:203) done accuracy:0.708333 logloss:0.545947\n",
      "I0000 00:00:1729625140.854758 6800442 random_forest.cc:812] Training of tree  213/300 (tree index:209) done accuracy:0.708333 logloss:0.549542\n",
      "I0000 00:00:1729625140.854893 6800445 random_forest.cc:812] Training of tree  223/300 (tree index:221) done accuracy:0.691667 logloss:0.55351\n",
      "I0000 00:00:1729625140.855032 6800442 random_forest.cc:812] Training of tree  233/300 (tree index:232) done accuracy:0.7 logloss:0.552798\n",
      "I0000 00:00:1729625140.855185 6800446 random_forest.cc:812] Training of tree  243/300 (tree index:241) done accuracy:0.691667 logloss:0.550072\n",
      "I0000 00:00:1729625140.855341 6800441 random_forest.cc:812] Training of tree  253/300 (tree index:253) done accuracy:0.708333 logloss:0.550094\n",
      "I0000 00:00:1729625140.855482 6800447 random_forest.cc:812] Training of tree  263/300 (tree index:265) done accuracy:0.708333 logloss:0.551148\n",
      "I0000 00:00:1729625140.855642 6800440 random_forest.cc:812] Training of tree  273/300 (tree index:275) done accuracy:0.708333 logloss:0.551202\n",
      "I0000 00:00:1729625140.855830 6800443 random_forest.cc:812] Training of tree  285/300 (tree index:285) done accuracy:0.708333 logloss:0.548452\n",
      "I0000 00:00:1729625140.856023 6800441 random_forest.cc:812] Training of tree  295/300 (tree index:296) done accuracy:0.708333 logloss:0.545011\n",
      "I0000 00:00:1729625140.856120 6800444 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.708333 logloss:0.545719\n",
      "I0000 00:00:1729625140.856166 6800430 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.545719\n",
      "I0000 00:00:1729625140.856658 6800430 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpks2zcivc with prefix c60a7291b8d446a1\n",
      "I0000 00:00:1729625140.859099 6800430 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625140.859675 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.545719\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  16  46\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:40.865310: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpks2zcivc/model/ with prefix c60a7291b8d446a1\n",
      "I0000 00:00:1729625140.871218 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4562 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:40.871242: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.148437. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023790\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp87lisrdz as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625141.151958 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625141.151968 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625141.151974 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625141.152048 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625141.152052 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625141.152102 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.152112 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.152117 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.152123 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.152151 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625141.152168 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625141.152321 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625141.152343 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp05gts_c4/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625141.152402 6800498 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625141.152493 6800498 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625141.153052 6800513 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.772727 logloss:8.19174\n",
      "I0000 00:00:1729625141.153184 6800511 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.666667 logloss:6.26601\n",
      "I0000 00:00:1729625141.153394 6800513 random_forest.cc:812] Training of tree  22/300 (tree index:21) done accuracy:0.7 logloss:1.6756\n",
      "I0000 00:00:1729625141.153593 6800513 random_forest.cc:812] Training of tree  32/300 (tree index:33) done accuracy:0.766667 logloss:1.07073\n",
      "I0000 00:00:1729625141.153742 6800510 random_forest.cc:812] Training of tree  42/300 (tree index:42) done accuracy:0.783333 logloss:0.514824\n",
      "I0000 00:00:1729625141.153914 6800511 random_forest.cc:812] Training of tree  52/300 (tree index:49) done accuracy:0.75 logloss:0.54246\n",
      "I0000 00:00:1729625141.154061 6800514 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.758333 logloss:0.540988\n",
      "I0000 00:00:1729625141.154207 6800510 random_forest.cc:812] Training of tree  72/300 (tree index:70) done accuracy:0.766667 logloss:0.535072\n",
      "I0000 00:00:1729625141.154392 6800508 random_forest.cc:812] Training of tree  82/300 (tree index:80) done accuracy:0.766667 logloss:0.523098\n",
      "I0000 00:00:1729625141.154585 6800508 random_forest.cc:812] Training of tree  92/300 (tree index:92) done accuracy:0.783333 logloss:0.523356\n",
      "I0000 00:00:1729625141.154737 6800510 random_forest.cc:812] Training of tree  102/300 (tree index:104) done accuracy:0.783333 logloss:0.528156\n",
      "I0000 00:00:1729625141.154869 6800512 random_forest.cc:812] Training of tree  112/300 (tree index:111) done accuracy:0.766667 logloss:0.532239\n",
      "I0000 00:00:1729625141.155046 6800512 random_forest.cc:812] Training of tree  122/300 (tree index:124) done accuracy:0.775 logloss:0.526613\n",
      "I0000 00:00:1729625141.155191 6800509 random_forest.cc:812] Training of tree  133/300 (tree index:133) done accuracy:0.75 logloss:0.526183\n",
      "I0000 00:00:1729625141.155388 6800511 random_forest.cc:812] Training of tree  144/300 (tree index:143) done accuracy:0.75 logloss:0.53403\n",
      "I0000 00:00:1729625141.155596 6800510 random_forest.cc:812] Training of tree  154/300 (tree index:154) done accuracy:0.75 logloss:0.535748\n",
      "I0000 00:00:1729625141.155731 6800512 random_forest.cc:812] Training of tree  164/300 (tree index:164) done accuracy:0.741667 logloss:0.537912\n",
      "I0000 00:00:1729625141.155883 6800507 random_forest.cc:812] Training of tree  174/300 (tree index:174) done accuracy:0.741667 logloss:0.538252\n",
      "I0000 00:00:1729625141.156012 6800507 random_forest.cc:812] Training of tree  184/300 (tree index:181) done accuracy:0.75 logloss:0.535592\n",
      "I0000 00:00:1729625141.156181 6800512 random_forest.cc:812] Training of tree  194/300 (tree index:195) done accuracy:0.75 logloss:0.54289\n",
      "I0000 00:00:1729625141.156368 6800509 random_forest.cc:812] Training of tree  204/300 (tree index:205) done accuracy:0.775 logloss:0.545771\n",
      "I0000 00:00:1729625141.156579 6800511 random_forest.cc:812] Training of tree  214/300 (tree index:214) done accuracy:0.766667 logloss:0.544656\n",
      "I0000 00:00:1729625141.156741 6800513 random_forest.cc:812] Training of tree  224/300 (tree index:223) done accuracy:0.775 logloss:0.544748\n",
      "I0000 00:00:1729625141.156916 6800510 random_forest.cc:812] Training of tree  234/300 (tree index:234) done accuracy:0.775 logloss:0.548791\n",
      "I0000 00:00:1729625141.157103 6800511 random_forest.cc:812] Training of tree  245/300 (tree index:236) done accuracy:0.783333 logloss:0.547137\n",
      "I0000 00:00:1729625141.157269 6800514 random_forest.cc:812] Training of tree  255/300 (tree index:253) done accuracy:0.766667 logloss:0.545578\n",
      "I0000 00:00:1729625141.157452 6800513 random_forest.cc:812] Training of tree  265/300 (tree index:266) done accuracy:0.775 logloss:0.547675\n",
      "I0000 00:00:1729625141.157613 6800512 random_forest.cc:812] Training of tree  275/300 (tree index:277) done accuracy:0.775 logloss:0.547262\n",
      "I0000 00:00:1729625141.157740 6800507 random_forest.cc:812] Training of tree  285/300 (tree index:284) done accuracy:0.775 logloss:0.545514\n",
      "I0000 00:00:1729625141.157963 6800512 random_forest.cc:812] Training of tree  296/300 (tree index:295) done accuracy:0.775 logloss:0.54692\n",
      "I0000 00:00:1729625141.158032 6800511 random_forest.cc:812] Training of tree  300/300 (tree index:297) done accuracy:0.775 logloss:0.547206\n",
      "I0000 00:00:1729625141.158087 6800498 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.547206\n",
      "I0000 00:00:1729625141.158579 6800498 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp05gts_c4 with prefix f8ea966ea49347c0\n",
      "I0000 00:00:1729625141.161003 6800498 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625141.161630 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.547206\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:41.167432: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp05gts_c4/model/ with prefix f8ea966ea49347c0\n",
      "I0000 00:00:1729625141.173464 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4612 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:41.173482: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146189. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023212\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp05n4u00o as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625141.448046 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625141.448057 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625141.448061 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625141.448120 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625141.448127 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625141.448169 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.448178 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.448184 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.448189 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.448216 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625141.448234 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625141.448358 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625141.448380 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp87lisrdz/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625141.448445 6800570 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625141.448588 6800570 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625141.449184 6800582 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.682927 logloss:11.4285\n",
      "I0000 00:00:1729625141.449378 6800583 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.731092 logloss:2.18296\n",
      "I0000 00:00:1729625141.449531 6800582 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.675 logloss:0.832724\n",
      "I0000 00:00:1729625141.449753 6800583 random_forest.cc:812] Training of tree  32/300 (tree index:31) done accuracy:0.691667 logloss:0.579603\n",
      "I0000 00:00:1729625141.449969 6800585 random_forest.cc:812] Training of tree  44/300 (tree index:43) done accuracy:0.666667 logloss:0.594149\n",
      "I0000 00:00:1729625141.450151 6800583 random_forest.cc:812] Training of tree  54/300 (tree index:54) done accuracy:0.683333 logloss:0.599367\n",
      "I0000 00:00:1729625141.450351 6800584 random_forest.cc:812] Training of tree  64/300 (tree index:64) done accuracy:0.691667 logloss:0.590499\n",
      "I0000 00:00:1729625141.450501 6800580 random_forest.cc:812] Training of tree  74/300 (tree index:75) done accuracy:0.716667 logloss:0.597795\n",
      "I0000 00:00:1729625141.450665 6800582 random_forest.cc:812] Training of tree  85/300 (tree index:83) done accuracy:0.725 logloss:0.590008\n",
      "I0000 00:00:1729625141.450858 6800582 random_forest.cc:812] Training of tree  95/300 (tree index:95) done accuracy:0.725 logloss:0.584083\n",
      "I0000 00:00:1729625141.450987 6800583 random_forest.cc:812] Training of tree  105/300 (tree index:104) done accuracy:0.733333 logloss:0.580077\n",
      "I0000 00:00:1729625141.451165 6800584 random_forest.cc:812] Training of tree  115/300 (tree index:111) done accuracy:0.7 logloss:0.589728\n",
      "I0000 00:00:1729625141.451324 6800586 random_forest.cc:812] Training of tree  125/300 (tree index:124) done accuracy:0.7 logloss:0.587356\n",
      "I0000 00:00:1729625141.451473 6800585 random_forest.cc:812] Training of tree  135/300 (tree index:136) done accuracy:0.725 logloss:0.581892\n",
      "I0000 00:00:1729625141.451618 6800581 random_forest.cc:812] Training of tree  145/300 (tree index:144) done accuracy:0.716667 logloss:0.584934\n",
      "I0000 00:00:1729625141.451775 6800586 random_forest.cc:812] Training of tree  155/300 (tree index:155) done accuracy:0.708333 logloss:0.58221\n",
      "I0000 00:00:1729625141.451935 6800584 random_forest.cc:812] Training of tree  165/300 (tree index:163) done accuracy:0.716667 logloss:0.576849\n",
      "I0000 00:00:1729625141.452072 6800583 random_forest.cc:812] Training of tree  175/300 (tree index:175) done accuracy:0.716667 logloss:0.571576\n",
      "I0000 00:00:1729625141.452313 6800579 random_forest.cc:812] Training of tree  187/300 (tree index:186) done accuracy:0.716667 logloss:0.567065\n",
      "I0000 00:00:1729625141.452495 6800580 random_forest.cc:812] Training of tree  197/300 (tree index:197) done accuracy:0.716667 logloss:0.570906\n",
      "I0000 00:00:1729625141.452655 6800584 random_forest.cc:812] Training of tree  207/300 (tree index:208) done accuracy:0.716667 logloss:0.568867\n",
      "I0000 00:00:1729625141.452849 6800582 random_forest.cc:812] Training of tree  218/300 (tree index:217) done accuracy:0.708333 logloss:0.564278\n",
      "I0000 00:00:1729625141.452985 6800584 random_forest.cc:812] Training of tree  228/300 (tree index:227) done accuracy:0.708333 logloss:0.564711\n",
      "I0000 00:00:1729625141.453147 6800583 random_forest.cc:812] Training of tree  238/300 (tree index:239) done accuracy:0.716667 logloss:0.567152\n",
      "I0000 00:00:1729625141.453299 6800585 random_forest.cc:812] Training of tree  248/300 (tree index:248) done accuracy:0.725 logloss:0.566641\n",
      "I0000 00:00:1729625141.453463 6800581 random_forest.cc:812] Training of tree  258/300 (tree index:252) done accuracy:0.716667 logloss:0.567671\n",
      "I0000 00:00:1729625141.453599 6800580 random_forest.cc:812] Training of tree  268/300 (tree index:266) done accuracy:0.716667 logloss:0.5651\n",
      "I0000 00:00:1729625141.453748 6800582 random_forest.cc:812] Training of tree  278/300 (tree index:278) done accuracy:0.708333 logloss:0.565365\n",
      "I0000 00:00:1729625141.453904 6800584 random_forest.cc:812] Training of tree  288/300 (tree index:287) done accuracy:0.725 logloss:0.56254\n",
      "I0000 00:00:1729625141.454058 6800580 random_forest.cc:812] Training of tree  298/300 (tree index:290) done accuracy:0.716667 logloss:0.561525\n",
      "I0000 00:00:1729625141.454085 6800583 random_forest.cc:812] Training of tree  300/300 (tree index:292) done accuracy:0.725 logloss:0.562004\n",
      "I0000 00:00:1729625141.454133 6800570 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.562004\n",
      "I0000 00:00:1729625141.454597 6800570 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp87lisrdz with prefix 0601e6c054a6465f\n",
      "I0000 00:00:1729625141.457101 6800570 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625141.457635 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.562004\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  16  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:41.463005: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp87lisrdz/model/ with prefix 0601e6c054a6465f\n",
      "I0000 00:00:1729625141.468952 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4626 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:41.468969: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146329. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022687\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw4ndbaqx as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625141.746733 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625141.746745 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625141.746749 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625141.746809 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625141.746815 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625141.746855 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.746864 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.746869 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.746874 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625141.746901 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625141.746918 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625141.747043 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625141.747065 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp05n4u00o/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625141.747125 6800637 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625141.747220 6800637 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625141.747752 6800651 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.674419 logloss:11.7351\n",
      "I0000 00:00:1729625141.747928 6800650 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.731092 logloss:1.95599\n",
      "I0000 00:00:1729625141.748138 6800647 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.741667 logloss:0.793002\n",
      "I0000 00:00:1729625141.748287 6800653 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.741667 logloss:0.774732\n",
      "I0000 00:00:1729625141.748518 6800651 random_forest.cc:812] Training of tree  43/300 (tree index:42) done accuracy:0.766667 logloss:0.776204\n",
      "I0000 00:00:1729625141.748738 6800647 random_forest.cc:812] Training of tree  54/300 (tree index:53) done accuracy:0.75 logloss:0.490205\n",
      "I0000 00:00:1729625141.748941 6800648 random_forest.cc:812] Training of tree  64/300 (tree index:60) done accuracy:0.775 logloss:0.494651\n",
      "I0000 00:00:1729625141.749083 6800651 random_forest.cc:812] Training of tree  74/300 (tree index:73) done accuracy:0.775 logloss:0.489717\n",
      "I0000 00:00:1729625141.749247 6800648 random_forest.cc:812] Training of tree  84/300 (tree index:84) done accuracy:0.766667 logloss:0.490252\n",
      "I0000 00:00:1729625141.749413 6800646 random_forest.cc:812] Training of tree  95/300 (tree index:93) done accuracy:0.766667 logloss:0.479537\n",
      "I0000 00:00:1729625141.749621 6800648 random_forest.cc:812] Training of tree  105/300 (tree index:105) done accuracy:0.8 logloss:0.473818\n",
      "I0000 00:00:1729625141.749806 6800651 random_forest.cc:812] Training of tree  115/300 (tree index:114) done accuracy:0.783333 logloss:0.468514\n",
      "I0000 00:00:1729625141.749952 6800652 random_forest.cc:812] Training of tree  125/300 (tree index:125) done accuracy:0.8 logloss:0.466936\n",
      "I0000 00:00:1729625141.750108 6800648 random_forest.cc:812] Training of tree  135/300 (tree index:127) done accuracy:0.791667 logloss:0.470773\n",
      "I0000 00:00:1729625141.750261 6800650 random_forest.cc:812] Training of tree  145/300 (tree index:146) done accuracy:0.791667 logloss:0.479903\n",
      "I0000 00:00:1729625141.750402 6800647 random_forest.cc:812] Training of tree  155/300 (tree index:154) done accuracy:0.791667 logloss:0.475626\n",
      "I0000 00:00:1729625141.750557 6800651 random_forest.cc:812] Training of tree  165/300 (tree index:165) done accuracy:0.791667 logloss:0.476636\n",
      "I0000 00:00:1729625141.750705 6800646 random_forest.cc:812] Training of tree  175/300 (tree index:174) done accuracy:0.8 logloss:0.477655\n",
      "I0000 00:00:1729625141.750858 6800653 random_forest.cc:812] Training of tree  185/300 (tree index:185) done accuracy:0.8 logloss:0.47917\n",
      "I0000 00:00:1729625141.751014 6800647 random_forest.cc:812] Training of tree  195/300 (tree index:196) done accuracy:0.791667 logloss:0.479554\n",
      "I0000 00:00:1729625141.751163 6800650 random_forest.cc:812] Training of tree  205/300 (tree index:205) done accuracy:0.791667 logloss:0.479071\n",
      "I0000 00:00:1729625141.751291 6800653 random_forest.cc:812] Training of tree  215/300 (tree index:216) done accuracy:0.8 logloss:0.47505\n",
      "I0000 00:00:1729625141.751406 6800651 random_forest.cc:812] Training of tree  225/300 (tree index:223) done accuracy:0.808333 logloss:0.475856\n",
      "I0000 00:00:1729625141.751553 6800648 random_forest.cc:812] Training of tree  235/300 (tree index:232) done accuracy:0.791667 logloss:0.47821\n",
      "I0000 00:00:1729625141.751742 6800652 random_forest.cc:812] Training of tree  245/300 (tree index:246) done accuracy:0.8 logloss:0.479904\n",
      "I0000 00:00:1729625141.751862 6800650 random_forest.cc:812] Training of tree  255/300 (tree index:254) done accuracy:0.8 logloss:0.480701\n",
      "I0000 00:00:1729625141.751993 6800651 random_forest.cc:812] Training of tree  265/300 (tree index:264) done accuracy:0.8 logloss:0.480707\n",
      "I0000 00:00:1729625141.752172 6800652 random_forest.cc:812] Training of tree  275/300 (tree index:274) done accuracy:0.8 logloss:0.479784\n",
      "I0000 00:00:1729625141.752347 6800653 random_forest.cc:812] Training of tree  285/300 (tree index:284) done accuracy:0.8 logloss:0.481977\n",
      "I0000 00:00:1729625141.752474 6800646 random_forest.cc:812] Training of tree  295/300 (tree index:296) done accuracy:0.8 logloss:0.481354\n",
      "I0000 00:00:1729625141.752565 6800651 random_forest.cc:812] Training of tree  300/300 (tree index:288) done accuracy:0.8 logloss:0.480652\n",
      "I0000 00:00:1729625141.752635 6800637 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.480652\n",
      "I0000 00:00:1729625141.753095 6800637 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp05n4u00o with prefix 1a215d5a50db47d8\n",
      "I0000 00:00:1729625141.755612 6800637 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625141.756175 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.480652\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:41.761469: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp05n4u00o/model/ with prefix 1a215d5a50db47d8\n",
      "I0000 00:00:1729625141.767123 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4352 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:41.767147: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.187586. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.024432\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 30, 'min_examples': 10, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdbpxrue3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625142.086404 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625142.086466 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625142.086476 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625142.086545 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625142.086551 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625142.086592 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.086601 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.086606 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.086611 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.086638 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625142.086657 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625142.086782 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625142.086809 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw4ndbaqx/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625142.086868 6800706 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625142.086963 6800706 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625142.087529 6800719 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.744186 logloss:9.22047\n",
      "I0000 00:00:1729625142.087685 6800715 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.773109 logloss:3.02914\n",
      "I0000 00:00:1729625142.087892 6800715 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.725 logloss:1.06106\n",
      "I0000 00:00:1729625142.088028 6800717 random_forest.cc:812] Training of tree  31/300 (tree index:31) done accuracy:0.741667 logloss:0.779805\n",
      "I0000 00:00:1729625142.088198 6800720 random_forest.cc:812] Training of tree  41/300 (tree index:27) done accuracy:0.741667 logloss:0.793004\n",
      "I0000 00:00:1729625142.088369 6800721 random_forest.cc:812] Training of tree  52/300 (tree index:51) done accuracy:0.741667 logloss:0.497415\n",
      "I0000 00:00:1729625142.088583 6800722 random_forest.cc:812] Training of tree  62/300 (tree index:58) done accuracy:0.775 logloss:0.490392\n",
      "I0000 00:00:1729625142.088732 6800721 random_forest.cc:812] Training of tree  72/300 (tree index:73) done accuracy:0.766667 logloss:0.487062\n",
      "I0000 00:00:1729625142.088924 6800715 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.775 logloss:0.489941\n",
      "I0000 00:00:1729625142.089079 6800718 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.758333 logloss:0.491278\n",
      "I0000 00:00:1729625142.089251 6800717 random_forest.cc:812] Training of tree  102/300 (tree index:101) done accuracy:0.775 logloss:0.496078\n",
      "I0000 00:00:1729625142.089402 6800716 random_forest.cc:812] Training of tree  112/300 (tree index:114) done accuracy:0.758333 logloss:0.498836\n",
      "I0000 00:00:1729625142.089567 6800715 random_forest.cc:812] Training of tree  123/300 (tree index:123) done accuracy:0.758333 logloss:0.497863\n",
      "I0000 00:00:1729625142.089731 6800720 random_forest.cc:812] Training of tree  133/300 (tree index:131) done accuracy:0.75 logloss:0.497182\n",
      "I0000 00:00:1729625142.089885 6800719 random_forest.cc:812] Training of tree  143/300 (tree index:144) done accuracy:0.75 logloss:0.499916\n",
      "I0000 00:00:1729625142.090042 6800718 random_forest.cc:812] Training of tree  153/300 (tree index:152) done accuracy:0.741667 logloss:0.499666\n",
      "I0000 00:00:1729625142.090232 6800718 random_forest.cc:812] Training of tree  163/300 (tree index:163) done accuracy:0.766667 logloss:0.501878\n",
      "I0000 00:00:1729625142.090403 6800719 random_forest.cc:812] Training of tree  173/300 (tree index:171) done accuracy:0.758333 logloss:0.499763\n",
      "I0000 00:00:1729625142.090579 6800722 random_forest.cc:812] Training of tree  183/300 (tree index:181) done accuracy:0.75 logloss:0.496024\n",
      "I0000 00:00:1729625142.090745 6800721 random_forest.cc:812] Training of tree  193/300 (tree index:193) done accuracy:0.741667 logloss:0.498227\n",
      "I0000 00:00:1729625142.090907 6800722 random_forest.cc:812] Training of tree  203/300 (tree index:203) done accuracy:0.75 logloss:0.491909\n",
      "I0000 00:00:1729625142.091038 6800719 random_forest.cc:812] Training of tree  213/300 (tree index:212) done accuracy:0.758333 logloss:0.488914\n",
      "I0000 00:00:1729625142.091195 6800718 random_forest.cc:812] Training of tree  223/300 (tree index:223) done accuracy:0.75 logloss:0.489475\n",
      "I0000 00:00:1729625142.091322 6800722 random_forest.cc:812] Training of tree  233/300 (tree index:233) done accuracy:0.741667 logloss:0.490535\n",
      "I0000 00:00:1729625142.091474 6800719 random_forest.cc:812] Training of tree  243/300 (tree index:243) done accuracy:0.741667 logloss:0.490855\n",
      "I0000 00:00:1729625142.091663 6800718 random_forest.cc:812] Training of tree  253/300 (tree index:249) done accuracy:0.75 logloss:0.492979\n",
      "I0000 00:00:1729625142.091824 6800717 random_forest.cc:812] Training of tree  263/300 (tree index:265) done accuracy:0.758333 logloss:0.492949\n",
      "I0000 00:00:1729625142.091961 6800721 random_forest.cc:812] Training of tree  274/300 (tree index:275) done accuracy:0.758333 logloss:0.491376\n",
      "I0000 00:00:1729625142.092154 6800718 random_forest.cc:812] Training of tree  284/300 (tree index:283) done accuracy:0.758333 logloss:0.490928\n",
      "I0000 00:00:1729625142.092275 6800720 random_forest.cc:812] Training of tree  294/300 (tree index:294) done accuracy:0.758333 logloss:0.489235\n",
      "I0000 00:00:1729625142.092388 6800715 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.75 logloss:0.490217\n",
      "I0000 00:00:1729625142.092488 6800706 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.490217\n",
      "I0000 00:00:1729625142.092996 6800706 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw4ndbaqx with prefix 6cc7b0104e93466e\n",
      "I0000 00:00:1729625142.096208 6800706 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625142.096971 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.490217\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  16\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:42.102895: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw4ndbaqx/model/ with prefix 6cc7b0104e93466e\n",
      "I0000 00:00:1729625142.108716 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4508 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:42.108734: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145684. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022600\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp128ylpb1 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625142.386141 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625142.386153 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625142.386161 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625142.386223 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625142.386228 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625142.386272 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.386281 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.386287 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.386291 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.386319 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625142.386338 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625142.386473 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625142.386495 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdbpxrue3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625142.386551 6800774 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625142.386650 6800774 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625142.387153 6800789 random_forest.cc:812] Training of tree  1/300 (tree index:4) done accuracy:0.767857 logloss:8.36728\n",
      "I0000 00:00:1729625142.387277 6800786 random_forest.cc:812] Training of tree  12/300 (tree index:10) done accuracy:0.733333 logloss:2.49897\n",
      "I0000 00:00:1729625142.387456 6800787 random_forest.cc:812] Training of tree  22/300 (tree index:18) done accuracy:0.758333 logloss:1.67526\n",
      "I0000 00:00:1729625142.387647 6800786 random_forest.cc:812] Training of tree  32/300 (tree index:27) done accuracy:0.766667 logloss:0.83393\n",
      "I0000 00:00:1729625142.387780 6800784 random_forest.cc:812] Training of tree  42/300 (tree index:40) done accuracy:0.775 logloss:0.841675\n",
      "I0000 00:00:1729625142.387991 6800783 random_forest.cc:812] Training of tree  54/300 (tree index:55) done accuracy:0.75 logloss:0.828165\n",
      "I0000 00:00:1729625142.388167 6800785 random_forest.cc:812] Training of tree  64/300 (tree index:63) done accuracy:0.733333 logloss:0.551647\n",
      "I0000 00:00:1729625142.388358 6800789 random_forest.cc:812] Training of tree  74/300 (tree index:73) done accuracy:0.691667 logloss:0.55267\n",
      "I0000 00:00:1729625142.388493 6800786 random_forest.cc:812] Training of tree  85/300 (tree index:84) done accuracy:0.691667 logloss:0.544641\n",
      "I0000 00:00:1729625142.388668 6800789 random_forest.cc:812] Training of tree  97/300 (tree index:96) done accuracy:0.716667 logloss:0.548479\n",
      "I0000 00:00:1729625142.388871 6800786 random_forest.cc:812] Training of tree  107/300 (tree index:107) done accuracy:0.716667 logloss:0.549137\n",
      "I0000 00:00:1729625142.389003 6800785 random_forest.cc:812] Training of tree  117/300 (tree index:117) done accuracy:0.716667 logloss:0.555888\n",
      "I0000 00:00:1729625142.389111 6800789 random_forest.cc:812] Training of tree  127/300 (tree index:128) done accuracy:0.716667 logloss:0.547128\n",
      "I0000 00:00:1729625142.389243 6800790 random_forest.cc:812] Training of tree  137/300 (tree index:138) done accuracy:0.7 logloss:0.54837\n",
      "I0000 00:00:1729625142.389360 6800789 random_forest.cc:812] Training of tree  147/300 (tree index:145) done accuracy:0.7 logloss:0.552559\n",
      "I0000 00:00:1729625142.389515 6800787 random_forest.cc:812] Training of tree  157/300 (tree index:155) done accuracy:0.716667 logloss:0.548879\n",
      "I0000 00:00:1729625142.389665 6800789 random_forest.cc:812] Training of tree  168/300 (tree index:168) done accuracy:0.7 logloss:0.550362\n",
      "I0000 00:00:1729625142.389848 6800783 random_forest.cc:812] Training of tree  180/300 (tree index:181) done accuracy:0.708333 logloss:0.548204\n",
      "I0000 00:00:1729625142.389987 6800784 random_forest.cc:812] Training of tree  190/300 (tree index:191) done accuracy:0.708333 logloss:0.545473\n",
      "I0000 00:00:1729625142.390096 6800785 random_forest.cc:812] Training of tree  200/300 (tree index:200) done accuracy:0.691667 logloss:0.54886\n",
      "I0000 00:00:1729625142.390239 6800783 random_forest.cc:812] Training of tree  211/300 (tree index:210) done accuracy:0.691667 logloss:0.549419\n",
      "I0000 00:00:1729625142.390397 6800786 random_forest.cc:812] Training of tree  222/300 (tree index:222) done accuracy:0.7 logloss:0.550073\n",
      "I0000 00:00:1729625142.390556 6800786 random_forest.cc:812] Training of tree  232/300 (tree index:232) done accuracy:0.716667 logloss:0.544943\n",
      "I0000 00:00:1729625142.390683 6800789 random_forest.cc:812] Training of tree  242/300 (tree index:242) done accuracy:0.708333 logloss:0.54831\n",
      "I0000 00:00:1729625142.390822 6800790 random_forest.cc:812] Training of tree  252/300 (tree index:252) done accuracy:0.7 logloss:0.550314\n",
      "I0000 00:00:1729625142.390991 6800790 random_forest.cc:812] Training of tree  263/300 (tree index:263) done accuracy:0.716667 logloss:0.547915\n",
      "I0000 00:00:1729625142.391153 6800789 random_forest.cc:812] Training of tree  273/300 (tree index:272) done accuracy:0.708333 logloss:0.547925\n",
      "I0000 00:00:1729625142.391316 6800784 random_forest.cc:812] Training of tree  285/300 (tree index:277) done accuracy:0.725 logloss:0.545872\n",
      "I0000 00:00:1729625142.391468 6800788 random_forest.cc:812] Training of tree  295/300 (tree index:294) done accuracy:0.725 logloss:0.544545\n",
      "I0000 00:00:1729625142.391531 6800786 random_forest.cc:812] Training of tree  300/300 (tree index:295) done accuracy:0.725 logloss:0.54511\n",
      "I0000 00:00:1729625142.391617 6800774 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.54511\n",
      "I0000 00:00:1729625142.392060 6800774 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdbpxrue3 with prefix 52a0e9b8c572466d\n",
      "I0000 00:00:1729625142.394658 6800774 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625142.395290 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.54511\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  16  46\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:42.401526: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpdbpxrue3/model/ with prefix 52a0e9b8c572466d\n",
      "I0000 00:00:1729625142.406420 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3792 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:42.406436: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146465. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021570\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwrks6f5n as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625142.685740 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625142.685750 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625142.685757 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625142.685825 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625142.685830 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625142.685879 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.685889 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.685894 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.685900 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.685931 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625142.685948 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625142.686082 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625142.686109 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp128ylpb1/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625142.686156 6800841 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625142.686253 6800841 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625142.686829 6800851 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625142.686941 6800856 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.722689 logloss:2.52136\n",
      "I0000 00:00:1729625142.687077 6800852 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.725 logloss:0.859321\n",
      "I0000 00:00:1729625142.687224 6800855 random_forest.cc:812] Training of tree  31/300 (tree index:29) done accuracy:0.708333 logloss:0.863601\n",
      "I0000 00:00:1729625142.687399 6800855 random_forest.cc:812] Training of tree  42/300 (tree index:42) done accuracy:0.741667 logloss:0.572828\n",
      "I0000 00:00:1729625142.687523 6800853 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.733333 logloss:0.575009\n",
      "I0000 00:00:1729625142.687668 6800856 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.733333 logloss:0.56633\n",
      "I0000 00:00:1729625142.687823 6800855 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.733333 logloss:0.571224\n",
      "I0000 00:00:1729625142.687993 6800854 random_forest.cc:812] Training of tree  82/300 (tree index:81) done accuracy:0.741667 logloss:0.569227\n",
      "I0000 00:00:1729625142.688133 6800850 random_forest.cc:812] Training of tree  92/300 (tree index:93) done accuracy:0.741667 logloss:0.562623\n",
      "I0000 00:00:1729625142.688234 6800852 random_forest.cc:812] Training of tree  102/300 (tree index:102) done accuracy:0.741667 logloss:0.556949\n",
      "I0000 00:00:1729625142.688384 6800855 random_forest.cc:812] Training of tree  112/300 (tree index:112) done accuracy:0.75 logloss:0.55916\n",
      "I0000 00:00:1729625142.688522 6800854 random_forest.cc:812] Training of tree  122/300 (tree index:121) done accuracy:0.766667 logloss:0.560616\n",
      "I0000 00:00:1729625142.688634 6800850 random_forest.cc:812] Training of tree  132/300 (tree index:130) done accuracy:0.775 logloss:0.559918\n",
      "I0000 00:00:1729625142.688790 6800851 random_forest.cc:812] Training of tree  142/300 (tree index:143) done accuracy:0.775 logloss:0.557794\n",
      "I0000 00:00:1729625142.688939 6800852 random_forest.cc:812] Training of tree  153/300 (tree index:154) done accuracy:0.766667 logloss:0.564669\n",
      "I0000 00:00:1729625142.689078 6800853 random_forest.cc:812] Training of tree  163/300 (tree index:164) done accuracy:0.75 logloss:0.565535\n",
      "I0000 00:00:1729625142.689210 6800851 random_forest.cc:812] Training of tree  173/300 (tree index:174) done accuracy:0.775 logloss:0.564106\n",
      "I0000 00:00:1729625142.689311 6800855 random_forest.cc:812] Training of tree  183/300 (tree index:182) done accuracy:0.775 logloss:0.561538\n",
      "I0000 00:00:1729625142.689508 6800856 random_forest.cc:812] Training of tree  195/300 (tree index:194) done accuracy:0.783333 logloss:0.558109\n",
      "I0000 00:00:1729625142.689692 6800853 random_forest.cc:812] Training of tree  205/300 (tree index:205) done accuracy:0.783333 logloss:0.559849\n",
      "I0000 00:00:1729625142.689869 6800856 random_forest.cc:812] Training of tree  215/300 (tree index:214) done accuracy:0.775 logloss:0.560814\n",
      "I0000 00:00:1729625142.690052 6800857 random_forest.cc:812] Training of tree  225/300 (tree index:224) done accuracy:0.766667 logloss:0.561243\n",
      "I0000 00:00:1729625142.690228 6800854 random_forest.cc:812] Training of tree  235/300 (tree index:234) done accuracy:0.766667 logloss:0.559367\n",
      "I0000 00:00:1729625142.690468 6800851 random_forest.cc:812] Training of tree  248/300 (tree index:249) done accuracy:0.775 logloss:0.557573\n",
      "I0000 00:00:1729625142.690699 6800854 random_forest.cc:812] Training of tree  258/300 (tree index:251) done accuracy:0.783333 logloss:0.553487\n",
      "I0000 00:00:1729625142.690828 6800853 random_forest.cc:812] Training of tree  268/300 (tree index:267) done accuracy:0.791667 logloss:0.553243\n",
      "I0000 00:00:1729625142.690994 6800855 random_forest.cc:812] Training of tree  278/300 (tree index:277) done accuracy:0.8 logloss:0.552095\n",
      "I0000 00:00:1729625142.691149 6800850 random_forest.cc:812] Training of tree  288/300 (tree index:289) done accuracy:0.783333 logloss:0.551359\n",
      "I0000 00:00:1729625142.691288 6800853 random_forest.cc:812] Training of tree  299/300 (tree index:297) done accuracy:0.783333 logloss:0.549476\n",
      "I0000 00:00:1729625142.691326 6800855 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.791667 logloss:0.55055\n",
      "I0000 00:00:1729625142.691421 6800841 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.55055\n",
      "I0000 00:00:1729625142.691842 6800841 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp128ylpb1 with prefix a262696d417642c5\n",
      "I0000 00:00:1729625142.694190 6800841 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625142.694844 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.55055\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  13\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:42.700488: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp128ylpb1/model/ with prefix a262696d417642c5\n",
      "I0000 00:00:1729625142.705407 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3804 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:42.705422: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.148158. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022058\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpux9nd884 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625142.984904 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625142.984918 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625142.984923 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625142.984995 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625142.985001 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625142.985056 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.985069 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.985075 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.985080 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625142.985118 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625142.985137 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625142.985284 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625142.985310 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwrks6f5n/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625142.985369 6800921 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625142.985473 6800921 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625142.986000 6800932 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625142.986140 6800935 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.683333 logloss:2.86263\n",
      "I0000 00:00:1729625142.986295 6800930 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.625 logloss:1.20467\n",
      "I0000 00:00:1729625142.986427 6800936 random_forest.cc:812] Training of tree  32/300 (tree index:31) done accuracy:0.675 logloss:0.891199\n",
      "I0000 00:00:1729625142.986574 6800935 random_forest.cc:812] Training of tree  42/300 (tree index:42) done accuracy:0.716667 logloss:0.599889\n",
      "I0000 00:00:1729625142.986718 6800930 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.7 logloss:0.600592\n",
      "I0000 00:00:1729625142.986837 6800930 random_forest.cc:812] Training of tree  62/300 (tree index:59) done accuracy:0.7 logloss:0.589348\n",
      "I0000 00:00:1729625142.986966 6800933 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.7 logloss:0.577134\n",
      "I0000 00:00:1729625142.987130 6800932 random_forest.cc:812] Training of tree  82/300 (tree index:65) done accuracy:0.683333 logloss:0.568806\n",
      "I0000 00:00:1729625142.987245 6800936 random_forest.cc:812] Training of tree  92/300 (tree index:93) done accuracy:0.675 logloss:0.567057\n",
      "I0000 00:00:1729625142.987367 6800935 random_forest.cc:812] Training of tree  102/300 (tree index:103) done accuracy:0.683333 logloss:0.570713\n",
      "I0000 00:00:1729625142.987485 6800932 random_forest.cc:812] Training of tree  112/300 (tree index:113) done accuracy:0.691667 logloss:0.565843\n",
      "I0000 00:00:1729625142.987622 6800936 random_forest.cc:812] Training of tree  122/300 (tree index:123) done accuracy:0.683333 logloss:0.558877\n",
      "I0000 00:00:1729625142.987755 6800933 random_forest.cc:812] Training of tree  132/300 (tree index:128) done accuracy:0.691667 logloss:0.551964\n",
      "I0000 00:00:1729625142.987909 6800932 random_forest.cc:812] Training of tree  142/300 (tree index:142) done accuracy:0.691667 logloss:0.55049\n",
      "I0000 00:00:1729625142.988050 6800931 random_forest.cc:812] Training of tree  152/300 (tree index:152) done accuracy:0.716667 logloss:0.554967\n",
      "I0000 00:00:1729625142.988179 6800930 random_forest.cc:812] Training of tree  162/300 (tree index:164) done accuracy:0.7 logloss:0.56052\n",
      "I0000 00:00:1729625142.988292 6800936 random_forest.cc:812] Training of tree  172/300 (tree index:171) done accuracy:0.708333 logloss:0.565171\n",
      "I0000 00:00:1729625142.988474 6800933 random_forest.cc:812] Training of tree  182/300 (tree index:181) done accuracy:0.733333 logloss:0.564368\n",
      "I0000 00:00:1729625142.988609 6800937 random_forest.cc:812] Training of tree  193/300 (tree index:192) done accuracy:0.733333 logloss:0.568575\n",
      "I0000 00:00:1729625142.988802 6800934 random_forest.cc:812] Training of tree  203/300 (tree index:202) done accuracy:0.741667 logloss:0.568295\n",
      "I0000 00:00:1729625142.988964 6800934 random_forest.cc:812] Training of tree  213/300 (tree index:214) done accuracy:0.733333 logloss:0.56306\n",
      "I0000 00:00:1729625142.989075 6800930 random_forest.cc:812] Training of tree  223/300 (tree index:225) done accuracy:0.733333 logloss:0.560511\n",
      "I0000 00:00:1729625142.989201 6800930 random_forest.cc:812] Training of tree  233/300 (tree index:230) done accuracy:0.741667 logloss:0.559949\n",
      "I0000 00:00:1729625142.989366 6800932 random_forest.cc:812] Training of tree  243/300 (tree index:244) done accuracy:0.75 logloss:0.560863\n",
      "I0000 00:00:1729625142.989505 6800934 random_forest.cc:812] Training of tree  253/300 (tree index:254) done accuracy:0.75 logloss:0.559899\n",
      "I0000 00:00:1729625142.989686 6800931 random_forest.cc:812] Training of tree  265/300 (tree index:266) done accuracy:0.741667 logloss:0.559352\n",
      "I0000 00:00:1729625142.989890 6800931 random_forest.cc:812] Training of tree  275/300 (tree index:276) done accuracy:0.741667 logloss:0.558092\n",
      "I0000 00:00:1729625142.990058 6800935 random_forest.cc:812] Training of tree  286/300 (tree index:287) done accuracy:0.741667 logloss:0.559445\n",
      "I0000 00:00:1729625142.990298 6800931 random_forest.cc:812] Training of tree  296/300 (tree index:295) done accuracy:0.741667 logloss:0.560033\n",
      "I0000 00:00:1729625142.990321 6800936 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.75 logloss:0.56046\n",
      "I0000 00:00:1729625142.990447 6800921 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.56046\n",
      "I0000 00:00:1729625142.990881 6800921 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwrks6f5n with prefix e6a8d9cdccf7496a\n",
      "I0000 00:00:1729625142.993213 6800921 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625142.993898 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.56046\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  18\n",
      "2  12  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:42.999727: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpwrks6f5n/model/ with prefix e6a8d9cdccf7496a\n",
      "I0000 00:00:1729625143.004612 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3854 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:43.004633: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.188228. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022962\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf63u5ne_ as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625143.325983 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625143.325993 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625143.325997 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625143.326059 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625143.326065 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625143.326124 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625143.326152 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625143.326158 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625143.326164 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625143.326197 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625143.326217 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625143.326361 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625143.326391 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpux9nd884/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625143.326436 6800991 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625143.326537 6800991 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625143.327104 6801007 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625143.327213 6801002 random_forest.cc:812] Training of tree  12/300 (tree index:9) done accuracy:0.689076 logloss:2.85385\n",
      "I0000 00:00:1729625143.327386 6801002 random_forest.cc:812] Training of tree  22/300 (tree index:21) done accuracy:0.7 logloss:1.10706\n",
      "I0000 00:00:1729625143.327515 6801001 random_forest.cc:812] Training of tree  32/300 (tree index:31) done accuracy:0.725 logloss:0.804078\n",
      "I0000 00:00:1729625143.327655 6801006 random_forest.cc:812] Training of tree  42/300 (tree index:41) done accuracy:0.741667 logloss:0.523616\n",
      "I0000 00:00:1729625143.327780 6801007 random_forest.cc:812] Training of tree  52/300 (tree index:51) done accuracy:0.75 logloss:0.521653\n",
      "I0000 00:00:1729625143.327913 6801006 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.733333 logloss:0.518413\n",
      "I0000 00:00:1729625143.328085 6801006 random_forest.cc:812] Training of tree  72/300 (tree index:71) done accuracy:0.758333 logloss:0.518942\n",
      "I0000 00:00:1729625143.328220 6801007 random_forest.cc:812] Training of tree  82/300 (tree index:79) done accuracy:0.75 logloss:0.520502\n",
      "I0000 00:00:1729625143.328417 6801006 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.75 logloss:0.517946\n",
      "I0000 00:00:1729625143.328563 6801004 random_forest.cc:812] Training of tree  102/300 (tree index:102) done accuracy:0.783333 logloss:0.510427\n",
      "I0000 00:00:1729625143.328694 6801001 random_forest.cc:812] Training of tree  112/300 (tree index:111) done accuracy:0.775 logloss:0.510325\n",
      "I0000 00:00:1729625143.328820 6801000 random_forest.cc:812] Training of tree  122/300 (tree index:122) done accuracy:0.758333 logloss:0.50855\n",
      "I0000 00:00:1729625143.328955 6801002 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.775 logloss:0.500077\n",
      "I0000 00:00:1729625143.329138 6801001 random_forest.cc:812] Training of tree  143/300 (tree index:143) done accuracy:0.775 logloss:0.497438\n",
      "I0000 00:00:1729625143.329344 6801003 random_forest.cc:812] Training of tree  153/300 (tree index:153) done accuracy:0.775 logloss:0.498036\n",
      "I0000 00:00:1729625143.329528 6801003 random_forest.cc:812] Training of tree  163/300 (tree index:163) done accuracy:0.783333 logloss:0.498636\n",
      "I0000 00:00:1729625143.329684 6801001 random_forest.cc:812] Training of tree  173/300 (tree index:172) done accuracy:0.783333 logloss:0.501011\n",
      "I0000 00:00:1729625143.329793 6801000 random_forest.cc:812] Training of tree  183/300 (tree index:182) done accuracy:0.766667 logloss:0.503453\n",
      "I0000 00:00:1729625143.329919 6801006 random_forest.cc:812] Training of tree  193/300 (tree index:183) done accuracy:0.775 logloss:0.501706\n",
      "I0000 00:00:1729625143.330070 6801006 random_forest.cc:812] Training of tree  203/300 (tree index:205) done accuracy:0.775 logloss:0.500384\n",
      "I0000 00:00:1729625143.330187 6801002 random_forest.cc:812] Training of tree  213/300 (tree index:212) done accuracy:0.783333 logloss:0.499007\n",
      "I0000 00:00:1729625143.330314 6801007 random_forest.cc:812] Training of tree  224/300 (tree index:223) done accuracy:0.766667 logloss:0.499187\n",
      "I0000 00:00:1729625143.330464 6801007 random_forest.cc:812] Training of tree  234/300 (tree index:235) done accuracy:0.766667 logloss:0.496177\n",
      "I0000 00:00:1729625143.330583 6801001 random_forest.cc:812] Training of tree  244/300 (tree index:242) done accuracy:0.766667 logloss:0.496858\n",
      "I0000 00:00:1729625143.330729 6801005 random_forest.cc:812] Training of tree  254/300 (tree index:254) done accuracy:0.775 logloss:0.495512\n",
      "I0000 00:00:1729625143.330844 6801000 random_forest.cc:812] Training of tree  264/300 (tree index:264) done accuracy:0.775 logloss:0.496571\n",
      "I0000 00:00:1729625143.331000 6801005 random_forest.cc:812] Training of tree  274/300 (tree index:272) done accuracy:0.783333 logloss:0.495388\n",
      "I0000 00:00:1729625143.331149 6801002 random_forest.cc:812] Training of tree  284/300 (tree index:284) done accuracy:0.775 logloss:0.495007\n",
      "I0000 00:00:1729625143.331277 6801004 random_forest.cc:812] Training of tree  294/300 (tree index:294) done accuracy:0.775 logloss:0.495476\n",
      "I0000 00:00:1729625143.331380 6801005 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.775 logloss:0.496575\n",
      "I0000 00:00:1729625143.331460 6800991 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.496575\n",
      "I0000 00:00:1729625143.331839 6800991 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpux9nd884 with prefix 9f57a69b252b4ac3\n",
      "I0000 00:00:1729625143.334945 6800991 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625143.335655 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.496575\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  15\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:43.341574: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpux9nd884/model/ with prefix 9f57a69b252b4ac3\n",
      "I0000 00:00:1729625143.346906 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3648 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:43.346928: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.149326. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022241\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 30, 'min_examples': 20, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq320w8py as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625143.625724 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625143.625740 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625143.625744 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625143.625809 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625143.625814 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625143.625861 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625143.625871 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625143.625876 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625143.625881 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625143.625908 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625143.625926 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625143.626077 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625143.626104 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf63u5ne_/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625143.626154 6801058 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625143.626250 6801058 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625143.626842 6801074 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.735849 logloss:9.52096\n",
      "I0000 00:00:1729625143.626969 6801073 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.716667 logloss:1.36744\n",
      "I0000 00:00:1729625143.627121 6801069 random_forest.cc:812] Training of tree  21/300 (tree index:5) done accuracy:0.733333 logloss:0.801122\n",
      "I0000 00:00:1729625143.627244 6801071 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.733333 logloss:0.484528\n",
      "I0000 00:00:1729625143.627400 6801072 random_forest.cc:812] Training of tree  41/300 (tree index:41) done accuracy:0.775 logloss:0.50913\n",
      "I0000 00:00:1729625143.627538 6801070 random_forest.cc:812] Training of tree  51/300 (tree index:52) done accuracy:0.766667 logloss:0.515584\n",
      "I0000 00:00:1729625143.627659 6801074 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.775 logloss:0.518971\n",
      "I0000 00:00:1729625143.627820 6801074 random_forest.cc:812] Training of tree  73/300 (tree index:73) done accuracy:0.775 logloss:0.525961\n",
      "I0000 00:00:1729625143.627998 6801069 random_forest.cc:812] Training of tree  83/300 (tree index:84) done accuracy:0.775 logloss:0.517634\n",
      "I0000 00:00:1729625143.628194 6801071 random_forest.cc:812] Training of tree  93/300 (tree index:95) done accuracy:0.766667 logloss:0.514252\n",
      "I0000 00:00:1729625143.628348 6801071 random_forest.cc:812] Training of tree  103/300 (tree index:103) done accuracy:0.775 logloss:0.519635\n",
      "I0000 00:00:1729625143.628500 6801071 random_forest.cc:812] Training of tree  113/300 (tree index:112) done accuracy:0.775 logloss:0.516514\n",
      "I0000 00:00:1729625143.628646 6801070 random_forest.cc:812] Training of tree  123/300 (tree index:124) done accuracy:0.775 logloss:0.513072\n",
      "I0000 00:00:1729625143.628806 6801073 random_forest.cc:812] Training of tree  135/300 (tree index:134) done accuracy:0.783333 logloss:0.507107\n",
      "I0000 00:00:1729625143.629016 6801073 random_forest.cc:812] Training of tree  145/300 (tree index:146) done accuracy:0.775 logloss:0.513562\n",
      "I0000 00:00:1729625143.629155 6801071 random_forest.cc:812] Training of tree  155/300 (tree index:155) done accuracy:0.775 logloss:0.514093\n",
      "I0000 00:00:1729625143.629270 6801073 random_forest.cc:812] Training of tree  165/300 (tree index:163) done accuracy:0.783333 logloss:0.513132\n",
      "I0000 00:00:1729625143.629405 6801068 random_forest.cc:812] Training of tree  175/300 (tree index:174) done accuracy:0.775 logloss:0.5153\n",
      "I0000 00:00:1729625143.629633 6801074 random_forest.cc:812] Training of tree  186/300 (tree index:185) done accuracy:0.783333 logloss:0.513867\n",
      "I0000 00:00:1729625143.629803 6801074 random_forest.cc:812] Training of tree  196/300 (tree index:196) done accuracy:0.766667 logloss:0.514371\n",
      "I0000 00:00:1729625143.629914 6801069 random_forest.cc:812] Training of tree  206/300 (tree index:206) done accuracy:0.775 logloss:0.517765\n",
      "I0000 00:00:1729625143.630052 6801072 random_forest.cc:812] Training of tree  216/300 (tree index:217) done accuracy:0.775 logloss:0.51667\n",
      "I0000 00:00:1729625143.630214 6801072 random_forest.cc:812] Training of tree  228/300 (tree index:229) done accuracy:0.783333 logloss:0.515229\n",
      "I0000 00:00:1729625143.630428 6801070 random_forest.cc:812] Training of tree  239/300 (tree index:239) done accuracy:0.783333 logloss:0.512726\n",
      "I0000 00:00:1729625143.630636 6801070 random_forest.cc:812] Training of tree  249/300 (tree index:248) done accuracy:0.783333 logloss:0.513059\n",
      "I0000 00:00:1729625143.630810 6801074 random_forest.cc:812] Training of tree  259/300 (tree index:258) done accuracy:0.783333 logloss:0.515959\n",
      "I0000 00:00:1729625143.630956 6801072 random_forest.cc:812] Training of tree  269/300 (tree index:269) done accuracy:0.783333 logloss:0.518744\n",
      "I0000 00:00:1729625143.631079 6801068 random_forest.cc:812] Training of tree  279/300 (tree index:280) done accuracy:0.783333 logloss:0.519151\n",
      "I0000 00:00:1729625143.631233 6801069 random_forest.cc:812] Training of tree  289/300 (tree index:270) done accuracy:0.783333 logloss:0.517966\n",
      "I0000 00:00:1729625143.631361 6801073 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.783333 logloss:0.516915\n",
      "I0000 00:00:1729625143.631462 6801058 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.516915\n",
      "I0000 00:00:1729625143.631864 6801058 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf63u5ne_ with prefix 7dd6e253193d4065\n",
      "I0000 00:00:1729625143.634108 6801058 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625143.634801 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.516915\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  12  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:43.640822: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpf63u5ne_/model/ with prefix 7dd6e253193d4065\n",
      "I0000 00:00:1729625143.645759 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3744 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:43.645786: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.538997. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.019465\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfa42cdr6 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625144.318508 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625144.318520 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625144.318524 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625144.318595 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625144.318601 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625144.318646 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.318657 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.318665 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.318671 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.318699 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625144.318716 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625144.318862 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625144.318888 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq320w8py/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625144.318972 6801133 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625144.319154 6801133 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625144.319751 6801143 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.525 logloss:17.1207\n",
      "I0000 00:00:1729625144.319910 6801144 random_forest.cc:812] Training of tree  13/300 (tree index:12) done accuracy:0.737288 logloss:4.01189\n",
      "I0000 00:00:1729625144.320080 6801148 random_forest.cc:812] Training of tree  23/300 (tree index:22) done accuracy:0.741667 logloss:2.22903\n",
      "I0000 00:00:1729625144.320229 6801144 random_forest.cc:812] Training of tree  33/300 (tree index:31) done accuracy:0.758333 logloss:1.40372\n",
      "I0000 00:00:1729625144.320337 6801143 random_forest.cc:812] Training of tree  43/300 (tree index:42) done accuracy:0.725 logloss:1.41591\n",
      "I0000 00:00:1729625144.320492 6801147 random_forest.cc:812] Training of tree  53/300 (tree index:54) done accuracy:0.725 logloss:1.14404\n",
      "I0000 00:00:1729625144.320600 6801146 random_forest.cc:812] Training of tree  63/300 (tree index:61) done accuracy:0.708333 logloss:0.848867\n",
      "I0000 00:00:1729625144.320734 6801145 random_forest.cc:812] Training of tree  73/300 (tree index:72) done accuracy:0.716667 logloss:0.841078\n",
      "I0000 00:00:1729625144.320881 6801146 random_forest.cc:812] Training of tree  83/300 (tree index:83) done accuracy:0.7 logloss:0.847659\n",
      "I0000 00:00:1729625144.321072 6801147 random_forest.cc:812] Training of tree  93/300 (tree index:93) done accuracy:0.7 logloss:0.585499\n",
      "I0000 00:00:1729625144.321202 6801144 random_forest.cc:812] Training of tree  103/300 (tree index:103) done accuracy:0.708333 logloss:0.582117\n",
      "I0000 00:00:1729625144.321308 6801147 random_forest.cc:812] Training of tree  113/300 (tree index:111) done accuracy:0.708333 logloss:0.594344\n",
      "I0000 00:00:1729625144.321442 6801142 random_forest.cc:812] Training of tree  123/300 (tree index:124) done accuracy:0.708333 logloss:0.589177\n",
      "I0000 00:00:1729625144.321562 6801149 random_forest.cc:812] Training of tree  133/300 (tree index:133) done accuracy:0.7 logloss:0.592284\n",
      "I0000 00:00:1729625144.321720 6801145 random_forest.cc:812] Training of tree  143/300 (tree index:121) done accuracy:0.708333 logloss:0.582757\n",
      "I0000 00:00:1729625144.321863 6801143 random_forest.cc:812] Training of tree  154/300 (tree index:153) done accuracy:0.708333 logloss:0.580996\n",
      "I0000 00:00:1729625144.322060 6801143 random_forest.cc:812] Training of tree  167/300 (tree index:167) done accuracy:0.725 logloss:0.577748\n",
      "I0000 00:00:1729625144.322231 6801149 random_forest.cc:812] Training of tree  177/300 (tree index:176) done accuracy:0.716667 logloss:0.570163\n",
      "I0000 00:00:1729625144.322342 6801143 random_forest.cc:812] Training of tree  187/300 (tree index:188) done accuracy:0.708333 logloss:0.571239\n",
      "I0000 00:00:1729625144.322460 6801146 random_forest.cc:812] Training of tree  199/300 (tree index:196) done accuracy:0.716667 logloss:0.571432\n",
      "I0000 00:00:1729625144.322665 6801144 random_forest.cc:812] Training of tree  209/300 (tree index:211) done accuracy:0.716667 logloss:0.577075\n",
      "I0000 00:00:1729625144.322855 6801149 random_forest.cc:812] Training of tree  219/300 (tree index:216) done accuracy:0.725 logloss:0.580464\n",
      "I0000 00:00:1729625144.322994 6801143 random_forest.cc:812] Training of tree  229/300 (tree index:228) done accuracy:0.733333 logloss:0.578132\n",
      "I0000 00:00:1729625144.323127 6801144 random_forest.cc:812] Training of tree  240/300 (tree index:240) done accuracy:0.716667 logloss:0.574294\n",
      "I0000 00:00:1729625144.323249 6801147 random_forest.cc:812] Training of tree  250/300 (tree index:249) done accuracy:0.733333 logloss:0.57321\n",
      "I0000 00:00:1729625144.323373 6801149 random_forest.cc:812] Training of tree  260/300 (tree index:260) done accuracy:0.741667 logloss:0.573355\n",
      "I0000 00:00:1729625144.323546 6801142 random_forest.cc:812] Training of tree  270/300 (tree index:268) done accuracy:0.725 logloss:0.576433\n",
      "I0000 00:00:1729625144.323661 6801146 random_forest.cc:812] Training of tree  280/300 (tree index:279) done accuracy:0.733333 logloss:0.576442\n",
      "I0000 00:00:1729625144.323804 6801145 random_forest.cc:812] Training of tree  290/300 (tree index:290) done accuracy:0.758333 logloss:0.574566\n",
      "I0000 00:00:1729625144.323909 6801146 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.741667 logloss:0.575649\n",
      "I0000 00:00:1729625144.323968 6801133 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.575649\n",
      "I0000 00:00:1729625144.324328 6801133 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq320w8py with prefix 1f4d3ea6e5244156\n",
      "I0000 00:00:1729625144.326514 6801133 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625144.327128 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.575649\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  14  48\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:44.332504: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpq320w8py/model/ with prefix 1f4d3ea6e5244156\n",
      "I0000 00:00:1729625144.335892 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2456 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:44.335910: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.161445. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.019409\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpngwy0_mn as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625144.640695 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625144.640708 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625144.640712 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625144.640783 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625144.640788 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625144.640843 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.640854 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.640860 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.640865 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.640896 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625144.640915 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625144.641088 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625144.641111 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfa42cdr6/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625144.641169 6801200 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625144.641284 6801200 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625144.641823 6801215 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.675 logloss:11.7142\n",
      "I0000 00:00:1729625144.641945 6801216 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.588235 logloss:5.22522\n",
      "I0000 00:00:1729625144.642067 6801215 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.658333 logloss:2.30676\n",
      "I0000 00:00:1729625144.642235 6801216 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.675 logloss:0.899216\n",
      "I0000 00:00:1729625144.642379 6801215 random_forest.cc:812] Training of tree  41/300 (tree index:41) done accuracy:0.716667 logloss:0.608767\n",
      "I0000 00:00:1729625144.642657 6801209 random_forest.cc:812] Training of tree  51/300 (tree index:54) done accuracy:0.716667 logloss:0.624003\n",
      "I0000 00:00:1729625144.642790 6801214 random_forest.cc:812] Training of tree  61/300 (tree index:57) done accuracy:0.7 logloss:0.625747\n",
      "I0000 00:00:1729625144.642965 6801214 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.733333 logloss:0.611541\n",
      "I0000 00:00:1729625144.643102 6801213 random_forest.cc:812] Training of tree  81/300 (tree index:76) done accuracy:0.733333 logloss:0.609949\n",
      "I0000 00:00:1729625144.643228 6801209 random_forest.cc:812] Training of tree  91/300 (tree index:92) done accuracy:0.741667 logloss:0.603953\n",
      "I0000 00:00:1729625144.643369 6801212 random_forest.cc:812] Training of tree  101/300 (tree index:102) done accuracy:0.733333 logloss:0.591948\n",
      "I0000 00:00:1729625144.643465 6801210 random_forest.cc:812] Training of tree  111/300 (tree index:112) done accuracy:0.725 logloss:0.594784\n",
      "I0000 00:00:1729625144.643614 6801215 random_forest.cc:812] Training of tree  122/300 (tree index:121) done accuracy:0.741667 logloss:0.58901\n",
      "I0000 00:00:1729625144.643733 6801214 random_forest.cc:812] Training of tree  132/300 (tree index:129) done accuracy:0.758333 logloss:0.592405\n",
      "I0000 00:00:1729625144.643881 6801212 random_forest.cc:812] Training of tree  143/300 (tree index:140) done accuracy:0.758333 logloss:0.597915\n",
      "I0000 00:00:1729625144.644084 6801214 random_forest.cc:812] Training of tree  156/300 (tree index:152) done accuracy:0.741667 logloss:0.603309\n",
      "I0000 00:00:1729625144.644248 6801212 random_forest.cc:812] Training of tree  166/300 (tree index:163) done accuracy:0.75 logloss:0.602501\n",
      "I0000 00:00:1729625144.644379 6801216 random_forest.cc:812] Training of tree  176/300 (tree index:176) done accuracy:0.758333 logloss:0.597904\n",
      "I0000 00:00:1729625144.644490 6801215 random_forest.cc:812] Training of tree  187/300 (tree index:187) done accuracy:0.766667 logloss:0.599878\n",
      "I0000 00:00:1729625144.644647 6801214 random_forest.cc:812] Training of tree  197/300 (tree index:196) done accuracy:0.775 logloss:0.601933\n",
      "I0000 00:00:1729625144.644768 6801213 random_forest.cc:812] Training of tree  208/300 (tree index:207) done accuracy:0.775 logloss:0.599953\n",
      "I0000 00:00:1729625144.644913 6801215 random_forest.cc:812] Training of tree  218/300 (tree index:216) done accuracy:0.766667 logloss:0.597257\n",
      "I0000 00:00:1729625144.645097 6801209 random_forest.cc:812] Training of tree  228/300 (tree index:227) done accuracy:0.758333 logloss:0.599536\n",
      "I0000 00:00:1729625144.645211 6801210 random_forest.cc:812] Training of tree  238/300 (tree index:237) done accuracy:0.766667 logloss:0.595461\n",
      "I0000 00:00:1729625144.645394 6801212 random_forest.cc:812] Training of tree  248/300 (tree index:248) done accuracy:0.766667 logloss:0.593199\n",
      "I0000 00:00:1729625144.645518 6801210 random_forest.cc:812] Training of tree  259/300 (tree index:258) done accuracy:0.783333 logloss:0.590605\n",
      "I0000 00:00:1729625144.645636 6801213 random_forest.cc:812] Training of tree  269/300 (tree index:268) done accuracy:0.775 logloss:0.588569\n",
      "I0000 00:00:1729625144.645764 6801214 random_forest.cc:812] Training of tree  279/300 (tree index:278) done accuracy:0.783333 logloss:0.586563\n",
      "I0000 00:00:1729625144.645860 6801213 random_forest.cc:812] Training of tree  289/300 (tree index:287) done accuracy:0.766667 logloss:0.584325\n",
      "I0000 00:00:1729625144.646024 6801216 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.791667 logloss:0.582991\n",
      "I0000 00:00:1729625144.646192 6801200 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.582991\n",
      "I0000 00:00:1729625144.646487 6801200 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfa42cdr6 with prefix 5b493d08a0a942a1\n",
      "I0000 00:00:1729625144.648366 6801200 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625144.649138 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.582991\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  10  57\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:44.654776: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfa42cdr6/model/ with prefix 5b493d08a0a942a1\n",
      "I0000 00:00:1729625144.658102 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2434 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:44.658119: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.194238. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.020239\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqmtsvfxh as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625144.993327 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625144.993337 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625144.993341 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625144.993410 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625144.993415 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625144.993461 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.993472 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.993478 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.993483 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625144.993513 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625144.993541 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625144.993692 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625144.993718 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpngwy0_mn/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625144.993767 6801268 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625144.993909 6801268 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625144.994459 6801284 random_forest.cc:812] Training of tree  1/300 (tree index:4) done accuracy:0.645833 logloss:12.7655\n",
      "I0000 00:00:1729625144.994589 6801283 random_forest.cc:812] Training of tree  12/300 (tree index:11) done accuracy:0.633333 logloss:3.45494\n",
      "I0000 00:00:1729625144.994730 6801277 random_forest.cc:812] Training of tree  22/300 (tree index:23) done accuracy:0.65 logloss:0.620804\n",
      "I0000 00:00:1729625144.994875 6801278 random_forest.cc:812] Training of tree  32/300 (tree index:31) done accuracy:0.708333 logloss:0.598998\n",
      "I0000 00:00:1729625144.995030 6801277 random_forest.cc:812] Training of tree  42/300 (tree index:41) done accuracy:0.708333 logloss:0.591163\n",
      "I0000 00:00:1729625144.995185 6801282 random_forest.cc:812] Training of tree  52/300 (tree index:53) done accuracy:0.708333 logloss:0.607554\n",
      "I0000 00:00:1729625144.995292 6801282 random_forest.cc:812] Training of tree  62/300 (tree index:59) done accuracy:0.708333 logloss:0.599859\n",
      "I0000 00:00:1729625144.995495 6801279 random_forest.cc:812] Training of tree  73/300 (tree index:72) done accuracy:0.716667 logloss:0.607062\n",
      "I0000 00:00:1729625144.995744 6801279 random_forest.cc:812] Training of tree  83/300 (tree index:80) done accuracy:0.716667 logloss:0.597396\n",
      "I0000 00:00:1729625144.995863 6801283 random_forest.cc:812] Training of tree  94/300 (tree index:94) done accuracy:0.716667 logloss:0.589103\n",
      "I0000 00:00:1729625144.995999 6801281 random_forest.cc:812] Training of tree  104/300 (tree index:104) done accuracy:0.716667 logloss:0.581966\n",
      "I0000 00:00:1729625144.996100 6801283 random_forest.cc:812] Training of tree  114/300 (tree index:113) done accuracy:0.716667 logloss:0.585491\n",
      "I0000 00:00:1729625144.996246 6801279 random_forest.cc:812] Training of tree  124/300 (tree index:123) done accuracy:0.708333 logloss:0.587343\n",
      "I0000 00:00:1729625144.996367 6801284 random_forest.cc:812] Training of tree  134/300 (tree index:136) done accuracy:0.691667 logloss:0.590133\n",
      "I0000 00:00:1729625144.996505 6801281 random_forest.cc:812] Training of tree  144/300 (tree index:143) done accuracy:0.7 logloss:0.592715\n",
      "I0000 00:00:1729625144.996683 6801280 random_forest.cc:812] Training of tree  154/300 (tree index:155) done accuracy:0.716667 logloss:0.592276\n",
      "I0000 00:00:1729625144.996827 6801278 random_forest.cc:812] Training of tree  164/300 (tree index:167) done accuracy:0.733333 logloss:0.594456\n",
      "I0000 00:00:1729625144.997017 6801279 random_forest.cc:812] Training of tree  174/300 (tree index:171) done accuracy:0.716667 logloss:0.58992\n",
      "I0000 00:00:1729625144.997216 6801283 random_forest.cc:812] Training of tree  184/300 (tree index:183) done accuracy:0.708333 logloss:0.58708\n",
      "I0000 00:00:1729625144.997354 6801282 random_forest.cc:812] Training of tree  194/300 (tree index:193) done accuracy:0.733333 logloss:0.588839\n",
      "I0000 00:00:1729625144.997468 6801280 random_forest.cc:812] Training of tree  204/300 (tree index:203) done accuracy:0.716667 logloss:0.590108\n",
      "I0000 00:00:1729625144.997599 6801281 random_forest.cc:812] Training of tree  214/300 (tree index:214) done accuracy:0.708333 logloss:0.592599\n",
      "I0000 00:00:1729625144.997742 6801278 random_forest.cc:812] Training of tree  224/300 (tree index:225) done accuracy:0.708333 logloss:0.593806\n",
      "I0000 00:00:1729625144.997850 6801281 random_forest.cc:812] Training of tree  235/300 (tree index:233) done accuracy:0.716667 logloss:0.592195\n",
      "I0000 00:00:1729625144.997991 6801281 random_forest.cc:812] Training of tree  245/300 (tree index:244) done accuracy:0.75 logloss:0.590492\n",
      "I0000 00:00:1729625144.998124 6801280 random_forest.cc:812] Training of tree  255/300 (tree index:255) done accuracy:0.741667 logloss:0.587701\n",
      "I0000 00:00:1729625144.998232 6801283 random_forest.cc:812] Training of tree  265/300 (tree index:264) done accuracy:0.725 logloss:0.587445\n",
      "I0000 00:00:1729625144.998367 6801279 random_forest.cc:812] Training of tree  275/300 (tree index:274) done accuracy:0.725 logloss:0.589922\n",
      "I0000 00:00:1729625144.998484 6801282 random_forest.cc:812] Training of tree  285/300 (tree index:286) done accuracy:0.733333 logloss:0.593526\n",
      "I0000 00:00:1729625144.998612 6801284 random_forest.cc:812] Training of tree  295/300 (tree index:295) done accuracy:0.725 logloss:0.592149\n",
      "I0000 00:00:1729625144.998685 6801278 random_forest.cc:812] Training of tree  300/300 (tree index:296) done accuracy:0.725 logloss:0.591725\n",
      "I0000 00:00:1729625144.998797 6801268 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.591725\n",
      "I0000 00:00:1729625144.999138 6801268 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpngwy0_mn with prefix 2ae5396c97b346be\n",
      "I0000 00:00:1729625145.001048 6801268 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625145.001780 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.591725\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  34  20\n",
      "2  13  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:45.007994: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpngwy0_mn/model/ with prefix 2ae5396c97b346be\n",
      "I0000 00:00:1729625145.011536 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2434 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:45.011557: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.150919. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018416\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1j1fkjse as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625145.301645 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625145.301657 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625145.301661 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625145.301725 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625145.301731 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625145.301772 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.301781 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.301787 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.301791 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.301818 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625145.301837 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625145.301963 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625145.301989 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqmtsvfxh/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625145.302051 6801335 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625145.302156 6801335 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625145.302802 6801344 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.65 logloss:12.6153\n",
      "I0000 00:00:1729625145.302980 6801345 random_forest.cc:812] Training of tree  15/300 (tree index:14) done accuracy:0.716667 logloss:3.63587\n",
      "I0000 00:00:1729625145.303185 6801350 random_forest.cc:812] Training of tree  25/300 (tree index:26) done accuracy:0.75 logloss:1.64026\n",
      "I0000 00:00:1729625145.303332 6801350 random_forest.cc:812] Training of tree  38/300 (tree index:39) done accuracy:0.75 logloss:1.09578\n",
      "I0000 00:00:1729625145.303501 6801347 random_forest.cc:812] Training of tree  48/300 (tree index:48) done accuracy:0.716667 logloss:0.550271\n",
      "I0000 00:00:1729625145.303611 6801351 random_forest.cc:812] Training of tree  58/300 (tree index:59) done accuracy:0.733333 logloss:0.524728\n",
      "I0000 00:00:1729625145.303752 6801346 random_forest.cc:812] Training of tree  68/300 (tree index:63) done accuracy:0.758333 logloss:0.51355\n",
      "I0000 00:00:1729625145.303869 6801351 random_forest.cc:812] Training of tree  78/300 (tree index:78) done accuracy:0.766667 logloss:0.516962\n",
      "I0000 00:00:1729625145.304009 6801347 random_forest.cc:812] Training of tree  88/300 (tree index:85) done accuracy:0.758333 logloss:0.514431\n",
      "I0000 00:00:1729625145.304154 6801345 random_forest.cc:812] Training of tree  98/300 (tree index:99) done accuracy:0.758333 logloss:0.507983\n",
      "I0000 00:00:1729625145.304261 6801344 random_forest.cc:812] Training of tree  109/300 (tree index:109) done accuracy:0.766667 logloss:0.508937\n",
      "I0000 00:00:1729625145.304413 6801347 random_forest.cc:812] Training of tree  121/300 (tree index:121) done accuracy:0.766667 logloss:0.506365\n",
      "I0000 00:00:1729625145.304674 6801346 random_forest.cc:812] Training of tree  137/300 (tree index:136) done accuracy:0.8 logloss:0.506574\n",
      "I0000 00:00:1729625145.304889 6801346 random_forest.cc:812] Training of tree  147/300 (tree index:148) done accuracy:0.808333 logloss:0.512288\n",
      "I0000 00:00:1729625145.304998 6801349 random_forest.cc:812] Training of tree  157/300 (tree index:156) done accuracy:0.791667 logloss:0.513579\n",
      "I0000 00:00:1729625145.305107 6801350 random_forest.cc:812] Training of tree  167/300 (tree index:169) done accuracy:0.783333 logloss:0.516486\n",
      "I0000 00:00:1729625145.305261 6801346 random_forest.cc:812] Training of tree  177/300 (tree index:177) done accuracy:0.8 logloss:0.511834\n",
      "I0000 00:00:1729625145.305374 6801348 random_forest.cc:812] Training of tree  187/300 (tree index:185) done accuracy:0.791667 logloss:0.511705\n",
      "I0000 00:00:1729625145.305492 6801346 random_forest.cc:812] Training of tree  197/300 (tree index:197) done accuracy:0.816667 logloss:0.511402\n",
      "I0000 00:00:1729625145.305613 6801347 random_forest.cc:812] Training of tree  207/300 (tree index:207) done accuracy:0.8 logloss:0.505497\n",
      "I0000 00:00:1729625145.305726 6801349 random_forest.cc:812] Training of tree  217/300 (tree index:217) done accuracy:0.8 logloss:0.507021\n",
      "I0000 00:00:1729625145.305834 6801351 random_forest.cc:812] Training of tree  227/300 (tree index:229) done accuracy:0.8 logloss:0.50795\n",
      "I0000 00:00:1729625145.305951 6801344 random_forest.cc:812] Training of tree  237/300 (tree index:236) done accuracy:0.8 logloss:0.508774\n",
      "I0000 00:00:1729625145.306070 6801351 random_forest.cc:812] Training of tree  247/300 (tree index:245) done accuracy:0.8 logloss:0.509218\n",
      "I0000 00:00:1729625145.306177 6801346 random_forest.cc:812] Training of tree  257/300 (tree index:256) done accuracy:0.8 logloss:0.510295\n",
      "I0000 00:00:1729625145.306296 6801347 random_forest.cc:812] Training of tree  267/300 (tree index:266) done accuracy:0.8 logloss:0.510867\n",
      "I0000 00:00:1729625145.306417 6801350 random_forest.cc:812] Training of tree  277/300 (tree index:277) done accuracy:0.8 logloss:0.508137\n",
      "I0000 00:00:1729625145.306554 6801345 random_forest.cc:812] Training of tree  287/300 (tree index:286) done accuracy:0.8 logloss:0.51085\n",
      "I0000 00:00:1729625145.306718 6801346 random_forest.cc:812] Training of tree  297/300 (tree index:295) done accuracy:0.8 logloss:0.511502\n",
      "I0000 00:00:1729625145.306794 6801347 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.8 logloss:0.512143\n",
      "I0000 00:00:1729625145.306854 6801335 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.512143\n",
      "I0000 00:00:1729625145.307165 6801335 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqmtsvfxh with prefix fe81490baabb4801\n",
      "I0000 00:00:1729625145.309116 6801335 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625145.309765 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.512143\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  15\n",
      "2   9  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:45.315270: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqmtsvfxh/model/ with prefix fe81490baabb4801\n",
      "I0000 00:00:1729625145.318348 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2394 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:45.318363: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.148819. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018781\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': 30, 'min_examples': 20, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy4toauy0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625145.602253 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625145.602263 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625145.602268 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625145.602334 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625145.602340 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625145.602390 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.602400 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.602405 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.602410 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.602438 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625145.602456 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625145.602590 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625145.602614 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1j1fkjse/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625145.602669 6801409 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625145.602772 6801409 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625145.603311 6801425 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.707317 logloss:10.5494\n",
      "I0000 00:00:1729625145.603447 6801421 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.756303 logloss:4.24553\n",
      "I0000 00:00:1729625145.603654 6801418 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.683333 logloss:1.44618\n",
      "I0000 00:00:1729625145.603785 6801420 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.725 logloss:1.16823\n",
      "I0000 00:00:1729625145.603948 6801419 random_forest.cc:812] Training of tree  42/300 (tree index:41) done accuracy:0.741667 logloss:0.857415\n",
      "I0000 00:00:1729625145.604079 6801425 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.775 logloss:0.847614\n",
      "I0000 00:00:1729625145.604217 6801425 random_forest.cc:812] Training of tree  62/300 (tree index:62) done accuracy:0.75 logloss:0.834709\n",
      "I0000 00:00:1729625145.604326 6801422 random_forest.cc:812] Training of tree  72/300 (tree index:71) done accuracy:0.75 logloss:0.832516\n",
      "I0000 00:00:1729625145.604444 6801420 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.75 logloss:0.834531\n",
      "I0000 00:00:1729625145.604587 6801423 random_forest.cc:812] Training of tree  92/300 (tree index:92) done accuracy:0.733333 logloss:0.834677\n",
      "I0000 00:00:1729625145.604723 6801425 random_forest.cc:812] Training of tree  102/300 (tree index:87) done accuracy:0.733333 logloss:0.838332\n",
      "I0000 00:00:1729625145.604856 6801418 random_forest.cc:812] Training of tree  112/300 (tree index:111) done accuracy:0.741667 logloss:0.835795\n",
      "I0000 00:00:1729625145.604972 6801420 random_forest.cc:812] Training of tree  122/300 (tree index:122) done accuracy:0.758333 logloss:0.831251\n",
      "I0000 00:00:1729625145.605082 6801424 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.766667 logloss:0.829575\n",
      "I0000 00:00:1729625145.605182 6801425 random_forest.cc:812] Training of tree  142/300 (tree index:139) done accuracy:0.766667 logloss:0.566277\n",
      "I0000 00:00:1729625145.605324 6801424 random_forest.cc:812] Training of tree  153/300 (tree index:151) done accuracy:0.758333 logloss:0.567659\n",
      "I0000 00:00:1729625145.605468 6801420 random_forest.cc:812] Training of tree  163/300 (tree index:162) done accuracy:0.75 logloss:0.570916\n",
      "I0000 00:00:1729625145.605633 6801425 random_forest.cc:812] Training of tree  173/300 (tree index:174) done accuracy:0.75 logloss:0.56134\n",
      "I0000 00:00:1729625145.605769 6801425 random_forest.cc:812] Training of tree  183/300 (tree index:184) done accuracy:0.75 logloss:0.561392\n",
      "I0000 00:00:1729625145.605900 6801424 random_forest.cc:812] Training of tree  193/300 (tree index:194) done accuracy:0.75 logloss:0.554975\n",
      "I0000 00:00:1729625145.606004 6801422 random_forest.cc:812] Training of tree  203/300 (tree index:204) done accuracy:0.75 logloss:0.550608\n",
      "I0000 00:00:1729625145.606186 6801419 random_forest.cc:812] Training of tree  216/300 (tree index:211) done accuracy:0.766667 logloss:0.549296\n",
      "I0000 00:00:1729625145.606341 6801421 random_forest.cc:812] Training of tree  226/300 (tree index:228) done accuracy:0.766667 logloss:0.550154\n",
      "I0000 00:00:1729625145.606442 6801423 random_forest.cc:812] Training of tree  236/300 (tree index:236) done accuracy:0.766667 logloss:0.552598\n",
      "I0000 00:00:1729625145.606588 6801418 random_forest.cc:812] Training of tree  249/300 (tree index:248) done accuracy:0.741667 logloss:0.553427\n",
      "I0000 00:00:1729625145.606749 6801424 random_forest.cc:812] Training of tree  259/300 (tree index:260) done accuracy:0.741667 logloss:0.552625\n",
      "I0000 00:00:1729625145.606868 6801420 random_forest.cc:812] Training of tree  269/300 (tree index:270) done accuracy:0.758333 logloss:0.551246\n",
      "I0000 00:00:1729625145.606968 6801420 random_forest.cc:812] Training of tree  279/300 (tree index:276) done accuracy:0.75 logloss:0.550995\n",
      "I0000 00:00:1729625145.607108 6801423 random_forest.cc:812] Training of tree  289/300 (tree index:292) done accuracy:0.766667 logloss:0.55145\n",
      "I0000 00:00:1729625145.607227 6801422 random_forest.cc:812] Training of tree  299/300 (tree index:298) done accuracy:0.766667 logloss:0.550636\n",
      "I0000 00:00:1729625145.607314 6801418 random_forest.cc:812] Training of tree  300/300 (tree index:297) done accuracy:0.766667 logloss:0.549098\n",
      "I0000 00:00:1729625145.607485 6801409 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.549098\n",
      "I0000 00:00:1729625145.607790 6801409 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1j1fkjse with prefix 3a1d96a59a304016\n",
      "I0000 00:00:1729625145.609507 6801409 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625145.610147 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.549098\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  18\n",
      "2  10  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:45.616041: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1j1fkjse/model/ with prefix 3a1d96a59a304016\n",
      "I0000 00:00:1729625145.619161 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2424 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:45.619179: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145513. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016288\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg0rsytkh as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625145.899572 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625145.899584 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625145.899587 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625145.899654 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625145.899659 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625145.899702 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.899713 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.899719 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.899724 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625145.899752 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625145.899771 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625145.899916 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625145.899940 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy4toauy0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625145.899984 6801477 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625145.900080 6801477 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625145.900626 6801493 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.530612 logloss:16.9184\n",
      "I0000 00:00:1729625145.900765 6801487 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.666667 logloss:4.58088\n",
      "I0000 00:00:1729625145.900903 6801492 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.675 logloss:1.15811\n",
      "I0000 00:00:1729625145.901025 6801486 random_forest.cc:812] Training of tree  31/300 (tree index:31) done accuracy:0.683333 logloss:0.885364\n",
      "I0000 00:00:1729625145.901128 6801490 random_forest.cc:812] Training of tree  41/300 (tree index:37) done accuracy:0.7 logloss:0.607805\n",
      "I0000 00:00:1729625145.901247 6801492 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.675 logloss:0.600297\n",
      "I0000 00:00:1729625145.901385 6801492 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.716667 logloss:0.585577\n",
      "I0000 00:00:1729625145.901514 6801488 random_forest.cc:812] Training of tree  72/300 (tree index:73) done accuracy:0.683333 logloss:0.583903\n",
      "I0000 00:00:1729625145.901665 6801487 random_forest.cc:812] Training of tree  84/300 (tree index:83) done accuracy:0.683333 logloss:0.587367\n",
      "I0000 00:00:1729625145.901801 6801493 random_forest.cc:812] Training of tree  94/300 (tree index:93) done accuracy:0.675 logloss:0.589046\n",
      "I0000 00:00:1729625145.901929 6801489 random_forest.cc:812] Training of tree  104/300 (tree index:107) done accuracy:0.691667 logloss:0.58307\n",
      "I0000 00:00:1729625145.902015 6801491 random_forest.cc:812] Training of tree  114/300 (tree index:113) done accuracy:0.7 logloss:0.574233\n",
      "I0000 00:00:1729625145.902149 6801488 random_forest.cc:812] Training of tree  124/300 (tree index:127) done accuracy:0.716667 logloss:0.57728\n",
      "I0000 00:00:1729625145.902263 6801490 random_forest.cc:812] Training of tree  136/300 (tree index:134) done accuracy:0.725 logloss:0.572612\n",
      "I0000 00:00:1729625145.902437 6801486 random_forest.cc:812] Training of tree  147/300 (tree index:148) done accuracy:0.7 logloss:0.579744\n",
      "I0000 00:00:1729625145.902564 6801489 random_forest.cc:812] Training of tree  157/300 (tree index:156) done accuracy:0.716667 logloss:0.574926\n",
      "I0000 00:00:1729625145.902666 6801490 random_forest.cc:812] Training of tree  167/300 (tree index:167) done accuracy:0.716667 logloss:0.576114\n",
      "I0000 00:00:1729625145.902760 6801491 random_forest.cc:812] Training of tree  177/300 (tree index:176) done accuracy:0.716667 logloss:0.573486\n",
      "I0000 00:00:1729625145.902866 6801489 random_forest.cc:812] Training of tree  188/300 (tree index:188) done accuracy:0.716667 logloss:0.572779\n",
      "I0000 00:00:1729625145.902982 6801489 random_forest.cc:812] Training of tree  199/300 (tree index:198) done accuracy:0.725 logloss:0.572498\n",
      "I0000 00:00:1729625145.903080 6801492 random_forest.cc:812] Training of tree  210/300 (tree index:210) done accuracy:0.725 logloss:0.575392\n",
      "I0000 00:00:1729625145.903185 6801487 random_forest.cc:812] Training of tree  220/300 (tree index:220) done accuracy:0.716667 logloss:0.579295\n",
      "I0000 00:00:1729625145.903276 6801492 random_forest.cc:812] Training of tree  230/300 (tree index:230) done accuracy:0.716667 logloss:0.575572\n",
      "I0000 00:00:1729625145.903381 6801489 random_forest.cc:812] Training of tree  240/300 (tree index:239) done accuracy:0.725 logloss:0.573532\n",
      "I0000 00:00:1729625145.903472 6801493 random_forest.cc:812] Training of tree  250/300 (tree index:250) done accuracy:0.716667 logloss:0.573078\n",
      "I0000 00:00:1729625145.903569 6801492 random_forest.cc:812] Training of tree  260/300 (tree index:259) done accuracy:0.725 logloss:0.576644\n",
      "I0000 00:00:1729625145.903670 6801487 random_forest.cc:812] Training of tree  270/300 (tree index:270) done accuracy:0.733333 logloss:0.575155\n",
      "I0000 00:00:1729625145.903814 6801493 random_forest.cc:812] Training of tree  280/300 (tree index:280) done accuracy:0.716667 logloss:0.574289\n",
      "I0000 00:00:1729625145.903933 6801491 random_forest.cc:812] Training of tree  290/300 (tree index:289) done accuracy:0.716667 logloss:0.575298\n",
      "I0000 00:00:1729625145.904082 6801489 random_forest.cc:812] Training of tree  300/300 (tree index:294) done accuracy:0.725 logloss:0.573882\n",
      "I0000 00:00:1729625145.904130 6801477 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.573882\n",
      "I0000 00:00:1729625145.904374 6801477 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy4toauy0 with prefix 75ed84a2a38c4e38\n",
      "I0000 00:00:1729625145.905891 6801477 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625145.906439 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.573882\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  14  48\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:45.911541: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpy4toauy0/model/ with prefix 75ed84a2a38c4e38\n",
      "I0000 00:00:1729625145.914088 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1944 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:45.914102: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.187365. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017762\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2ecq690s as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625146.232981 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625146.232992 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625146.232997 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625146.233063 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625146.233068 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625146.233119 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.233132 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.233137 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.233142 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.233170 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625146.233187 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625146.233332 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625146.233354 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg0rsytkh/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625146.233401 6801564 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625146.233491 6801564 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625146.234026 6801574 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.574468 logloss:15.3377\n",
      "I0000 00:00:1729625146.234137 6801573 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.537815 logloss:4.7506\n",
      "I0000 00:00:1729625146.234270 6801573 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.708333 logloss:1.74128\n",
      "I0000 00:00:1729625146.234368 6801580 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.716667 logloss:0.890962\n",
      "I0000 00:00:1729625146.234496 6801580 random_forest.cc:812] Training of tree  42/300 (tree index:41) done accuracy:0.725 logloss:0.880799\n",
      "I0000 00:00:1729625146.234686 6801576 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.708333 logloss:0.617028\n",
      "I0000 00:00:1729625146.234810 6801574 random_forest.cc:812] Training of tree  62/300 (tree index:58) done accuracy:0.716667 logloss:0.607814\n",
      "I0000 00:00:1729625146.234983 6801580 random_forest.cc:812] Training of tree  74/300 (tree index:74) done accuracy:0.691667 logloss:0.608026\n",
      "I0000 00:00:1729625146.235176 6801573 random_forest.cc:812] Training of tree  88/300 (tree index:86) done accuracy:0.716667 logloss:0.600123\n",
      "I0000 00:00:1729625146.235343 6801580 random_forest.cc:812] Training of tree  98/300 (tree index:97) done accuracy:0.716667 logloss:0.609626\n",
      "I0000 00:00:1729625146.235490 6801580 random_forest.cc:812] Training of tree  108/300 (tree index:107) done accuracy:0.725 logloss:0.611089\n",
      "I0000 00:00:1729625146.235629 6801575 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.716667 logloss:0.608088\n",
      "I0000 00:00:1729625146.235773 6801579 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.741667 logloss:0.607478\n",
      "I0000 00:00:1729625146.235897 6801576 random_forest.cc:812] Training of tree  142/300 (tree index:142) done accuracy:0.733333 logloss:0.602353\n",
      "I0000 00:00:1729625146.236009 6801579 random_forest.cc:812] Training of tree  152/300 (tree index:151) done accuracy:0.75 logloss:0.60184\n",
      "I0000 00:00:1729625146.236103 6801580 random_forest.cc:812] Training of tree  162/300 (tree index:161) done accuracy:0.741667 logloss:0.607767\n",
      "I0000 00:00:1729625146.236204 6801578 random_forest.cc:812] Training of tree  172/300 (tree index:173) done accuracy:0.733333 logloss:0.605612\n",
      "I0000 00:00:1729625146.236286 6801573 random_forest.cc:812] Training of tree  182/300 (tree index:182) done accuracy:0.758333 logloss:0.59963\n",
      "I0000 00:00:1729625146.236390 6801580 random_forest.cc:812] Training of tree  192/300 (tree index:192) done accuracy:0.741667 logloss:0.598358\n",
      "I0000 00:00:1729625146.236485 6801575 random_forest.cc:812] Training of tree  202/300 (tree index:202) done accuracy:0.741667 logloss:0.602435\n",
      "I0000 00:00:1729625146.236579 6801573 random_forest.cc:812] Training of tree  212/300 (tree index:212) done accuracy:0.741667 logloss:0.60106\n",
      "I0000 00:00:1729625146.236704 6801575 random_forest.cc:812] Training of tree  222/300 (tree index:220) done accuracy:0.758333 logloss:0.600602\n",
      "I0000 00:00:1729625146.236791 6801574 random_forest.cc:812] Training of tree  232/300 (tree index:232) done accuracy:0.758333 logloss:0.600298\n",
      "I0000 00:00:1729625146.236881 6801580 random_forest.cc:812] Training of tree  242/300 (tree index:243) done accuracy:0.766667 logloss:0.596907\n",
      "I0000 00:00:1729625146.236983 6801578 random_forest.cc:812] Training of tree  252/300 (tree index:253) done accuracy:0.766667 logloss:0.597741\n",
      "I0000 00:00:1729625146.237101 6801575 random_forest.cc:812] Training of tree  262/300 (tree index:261) done accuracy:0.766667 logloss:0.599036\n",
      "I0000 00:00:1729625146.237201 6801578 random_forest.cc:812] Training of tree  272/300 (tree index:272) done accuracy:0.758333 logloss:0.59834\n",
      "I0000 00:00:1729625146.237317 6801578 random_forest.cc:812] Training of tree  282/300 (tree index:284) done accuracy:0.758333 logloss:0.598118\n",
      "I0000 00:00:1729625146.237400 6801577 random_forest.cc:812] Training of tree  292/300 (tree index:293) done accuracy:0.758333 logloss:0.597018\n",
      "I0000 00:00:1729625146.237522 6801573 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.758333 logloss:0.595347\n",
      "I0000 00:00:1729625146.237642 6801564 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.595347\n",
      "I0000 00:00:1729625146.237897 6801564 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg0rsytkh with prefix 8d8d0d6a20b14338\n",
      "I0000 00:00:1729625146.239554 6801564 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625146.240193 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.595347\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  17\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:46.246246: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpg0rsytkh/model/ with prefix 8d8d0d6a20b14338\n",
      "I0000 00:00:1729625146.248952 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1954 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:46.248970: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.148059. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018153\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp40faffdl as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625146.533356 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625146.533369 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625146.533377 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625146.533440 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625146.533450 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625146.533495 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.533505 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.533511 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.533516 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.533556 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625146.533579 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625146.533721 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625146.533743 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2ecq690s/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625146.533806 6801634 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625146.533908 6801634 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625146.534523 6801646 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625146.534676 6801646 random_forest.cc:812] Training of tree  14/300 (tree index:14) done accuracy:0.616667 logloss:2.94233\n",
      "I0000 00:00:1729625146.534846 6801643 random_forest.cc:812] Training of tree  24/300 (tree index:23) done accuracy:0.683333 logloss:0.885546\n",
      "I0000 00:00:1729625146.534991 6801647 random_forest.cc:812] Training of tree  34/300 (tree index:32) done accuracy:0.725 logloss:0.853588\n",
      "I0000 00:00:1729625146.535095 6801646 random_forest.cc:812] Training of tree  44/300 (tree index:44) done accuracy:0.7 logloss:0.597661\n",
      "I0000 00:00:1729625146.535196 6801645 random_forest.cc:812] Training of tree  54/300 (tree index:51) done accuracy:0.675 logloss:0.620245\n",
      "I0000 00:00:1729625146.535318 6801650 random_forest.cc:812] Training of tree  65/300 (tree index:63) done accuracy:0.7 logloss:0.604133\n",
      "I0000 00:00:1729625146.535461 6801643 random_forest.cc:812] Training of tree  76/300 (tree index:75) done accuracy:0.716667 logloss:0.607727\n",
      "I0000 00:00:1729625146.535589 6801643 random_forest.cc:812] Training of tree  87/300 (tree index:87) done accuracy:0.7 logloss:0.603857\n",
      "I0000 00:00:1729625146.535678 6801650 random_forest.cc:812] Training of tree  97/300 (tree index:96) done accuracy:0.708333 logloss:0.601586\n",
      "I0000 00:00:1729625146.535828 6801649 random_forest.cc:812] Training of tree  107/300 (tree index:106) done accuracy:0.708333 logloss:0.609935\n",
      "I0000 00:00:1729625146.535954 6801647 random_forest.cc:812] Training of tree  117/300 (tree index:116) done accuracy:0.716667 logloss:0.610337\n",
      "I0000 00:00:1729625146.536065 6801644 random_forest.cc:812] Training of tree  127/300 (tree index:127) done accuracy:0.708333 logloss:0.618368\n",
      "I0000 00:00:1729625146.536201 6801646 random_forest.cc:812] Training of tree  137/300 (tree index:137) done accuracy:0.708333 logloss:0.613231\n",
      "I0000 00:00:1729625146.536377 6801648 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.708333 logloss:0.608994\n",
      "I0000 00:00:1729625146.536507 6801646 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.708333 logloss:0.609032\n",
      "I0000 00:00:1729625146.536600 6801648 random_forest.cc:812] Training of tree  172/300 (tree index:173) done accuracy:0.7 logloss:0.615579\n",
      "I0000 00:00:1729625146.536719 6801650 random_forest.cc:812] Training of tree  182/300 (tree index:184) done accuracy:0.683333 logloss:0.61299\n",
      "I0000 00:00:1729625146.536851 6801645 random_forest.cc:812] Training of tree  193/300 (tree index:192) done accuracy:0.691667 logloss:0.612143\n",
      "I0000 00:00:1729625146.536971 6801645 random_forest.cc:812] Training of tree  203/300 (tree index:203) done accuracy:0.675 logloss:0.613679\n",
      "I0000 00:00:1729625146.537106 6801647 random_forest.cc:812] Training of tree  213/300 (tree index:213) done accuracy:0.691667 logloss:0.611153\n",
      "I0000 00:00:1729625146.537212 6801643 random_forest.cc:812] Training of tree  223/300 (tree index:221) done accuracy:0.691667 logloss:0.609146\n",
      "I0000 00:00:1729625146.537313 6801646 random_forest.cc:812] Training of tree  233/300 (tree index:232) done accuracy:0.7 logloss:0.606112\n",
      "I0000 00:00:1729625146.537492 6801644 random_forest.cc:812] Training of tree  243/300 (tree index:243) done accuracy:0.691667 logloss:0.604945\n",
      "I0000 00:00:1729625146.537686 6801649 random_forest.cc:812] Training of tree  253/300 (tree index:247) done accuracy:0.691667 logloss:0.60684\n",
      "I0000 00:00:1729625146.537829 6801650 random_forest.cc:812] Training of tree  263/300 (tree index:261) done accuracy:0.691667 logloss:0.60786\n",
      "I0000 00:00:1729625146.537953 6801645 random_forest.cc:812] Training of tree  273/300 (tree index:272) done accuracy:0.708333 logloss:0.605246\n",
      "I0000 00:00:1729625146.538083 6801646 random_forest.cc:812] Training of tree  283/300 (tree index:282) done accuracy:0.708333 logloss:0.604129\n",
      "I0000 00:00:1729625146.538195 6801648 random_forest.cc:812] Training of tree  293/300 (tree index:294) done accuracy:0.708333 logloss:0.604633\n",
      "I0000 00:00:1729625146.538276 6801650 random_forest.cc:812] Training of tree  300/300 (tree index:295) done accuracy:0.708333 logloss:0.603563\n",
      "I0000 00:00:1729625146.538356 6801634 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.603563\n",
      "I0000 00:00:1729625146.538622 6801634 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2ecq690s with prefix e7127101038f4858\n",
      "I0000 00:00:1729625146.540611 6801634 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625146.541282 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.603563\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  32  22\n",
      "2  13  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:46.547214: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2ecq690s/model/ with prefix e7127101038f4858\n",
      "I0000 00:00:1729625146.549771 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1928 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:46.549788: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147323. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016551\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmplagbyjc1 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625146.830252 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625146.830265 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625146.830269 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625146.830336 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625146.830343 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625146.830385 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.830394 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.830400 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.830405 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625146.830433 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625146.830452 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625146.830578 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625146.830600 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp40faffdl/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625146.830663 6801702 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625146.830791 6801702 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625146.831421 6801712 random_forest.cc:812] Training of tree  1/300 (tree index:4) done accuracy:0.428571 logloss:20.5964\n",
      "I0000 00:00:1729625146.831574 6801715 random_forest.cc:812] Training of tree  13/300 (tree index:12) done accuracy:0.571429 logloss:2.92891\n",
      "I0000 00:00:1729625146.831718 6801712 random_forest.cc:812] Training of tree  23/300 (tree index:22) done accuracy:0.716667 logloss:1.4535\n",
      "I0000 00:00:1729625146.831845 6801712 random_forest.cc:812] Training of tree  34/300 (tree index:34) done accuracy:0.733333 logloss:0.850933\n",
      "I0000 00:00:1729625146.831970 6801711 random_forest.cc:812] Training of tree  44/300 (tree index:43) done accuracy:0.725 logloss:0.562026\n",
      "I0000 00:00:1729625146.832081 6801713 random_forest.cc:812] Training of tree  54/300 (tree index:51) done accuracy:0.733333 logloss:0.569988\n",
      "I0000 00:00:1729625146.832182 6801712 random_forest.cc:812] Training of tree  66/300 (tree index:66) done accuracy:0.725 logloss:0.575598\n",
      "I0000 00:00:1729625146.832296 6801717 random_forest.cc:812] Training of tree  76/300 (tree index:77) done accuracy:0.725 logloss:0.56832\n",
      "I0000 00:00:1729625146.832386 6801715 random_forest.cc:812] Training of tree  86/300 (tree index:87) done accuracy:0.725 logloss:0.564476\n",
      "I0000 00:00:1729625146.832530 6801718 random_forest.cc:812] Training of tree  96/300 (tree index:96) done accuracy:0.741667 logloss:0.554313\n",
      "I0000 00:00:1729625146.832660 6801714 random_forest.cc:812] Training of tree  107/300 (tree index:107) done accuracy:0.725 logloss:0.554973\n",
      "I0000 00:00:1729625146.832794 6801714 random_forest.cc:812] Training of tree  117/300 (tree index:115) done accuracy:0.733333 logloss:0.557237\n",
      "I0000 00:00:1729625146.832937 6801711 random_forest.cc:812] Training of tree  127/300 (tree index:126) done accuracy:0.733333 logloss:0.554214\n",
      "I0000 00:00:1729625146.833031 6801713 random_forest.cc:812] Training of tree  137/300 (tree index:136) done accuracy:0.733333 logloss:0.552805\n",
      "I0000 00:00:1729625146.833181 6801716 random_forest.cc:812] Training of tree  150/300 (tree index:148) done accuracy:0.75 logloss:0.546041\n",
      "I0000 00:00:1729625146.833367 6801715 random_forest.cc:812] Training of tree  160/300 (tree index:161) done accuracy:0.741667 logloss:0.546837\n",
      "I0000 00:00:1729625146.833463 6801716 random_forest.cc:812] Training of tree  171/300 (tree index:169) done accuracy:0.733333 logloss:0.548193\n",
      "I0000 00:00:1729625146.833587 6801713 random_forest.cc:812] Training of tree  181/300 (tree index:179) done accuracy:0.741667 logloss:0.546617\n",
      "I0000 00:00:1729625146.833683 6801716 random_forest.cc:812] Training of tree  191/300 (tree index:191) done accuracy:0.75 logloss:0.544265\n",
      "I0000 00:00:1729625146.833775 6801712 random_forest.cc:812] Training of tree  201/300 (tree index:200) done accuracy:0.75 logloss:0.541025\n",
      "I0000 00:00:1729625146.833915 6801715 random_forest.cc:812] Training of tree  211/300 (tree index:202) done accuracy:0.758333 logloss:0.539562\n",
      "I0000 00:00:1729625146.834046 6801711 random_forest.cc:812] Training of tree  222/300 (tree index:221) done accuracy:0.75 logloss:0.535966\n",
      "I0000 00:00:1729625146.834189 6801712 random_forest.cc:812] Training of tree  232/300 (tree index:232) done accuracy:0.758333 logloss:0.534256\n",
      "I0000 00:00:1729625146.834295 6801711 random_forest.cc:812] Training of tree  242/300 (tree index:241) done accuracy:0.758333 logloss:0.534402\n",
      "I0000 00:00:1729625146.834442 6801712 random_forest.cc:812] Training of tree  252/300 (tree index:250) done accuracy:0.758333 logloss:0.534855\n",
      "I0000 00:00:1729625146.834606 6801713 random_forest.cc:812] Training of tree  262/300 (tree index:259) done accuracy:0.75 logloss:0.535093\n",
      "I0000 00:00:1729625146.834734 6801715 random_forest.cc:812] Training of tree  272/300 (tree index:272) done accuracy:0.766667 logloss:0.531454\n",
      "I0000 00:00:1729625146.834862 6801715 random_forest.cc:812] Training of tree  282/300 (tree index:283) done accuracy:0.75 logloss:0.531312\n",
      "I0000 00:00:1729625146.834936 6801711 random_forest.cc:812] Training of tree  292/300 (tree index:290) done accuracy:0.75 logloss:0.529085\n",
      "I0000 00:00:1729625146.835056 6801714 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.775 logloss:0.528174\n",
      "I0000 00:00:1729625146.835118 6801702 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.528174\n",
      "I0000 00:00:1729625146.835352 6801702 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp40faffdl with prefix e5e5e3c586a54503\n",
      "I0000 00:00:1729625146.837199 6801702 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625146.837736 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.528174\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  17\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:46.842490: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp40faffdl/model/ with prefix e5e5e3c586a54503\n",
      "I0000 00:00:1729625146.845215 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1950 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:46.845229: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.150549. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016524\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': -1, 'min_examples': 5, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp93l8hfdh as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625147.128331 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625147.128342 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625147.128346 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625147.128413 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625147.128419 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625147.128461 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.128471 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.128477 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.128482 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.128508 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625147.128526 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625147.128657 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 30\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625147.128681 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmplagbyjc1/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625147.128740 6801769 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625147.128902 6801769 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625147.129482 6801784 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.531915 logloss:16.8715\n",
      "I0000 00:00:1729625147.129575 6801785 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.689076 logloss:4.03395\n",
      "I0000 00:00:1729625147.129699 6801778 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.733333 logloss:1.70907\n",
      "I0000 00:00:1729625147.129850 6801782 random_forest.cc:812] Training of tree  31/300 (tree index:32) done accuracy:0.733333 logloss:1.1297\n",
      "I0000 00:00:1729625147.129964 6801779 random_forest.cc:812] Training of tree  41/300 (tree index:38) done accuracy:0.716667 logloss:0.85669\n",
      "I0000 00:00:1729625147.130130 6801778 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.666667 logloss:0.599917\n",
      "I0000 00:00:1729625147.130229 6801779 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.7 logloss:0.585204\n",
      "I0000 00:00:1729625147.130328 6801781 random_forest.cc:812] Training of tree  71/300 (tree index:71) done accuracy:0.7 logloss:0.585063\n",
      "I0000 00:00:1729625147.130430 6801780 random_forest.cc:812] Training of tree  82/300 (tree index:81) done accuracy:0.725 logloss:0.577143\n",
      "I0000 00:00:1729625147.130532 6801782 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.7 logloss:0.58279\n",
      "I0000 00:00:1729625147.130657 6801778 random_forest.cc:812] Training of tree  103/300 (tree index:103) done accuracy:0.7 logloss:0.580671\n",
      "I0000 00:00:1729625147.130820 6801780 random_forest.cc:812] Training of tree  113/300 (tree index:111) done accuracy:0.716667 logloss:0.580621\n",
      "I0000 00:00:1729625147.130979 6801780 random_forest.cc:812] Training of tree  123/300 (tree index:123) done accuracy:0.7 logloss:0.580873\n",
      "I0000 00:00:1729625147.131070 6801778 random_forest.cc:812] Training of tree  133/300 (tree index:131) done accuracy:0.716667 logloss:0.576153\n",
      "I0000 00:00:1729625147.131165 6801780 random_forest.cc:812] Training of tree  143/300 (tree index:142) done accuracy:0.716667 logloss:0.576635\n",
      "I0000 00:00:1729625147.131271 6801784 random_forest.cc:812] Training of tree  153/300 (tree index:152) done accuracy:0.725 logloss:0.577507\n",
      "I0000 00:00:1729625147.131369 6801779 random_forest.cc:812] Training of tree  163/300 (tree index:162) done accuracy:0.725 logloss:0.579691\n",
      "I0000 00:00:1729625147.131515 6801783 random_forest.cc:812] Training of tree  176/300 (tree index:173) done accuracy:0.708333 logloss:0.57693\n",
      "I0000 00:00:1729625147.131646 6801785 random_forest.cc:812] Training of tree  186/300 (tree index:184) done accuracy:0.708333 logloss:0.577821\n",
      "I0000 00:00:1729625147.131756 6801784 random_forest.cc:812] Training of tree  196/300 (tree index:195) done accuracy:0.708333 logloss:0.575952\n",
      "I0000 00:00:1729625147.131853 6801782 random_forest.cc:812] Training of tree  207/300 (tree index:206) done accuracy:0.7 logloss:0.575998\n",
      "I0000 00:00:1729625147.131957 6801778 random_forest.cc:812] Training of tree  217/300 (tree index:216) done accuracy:0.716667 logloss:0.571771\n",
      "I0000 00:00:1729625147.132070 6801783 random_forest.cc:812] Training of tree  229/300 (tree index:228) done accuracy:0.725 logloss:0.572294\n",
      "I0000 00:00:1729625147.132176 6801780 random_forest.cc:812] Training of tree  240/300 (tree index:239) done accuracy:0.725 logloss:0.570119\n",
      "I0000 00:00:1729625147.132314 6801780 random_forest.cc:812] Training of tree  250/300 (tree index:251) done accuracy:0.725 logloss:0.569823\n",
      "I0000 00:00:1729625147.132393 6801778 random_forest.cc:812] Training of tree  260/300 (tree index:259) done accuracy:0.725 logloss:0.569569\n",
      "I0000 00:00:1729625147.132522 6801780 random_forest.cc:812] Training of tree  271/300 (tree index:272) done accuracy:0.725 logloss:0.569438\n",
      "I0000 00:00:1729625147.132680 6801783 random_forest.cc:812] Training of tree  284/300 (tree index:283) done accuracy:0.733333 logloss:0.568908\n",
      "I0000 00:00:1729625147.132815 6801785 random_forest.cc:812] Training of tree  294/300 (tree index:294) done accuracy:0.733333 logloss:0.564593\n",
      "I0000 00:00:1729625147.132886 6801785 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.733333 logloss:0.562626\n",
      "I0000 00:00:1729625147.132944 6801769 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.562626\n",
      "I0000 00:00:1729625147.133166 6801769 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmplagbyjc1 with prefix 75ea2a63fc444035\n",
      "I0000 00:00:1729625147.134711 6801769 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625147.135398 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.562626\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  19\n",
      "2  13  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:47.140488: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmplagbyjc1/model/ with prefix 75ea2a63fc444035\n",
      "I0000 00:00:1729625147.143194 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1930 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:47.143212: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147638. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.028356\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw8r5j6_3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625147.425808 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625147.425821 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625147.425825 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625147.425887 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625147.425893 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625147.425938 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.425948 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.425954 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.425958 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.425985 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625147.426004 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625147.426134 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625147.426158 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp93l8hfdh/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625147.426202 6801837 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625147.426283 6801837 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625147.427057 6801847 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.55814 logloss:15.9263\n",
      "I0000 00:00:1729625147.427229 6801852 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.677966 logloss:4.06194\n",
      "I0000 00:00:1729625147.427403 6801849 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.708333 logloss:1.12473\n",
      "I0000 00:00:1729625147.427638 6801852 random_forest.cc:812] Training of tree  31/300 (tree index:34) done accuracy:0.733333 logloss:0.848715\n",
      "I0000 00:00:1729625147.427801 6801851 random_forest.cc:812] Training of tree  41/300 (tree index:31) done accuracy:0.733333 logloss:0.827633\n",
      "I0000 00:00:1729625147.427992 6801852 random_forest.cc:812] Training of tree  51/300 (tree index:51) done accuracy:0.716667 logloss:0.556915\n",
      "I0000 00:00:1729625147.428155 6801847 random_forest.cc:812] Training of tree  61/300 (tree index:62) done accuracy:0.758333 logloss:0.526595\n",
      "I0000 00:00:1729625147.428331 6801853 random_forest.cc:812] Training of tree  71/300 (tree index:72) done accuracy:0.75 logloss:0.524481\n",
      "I0000 00:00:1729625147.428491 6801848 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.733333 logloss:0.52523\n",
      "I0000 00:00:1729625147.428656 6801853 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.733333 logloss:0.52544\n",
      "I0000 00:00:1729625147.428855 6801851 random_forest.cc:812] Training of tree  101/300 (tree index:102) done accuracy:0.758333 logloss:0.52413\n",
      "I0000 00:00:1729625147.429006 6801846 random_forest.cc:812] Training of tree  111/300 (tree index:112) done accuracy:0.741667 logloss:0.529779\n",
      "I0000 00:00:1729625147.429189 6801849 random_forest.cc:812] Training of tree  123/300 (tree index:123) done accuracy:0.75 logloss:0.525204\n",
      "I0000 00:00:1729625147.429382 6801852 random_forest.cc:812] Training of tree  133/300 (tree index:134) done accuracy:0.758333 logloss:0.52349\n",
      "I0000 00:00:1729625147.429573 6801848 random_forest.cc:812] Training of tree  145/300 (tree index:132) done accuracy:0.75 logloss:0.532388\n",
      "I0000 00:00:1729625147.429767 6801852 random_forest.cc:812] Training of tree  155/300 (tree index:155) done accuracy:0.733333 logloss:0.533143\n",
      "I0000 00:00:1729625147.429929 6801853 random_forest.cc:812] Training of tree  165/300 (tree index:166) done accuracy:0.733333 logloss:0.535033\n",
      "I0000 00:00:1729625147.430081 6801852 random_forest.cc:812] Training of tree  175/300 (tree index:176) done accuracy:0.725 logloss:0.531979\n",
      "I0000 00:00:1729625147.430283 6801853 random_forest.cc:812] Training of tree  187/300 (tree index:183) done accuracy:0.741667 logloss:0.52588\n",
      "I0000 00:00:1729625147.430515 6801850 random_forest.cc:812] Training of tree  197/300 (tree index:197) done accuracy:0.741667 logloss:0.523196\n",
      "I0000 00:00:1729625147.430698 6801852 random_forest.cc:812] Training of tree  208/300 (tree index:208) done accuracy:0.725 logloss:0.519355\n",
      "I0000 00:00:1729625147.430851 6801848 random_forest.cc:812] Training of tree  218/300 (tree index:218) done accuracy:0.725 logloss:0.523005\n",
      "I0000 00:00:1729625147.431053 6801846 random_forest.cc:812] Training of tree  228/300 (tree index:229) done accuracy:0.725 logloss:0.528526\n",
      "I0000 00:00:1729625147.431228 6801849 random_forest.cc:812] Training of tree  239/300 (tree index:239) done accuracy:0.716667 logloss:0.529362\n",
      "I0000 00:00:1729625147.431409 6801848 random_forest.cc:812] Training of tree  250/300 (tree index:248) done accuracy:0.708333 logloss:0.52809\n",
      "I0000 00:00:1729625147.431600 6801847 random_forest.cc:812] Training of tree  260/300 (tree index:259) done accuracy:0.716667 logloss:0.527876\n",
      "I0000 00:00:1729625147.431768 6801848 random_forest.cc:812] Training of tree  270/300 (tree index:271) done accuracy:0.708333 logloss:0.526823\n",
      "I0000 00:00:1729625147.431935 6801851 random_forest.cc:812] Training of tree  280/300 (tree index:280) done accuracy:0.708333 logloss:0.527938\n",
      "I0000 00:00:1729625147.432158 6801853 random_forest.cc:812] Training of tree  292/300 (tree index:291) done accuracy:0.7 logloss:0.524662\n",
      "I0000 00:00:1729625147.432370 6801852 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.708333 logloss:0.52502\n",
      "I0000 00:00:1729625147.432398 6801837 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.52502\n",
      "I0000 00:00:1729625147.433177 6801837 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp93l8hfdh with prefix f55ee177e09c4a3d\n",
      "I0000 00:00:1729625147.436737 6801837 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625147.437391 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.52502\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  44  14\n",
      "2  21  41\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:47.443469: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp93l8hfdh/model/ with prefix f55ee177e09c4a3d\n",
      "I0000 00:00:1729625147.451669 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6548 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:47.451689: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.148089. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.030553\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpd1ptpvjc as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625147.774950 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625147.774972 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625147.774977 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625147.775047 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625147.775054 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625147.775100 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.775112 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.775118 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.775123 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625147.775151 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625147.775171 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625147.775306 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625147.775330 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw8r5j6_3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625147.775403 6801905 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625147.775500 6801905 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625147.776178 6801918 random_forest.cc:812] Training of tree  1/300 (tree index:4) done accuracy:0.729167 logloss:9.76182\n",
      "I0000 00:00:1729625147.776408 6801919 random_forest.cc:812] Training of tree  11/300 (tree index:13) done accuracy:0.647059 logloss:4.61306\n",
      "I0000 00:00:1729625147.776640 6801915 random_forest.cc:812] Training of tree  21/300 (tree index:11) done accuracy:0.691667 logloss:1.11715\n",
      "I0000 00:00:1729625147.776894 6801920 random_forest.cc:812] Training of tree  31/300 (tree index:29) done accuracy:0.75 logloss:0.783472\n",
      "I0000 00:00:1729625147.777108 6801914 random_forest.cc:812] Training of tree  41/300 (tree index:42) done accuracy:0.741667 logloss:0.515221\n",
      "I0000 00:00:1729625147.777370 6801915 random_forest.cc:812] Training of tree  51/300 (tree index:53) done accuracy:0.741667 logloss:0.51815\n",
      "I0000 00:00:1729625147.777600 6801914 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.725 logloss:0.514785\n",
      "I0000 00:00:1729625147.777792 6801921 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.725 logloss:0.510684\n",
      "I0000 00:00:1729625147.777972 6801918 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.741667 logloss:0.504442\n",
      "I0000 00:00:1729625147.778149 6801920 random_forest.cc:812] Training of tree  91/300 (tree index:91) done accuracy:0.775 logloss:0.489157\n",
      "I0000 00:00:1729625147.778333 6801919 random_forest.cc:812] Training of tree  101/300 (tree index:103) done accuracy:0.766667 logloss:0.489426\n",
      "I0000 00:00:1729625147.778563 6801914 random_forest.cc:812] Training of tree  112/300 (tree index:112) done accuracy:0.766667 logloss:0.494271\n",
      "I0000 00:00:1729625147.778780 6801916 random_forest.cc:812] Training of tree  122/300 (tree index:122) done accuracy:0.766667 logloss:0.49948\n",
      "I0000 00:00:1729625147.778999 6801914 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.766667 logloss:0.495545\n",
      "I0000 00:00:1729625147.779163 6801919 random_forest.cc:812] Training of tree  142/300 (tree index:138) done accuracy:0.775 logloss:0.491426\n",
      "I0000 00:00:1729625147.779383 6801920 random_forest.cc:812] Training of tree  152/300 (tree index:150) done accuracy:0.766667 logloss:0.494268\n",
      "I0000 00:00:1729625147.779615 6801919 random_forest.cc:812] Training of tree  162/300 (tree index:157) done accuracy:0.766667 logloss:0.494008\n",
      "I0000 00:00:1729625147.779766 6801914 random_forest.cc:812] Training of tree  172/300 (tree index:172) done accuracy:0.766667 logloss:0.492232\n",
      "I0000 00:00:1729625147.779957 6801916 random_forest.cc:812] Training of tree  182/300 (tree index:181) done accuracy:0.775 logloss:0.495652\n",
      "I0000 00:00:1729625147.780177 6801917 random_forest.cc:812] Training of tree  192/300 (tree index:190) done accuracy:0.766667 logloss:0.499151\n",
      "I0000 00:00:1729625147.780372 6801915 random_forest.cc:812] Training of tree  202/300 (tree index:201) done accuracy:0.766667 logloss:0.499152\n",
      "I0000 00:00:1729625147.780580 6801918 random_forest.cc:812] Training of tree  212/300 (tree index:208) done accuracy:0.766667 logloss:0.499341\n",
      "I0000 00:00:1729625147.780786 6801921 random_forest.cc:812] Training of tree  222/300 (tree index:215) done accuracy:0.758333 logloss:0.4996\n",
      "I0000 00:00:1729625147.780948 6801914 random_forest.cc:812] Training of tree  234/300 (tree index:233) done accuracy:0.758333 logloss:0.499959\n",
      "I0000 00:00:1729625147.781164 6801917 random_forest.cc:812] Training of tree  244/300 (tree index:243) done accuracy:0.75 logloss:0.497233\n",
      "I0000 00:00:1729625147.781395 6801917 random_forest.cc:812] Training of tree  254/300 (tree index:257) done accuracy:0.766667 logloss:0.496002\n",
      "I0000 00:00:1729625147.781579 6801919 random_forest.cc:812] Training of tree  264/300 (tree index:263) done accuracy:0.758333 logloss:0.498388\n",
      "I0000 00:00:1729625147.781767 6801920 random_forest.cc:812] Training of tree  274/300 (tree index:274) done accuracy:0.758333 logloss:0.497737\n",
      "I0000 00:00:1729625147.781988 6801919 random_forest.cc:812] Training of tree  284/300 (tree index:283) done accuracy:0.775 logloss:0.499208\n",
      "I0000 00:00:1729625147.782115 6801918 random_forest.cc:812] Training of tree  294/300 (tree index:295) done accuracy:0.775 logloss:0.498297\n",
      "I0000 00:00:1729625147.782245 6801916 random_forest.cc:812] Training of tree  300/300 (tree index:296) done accuracy:0.783333 logloss:0.496164\n",
      "I0000 00:00:1729625147.782319 6801905 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.496164\n",
      "I0000 00:00:1729625147.783122 6801905 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw8r5j6_3 with prefix 1f9fbafc1006492c\n",
      "I0000 00:00:1729625147.786539 6801905 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625147.787365 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.496164\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  14\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:47.794606: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpw8r5j6_3/model/ with prefix 1f9fbafc1006492c\n",
      "I0000 00:00:1729625147.803010 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6732 node(s), and 19 input feature(s).\n",
      "I0000 00:00:1729625147.803024 6784195 abstract_model.cc:1323] Engine \"RandomForestOptPred\" built\n",
      "2024-10-22 20:25:47.803029: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.148768. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.030029\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpd7w0iuv0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625148.089481 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625148.089491 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625148.089495 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625148.089558 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625148.089563 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625148.089607 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.089616 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.089621 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.089627 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.089655 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625148.089673 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625148.089842 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625148.089869 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpd1ptpvjc/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625148.089935 6801973 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625148.090032 6801973 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625148.090615 6801988 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.590909 logloss:14.7451\n",
      "I0000 00:00:1729625148.090778 6801985 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.714286 logloss:2.79812\n",
      "I0000 00:00:1729625148.090959 6801984 random_forest.cc:812] Training of tree  21/300 (tree index:18) done accuracy:0.658333 logloss:0.58549\n",
      "I0000 00:00:1729625148.091189 6801982 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.7 logloss:0.563726\n",
      "I0000 00:00:1729625148.091366 6801983 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.708333 logloss:0.565499\n",
      "I0000 00:00:1729625148.091578 6801986 random_forest.cc:812] Training of tree  52/300 (tree index:50) done accuracy:0.725 logloss:0.549105\n",
      "I0000 00:00:1729625148.091829 6801985 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.758333 logloss:0.542153\n",
      "I0000 00:00:1729625148.092048 6801987 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.733333 logloss:0.542762\n",
      "I0000 00:00:1729625148.092199 6801984 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.741667 logloss:0.542672\n",
      "I0000 00:00:1729625148.092388 6801982 random_forest.cc:812] Training of tree  92/300 (tree index:90) done accuracy:0.716667 logloss:0.544227\n",
      "I0000 00:00:1729625148.092601 6801985 random_forest.cc:812] Training of tree  102/300 (tree index:101) done accuracy:0.741667 logloss:0.537188\n",
      "I0000 00:00:1729625148.092792 6801986 random_forest.cc:812] Training of tree  112/300 (tree index:115) done accuracy:0.716667 logloss:0.532407\n",
      "I0000 00:00:1729625148.092931 6801985 random_forest.cc:812] Training of tree  122/300 (tree index:123) done accuracy:0.708333 logloss:0.540208\n",
      "I0000 00:00:1729625148.093112 6801983 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.725 logloss:0.54023\n",
      "I0000 00:00:1729625148.093292 6801984 random_forest.cc:812] Training of tree  142/300 (tree index:142) done accuracy:0.716667 logloss:0.540886\n",
      "I0000 00:00:1729625148.093463 6801982 random_forest.cc:812] Training of tree  152/300 (tree index:152) done accuracy:0.733333 logloss:0.542717\n",
      "I0000 00:00:1729625148.093600 6801986 random_forest.cc:812] Training of tree  162/300 (tree index:162) done accuracy:0.733333 logloss:0.538548\n",
      "I0000 00:00:1729625148.093781 6801987 random_forest.cc:812] Training of tree  172/300 (tree index:173) done accuracy:0.725 logloss:0.541687\n",
      "I0000 00:00:1729625148.094000 6801984 random_forest.cc:812] Training of tree  182/300 (tree index:185) done accuracy:0.733333 logloss:0.539111\n",
      "I0000 00:00:1729625148.094221 6801984 random_forest.cc:812] Training of tree  192/300 (tree index:194) done accuracy:0.741667 logloss:0.542701\n",
      "I0000 00:00:1729625148.094425 6801984 random_forest.cc:812] Training of tree  202/300 (tree index:202) done accuracy:0.733333 logloss:0.542551\n",
      "I0000 00:00:1729625148.094663 6801989 random_forest.cc:812] Training of tree  212/300 (tree index:210) done accuracy:0.725 logloss:0.542162\n",
      "I0000 00:00:1729625148.094792 6801986 random_forest.cc:812] Training of tree  222/300 (tree index:220) done accuracy:0.733333 logloss:0.540919\n",
      "I0000 00:00:1729625148.095015 6801984 random_forest.cc:812] Training of tree  232/300 (tree index:225) done accuracy:0.733333 logloss:0.541063\n",
      "I0000 00:00:1729625148.095195 6801987 random_forest.cc:812] Training of tree  242/300 (tree index:242) done accuracy:0.733333 logloss:0.542559\n",
      "I0000 00:00:1729625148.095355 6801989 random_forest.cc:812] Training of tree  252/300 (tree index:253) done accuracy:0.733333 logloss:0.540138\n",
      "I0000 00:00:1729625148.095523 6801988 random_forest.cc:812] Training of tree  262/300 (tree index:263) done accuracy:0.725 logloss:0.540015\n",
      "I0000 00:00:1729625148.095689 6801983 random_forest.cc:812] Training of tree  272/300 (tree index:268) done accuracy:0.725 logloss:0.535012\n",
      "I0000 00:00:1729625148.095870 6801986 random_forest.cc:812] Training of tree  282/300 (tree index:282) done accuracy:0.741667 logloss:0.531692\n",
      "I0000 00:00:1729625148.096014 6801984 random_forest.cc:812] Training of tree  292/300 (tree index:291) done accuracy:0.741667 logloss:0.531568\n",
      "I0000 00:00:1729625148.096156 6801985 random_forest.cc:812] Training of tree  300/300 (tree index:295) done accuracy:0.741667 logloss:0.530101\n",
      "I0000 00:00:1729625148.096231 6801973 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.530101\n",
      "I0000 00:00:1729625148.097035 6801973 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpd1ptpvjc with prefix a9bf8430961a43cb\n",
      "I0000 00:00:1729625148.100521 6801973 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625148.101240 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.530101\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  14  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:48.108112: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpd1ptpvjc/model/ with prefix a9bf8430961a43cb\n",
      "I0000 00:00:1729625148.116904 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6878 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:48.116919: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.149023. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027650\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5hfr1ts7 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625148.401764 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625148.401776 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625148.401780 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625148.401842 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625148.401847 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625148.401889 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.401898 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.401903 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.401908 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.401935 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625148.401953 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625148.402095 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625148.402117 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpd7w0iuv0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625148.402193 6802041 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625148.402290 6802041 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625148.402837 6802057 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.756098 logloss:8.79113\n",
      "I0000 00:00:1729625148.402985 6802054 random_forest.cc:812] Training of tree  11/300 (tree index:8) done accuracy:0.745763 logloss:2.45885\n",
      "I0000 00:00:1729625148.403174 6802050 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.808333 logloss:0.423446\n",
      "I0000 00:00:1729625148.403327 6802057 random_forest.cc:812] Training of tree  31/300 (tree index:32) done accuracy:0.816667 logloss:0.418241\n",
      "I0000 00:00:1729625148.403519 6802055 random_forest.cc:812] Training of tree  41/300 (tree index:43) done accuracy:0.775 logloss:0.435279\n",
      "I0000 00:00:1729625148.403670 6802050 random_forest.cc:812] Training of tree  51/300 (tree index:52) done accuracy:0.783333 logloss:0.42377\n",
      "I0000 00:00:1729625148.403853 6802056 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.791667 logloss:0.428804\n",
      "I0000 00:00:1729625148.404012 6802051 random_forest.cc:812] Training of tree  71/300 (tree index:71) done accuracy:0.783333 logloss:0.438192\n",
      "I0000 00:00:1729625148.404230 6802054 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.791667 logloss:0.450546\n",
      "I0000 00:00:1729625148.404386 6802051 random_forest.cc:812] Training of tree  91/300 (tree index:91) done accuracy:0.8 logloss:0.447617\n",
      "I0000 00:00:1729625148.404544 6802052 random_forest.cc:812] Training of tree  101/300 (tree index:102) done accuracy:0.8 logloss:0.452396\n",
      "I0000 00:00:1729625148.404699 6802054 random_forest.cc:812] Training of tree  112/300 (tree index:112) done accuracy:0.8 logloss:0.44784\n",
      "I0000 00:00:1729625148.404882 6802050 random_forest.cc:812] Training of tree  122/300 (tree index:121) done accuracy:0.8 logloss:0.453439\n",
      "I0000 00:00:1729625148.405030 6802057 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.791667 logloss:0.448844\n",
      "I0000 00:00:1729625148.405266 6802057 random_forest.cc:812] Training of tree  143/300 (tree index:144) done accuracy:0.791667 logloss:0.449012\n",
      "I0000 00:00:1729625148.405476 6802053 random_forest.cc:812] Training of tree  153/300 (tree index:152) done accuracy:0.791667 logloss:0.445484\n",
      "I0000 00:00:1729625148.405603 6802050 random_forest.cc:812] Training of tree  163/300 (tree index:163) done accuracy:0.791667 logloss:0.445793\n",
      "I0000 00:00:1729625148.405747 6802053 random_forest.cc:812] Training of tree  173/300 (tree index:173) done accuracy:0.8 logloss:0.448207\n",
      "I0000 00:00:1729625148.405893 6802056 random_forest.cc:812] Training of tree  183/300 (tree index:183) done accuracy:0.783333 logloss:0.454633\n",
      "I0000 00:00:1729625148.406078 6802054 random_forest.cc:812] Training of tree  194/300 (tree index:194) done accuracy:0.783333 logloss:0.455548\n",
      "I0000 00:00:1729625148.406368 6802055 random_forest.cc:812] Training of tree  205/300 (tree index:204) done accuracy:0.783333 logloss:0.457401\n",
      "I0000 00:00:1729625148.406585 6802055 random_forest.cc:812] Training of tree  215/300 (tree index:216) done accuracy:0.783333 logloss:0.45424\n",
      "I0000 00:00:1729625148.406794 6802053 random_forest.cc:812] Training of tree  225/300 (tree index:223) done accuracy:0.783333 logloss:0.454355\n",
      "I0000 00:00:1729625148.406947 6802055 random_forest.cc:812] Training of tree  235/300 (tree index:236) done accuracy:0.783333 logloss:0.453376\n",
      "I0000 00:00:1729625148.407077 6802053 random_forest.cc:812] Training of tree  245/300 (tree index:243) done accuracy:0.8 logloss:0.45331\n",
      "I0000 00:00:1729625148.407245 6802050 random_forest.cc:812] Training of tree  255/300 (tree index:255) done accuracy:0.783333 logloss:0.453777\n",
      "I0000 00:00:1729625148.407382 6802051 random_forest.cc:812] Training of tree  265/300 (tree index:266) done accuracy:0.791667 logloss:0.453955\n",
      "I0000 00:00:1729625148.407531 6802057 random_forest.cc:812] Training of tree  275/300 (tree index:275) done accuracy:0.791667 logloss:0.455686\n",
      "I0000 00:00:1729625148.407673 6802056 random_forest.cc:812] Training of tree  286/300 (tree index:286) done accuracy:0.791667 logloss:0.456937\n",
      "I0000 00:00:1729625148.407848 6802050 random_forest.cc:812] Training of tree  296/300 (tree index:297) done accuracy:0.791667 logloss:0.456276\n",
      "I0000 00:00:1729625148.407939 6802054 random_forest.cc:812] Training of tree  300/300 (tree index:295) done accuracy:0.791667 logloss:0.457814\n",
      "I0000 00:00:1729625148.407976 6802041 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.457814\n",
      "I0000 00:00:1729625148.408693 6802041 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpd7w0iuv0 with prefix 1ffdb48a7f1441e5\n",
      "I0000 00:00:1729625148.411786 6802041 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625148.412502 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.457814\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  11  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:48.418999: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpd7w0iuv0/model/ with prefix 1ffdb48a7f1441e5\n",
      "I0000 00:00:1729625148.426839 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6178 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:48.426867: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.187821. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.030296\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': -1, 'min_examples': 5, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1g6pbukz as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625148.751912 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625148.751922 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625148.751927 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625148.751996 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625148.752002 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625148.752050 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.752064 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.752070 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.752075 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625148.752102 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625148.752119 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625148.752290 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625148.752312 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5hfr1ts7/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625148.752370 6802109 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625148.752454 6802109 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625148.753030 6802120 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625148.753304 6802120 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.705882 logloss:3.96318\n",
      "I0000 00:00:1729625148.753451 6802122 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.733333 logloss:1.92422\n",
      "I0000 00:00:1729625148.753632 6802118 random_forest.cc:812] Training of tree  31/300 (tree index:33) done accuracy:0.766667 logloss:1.63677\n",
      "I0000 00:00:1729625148.753809 6802124 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.775 logloss:0.781972\n",
      "I0000 00:00:1729625148.753958 6802118 random_forest.cc:812] Training of tree  51/300 (tree index:53) done accuracy:0.775 logloss:0.486655\n",
      "I0000 00:00:1729625148.754131 6802120 random_forest.cc:812] Training of tree  61/300 (tree index:62) done accuracy:0.8 logloss:0.480621\n",
      "I0000 00:00:1729625148.754314 6802119 random_forest.cc:812] Training of tree  71/300 (tree index:73) done accuracy:0.783333 logloss:0.48128\n",
      "I0000 00:00:1729625148.754472 6802124 random_forest.cc:812] Training of tree  81/300 (tree index:81) done accuracy:0.783333 logloss:0.480288\n",
      "I0000 00:00:1729625148.754718 6802122 random_forest.cc:812] Training of tree  91/300 (tree index:90) done accuracy:0.775 logloss:0.47863\n",
      "I0000 00:00:1729625148.754878 6802121 random_forest.cc:812] Training of tree  101/300 (tree index:101) done accuracy:0.783333 logloss:0.47819\n",
      "I0000 00:00:1729625148.755096 6802118 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.775 logloss:0.481882\n",
      "I0000 00:00:1729625148.755298 6802120 random_forest.cc:812] Training of tree  122/300 (tree index:123) done accuracy:0.775 logloss:0.485176\n",
      "I0000 00:00:1729625148.755472 6802121 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.775 logloss:0.492939\n",
      "I0000 00:00:1729625148.755660 6802124 random_forest.cc:812] Training of tree  142/300 (tree index:134) done accuracy:0.766667 logloss:0.491768\n",
      "I0000 00:00:1729625148.755847 6802121 random_forest.cc:812] Training of tree  152/300 (tree index:150) done accuracy:0.766667 logloss:0.494617\n",
      "I0000 00:00:1729625148.756021 6802123 random_forest.cc:812] Training of tree  162/300 (tree index:163) done accuracy:0.766667 logloss:0.494468\n",
      "I0000 00:00:1729625148.756161 6802121 random_forest.cc:812] Training of tree  173/300 (tree index:173) done accuracy:0.766667 logloss:0.495442\n",
      "I0000 00:00:1729625148.756348 6802120 random_forest.cc:812] Training of tree  183/300 (tree index:182) done accuracy:0.766667 logloss:0.494414\n",
      "I0000 00:00:1729625148.756597 6802121 random_forest.cc:812] Training of tree  195/300 (tree index:194) done accuracy:0.766667 logloss:0.495514\n",
      "I0000 00:00:1729625148.756795 6802120 random_forest.cc:812] Training of tree  205/300 (tree index:204) done accuracy:0.766667 logloss:0.490487\n",
      "I0000 00:00:1729625148.756951 6802125 random_forest.cc:812] Training of tree  215/300 (tree index:214) done accuracy:0.766667 logloss:0.48968\n",
      "I0000 00:00:1729625148.757138 6802123 random_forest.cc:812] Training of tree  225/300 (tree index:225) done accuracy:0.783333 logloss:0.485278\n",
      "I0000 00:00:1729625148.757278 6802121 random_forest.cc:812] Training of tree  235/300 (tree index:232) done accuracy:0.783333 logloss:0.48378\n",
      "I0000 00:00:1729625148.757444 6802124 random_forest.cc:812] Training of tree  245/300 (tree index:244) done accuracy:0.766667 logloss:0.481308\n",
      "I0000 00:00:1729625148.757613 6802118 random_forest.cc:812] Training of tree  255/300 (tree index:255) done accuracy:0.766667 logloss:0.480605\n",
      "I0000 00:00:1729625148.757765 6802124 random_forest.cc:812] Training of tree  265/300 (tree index:263) done accuracy:0.766667 logloss:0.480156\n",
      "I0000 00:00:1729625148.757953 6802119 random_forest.cc:812] Training of tree  275/300 (tree index:276) done accuracy:0.775 logloss:0.47989\n",
      "I0000 00:00:1729625148.758132 6802123 random_forest.cc:812] Training of tree  285/300 (tree index:287) done accuracy:0.775 logloss:0.480121\n",
      "I0000 00:00:1729625148.758342 6802119 random_forest.cc:812] Training of tree  297/300 (tree index:294) done accuracy:0.775 logloss:0.476832\n",
      "I0000 00:00:1729625148.758398 6802118 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.783333 logloss:0.47604\n",
      "I0000 00:00:1729625148.758512 6802109 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.47604\n",
      "I0000 00:00:1729625148.759223 6802109 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5hfr1ts7 with prefix 08cc063267b04aa9\n",
      "I0000 00:00:1729625148.762785 6802109 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625148.763518 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.47604\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43  12\n",
      "2  14  51\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:48.770782: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5hfr1ts7/model/ with prefix 08cc063267b04aa9\n",
      "I0000 00:00:1729625148.779103 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 6562 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:48.779122: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147376. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.026635\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7pulbhn4 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625149.061787 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625149.061800 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625149.061804 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625149.061869 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625149.061873 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625149.061919 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.061930 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.061935 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.061940 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.061981 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625149.062001 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625149.062135 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625149.062158 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1g6pbukz/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625149.062238 6802178 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625149.062327 6802178 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625149.062967 6802187 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625149.063130 6802193 random_forest.cc:812] Training of tree  11/300 (tree index:8) done accuracy:0.689076 logloss:1.68215\n",
      "I0000 00:00:1729625149.063282 6802194 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.708333 logloss:0.796801\n",
      "I0000 00:00:1729625149.063444 6802188 random_forest.cc:812] Training of tree  31/300 (tree index:29) done accuracy:0.708333 logloss:0.521725\n",
      "I0000 00:00:1729625149.063666 6802191 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.683333 logloss:0.565775\n",
      "I0000 00:00:1729625149.063837 6802192 random_forest.cc:812] Training of tree  51/300 (tree index:51) done accuracy:0.691667 logloss:0.563067\n",
      "I0000 00:00:1729625149.064009 6802187 random_forest.cc:812] Training of tree  61/300 (tree index:63) done accuracy:0.708333 logloss:0.540623\n",
      "I0000 00:00:1729625149.064153 6802191 random_forest.cc:812] Training of tree  71/300 (tree index:71) done accuracy:0.7 logloss:0.545124\n",
      "I0000 00:00:1729625149.064338 6802189 random_forest.cc:812] Training of tree  81/300 (tree index:81) done accuracy:0.708333 logloss:0.539517\n",
      "I0000 00:00:1729625149.064519 6802191 random_forest.cc:812] Training of tree  91/300 (tree index:88) done accuracy:0.708333 logloss:0.543999\n",
      "I0000 00:00:1729625149.064672 6802193 random_forest.cc:812] Training of tree  101/300 (tree index:101) done accuracy:0.708333 logloss:0.539487\n",
      "I0000 00:00:1729625149.064890 6802191 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.725 logloss:0.539151\n",
      "I0000 00:00:1729625149.065106 6802194 random_forest.cc:812] Training of tree  121/300 (tree index:124) done accuracy:0.733333 logloss:0.532734\n",
      "I0000 00:00:1729625149.065240 6802192 random_forest.cc:812] Training of tree  131/300 (tree index:129) done accuracy:0.733333 logloss:0.533219\n",
      "I0000 00:00:1729625149.065486 6802191 random_forest.cc:812] Training of tree  142/300 (tree index:142) done accuracy:0.741667 logloss:0.527458\n",
      "I0000 00:00:1729625149.065702 6802190 random_forest.cc:812] Training of tree  152/300 (tree index:153) done accuracy:0.733333 logloss:0.525718\n",
      "I0000 00:00:1729625149.065865 6802189 random_forest.cc:812] Training of tree  162/300 (tree index:162) done accuracy:0.733333 logloss:0.532132\n",
      "I0000 00:00:1729625149.066012 6802188 random_forest.cc:812] Training of tree  172/300 (tree index:171) done accuracy:0.733333 logloss:0.528451\n",
      "I0000 00:00:1729625149.066240 6802191 random_forest.cc:812] Training of tree  182/300 (tree index:179) done accuracy:0.741667 logloss:0.520946\n",
      "I0000 00:00:1729625149.066380 6802187 random_forest.cc:812] Training of tree  192/300 (tree index:191) done accuracy:0.733333 logloss:0.521535\n",
      "I0000 00:00:1729625149.066576 6802188 random_forest.cc:812] Training of tree  202/300 (tree index:201) done accuracy:0.733333 logloss:0.518089\n",
      "I0000 00:00:1729625149.066735 6802194 random_forest.cc:812] Training of tree  212/300 (tree index:213) done accuracy:0.725 logloss:0.517332\n",
      "I0000 00:00:1729625149.066867 6802189 random_forest.cc:812] Training of tree  222/300 (tree index:222) done accuracy:0.733333 logloss:0.517012\n",
      "I0000 00:00:1729625149.067009 6802193 random_forest.cc:812] Training of tree  232/300 (tree index:233) done accuracy:0.741667 logloss:0.514433\n",
      "I0000 00:00:1729625149.067133 6802192 random_forest.cc:812] Training of tree  242/300 (tree index:241) done accuracy:0.733333 logloss:0.511498\n",
      "I0000 00:00:1729625149.067303 6802194 random_forest.cc:812] Training of tree  252/300 (tree index:251) done accuracy:0.733333 logloss:0.510674\n",
      "I0000 00:00:1729625149.067510 6802194 random_forest.cc:812] Training of tree  262/300 (tree index:262) done accuracy:0.733333 logloss:0.511109\n",
      "I0000 00:00:1729625149.067707 6802193 random_forest.cc:812] Training of tree  272/300 (tree index:266) done accuracy:0.741667 logloss:0.510511\n",
      "I0000 00:00:1729625149.067858 6802189 random_forest.cc:812] Training of tree  282/300 (tree index:282) done accuracy:0.733333 logloss:0.510802\n",
      "I0000 00:00:1729625149.068037 6802191 random_forest.cc:812] Training of tree  293/300 (tree index:294) done accuracy:0.733333 logloss:0.510917\n",
      "I0000 00:00:1729625149.068182 6802190 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.741667 logloss:0.510612\n",
      "I0000 00:00:1729625149.068231 6802178 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.510612\n",
      "I0000 00:00:1729625149.068838 6802178 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1g6pbukz with prefix c2829f432a9f4026\n",
      "I0000 00:00:1729625149.071719 6802178 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625149.072310 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.510612\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  16\n",
      "2  15  47\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:49.078640: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp1g6pbukz/model/ with prefix c2829f432a9f4026\n",
      "I0000 00:00:1729625149.085894 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5638 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:49.085927: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147095. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.026423\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfks9cyiu as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625149.369509 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625149.369527 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625149.369531 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625149.369600 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625149.369605 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625149.369651 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.369661 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.369666 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.369671 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.369699 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625149.369728 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625149.369862 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625149.369888 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7pulbhn4/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625149.369936 6802246 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625149.370025 6802246 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625149.370655 6802258 random_forest.cc:812] Training of tree  1/300 (tree index:4) done accuracy:0.660714 logloss:12.2291\n",
      "I0000 00:00:1729625149.370809 6802262 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.697479 logloss:3.72176\n",
      "I0000 00:00:1729625149.370990 6802255 random_forest.cc:812] Training of tree  22/300 (tree index:19) done accuracy:0.691667 logloss:1.17956\n",
      "I0000 00:00:1729625149.371148 6802259 random_forest.cc:812] Training of tree  32/300 (tree index:31) done accuracy:0.7 logloss:0.597494\n",
      "I0000 00:00:1729625149.371342 6802261 random_forest.cc:812] Training of tree  42/300 (tree index:41) done accuracy:0.7 logloss:0.583066\n",
      "I0000 00:00:1729625149.371487 6802260 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.716667 logloss:0.559356\n",
      "I0000 00:00:1729625149.371737 6802257 random_forest.cc:812] Training of tree  62/300 (tree index:54) done accuracy:0.725 logloss:0.571707\n",
      "I0000 00:00:1729625149.371968 6802257 random_forest.cc:812] Training of tree  72/300 (tree index:68) done accuracy:0.725 logloss:0.566016\n",
      "I0000 00:00:1729625149.372166 6802259 random_forest.cc:812] Training of tree  82/300 (tree index:80) done accuracy:0.725 logloss:0.563284\n",
      "I0000 00:00:1729625149.372330 6802260 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.725 logloss:0.559882\n",
      "I0000 00:00:1729625149.372543 6802262 random_forest.cc:812] Training of tree  102/300 (tree index:101) done accuracy:0.733333 logloss:0.556732\n",
      "I0000 00:00:1729625149.372702 6802257 random_forest.cc:812] Training of tree  113/300 (tree index:112) done accuracy:0.75 logloss:0.555649\n",
      "I0000 00:00:1729625149.372933 6802256 random_forest.cc:812] Training of tree  124/300 (tree index:123) done accuracy:0.758333 logloss:0.550851\n",
      "I0000 00:00:1729625149.373071 6802255 random_forest.cc:812] Training of tree  134/300 (tree index:133) done accuracy:0.75 logloss:0.551847\n",
      "I0000 00:00:1729625149.373225 6802259 random_forest.cc:812] Training of tree  144/300 (tree index:144) done accuracy:0.758333 logloss:0.552777\n",
      "I0000 00:00:1729625149.373364 6802256 random_forest.cc:812] Training of tree  154/300 (tree index:155) done accuracy:0.766667 logloss:0.551624\n",
      "I0000 00:00:1729625149.373505 6802260 random_forest.cc:812] Training of tree  164/300 (tree index:165) done accuracy:0.766667 logloss:0.545945\n",
      "I0000 00:00:1729625149.373672 6802259 random_forest.cc:812] Training of tree  174/300 (tree index:175) done accuracy:0.775 logloss:0.545856\n",
      "I0000 00:00:1729625149.373833 6802257 random_forest.cc:812] Training of tree  184/300 (tree index:180) done accuracy:0.775 logloss:0.544198\n",
      "I0000 00:00:1729625149.373978 6802259 random_forest.cc:812] Training of tree  194/300 (tree index:195) done accuracy:0.783333 logloss:0.54218\n",
      "I0000 00:00:1729625149.374147 6802262 random_forest.cc:812] Training of tree  205/300 (tree index:202) done accuracy:0.775 logloss:0.540433\n",
      "I0000 00:00:1729625149.374313 6802256 random_forest.cc:812] Training of tree  215/300 (tree index:215) done accuracy:0.766667 logloss:0.544221\n",
      "I0000 00:00:1729625149.374507 6802258 random_forest.cc:812] Training of tree  226/300 (tree index:225) done accuracy:0.775 logloss:0.540721\n",
      "I0000 00:00:1729625149.374660 6802259 random_forest.cc:812] Training of tree  236/300 (tree index:236) done accuracy:0.766667 logloss:0.54214\n",
      "I0000 00:00:1729625149.374826 6802257 random_forest.cc:812] Training of tree  246/300 (tree index:246) done accuracy:0.766667 logloss:0.540531\n",
      "I0000 00:00:1729625149.375034 6802261 random_forest.cc:812] Training of tree  257/300 (tree index:256) done accuracy:0.766667 logloss:0.535703\n",
      "I0000 00:00:1729625149.375161 6802261 random_forest.cc:812] Training of tree  267/300 (tree index:263) done accuracy:0.775 logloss:0.532708\n",
      "I0000 00:00:1729625149.375340 6802256 random_forest.cc:812] Training of tree  277/300 (tree index:277) done accuracy:0.783333 logloss:0.531897\n",
      "I0000 00:00:1729625149.375489 6802259 random_forest.cc:812] Training of tree  287/300 (tree index:288) done accuracy:0.766667 logloss:0.531281\n",
      "I0000 00:00:1729625149.375681 6802258 random_forest.cc:812] Training of tree  297/300 (tree index:296) done accuracy:0.766667 logloss:0.531865\n",
      "I0000 00:00:1729625149.375747 6802256 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.766667 logloss:0.530043\n",
      "I0000 00:00:1729625149.375853 6802246 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.530043\n",
      "I0000 00:00:1729625149.376505 6802246 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7pulbhn4 with prefix f02ea50279f542d8\n",
      "I0000 00:00:1729625149.379744 6802246 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625149.380402 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.530043\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  13  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:49.386297: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp7pulbhn4/model/ with prefix f02ea50279f542d8\n",
      "I0000 00:00:1729625149.393643 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5776 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:49.393658: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146924. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.027171\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpa0e1o9o9 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625149.675328 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625149.675340 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625149.675345 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625149.675416 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625149.675420 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625149.675467 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.675478 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.675484 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.675490 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.675517 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625149.675535 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625149.675672 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625149.675700 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfks9cyiu/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625149.675776 6802317 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625149.675861 6802317 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625149.676433 6802333 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.632653 logloss:13.2405\n",
      "I0000 00:00:1729625149.676645 6802333 random_forest.cc:812] Training of tree  13/300 (tree index:12) done accuracy:0.683761 logloss:4.35881\n",
      "I0000 00:00:1729625149.676943 6802329 random_forest.cc:812] Training of tree  23/300 (tree index:25) done accuracy:0.7 logloss:1.14906\n",
      "I0000 00:00:1729625149.677170 6802332 random_forest.cc:812] Training of tree  33/300 (tree index:31) done accuracy:0.7 logloss:0.575121\n",
      "I0000 00:00:1729625149.677349 6802333 random_forest.cc:812] Training of tree  43/300 (tree index:44) done accuracy:0.733333 logloss:0.568744\n",
      "I0000 00:00:1729625149.677514 6802330 random_forest.cc:812] Training of tree  53/300 (tree index:36) done accuracy:0.75 logloss:0.556097\n",
      "I0000 00:00:1729625149.677709 6802327 random_forest.cc:812] Training of tree  65/300 (tree index:64) done accuracy:0.775 logloss:0.543487\n",
      "I0000 00:00:1729625149.677887 6802331 random_forest.cc:812] Training of tree  76/300 (tree index:73) done accuracy:0.791667 logloss:0.545123\n",
      "I0000 00:00:1729625149.678082 6802327 random_forest.cc:812] Training of tree  86/300 (tree index:87) done accuracy:0.783333 logloss:0.53367\n",
      "I0000 00:00:1729625149.678249 6802333 random_forest.cc:812] Training of tree  96/300 (tree index:95) done accuracy:0.791667 logloss:0.534372\n",
      "I0000 00:00:1729625149.678440 6802328 random_forest.cc:812] Training of tree  106/300 (tree index:105) done accuracy:0.791667 logloss:0.531729\n",
      "I0000 00:00:1729625149.678633 6802328 random_forest.cc:812] Training of tree  116/300 (tree index:115) done accuracy:0.791667 logloss:0.524325\n",
      "I0000 00:00:1729625149.678790 6802326 random_forest.cc:812] Training of tree  126/300 (tree index:116) done accuracy:0.775 logloss:0.52206\n",
      "I0000 00:00:1729625149.678956 6802328 random_forest.cc:812] Training of tree  136/300 (tree index:136) done accuracy:0.766667 logloss:0.51824\n",
      "I0000 00:00:1729625149.679123 6802333 random_forest.cc:812] Training of tree  146/300 (tree index:133) done accuracy:0.766667 logloss:0.519941\n",
      "I0000 00:00:1729625149.679246 6802331 random_forest.cc:812] Training of tree  156/300 (tree index:155) done accuracy:0.775 logloss:0.52114\n",
      "I0000 00:00:1729625149.679409 6802330 random_forest.cc:812] Training of tree  166/300 (tree index:164) done accuracy:0.775 logloss:0.525798\n",
      "I0000 00:00:1729625149.679548 6802326 random_forest.cc:812] Training of tree  176/300 (tree index:177) done accuracy:0.775 logloss:0.526451\n",
      "I0000 00:00:1729625149.679687 6802331 random_forest.cc:812] Training of tree  186/300 (tree index:185) done accuracy:0.783333 logloss:0.526162\n",
      "I0000 00:00:1729625149.679822 6802330 random_forest.cc:812] Training of tree  196/300 (tree index:196) done accuracy:0.783333 logloss:0.524591\n",
      "I0000 00:00:1729625149.679940 6802330 random_forest.cc:812] Training of tree  206/300 (tree index:203) done accuracy:0.783333 logloss:0.519005\n",
      "I0000 00:00:1729625149.680101 6802328 random_forest.cc:812] Training of tree  216/300 (tree index:217) done accuracy:0.783333 logloss:0.519887\n",
      "I0000 00:00:1729625149.680237 6802331 random_forest.cc:812] Training of tree  226/300 (tree index:225) done accuracy:0.783333 logloss:0.518766\n",
      "I0000 00:00:1729625149.680415 6802330 random_forest.cc:812] Training of tree  236/300 (tree index:237) done accuracy:0.783333 logloss:0.518603\n",
      "I0000 00:00:1729625149.680586 6802332 random_forest.cc:812] Training of tree  246/300 (tree index:246) done accuracy:0.783333 logloss:0.520645\n",
      "I0000 00:00:1729625149.680771 6802332 random_forest.cc:812] Training of tree  257/300 (tree index:257) done accuracy:0.783333 logloss:0.520041\n",
      "I0000 00:00:1729625149.680984 6802326 random_forest.cc:812] Training of tree  267/300 (tree index:268) done accuracy:0.783333 logloss:0.519499\n",
      "I0000 00:00:1729625149.681139 6802330 random_forest.cc:812] Training of tree  277/300 (tree index:278) done accuracy:0.783333 logloss:0.521549\n",
      "I0000 00:00:1729625149.681275 6802327 random_forest.cc:812] Training of tree  287/300 (tree index:286) done accuracy:0.791667 logloss:0.521464\n",
      "I0000 00:00:1729625149.681447 6802328 random_forest.cc:812] Training of tree  297/300 (tree index:288) done accuracy:0.791667 logloss:0.519754\n",
      "I0000 00:00:1729625149.681523 6802332 random_forest.cc:812] Training of tree  300/300 (tree index:297) done accuracy:0.791667 logloss:0.519838\n",
      "I0000 00:00:1729625149.681614 6802317 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.519838\n",
      "I0000 00:00:1729625149.682352 6802317 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfks9cyiu with prefix 2ee5015cf1494473\n",
      "I0000 00:00:1729625149.685444 6802317 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625149.686211 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.519838\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  14\n",
      "2  11  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:49.692479: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpfks9cyiu/model/ with prefix 2ee5015cf1494473\n",
      "I0000 00:00:1729625149.699930 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5828 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:49.699947: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145105. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.024877\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3izhph0g as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625149.978159 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625149.978172 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625149.978176 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625149.978243 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625149.978248 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625149.978294 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.978303 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.978308 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.978313 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625149.978340 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625149.978367 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625149.978539 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625149.978574 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpa0e1o9o9/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625149.978630 6802386 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625149.978728 6802386 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625149.979262 6802402 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.698113 logloss:10.8811\n",
      "I0000 00:00:1729625149.979410 6802400 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.716667 logloss:1.63255\n",
      "I0000 00:00:1729625149.979538 6802401 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.758333 logloss:1.31472\n",
      "I0000 00:00:1729625149.979766 6802399 random_forest.cc:812] Training of tree  34/300 (tree index:0) done accuracy:0.758333 logloss:1.0413\n",
      "I0000 00:00:1729625149.979937 6802397 random_forest.cc:812] Training of tree  45/300 (tree index:43) done accuracy:0.766667 logloss:0.491942\n",
      "I0000 00:00:1729625149.980134 6802397 random_forest.cc:812] Training of tree  56/300 (tree index:55) done accuracy:0.758333 logloss:0.488263\n",
      "I0000 00:00:1729625149.980273 6802396 random_forest.cc:812] Training of tree  66/300 (tree index:63) done accuracy:0.783333 logloss:0.486112\n",
      "I0000 00:00:1729625149.980432 6802398 random_forest.cc:812] Training of tree  76/300 (tree index:78) done accuracy:0.775 logloss:0.477473\n",
      "I0000 00:00:1729625149.980595 6802401 random_forest.cc:812] Training of tree  86/300 (tree index:85) done accuracy:0.758333 logloss:0.479436\n",
      "I0000 00:00:1729625149.980766 6802396 random_forest.cc:812] Training of tree  98/300 (tree index:97) done accuracy:0.783333 logloss:0.473211\n",
      "I0000 00:00:1729625149.980924 6802396 random_forest.cc:812] Training of tree  108/300 (tree index:109) done accuracy:0.791667 logloss:0.478752\n",
      "I0000 00:00:1729625149.981104 6802398 random_forest.cc:812] Training of tree  119/300 (tree index:118) done accuracy:0.8 logloss:0.479645\n",
      "I0000 00:00:1729625149.981309 6802400 random_forest.cc:812] Training of tree  129/300 (tree index:130) done accuracy:0.791667 logloss:0.478444\n",
      "I0000 00:00:1729625149.981428 6802399 random_forest.cc:812] Training of tree  139/300 (tree index:138) done accuracy:0.791667 logloss:0.476921\n",
      "I0000 00:00:1729625149.981612 6802402 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.783333 logloss:0.477846\n",
      "I0000 00:00:1729625149.981837 6802395 random_forest.cc:812] Training of tree  161/300 (tree index:162) done accuracy:0.783333 logloss:0.478389\n",
      "I0000 00:00:1729625149.981971 6802401 random_forest.cc:812] Training of tree  171/300 (tree index:171) done accuracy:0.783333 logloss:0.479906\n",
      "I0000 00:00:1729625149.982212 6802398 random_forest.cc:812] Training of tree  181/300 (tree index:181) done accuracy:0.775 logloss:0.480453\n",
      "I0000 00:00:1729625149.982362 6802398 random_forest.cc:812] Training of tree  191/300 (tree index:192) done accuracy:0.783333 logloss:0.481133\n",
      "I0000 00:00:1729625149.982546 6802396 random_forest.cc:812] Training of tree  201/300 (tree index:201) done accuracy:0.783333 logloss:0.480198\n",
      "I0000 00:00:1729625149.982713 6802399 random_forest.cc:812] Training of tree  211/300 (tree index:198) done accuracy:0.775 logloss:0.478042\n",
      "I0000 00:00:1729625149.982843 6802395 random_forest.cc:812] Training of tree  221/300 (tree index:220) done accuracy:0.783333 logloss:0.476364\n",
      "I0000 00:00:1729625149.982978 6802399 random_forest.cc:812] Training of tree  232/300 (tree index:231) done accuracy:0.783333 logloss:0.475604\n",
      "I0000 00:00:1729625149.983125 6802399 random_forest.cc:812] Training of tree  242/300 (tree index:237) done accuracy:0.783333 logloss:0.474294\n",
      "I0000 00:00:1729625149.983307 6802402 random_forest.cc:812] Training of tree  252/300 (tree index:253) done accuracy:0.783333 logloss:0.470576\n",
      "I0000 00:00:1729625149.983467 6802398 random_forest.cc:812] Training of tree  262/300 (tree index:263) done accuracy:0.783333 logloss:0.473213\n",
      "I0000 00:00:1729625149.983625 6802396 random_forest.cc:812] Training of tree  275/300 (tree index:274) done accuracy:0.783333 logloss:0.475423\n",
      "I0000 00:00:1729625149.983835 6802395 random_forest.cc:812] Training of tree  285/300 (tree index:285) done accuracy:0.8 logloss:0.47604\n",
      "I0000 00:00:1729625149.983981 6802398 random_forest.cc:812] Training of tree  295/300 (tree index:297) done accuracy:0.8 logloss:0.475186\n",
      "I0000 00:00:1729625149.984057 6802401 random_forest.cc:812] Training of tree  300/300 (tree index:289) done accuracy:0.8 logloss:0.474312\n",
      "I0000 00:00:1729625149.984122 6802386 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.474312\n",
      "I0000 00:00:1729625149.984717 6802386 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpa0e1o9o9 with prefix a9a9e4c839944e40\n",
      "I0000 00:00:1729625149.987720 6802386 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625149.988326 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.474312\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:49.994089: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpa0e1o9o9/model/ with prefix a9a9e4c839944e40\n",
      "I0000 00:00:1729625150.000852 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5290 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:50.000867: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144603. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.025980\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': -1, 'min_examples': 10, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp__jp2mq9 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625150.314447 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625150.314458 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625150.314463 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625150.314534 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625150.314539 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625150.314583 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.314592 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.314597 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.314603 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.314630 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625150.314648 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625150.314792 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625150.314817 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3izhph0g/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625150.314874 6802457 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625150.314976 6802457 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625150.315502 6802473 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.641509 logloss:12.9213\n",
      "I0000 00:00:1729625150.315640 6802471 random_forest.cc:812] Training of tree  11/300 (tree index:9) done accuracy:0.781513 logloss:2.14357\n",
      "I0000 00:00:1729625150.315819 6802471 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.733333 logloss:0.730762\n",
      "I0000 00:00:1729625150.315948 6802467 random_forest.cc:812] Training of tree  31/300 (tree index:29) done accuracy:0.758333 logloss:0.72806\n",
      "I0000 00:00:1729625150.316119 6802470 random_forest.cc:812] Training of tree  41/300 (tree index:42) done accuracy:0.766667 logloss:0.47892\n",
      "I0000 00:00:1729625150.316355 6802472 random_forest.cc:812] Training of tree  51/300 (tree index:52) done accuracy:0.775 logloss:0.474318\n",
      "I0000 00:00:1729625150.316561 6802468 random_forest.cc:812] Training of tree  61/300 (tree index:59) done accuracy:0.766667 logloss:0.474378\n",
      "I0000 00:00:1729625150.316799 6802469 random_forest.cc:812] Training of tree  73/300 (tree index:72) done accuracy:0.766667 logloss:0.47829\n",
      "I0000 00:00:1729625150.316948 6802473 random_forest.cc:812] Training of tree  83/300 (tree index:83) done accuracy:0.775 logloss:0.464985\n",
      "I0000 00:00:1729625150.317122 6802466 random_forest.cc:812] Training of tree  93/300 (tree index:92) done accuracy:0.791667 logloss:0.457005\n",
      "I0000 00:00:1729625150.317301 6802466 random_forest.cc:812] Training of tree  103/300 (tree index:102) done accuracy:0.783333 logloss:0.463994\n",
      "I0000 00:00:1729625150.317422 6802470 random_forest.cc:812] Training of tree  113/300 (tree index:112) done accuracy:0.783333 logloss:0.4622\n",
      "I0000 00:00:1729625150.317593 6802473 random_forest.cc:812] Training of tree  123/300 (tree index:123) done accuracy:0.791667 logloss:0.469275\n",
      "I0000 00:00:1729625150.317763 6802467 random_forest.cc:812] Training of tree  134/300 (tree index:133) done accuracy:0.791667 logloss:0.458912\n",
      "I0000 00:00:1729625150.317957 6802471 random_forest.cc:812] Training of tree  146/300 (tree index:147) done accuracy:0.775 logloss:0.470389\n",
      "I0000 00:00:1729625150.318126 6802472 random_forest.cc:812] Training of tree  156/300 (tree index:154) done accuracy:0.775 logloss:0.472748\n",
      "I0000 00:00:1729625150.318303 6802470 random_forest.cc:812] Training of tree  166/300 (tree index:168) done accuracy:0.783333 logloss:0.477481\n",
      "I0000 00:00:1729625150.318440 6802473 random_forest.cc:812] Training of tree  176/300 (tree index:176) done accuracy:0.783333 logloss:0.472141\n",
      "I0000 00:00:1729625150.318585 6802468 random_forest.cc:812] Training of tree  186/300 (tree index:185) done accuracy:0.766667 logloss:0.474258\n",
      "I0000 00:00:1729625150.318762 6802468 random_forest.cc:812] Training of tree  196/300 (tree index:197) done accuracy:0.766667 logloss:0.474342\n",
      "I0000 00:00:1729625150.318922 6802466 random_forest.cc:812] Training of tree  206/300 (tree index:204) done accuracy:0.775 logloss:0.476545\n",
      "I0000 00:00:1729625150.319089 6802467 random_forest.cc:812] Training of tree  216/300 (tree index:216) done accuracy:0.766667 logloss:0.47595\n",
      "I0000 00:00:1729625150.319220 6802473 random_forest.cc:812] Training of tree  226/300 (tree index:227) done accuracy:0.775 logloss:0.474777\n",
      "I0000 00:00:1729625150.319378 6802470 random_forest.cc:812] Training of tree  236/300 (tree index:237) done accuracy:0.758333 logloss:0.473885\n",
      "I0000 00:00:1729625150.319515 6802472 random_forest.cc:812] Training of tree  246/300 (tree index:247) done accuracy:0.766667 logloss:0.471832\n",
      "I0000 00:00:1729625150.319694 6802466 random_forest.cc:812] Training of tree  256/300 (tree index:256) done accuracy:0.783333 logloss:0.474832\n",
      "I0000 00:00:1729625150.319860 6802467 random_forest.cc:812] Training of tree  266/300 (tree index:266) done accuracy:0.775 logloss:0.476689\n",
      "I0000 00:00:1729625150.320107 6802472 random_forest.cc:812] Training of tree  276/300 (tree index:277) done accuracy:0.783333 logloss:0.478931\n",
      "I0000 00:00:1729625150.320253 6802469 random_forest.cc:812] Training of tree  286/300 (tree index:275) done accuracy:0.791667 logloss:0.476672\n",
      "I0000 00:00:1729625150.320433 6802466 random_forest.cc:812] Training of tree  296/300 (tree index:295) done accuracy:0.775 logloss:0.476357\n",
      "I0000 00:00:1729625150.320513 6802469 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.775 logloss:0.476714\n",
      "I0000 00:00:1729625150.320608 6802457 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.476714\n",
      "I0000 00:00:1729625150.321214 6802457 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3izhph0g with prefix 67095673382b44d1\n",
      "I0000 00:00:1729625150.323940 6802457 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625150.324693 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.476714\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  13  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:50.331030: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp3izhph0g/model/ with prefix 67095673382b44d1\n",
      "I0000 00:00:1729625150.338090 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 5552 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:50.338105: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146265. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023099\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp4x_nwnjc as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625150.616364 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625150.616384 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625150.616387 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625150.616452 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625150.616458 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625150.616501 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.616511 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.616517 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.616522 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.616550 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625150.616568 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625150.616703 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625150.616729 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp__jp2mq9/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625150.616789 6802527 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625150.616890 6802527 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625150.617444 6802536 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625150.617624 6802542 random_forest.cc:812] Training of tree  12/300 (tree index:12) done accuracy:0.726496 logloss:5.51321\n",
      "I0000 00:00:1729625150.617838 6802540 random_forest.cc:812] Training of tree  22/300 (tree index:20) done accuracy:0.75 logloss:1.40534\n",
      "I0000 00:00:1729625150.617976 6802538 random_forest.cc:812] Training of tree  32/300 (tree index:32) done accuracy:0.766667 logloss:1.09833\n",
      "I0000 00:00:1729625150.618157 6802536 random_forest.cc:812] Training of tree  42/300 (tree index:42) done accuracy:0.766667 logloss:0.82355\n",
      "I0000 00:00:1729625150.618303 6802539 random_forest.cc:812] Training of tree  52/300 (tree index:53) done accuracy:0.733333 logloss:0.811604\n",
      "I0000 00:00:1729625150.618477 6802543 random_forest.cc:812] Training of tree  62/300 (tree index:60) done accuracy:0.75 logloss:0.801861\n",
      "I0000 00:00:1729625150.618640 6802542 random_forest.cc:812] Training of tree  72/300 (tree index:71) done accuracy:0.725 logloss:0.80185\n",
      "I0000 00:00:1729625150.618763 6802536 random_forest.cc:812] Training of tree  82/300 (tree index:81) done accuracy:0.725 logloss:0.811335\n",
      "I0000 00:00:1729625150.618969 6802540 random_forest.cc:812] Training of tree  93/300 (tree index:87) done accuracy:0.708333 logloss:0.81547\n",
      "I0000 00:00:1729625150.619145 6802539 random_forest.cc:812] Training of tree  103/300 (tree index:102) done accuracy:0.708333 logloss:0.54383\n",
      "I0000 00:00:1729625150.619274 6802540 random_forest.cc:812] Training of tree  113/300 (tree index:110) done accuracy:0.708333 logloss:0.547888\n",
      "I0000 00:00:1729625150.619420 6802539 random_forest.cc:812] Training of tree  123/300 (tree index:123) done accuracy:0.716667 logloss:0.548792\n",
      "I0000 00:00:1729625150.619576 6802538 random_forest.cc:812] Training of tree  133/300 (tree index:134) done accuracy:0.7 logloss:0.549138\n",
      "I0000 00:00:1729625150.619724 6802536 random_forest.cc:812] Training of tree  143/300 (tree index:143) done accuracy:0.716667 logloss:0.553276\n",
      "I0000 00:00:1729625150.619862 6802543 random_forest.cc:812] Training of tree  153/300 (tree index:153) done accuracy:0.708333 logloss:0.558577\n",
      "I0000 00:00:1729625150.620010 6802536 random_forest.cc:812] Training of tree  164/300 (tree index:150) done accuracy:0.708333 logloss:0.558416\n",
      "I0000 00:00:1729625150.620188 6802541 random_forest.cc:812] Training of tree  174/300 (tree index:168) done accuracy:0.708333 logloss:0.551189\n",
      "I0000 00:00:1729625150.620345 6802542 random_forest.cc:812] Training of tree  184/300 (tree index:184) done accuracy:0.683333 logloss:0.550468\n",
      "I0000 00:00:1729625150.620481 6802541 random_forest.cc:812] Training of tree  194/300 (tree index:195) done accuracy:0.691667 logloss:0.549194\n",
      "I0000 00:00:1729625150.620681 6802543 random_forest.cc:812] Training of tree  205/300 (tree index:204) done accuracy:0.7 logloss:0.548248\n",
      "I0000 00:00:1729625150.620845 6802536 random_forest.cc:812] Training of tree  215/300 (tree index:216) done accuracy:0.7 logloss:0.551602\n",
      "I0000 00:00:1729625150.620966 6802539 random_forest.cc:812] Training of tree  226/300 (tree index:225) done accuracy:0.691667 logloss:0.554663\n",
      "I0000 00:00:1729625150.621155 6802538 random_forest.cc:812] Training of tree  236/300 (tree index:237) done accuracy:0.691667 logloss:0.553791\n",
      "I0000 00:00:1729625150.621302 6802537 random_forest.cc:812] Training of tree  247/300 (tree index:246) done accuracy:0.691667 logloss:0.549609\n",
      "I0000 00:00:1729625150.621478 6802543 random_forest.cc:812] Training of tree  257/300 (tree index:257) done accuracy:0.708333 logloss:0.551396\n",
      "I0000 00:00:1729625150.621658 6802539 random_forest.cc:812] Training of tree  267/300 (tree index:255) done accuracy:0.708333 logloss:0.552909\n",
      "I0000 00:00:1729625150.621817 6802537 random_forest.cc:812] Training of tree  277/300 (tree index:278) done accuracy:0.708333 logloss:0.549916\n",
      "I0000 00:00:1729625150.622004 6802541 random_forest.cc:812] Training of tree  287/300 (tree index:279) done accuracy:0.708333 logloss:0.547358\n",
      "I0000 00:00:1729625150.622210 6802541 random_forest.cc:812] Training of tree  297/300 (tree index:299) done accuracy:0.708333 logloss:0.54461\n",
      "I0000 00:00:1729625150.622286 6802543 random_forest.cc:812] Training of tree  300/300 (tree index:296) done accuracy:0.708333 logloss:0.545719\n",
      "I0000 00:00:1729625150.622335 6802527 random_forest.cc:892] Final OOB metrics: accuracy:0.708333 logloss:0.545719\n",
      "I0000 00:00:1729625150.622818 6802527 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp__jp2mq9 with prefix fbbfdce0f8cc4640\n",
      "I0000 00:00:1729625150.625326 6802527 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625150.625886 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.708333  CI95[W][0.632502 0.776259]\n",
      "LogLoss: : 0.545719\n",
      "ErrorRate: : 0.291667\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  16  46\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:50.631678: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp__jp2mq9/model/ with prefix fbbfdce0f8cc4640\n",
      "I0000 00:00:1729625150.637523 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4562 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:50.637541: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.148504. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023694\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvn1433fs as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625150.919956 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625150.919969 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625150.919973 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625150.920043 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625150.920049 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625150.920095 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.920105 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.920111 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.920117 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625150.920146 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625150.920165 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625150.920299 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625150.920323 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp4x_nwnjc/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625150.920384 6802603 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625150.920495 6802603 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625150.921153 6802612 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.731707 logloss:9.67025\n",
      "I0000 00:00:1729625150.921347 6802614 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.708333 logloss:5.40116\n",
      "I0000 00:00:1729625150.921559 6802617 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.758333 logloss:1.6697\n",
      "I0000 00:00:1729625150.921759 6802614 random_forest.cc:812] Training of tree  31/300 (tree index:28) done accuracy:0.741667 logloss:1.07224\n",
      "I0000 00:00:1729625150.921929 6802612 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.758333 logloss:0.802897\n",
      "I0000 00:00:1729625150.922065 6802618 random_forest.cc:812] Training of tree  51/300 (tree index:51) done accuracy:0.758333 logloss:0.543122\n",
      "I0000 00:00:1729625150.922207 6802613 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.766667 logloss:0.531089\n",
      "I0000 00:00:1729625150.922319 6802612 random_forest.cc:812] Training of tree  71/300 (tree index:70) done accuracy:0.766667 logloss:0.533355\n",
      "I0000 00:00:1729625150.922514 6802617 random_forest.cc:812] Training of tree  81/300 (tree index:71) done accuracy:0.766667 logloss:0.528473\n",
      "I0000 00:00:1729625150.922651 6802614 random_forest.cc:812] Training of tree  91/300 (tree index:91) done accuracy:0.758333 logloss:0.530359\n",
      "I0000 00:00:1729625150.922862 6802617 random_forest.cc:812] Training of tree  101/300 (tree index:88) done accuracy:0.766667 logloss:0.525852\n",
      "I0000 00:00:1729625150.922999 6802614 random_forest.cc:812] Training of tree  111/300 (tree index:110) done accuracy:0.775 logloss:0.529023\n",
      "I0000 00:00:1729625150.923193 6802614 random_forest.cc:812] Training of tree  121/300 (tree index:120) done accuracy:0.766667 logloss:0.526188\n",
      "I0000 00:00:1729625150.923351 6802615 random_forest.cc:812] Training of tree  131/300 (tree index:132) done accuracy:0.75 logloss:0.524378\n",
      "I0000 00:00:1729625150.923498 6802619 random_forest.cc:812] Training of tree  141/300 (tree index:142) done accuracy:0.758333 logloss:0.525561\n",
      "I0000 00:00:1729625150.923695 6802619 random_forest.cc:812] Training of tree  151/300 (tree index:150) done accuracy:0.741667 logloss:0.530535\n",
      "I0000 00:00:1729625150.923825 6802618 random_forest.cc:812] Training of tree  161/300 (tree index:159) done accuracy:0.758333 logloss:0.533228\n",
      "I0000 00:00:1729625150.923980 6802612 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.741667 logloss:0.537613\n",
      "I0000 00:00:1729625150.924104 6802617 random_forest.cc:812] Training of tree  181/300 (tree index:180) done accuracy:0.75 logloss:0.534743\n",
      "I0000 00:00:1729625150.924292 6802615 random_forest.cc:812] Training of tree  191/300 (tree index:192) done accuracy:0.75 logloss:0.540343\n",
      "I0000 00:00:1729625150.924455 6802616 random_forest.cc:812] Training of tree  202/300 (tree index:201) done accuracy:0.766667 logloss:0.545157\n",
      "I0000 00:00:1729625150.924620 6802618 random_forest.cc:812] Training of tree  213/300 (tree index:210) done accuracy:0.775 logloss:0.544284\n",
      "I0000 00:00:1729625150.924799 6802618 random_forest.cc:812] Training of tree  223/300 (tree index:225) done accuracy:0.775 logloss:0.545277\n",
      "I0000 00:00:1729625150.924939 6802617 random_forest.cc:812] Training of tree  233/300 (tree index:233) done accuracy:0.766667 logloss:0.546423\n",
      "I0000 00:00:1729625150.925113 6802615 random_forest.cc:812] Training of tree  243/300 (tree index:242) done accuracy:0.775 logloss:0.545535\n",
      "I0000 00:00:1729625150.925343 6802615 random_forest.cc:812] Training of tree  255/300 (tree index:255) done accuracy:0.766667 logloss:0.546325\n",
      "I0000 00:00:1729625150.925571 6802617 random_forest.cc:812] Training of tree  266/300 (tree index:264) done accuracy:0.775 logloss:0.54767\n",
      "I0000 00:00:1729625150.925785 6802612 random_forest.cc:812] Training of tree  278/300 (tree index:277) done accuracy:0.766667 logloss:0.547565\n",
      "I0000 00:00:1729625150.925955 6802619 random_forest.cc:812] Training of tree  288/300 (tree index:287) done accuracy:0.775 logloss:0.545164\n",
      "I0000 00:00:1729625150.926138 6802617 random_forest.cc:812] Training of tree  298/300 (tree index:298) done accuracy:0.775 logloss:0.547901\n",
      "I0000 00:00:1729625150.926173 6802612 random_forest.cc:812] Training of tree  300/300 (tree index:297) done accuracy:0.775 logloss:0.547206\n",
      "I0000 00:00:1729625150.926262 6802603 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.547206\n",
      "I0000 00:00:1729625150.926729 6802603 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp4x_nwnjc with prefix 86e3025fd12543a1\n",
      "I0000 00:00:1729625150.929214 6802603 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625150.930020 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.547206\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  38  15\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:50.935513: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp4x_nwnjc/model/ with prefix 86e3025fd12543a1\n",
      "I0000 00:00:1729625150.941581 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4612 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:50.941601: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.189323. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.024298\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp86gya92n as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625151.266391 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625151.266405 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625151.266410 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625151.266480 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625151.266485 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625151.266529 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.266539 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.266544 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.266549 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.266632 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625151.266659 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625151.266800 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625151.266826 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvn1433fs/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625151.266869 6802671 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625151.266979 6802671 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625151.267577 6802681 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.682927 logloss:11.4285\n",
      "I0000 00:00:1729625151.267767 6802685 random_forest.cc:812] Training of tree  11/300 (tree index:5) done accuracy:0.689076 logloss:1.91993\n",
      "I0000 00:00:1729625151.267957 6802681 random_forest.cc:812] Training of tree  21/300 (tree index:16) done accuracy:0.7 logloss:0.842303\n",
      "I0000 00:00:1729625151.268090 6802687 random_forest.cc:812] Training of tree  31/300 (tree index:32) done accuracy:0.716667 logloss:0.865308\n",
      "I0000 00:00:1729625151.268264 6802681 random_forest.cc:812] Training of tree  41/300 (tree index:41) done accuracy:0.708333 logloss:0.594369\n",
      "I0000 00:00:1729625151.268406 6802685 random_forest.cc:812] Training of tree  52/300 (tree index:53) done accuracy:0.658333 logloss:0.596785\n",
      "I0000 00:00:1729625151.268597 6802680 random_forest.cc:812] Training of tree  62/300 (tree index:62) done accuracy:0.691667 logloss:0.595042\n",
      "I0000 00:00:1729625151.268754 6802681 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.733333 logloss:0.595425\n",
      "I0000 00:00:1729625151.268917 6802685 random_forest.cc:812] Training of tree  82/300 (tree index:82) done accuracy:0.725 logloss:0.588955\n",
      "I0000 00:00:1729625151.269071 6802684 random_forest.cc:812] Training of tree  92/300 (tree index:88) done accuracy:0.725 logloss:0.588186\n",
      "I0000 00:00:1729625151.269227 6802680 random_forest.cc:812] Training of tree  102/300 (tree index:103) done accuracy:0.716667 logloss:0.58213\n",
      "I0000 00:00:1729625151.269356 6802684 random_forest.cc:812] Training of tree  112/300 (tree index:111) done accuracy:0.708333 logloss:0.585028\n",
      "I0000 00:00:1729625151.269500 6802681 random_forest.cc:812] Training of tree  122/300 (tree index:123) done accuracy:0.7 logloss:0.586571\n",
      "I0000 00:00:1729625151.269641 6802685 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.733333 logloss:0.584176\n",
      "I0000 00:00:1729625151.269789 6802683 random_forest.cc:812] Training of tree  142/300 (tree index:142) done accuracy:0.716667 logloss:0.585732\n",
      "I0000 00:00:1729625151.269983 6802686 random_forest.cc:812] Training of tree  152/300 (tree index:151) done accuracy:0.725 logloss:0.583051\n",
      "I0000 00:00:1729625151.270165 6802686 random_forest.cc:812] Training of tree  162/300 (tree index:162) done accuracy:0.725 logloss:0.578746\n",
      "I0000 00:00:1729625151.270330 6802682 random_forest.cc:812] Training of tree  173/300 (tree index:160) done accuracy:0.725 logloss:0.57674\n",
      "I0000 00:00:1729625151.270511 6802684 random_forest.cc:812] Training of tree  183/300 (tree index:183) done accuracy:0.716667 logloss:0.571424\n",
      "I0000 00:00:1729625151.270647 6802681 random_forest.cc:812] Training of tree  193/300 (tree index:193) done accuracy:0.708333 logloss:0.570101\n",
      "I0000 00:00:1729625151.270814 6802686 random_forest.cc:812] Training of tree  203/300 (tree index:203) done accuracy:0.708333 logloss:0.568682\n",
      "I0000 00:00:1729625151.270965 6802684 random_forest.cc:812] Training of tree  213/300 (tree index:213) done accuracy:0.7 logloss:0.565943\n",
      "I0000 00:00:1729625151.271131 6802687 random_forest.cc:812] Training of tree  224/300 (tree index:223) done accuracy:0.708333 logloss:0.564167\n",
      "I0000 00:00:1729625151.271272 6802682 random_forest.cc:812] Training of tree  234/300 (tree index:233) done accuracy:0.725 logloss:0.567679\n",
      "I0000 00:00:1729625151.271422 6802681 random_forest.cc:812] Training of tree  244/300 (tree index:244) done accuracy:0.716667 logloss:0.566102\n",
      "I0000 00:00:1729625151.271561 6802687 random_forest.cc:812] Training of tree  254/300 (tree index:253) done accuracy:0.716667 logloss:0.563251\n",
      "I0000 00:00:1729625151.271711 6802682 random_forest.cc:812] Training of tree  264/300 (tree index:263) done accuracy:0.725 logloss:0.564517\n",
      "I0000 00:00:1729625151.271880 6802682 random_forest.cc:812] Training of tree  274/300 (tree index:273) done accuracy:0.716667 logloss:0.563589\n",
      "I0000 00:00:1729625151.272026 6802687 random_forest.cc:812] Training of tree  284/300 (tree index:281) done accuracy:0.716667 logloss:0.563098\n",
      "I0000 00:00:1729625151.272210 6802683 random_forest.cc:812] Training of tree  294/300 (tree index:295) done accuracy:0.725 logloss:0.562061\n",
      "I0000 00:00:1729625151.272294 6802680 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.725 logloss:0.562004\n",
      "I0000 00:00:1729625151.272373 6802671 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.562004\n",
      "I0000 00:00:1729625151.272851 6802671 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvn1433fs with prefix a030d65f24664e29\n",
      "I0000 00:00:1729625151.275110 6802671 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625151.275786 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.562004\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  17\n",
      "2  16  50\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:51.282478: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvn1433fs/model/ with prefix a030d65f24664e29\n",
      "I0000 00:00:1729625151.288519 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4626 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:51.288536: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146256. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023235\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpavttvbzg as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625151.567693 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625151.567709 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625151.567714 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625151.567782 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625151.567788 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625151.567832 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.567842 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.567847 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.567852 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.567880 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625151.567899 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625151.568038 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625151.568059 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp86gya92n/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625151.568117 6802743 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625151.568203 6802743 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625151.568740 6802756 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.674419 logloss:11.7351\n",
      "I0000 00:00:1729625151.568909 6802758 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.706897 logloss:3.48212\n",
      "I0000 00:00:1729625151.569147 6802753 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.75 logloss:0.777457\n",
      "I0000 00:00:1729625151.569292 6802755 random_forest.cc:812] Training of tree  31/300 (tree index:32) done accuracy:0.758333 logloss:0.770449\n",
      "I0000 00:00:1729625151.569435 6802758 random_forest.cc:812] Training of tree  41/300 (tree index:42) done accuracy:0.733333 logloss:0.779624\n",
      "I0000 00:00:1729625151.569599 6802755 random_forest.cc:812] Training of tree  52/300 (tree index:50) done accuracy:0.758333 logloss:0.507608\n",
      "I0000 00:00:1729625151.569774 6802759 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.75 logloss:0.495727\n",
      "I0000 00:00:1729625151.569917 6802752 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.758333 logloss:0.488119\n",
      "I0000 00:00:1729625151.570066 6802754 random_forest.cc:812] Training of tree  82/300 (tree index:81) done accuracy:0.775 logloss:0.489225\n",
      "I0000 00:00:1729625151.570209 6802759 random_forest.cc:812] Training of tree  92/300 (tree index:92) done accuracy:0.775 logloss:0.479269\n",
      "I0000 00:00:1729625151.570337 6802753 random_forest.cc:812] Training of tree  102/300 (tree index:102) done accuracy:0.8 logloss:0.474019\n",
      "I0000 00:00:1729625151.570492 6802756 random_forest.cc:812] Training of tree  112/300 (tree index:113) done accuracy:0.8 logloss:0.469051\n",
      "I0000 00:00:1729625151.570634 6802759 random_forest.cc:812] Training of tree  122/300 (tree index:123) done accuracy:0.791667 logloss:0.470533\n",
      "I0000 00:00:1729625151.570807 6802758 random_forest.cc:812] Training of tree  133/300 (tree index:133) done accuracy:0.791667 logloss:0.467489\n",
      "I0000 00:00:1729625151.571004 6802753 random_forest.cc:812] Training of tree  143/300 (tree index:143) done accuracy:0.791667 logloss:0.477403\n",
      "I0000 00:00:1729625151.571162 6802756 random_forest.cc:812] Training of tree  153/300 (tree index:152) done accuracy:0.791667 logloss:0.479561\n",
      "I0000 00:00:1729625151.571314 6802755 random_forest.cc:812] Training of tree  163/300 (tree index:163) done accuracy:0.791667 logloss:0.475343\n",
      "I0000 00:00:1729625151.571485 6802753 random_forest.cc:812] Training of tree  174/300 (tree index:171) done accuracy:0.8 logloss:0.478553\n",
      "I0000 00:00:1729625151.571666 6802754 random_forest.cc:812] Training of tree  184/300 (tree index:185) done accuracy:0.8 logloss:0.482235\n",
      "I0000 00:00:1729625151.571803 6802753 random_forest.cc:812] Training of tree  194/300 (tree index:193) done accuracy:0.8 logloss:0.479638\n",
      "I0000 00:00:1729625151.571928 6802754 random_forest.cc:812] Training of tree  204/300 (tree index:204) done accuracy:0.791667 logloss:0.478997\n",
      "I0000 00:00:1729625151.572088 6802753 random_forest.cc:812] Training of tree  214/300 (tree index:214) done accuracy:0.791667 logloss:0.475417\n",
      "I0000 00:00:1729625151.572229 6802757 random_forest.cc:812] Training of tree  224/300 (tree index:225) done accuracy:0.791667 logloss:0.477665\n",
      "I0000 00:00:1729625151.572349 6802756 random_forest.cc:812] Training of tree  234/300 (tree index:234) done accuracy:0.8 logloss:0.4792\n",
      "I0000 00:00:1729625151.572533 6802754 random_forest.cc:812] Training of tree  244/300 (tree index:232) done accuracy:0.808333 logloss:0.479785\n",
      "I0000 00:00:1729625151.572638 6802757 random_forest.cc:812] Training of tree  254/300 (tree index:253) done accuracy:0.8 logloss:0.480682\n",
      "I0000 00:00:1729625151.572832 6802758 random_forest.cc:812] Training of tree  264/300 (tree index:263) done accuracy:0.8 logloss:0.479237\n",
      "I0000 00:00:1729625151.573036 6802754 random_forest.cc:812] Training of tree  274/300 (tree index:270) done accuracy:0.8 logloss:0.481309\n",
      "I0000 00:00:1729625151.573226 6802754 random_forest.cc:812] Training of tree  284/300 (tree index:286) done accuracy:0.8 logloss:0.48092\n",
      "I0000 00:00:1729625151.573417 6802759 random_forest.cc:812] Training of tree  294/300 (tree index:295) done accuracy:0.8 logloss:0.481734\n",
      "I0000 00:00:1729625151.573517 6802756 random_forest.cc:812] Training of tree  300/300 (tree index:296) done accuracy:0.8 logloss:0.480404\n",
      "I0000 00:00:1729625151.573674 6802743 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.480404\n",
      "I0000 00:00:1729625151.574144 6802743 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp86gya92n with prefix 5672635bc28b42bf\n",
      "I0000 00:00:1729625151.576559 6802743 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625151.577164 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.480404\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  42  14\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:51.582865: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp86gya92n/model/ with prefix 5672635bc28b42bf\n",
      "I0000 00:00:1729625151.588515 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4352 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:51.588543: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144870. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023667\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': -1, 'min_examples': 10, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5uymg1t3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625151.865544 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625151.865554 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625151.865558 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625151.865621 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625151.865630 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625151.865671 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.865680 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.865685 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.865690 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625151.865717 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625151.865734 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625151.865865 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625151.865891 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpavttvbzg/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625151.865934 6802811 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625151.866088 6802811 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625151.866714 6802825 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.744186 logloss:9.22047\n",
      "I0000 00:00:1729625151.866837 6802824 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.762712 logloss:2.76967\n",
      "I0000 00:00:1729625151.867027 6802823 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.741667 logloss:1.06649\n",
      "I0000 00:00:1729625151.867166 6802824 random_forest.cc:812] Training of tree  31/300 (tree index:31) done accuracy:0.741667 logloss:0.788357\n",
      "I0000 00:00:1729625151.867326 6802822 random_forest.cc:812] Training of tree  42/300 (tree index:42) done accuracy:0.75 logloss:0.782031\n",
      "I0000 00:00:1729625151.867512 6802823 random_forest.cc:812] Training of tree  52/300 (tree index:50) done accuracy:0.766667 logloss:0.480964\n",
      "I0000 00:00:1729625151.867743 6802820 random_forest.cc:812] Training of tree  62/300 (tree index:63) done accuracy:0.783333 logloss:0.485564\n",
      "I0000 00:00:1729625151.867892 6802823 random_forest.cc:812] Training of tree  72/300 (tree index:73) done accuracy:0.766667 logloss:0.489283\n",
      "I0000 00:00:1729625151.868054 6802823 random_forest.cc:812] Training of tree  82/300 (tree index:84) done accuracy:0.775 logloss:0.49136\n",
      "I0000 00:00:1729625151.868196 6802825 random_forest.cc:812] Training of tree  92/300 (tree index:91) done accuracy:0.766667 logloss:0.486999\n",
      "I0000 00:00:1729625151.868373 6802825 random_forest.cc:812] Training of tree  102/300 (tree index:102) done accuracy:0.775 logloss:0.491955\n",
      "I0000 00:00:1729625151.868518 6802826 random_forest.cc:812] Training of tree  112/300 (tree index:111) done accuracy:0.758333 logloss:0.495092\n",
      "I0000 00:00:1729625151.868660 6802822 random_forest.cc:812] Training of tree  122/300 (tree index:122) done accuracy:0.758333 logloss:0.491126\n",
      "I0000 00:00:1729625151.868790 6802825 random_forest.cc:812] Training of tree  132/300 (tree index:134) done accuracy:0.758333 logloss:0.489861\n",
      "I0000 00:00:1729625151.868965 6802822 random_forest.cc:812] Training of tree  142/300 (tree index:143) done accuracy:0.75 logloss:0.495804\n",
      "I0000 00:00:1729625151.869101 6802820 random_forest.cc:812] Training of tree  152/300 (tree index:152) done accuracy:0.75 logloss:0.497327\n",
      "I0000 00:00:1729625151.869260 6802825 random_forest.cc:812] Training of tree  162/300 (tree index:163) done accuracy:0.758333 logloss:0.500691\n",
      "I0000 00:00:1729625151.869416 6802826 random_forest.cc:812] Training of tree  175/300 (tree index:174) done accuracy:0.75 logloss:0.501218\n",
      "I0000 00:00:1729625151.869641 6802820 random_forest.cc:812] Training of tree  185/300 (tree index:184) done accuracy:0.75 logloss:0.497904\n",
      "I0000 00:00:1729625151.869835 6802827 random_forest.cc:812] Training of tree  195/300 (tree index:186) done accuracy:0.758333 logloss:0.49522\n",
      "I0000 00:00:1729625151.869955 6802825 random_forest.cc:812] Training of tree  205/300 (tree index:205) done accuracy:0.758333 logloss:0.491541\n",
      "I0000 00:00:1729625151.870117 6802827 random_forest.cc:812] Training of tree  215/300 (tree index:214) done accuracy:0.75 logloss:0.487444\n",
      "I0000 00:00:1729625151.870311 6802825 random_forest.cc:812] Training of tree  226/300 (tree index:227) done accuracy:0.75 logloss:0.487164\n",
      "I0000 00:00:1729625151.870471 6802821 random_forest.cc:812] Training of tree  236/300 (tree index:237) done accuracy:0.741667 logloss:0.490868\n",
      "I0000 00:00:1729625151.870643 6802824 random_forest.cc:812] Training of tree  246/300 (tree index:248) done accuracy:0.75 logloss:0.490816\n",
      "I0000 00:00:1729625151.870784 6802822 random_forest.cc:812] Training of tree  256/300 (tree index:255) done accuracy:0.75 logloss:0.491991\n",
      "I0000 00:00:1729625151.871012 6802825 random_forest.cc:812] Training of tree  266/300 (tree index:268) done accuracy:0.741667 logloss:0.491116\n",
      "I0000 00:00:1729625151.871191 6802822 random_forest.cc:812] Training of tree  276/300 (tree index:274) done accuracy:0.758333 logloss:0.490577\n",
      "I0000 00:00:1729625151.871378 6802824 random_forest.cc:812] Training of tree  286/300 (tree index:286) done accuracy:0.758333 logloss:0.490964\n",
      "I0000 00:00:1729625151.871589 6802825 random_forest.cc:812] Training of tree  296/300 (tree index:294) done accuracy:0.758333 logloss:0.489194\n",
      "I0000 00:00:1729625151.871609 6802827 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.758333 logloss:0.489597\n",
      "I0000 00:00:1729625151.871733 6802811 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.489597\n",
      "I0000 00:00:1729625151.872203 6802811 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpavttvbzg with prefix 74ee933b4ec541e7\n",
      "I0000 00:00:1729625151.874774 6802811 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625151.875329 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.489597\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  16\n",
      "2  13  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:51.880832: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpavttvbzg/model/ with prefix 74ee933b4ec541e7\n",
      "I0000 00:00:1729625151.886729 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 4508 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:51.886747: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143995. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022654\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps112s2s3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625152.162088 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625152.162100 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625152.162108 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625152.162180 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625152.162185 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625152.162231 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.162240 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.162245 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.162250 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.162279 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625152.162296 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625152.162452 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625152.162479 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5uymg1t3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625152.162547 6802878 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625152.162639 6802878 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625152.163172 6802894 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.55102 logloss:16.1829\n",
      "I0000 00:00:1729625152.163351 6802894 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.720339 logloss:3.12225\n",
      "I0000 00:00:1729625152.163563 6802892 random_forest.cc:812] Training of tree  22/300 (tree index:20) done accuracy:0.758333 logloss:1.37721\n",
      "I0000 00:00:1729625152.163794 6802890 random_forest.cc:812] Training of tree  32/300 (tree index:35) done accuracy:0.758333 logloss:0.832075\n",
      "I0000 00:00:1729625152.163939 6802888 random_forest.cc:812] Training of tree  42/300 (tree index:40) done accuracy:0.758333 logloss:0.842704\n",
      "I0000 00:00:1729625152.164090 6802890 random_forest.cc:812] Training of tree  54/300 (tree index:55) done accuracy:0.758333 logloss:0.552951\n",
      "I0000 00:00:1729625152.164255 6802888 random_forest.cc:812] Training of tree  64/300 (tree index:63) done accuracy:0.725 logloss:0.546539\n",
      "I0000 00:00:1729625152.164425 6802891 random_forest.cc:812] Training of tree  75/300 (tree index:72) done accuracy:0.675 logloss:0.554959\n",
      "I0000 00:00:1729625152.164606 6802888 random_forest.cc:812] Training of tree  85/300 (tree index:86) done accuracy:0.7 logloss:0.547197\n",
      "I0000 00:00:1729625152.164718 6802893 random_forest.cc:812] Training of tree  95/300 (tree index:93) done accuracy:0.7 logloss:0.549978\n",
      "I0000 00:00:1729625152.164960 6802892 random_forest.cc:812] Training of tree  105/300 (tree index:104) done accuracy:0.708333 logloss:0.556863\n",
      "I0000 00:00:1729625152.165113 6802889 random_forest.cc:812] Training of tree  115/300 (tree index:115) done accuracy:0.725 logloss:0.556312\n",
      "I0000 00:00:1729625152.165243 6802891 random_forest.cc:812] Training of tree  125/300 (tree index:124) done accuracy:0.716667 logloss:0.555896\n",
      "I0000 00:00:1729625152.165371 6802889 random_forest.cc:812] Training of tree  135/300 (tree index:134) done accuracy:0.7 logloss:0.548975\n",
      "I0000 00:00:1729625152.165489 6802892 random_forest.cc:812] Training of tree  145/300 (tree index:144) done accuracy:0.716667 logloss:0.552583\n",
      "I0000 00:00:1729625152.165631 6802887 random_forest.cc:812] Training of tree  156/300 (tree index:156) done accuracy:0.7 logloss:0.550214\n",
      "I0000 00:00:1729625152.165762 6802888 random_forest.cc:812] Training of tree  166/300 (tree index:165) done accuracy:0.708333 logloss:0.554406\n",
      "I0000 00:00:1729625152.165903 6802892 random_forest.cc:812] Training of tree  177/300 (tree index:174) done accuracy:0.708333 logloss:0.548388\n",
      "I0000 00:00:1729625152.166029 6802887 random_forest.cc:812] Training of tree  187/300 (tree index:178) done accuracy:0.691667 logloss:0.54747\n",
      "I0000 00:00:1729625152.166208 6802888 random_forest.cc:812] Training of tree  197/300 (tree index:197) done accuracy:0.708333 logloss:0.543769\n",
      "I0000 00:00:1729625152.166392 6802890 random_forest.cc:812] Training of tree  207/300 (tree index:207) done accuracy:0.691667 logloss:0.549188\n",
      "I0000 00:00:1729625152.166541 6802887 random_forest.cc:812] Training of tree  218/300 (tree index:217) done accuracy:0.708333 logloss:0.549361\n",
      "I0000 00:00:1729625152.166682 6802887 random_forest.cc:812] Training of tree  229/300 (tree index:230) done accuracy:0.7 logloss:0.547213\n",
      "I0000 00:00:1729625152.166851 6802889 random_forest.cc:812] Training of tree  239/300 (tree index:238) done accuracy:0.716667 logloss:0.545989\n",
      "I0000 00:00:1729625152.166997 6802892 random_forest.cc:812] Training of tree  249/300 (tree index:249) done accuracy:0.691667 logloss:0.548767\n",
      "I0000 00:00:1729625152.167124 6802888 random_forest.cc:812] Training of tree  259/300 (tree index:258) done accuracy:0.716667 logloss:0.547575\n",
      "I0000 00:00:1729625152.167251 6802890 random_forest.cc:812] Training of tree  269/300 (tree index:268) done accuracy:0.708333 logloss:0.547209\n",
      "I0000 00:00:1729625152.167366 6802889 random_forest.cc:812] Training of tree  279/300 (tree index:278) done accuracy:0.716667 logloss:0.54941\n",
      "I0000 00:00:1729625152.167503 6802894 random_forest.cc:812] Training of tree  289/300 (tree index:289) done accuracy:0.716667 logloss:0.545754\n",
      "I0000 00:00:1729625152.167645 6802893 random_forest.cc:812] Training of tree  299/300 (tree index:298) done accuracy:0.725 logloss:0.543364\n",
      "I0000 00:00:1729625152.167668 6802890 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.725 logloss:0.54404\n",
      "I0000 00:00:1729625152.167784 6802878 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.54404\n",
      "I0000 00:00:1729625152.168236 6802878 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5uymg1t3 with prefix e3eed2c3e2e54fef\n",
      "I0000 00:00:1729625152.170852 6802878 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625152.171456 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.54404\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  16  46\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:52.177356: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp5uymg1t3/model/ with prefix e3eed2c3e2e54fef\n",
      "I0000 00:00:1729625152.182424 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3792 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:52.182452: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146993. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.023194\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2wfi03z3 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625152.461418 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625152.461436 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625152.461440 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625152.461526 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625152.461542 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625152.461592 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.461601 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.461607 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.461612 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.461640 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625152.461657 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625152.461787 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625152.461814 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps112s2s3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625152.461862 6802946 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625152.461953 6802946 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625152.462609 6802958 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.792453 logloss:7.48076\n",
      "I0000 00:00:1729625152.462730 6802961 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.714286 logloss:2.82398\n",
      "I0000 00:00:1729625152.462904 6802955 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.725 logloss:1.15018\n",
      "I0000 00:00:1729625152.463037 6802956 random_forest.cc:812] Training of tree  32/300 (tree index:18) done accuracy:0.725 logloss:0.866194\n",
      "I0000 00:00:1729625152.463176 6802962 random_forest.cc:812] Training of tree  42/300 (tree index:43) done accuracy:0.725 logloss:0.58345\n",
      "I0000 00:00:1729625152.463276 6802956 random_forest.cc:812] Training of tree  52/300 (tree index:51) done accuracy:0.725 logloss:0.58268\n",
      "I0000 00:00:1729625152.463460 6802955 random_forest.cc:812] Training of tree  62/300 (tree index:64) done accuracy:0.716667 logloss:0.566621\n",
      "I0000 00:00:1729625152.463607 6802956 random_forest.cc:812] Training of tree  74/300 (tree index:68) done accuracy:0.741667 logloss:0.572263\n",
      "I0000 00:00:1729625152.463814 6802959 random_forest.cc:812] Training of tree  84/300 (tree index:84) done accuracy:0.733333 logloss:0.569579\n",
      "I0000 00:00:1729625152.463956 6802958 random_forest.cc:812] Training of tree  95/300 (tree index:94) done accuracy:0.75 logloss:0.563142\n",
      "I0000 00:00:1729625152.464173 6802962 random_forest.cc:812] Training of tree  106/300 (tree index:105) done accuracy:0.75 logloss:0.560404\n",
      "I0000 00:00:1729625152.464328 6802956 random_forest.cc:812] Training of tree  116/300 (tree index:117) done accuracy:0.758333 logloss:0.554041\n",
      "I0000 00:00:1729625152.464459 6802957 random_forest.cc:812] Training of tree  126/300 (tree index:115) done accuracy:0.766667 logloss:0.55961\n",
      "I0000 00:00:1729625152.464591 6802961 random_forest.cc:812] Training of tree  136/300 (tree index:135) done accuracy:0.775 logloss:0.563536\n",
      "I0000 00:00:1729625152.464752 6802959 random_forest.cc:812] Training of tree  146/300 (tree index:149) done accuracy:0.783333 logloss:0.559536\n",
      "I0000 00:00:1729625152.464850 6802958 random_forest.cc:812] Training of tree  156/300 (tree index:146) done accuracy:0.775 logloss:0.562857\n",
      "I0000 00:00:1729625152.465053 6802955 random_forest.cc:812] Training of tree  166/300 (tree index:163) done accuracy:0.766667 logloss:0.563892\n",
      "I0000 00:00:1729625152.465166 6802956 random_forest.cc:812] Training of tree  176/300 (tree index:176) done accuracy:0.775 logloss:0.56493\n",
      "I0000 00:00:1729625152.465328 6802960 random_forest.cc:812] Training of tree  186/300 (tree index:185) done accuracy:0.775 logloss:0.560135\n",
      "I0000 00:00:1729625152.465521 6802959 random_forest.cc:812] Training of tree  197/300 (tree index:196) done accuracy:0.783333 logloss:0.557332\n",
      "I0000 00:00:1729625152.465675 6802962 random_forest.cc:812] Training of tree  207/300 (tree index:206) done accuracy:0.791667 logloss:0.561646\n",
      "I0000 00:00:1729625152.465809 6802958 random_forest.cc:812] Training of tree  217/300 (tree index:218) done accuracy:0.775 logloss:0.561226\n",
      "I0000 00:00:1729625152.465926 6802960 random_forest.cc:812] Training of tree  227/300 (tree index:228) done accuracy:0.766667 logloss:0.560708\n",
      "I0000 00:00:1729625152.466058 6802957 random_forest.cc:812] Training of tree  237/300 (tree index:237) done accuracy:0.766667 logloss:0.558188\n",
      "I0000 00:00:1729625152.466229 6802960 random_forest.cc:812] Training of tree  248/300 (tree index:249) done accuracy:0.775 logloss:0.557617\n",
      "I0000 00:00:1729625152.466377 6802959 random_forest.cc:812] Training of tree  258/300 (tree index:257) done accuracy:0.783333 logloss:0.55416\n",
      "I0000 00:00:1729625152.466565 6802959 random_forest.cc:812] Training of tree  268/300 (tree index:269) done accuracy:0.791667 logloss:0.552139\n",
      "I0000 00:00:1729625152.466795 6802959 random_forest.cc:812] Training of tree  281/300 (tree index:280) done accuracy:0.8 logloss:0.55124\n",
      "I0000 00:00:1729625152.466993 6802961 random_forest.cc:812] Training of tree  291/300 (tree index:291) done accuracy:0.775 logloss:0.55227\n",
      "I0000 00:00:1729625152.467152 6802958 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.791667 logloss:0.55055\n",
      "I0000 00:00:1729625152.467216 6802946 random_forest.cc:892] Final OOB metrics: accuracy:0.791667 logloss:0.55055\n",
      "I0000 00:00:1729625152.467653 6802946 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps112s2s3 with prefix 58eceb80578045af\n",
      "I0000 00:00:1729625152.470215 6802946 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625152.471383 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.791667  CI95[W][0.72135 0.850825]\n",
      "LogLoss: : 0.55055\n",
      "ErrorRate: : 0.208333\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  40  13\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:52.477484: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmps112s2s3/model/ with prefix 58eceb80578045af\n",
      "I0000 00:00:1729625152.482419 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3804 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:52.482453: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143735. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.022407\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgie342tt as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625152.799540 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625152.799550 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625152.799556 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625152.799624 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625152.799634 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625152.799679 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.799689 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.799694 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.799699 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625152.799747 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625152.799769 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625152.799905 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625152.799931 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2wfi03z3/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625152.799979 6803020 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625152.800078 6803020 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625152.800620 6803034 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625152.800759 6803032 random_forest.cc:812] Training of tree  11/300 (tree index:7) done accuracy:0.683333 logloss:2.31274\n",
      "I0000 00:00:1729625152.800897 6803029 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.633333 logloss:1.21026\n",
      "I0000 00:00:1729625152.800999 6803034 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.65 logloss:0.905716\n",
      "I0000 00:00:1729625152.801165 6803034 random_forest.cc:812] Training of tree  41/300 (tree index:41) done accuracy:0.691667 logloss:0.583742\n",
      "I0000 00:00:1729625152.801337 6803030 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.716667 logloss:0.591352\n",
      "I0000 00:00:1729625152.801532 6803034 random_forest.cc:812] Training of tree  61/300 (tree index:61) done accuracy:0.708333 logloss:0.583709\n",
      "I0000 00:00:1729625152.801694 6803034 random_forest.cc:812] Training of tree  71/300 (tree index:68) done accuracy:0.7 logloss:0.583314\n",
      "I0000 00:00:1729625152.801817 6803030 random_forest.cc:812] Training of tree  81/300 (tree index:81) done accuracy:0.691667 logloss:0.573379\n",
      "I0000 00:00:1729625152.801963 6803032 random_forest.cc:812] Training of tree  91/300 (tree index:83) done accuracy:0.7 logloss:0.564537\n",
      "I0000 00:00:1729625152.802110 6803033 random_forest.cc:812] Training of tree  101/300 (tree index:102) done accuracy:0.683333 logloss:0.561225\n",
      "I0000 00:00:1729625152.802239 6803036 random_forest.cc:812] Training of tree  111/300 (tree index:100) done accuracy:0.691667 logloss:0.561185\n",
      "I0000 00:00:1729625152.802363 6803032 random_forest.cc:812] Training of tree  121/300 (tree index:121) done accuracy:0.7 logloss:0.557938\n",
      "I0000 00:00:1729625152.802481 6803034 random_forest.cc:812] Training of tree  131/300 (tree index:130) done accuracy:0.691667 logloss:0.553154\n",
      "I0000 00:00:1729625152.802660 6803029 random_forest.cc:812] Training of tree  141/300 (tree index:136) done accuracy:0.708333 logloss:0.549305\n",
      "I0000 00:00:1729625152.802829 6803032 random_forest.cc:812] Training of tree  151/300 (tree index:149) done accuracy:0.691667 logloss:0.553932\n",
      "I0000 00:00:1729625152.802961 6803031 random_forest.cc:812] Training of tree  161/300 (tree index:160) done accuracy:0.708333 logloss:0.554829\n",
      "I0000 00:00:1729625152.803142 6803035 random_forest.cc:812] Training of tree  172/300 (tree index:171) done accuracy:0.716667 logloss:0.559926\n",
      "I0000 00:00:1729625152.803290 6803036 random_forest.cc:812] Training of tree  182/300 (tree index:181) done accuracy:0.725 logloss:0.564459\n",
      "I0000 00:00:1729625152.803486 6803032 random_forest.cc:812] Training of tree  192/300 (tree index:193) done accuracy:0.741667 logloss:0.567347\n",
      "I0000 00:00:1729625152.803612 6803035 random_forest.cc:812] Training of tree  202/300 (tree index:202) done accuracy:0.741667 logloss:0.568579\n",
      "I0000 00:00:1729625152.803793 6803033 random_forest.cc:812] Training of tree  212/300 (tree index:214) done accuracy:0.733333 logloss:0.563553\n",
      "I0000 00:00:1729625152.803957 6803034 random_forest.cc:812] Training of tree  223/300 (tree index:222) done accuracy:0.725 logloss:0.562095\n",
      "I0000 00:00:1729625152.804125 6803034 random_forest.cc:812] Training of tree  235/300 (tree index:235) done accuracy:0.741667 logloss:0.560515\n",
      "I0000 00:00:1729625152.804329 6803033 random_forest.cc:812] Training of tree  245/300 (tree index:244) done accuracy:0.758333 logloss:0.560406\n",
      "I0000 00:00:1729625152.804485 6803030 random_forest.cc:812] Training of tree  255/300 (tree index:248) done accuracy:0.741667 logloss:0.559263\n",
      "I0000 00:00:1729625152.804659 6803030 random_forest.cc:812] Training of tree  268/300 (tree index:268) done accuracy:0.741667 logloss:0.558619\n",
      "I0000 00:00:1729625152.804902 6803033 random_forest.cc:812] Training of tree  282/300 (tree index:281) done accuracy:0.741667 logloss:0.559408\n",
      "I0000 00:00:1729625152.805096 6803035 random_forest.cc:812] Training of tree  292/300 (tree index:292) done accuracy:0.741667 logloss:0.560714\n",
      "I0000 00:00:1729625152.805264 6803029 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.75 logloss:0.558914\n",
      "I0000 00:00:1729625152.805424 6803020 random_forest.cc:892] Final OOB metrics: accuracy:0.75 logloss:0.558914\n",
      "I0000 00:00:1729625152.805862 6803020 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2wfi03z3 with prefix 5f58c1ae3fdf427a\n",
      "I0000 00:00:1729625152.808370 6803020 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625152.809178 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0.676537 0.813944]\n",
      "LogLoss: : 0.558914\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  18\n",
      "2  12  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:52.814783: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp2wfi03z3/model/ with prefix 5f58c1ae3fdf427a\n",
      "I0000 00:00:1729625152.819775 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3854 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:52.819796: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146040. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021678\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_9gw86s6 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625153.097366 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625153.097375 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625153.097382 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625153.097448 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625153.097453 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625153.097499 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.097508 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.097515 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.097520 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.097548 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625153.097569 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625153.097712 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625153.097734 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgie342tt/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625153.097791 6803091 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625153.097884 6803091 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625153.098379 6803107 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.632653 logloss:13.2405\n",
      "I0000 00:00:1729625153.098569 6803106 random_forest.cc:812] Training of tree  14/300 (tree index:13) done accuracy:0.680672 logloss:2.28381\n",
      "I0000 00:00:1729625153.098733 6803105 random_forest.cc:812] Training of tree  24/300 (tree index:23) done accuracy:0.708333 logloss:1.10068\n",
      "I0000 00:00:1729625153.098876 6803103 random_forest.cc:812] Training of tree  34/300 (tree index:35) done accuracy:0.75 logloss:0.798494\n",
      "I0000 00:00:1729625153.099026 6803102 random_forest.cc:812] Training of tree  45/300 (tree index:25) done accuracy:0.758333 logloss:0.522598\n",
      "I0000 00:00:1729625153.099188 6803104 random_forest.cc:812] Training of tree  55/300 (tree index:54) done accuracy:0.75 logloss:0.518075\n",
      "I0000 00:00:1729625153.099336 6803101 random_forest.cc:812] Training of tree  65/300 (tree index:65) done accuracy:0.75 logloss:0.516355\n",
      "I0000 00:00:1729625153.099469 6803106 random_forest.cc:812] Training of tree  75/300 (tree index:67) done accuracy:0.775 logloss:0.520947\n",
      "I0000 00:00:1729625153.099634 6803106 random_forest.cc:812] Training of tree  85/300 (tree index:85) done accuracy:0.733333 logloss:0.518039\n",
      "I0000 00:00:1729625153.099811 6803104 random_forest.cc:812] Training of tree  95/300 (tree index:87) done accuracy:0.758333 logloss:0.511269\n",
      "I0000 00:00:1729625153.099967 6803102 random_forest.cc:812] Training of tree  106/300 (tree index:108) done accuracy:0.775 logloss:0.511612\n",
      "I0000 00:00:1729625153.100111 6803102 random_forest.cc:812] Training of tree  116/300 (tree index:116) done accuracy:0.775 logloss:0.51263\n",
      "I0000 00:00:1729625153.100243 6803100 random_forest.cc:812] Training of tree  126/300 (tree index:127) done accuracy:0.775 logloss:0.506242\n",
      "I0000 00:00:1729625153.100446 6803100 random_forest.cc:812] Training of tree  138/300 (tree index:137) done accuracy:0.775 logloss:0.501765\n",
      "I0000 00:00:1729625153.100588 6803106 random_forest.cc:812] Training of tree  148/300 (tree index:145) done accuracy:0.775 logloss:0.498498\n",
      "I0000 00:00:1729625153.100794 6803103 random_forest.cc:812] Training of tree  159/300 (tree index:158) done accuracy:0.766667 logloss:0.496972\n",
      "I0000 00:00:1729625153.101005 6803107 random_forest.cc:812] Training of tree  171/300 (tree index:170) done accuracy:0.775 logloss:0.498621\n",
      "I0000 00:00:1729625153.101196 6803104 random_forest.cc:812] Training of tree  183/300 (tree index:182) done accuracy:0.775 logloss:0.50151\n",
      "I0000 00:00:1729625153.101407 6803100 random_forest.cc:812] Training of tree  194/300 (tree index:193) done accuracy:0.775 logloss:0.501296\n",
      "I0000 00:00:1729625153.101597 6803107 random_forest.cc:812] Training of tree  204/300 (tree index:205) done accuracy:0.783333 logloss:0.499516\n",
      "I0000 00:00:1729625153.101714 6803102 random_forest.cc:812] Training of tree  214/300 (tree index:215) done accuracy:0.766667 logloss:0.499612\n",
      "I0000 00:00:1729625153.101862 6803106 random_forest.cc:812] Training of tree  226/300 (tree index:225) done accuracy:0.766667 logloss:0.498783\n",
      "I0000 00:00:1729625153.102032 6803103 random_forest.cc:812] Training of tree  236/300 (tree index:237) done accuracy:0.775 logloss:0.49701\n",
      "I0000 00:00:1729625153.102157 6803100 random_forest.cc:812] Training of tree  246/300 (tree index:246) done accuracy:0.775 logloss:0.496374\n",
      "I0000 00:00:1729625153.102347 6803106 random_forest.cc:812] Training of tree  256/300 (tree index:256) done accuracy:0.775 logloss:0.495678\n",
      "I0000 00:00:1729625153.102561 6803100 random_forest.cc:812] Training of tree  266/300 (tree index:265) done accuracy:0.783333 logloss:0.495438\n",
      "I0000 00:00:1729625153.102721 6803101 random_forest.cc:812] Training of tree  278/300 (tree index:277) done accuracy:0.783333 logloss:0.49568\n",
      "I0000 00:00:1729625153.102926 6803100 random_forest.cc:812] Training of tree  291/300 (tree index:290) done accuracy:0.783333 logloss:0.493788\n",
      "I0000 00:00:1729625153.103094 6803105 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.775 logloss:0.496719\n",
      "I0000 00:00:1729625153.103172 6803091 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.496719\n",
      "I0000 00:00:1729625153.103594 6803091 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgie342tt with prefix 2dad5dc8f6064f58\n",
      "I0000 00:00:1729625153.105906 6803091 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625153.106537 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.496719\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  15\n",
      "2  12  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:53.112428: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgie342tt/model/ with prefix 2dad5dc8f6064f58\n",
      "I0000 00:00:1729625153.117157 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3648 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:53.117178: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.147652. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.021730\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': -1, 'min_examples': 20, 'bootstrap_size_ratio': 1.0}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo8i4aknz as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625153.397131 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625153.397141 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625153.397150 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625153.397217 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625153.397221 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625153.397264 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.397273 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.397278 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.397283 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.397311 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625153.397329 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625153.397476 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 10\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625153.397499 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_9gw86s6/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625153.397556 6803169 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625153.397645 6803169 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625153.398271 6803182 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.679245 logloss:11.5612\n",
      "I0000 00:00:1729625153.398415 6803185 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.783333 logloss:2.13031\n",
      "I0000 00:00:1729625153.398585 6803179 random_forest.cc:812] Training of tree  21/300 (tree index:16) done accuracy:0.766667 logloss:0.769817\n",
      "I0000 00:00:1729625153.398704 6803184 random_forest.cc:812] Training of tree  31/300 (tree index:29) done accuracy:0.741667 logloss:0.49272\n",
      "I0000 00:00:1729625153.398846 6803181 random_forest.cc:812] Training of tree  42/300 (tree index:41) done accuracy:0.75 logloss:0.520375\n",
      "I0000 00:00:1729625153.399005 6803183 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.766667 logloss:0.523061\n",
      "I0000 00:00:1729625153.399140 6803184 random_forest.cc:812] Training of tree  62/300 (tree index:63) done accuracy:0.766667 logloss:0.523101\n",
      "I0000 00:00:1729625153.399277 6803179 random_forest.cc:812] Training of tree  72/300 (tree index:72) done accuracy:0.741667 logloss:0.523191\n",
      "I0000 00:00:1729625153.399464 6803182 random_forest.cc:812] Training of tree  82/300 (tree index:84) done accuracy:0.766667 logloss:0.522956\n",
      "I0000 00:00:1729625153.399624 6803182 random_forest.cc:812] Training of tree  92/300 (tree index:93) done accuracy:0.775 logloss:0.51565\n",
      "I0000 00:00:1729625153.399760 6803179 random_forest.cc:812] Training of tree  102/300 (tree index:101) done accuracy:0.775 logloss:0.514153\n",
      "I0000 00:00:1729625153.399897 6803183 random_forest.cc:812] Training of tree  112/300 (tree index:110) done accuracy:0.775 logloss:0.516378\n",
      "I0000 00:00:1729625153.400045 6803180 random_forest.cc:812] Training of tree  123/300 (tree index:122) done accuracy:0.775 logloss:0.515257\n",
      "I0000 00:00:1729625153.400216 6803185 random_forest.cc:812] Training of tree  133/300 (tree index:127) done accuracy:0.766667 logloss:0.508812\n",
      "I0000 00:00:1729625153.400404 6803181 random_forest.cc:812] Training of tree  143/300 (tree index:144) done accuracy:0.775 logloss:0.513701\n",
      "I0000 00:00:1729625153.400567 6803179 random_forest.cc:812] Training of tree  156/300 (tree index:155) done accuracy:0.783333 logloss:0.514875\n",
      "I0000 00:00:1729625153.400785 6803185 random_forest.cc:812] Training of tree  166/300 (tree index:167) done accuracy:0.783333 logloss:0.511901\n",
      "I0000 00:00:1729625153.400911 6803184 random_forest.cc:812] Training of tree  176/300 (tree index:176) done accuracy:0.783333 logloss:0.513241\n",
      "I0000 00:00:1729625153.401059 6803182 random_forest.cc:812] Training of tree  186/300 (tree index:185) done accuracy:0.783333 logloss:0.513832\n",
      "I0000 00:00:1729625153.401200 6803179 random_forest.cc:812] Training of tree  196/300 (tree index:196) done accuracy:0.766667 logloss:0.515419\n",
      "I0000 00:00:1729625153.401349 6803181 random_forest.cc:812] Training of tree  206/300 (tree index:207) done accuracy:0.775 logloss:0.515585\n",
      "I0000 00:00:1729625153.401486 6803184 random_forest.cc:812] Training of tree  216/300 (tree index:214) done accuracy:0.775 logloss:0.516484\n",
      "I0000 00:00:1729625153.401634 6803182 random_forest.cc:812] Training of tree  226/300 (tree index:225) done accuracy:0.783333 logloss:0.516712\n",
      "I0000 00:00:1729625153.401777 6803183 random_forest.cc:812] Training of tree  237/300 (tree index:236) done accuracy:0.783333 logloss:0.512441\n",
      "I0000 00:00:1729625153.401956 6803180 random_forest.cc:812] Training of tree  247/300 (tree index:241) done accuracy:0.783333 logloss:0.512445\n",
      "I0000 00:00:1729625153.402112 6803183 random_forest.cc:812] Training of tree  257/300 (tree index:256) done accuracy:0.783333 logloss:0.513699\n",
      "I0000 00:00:1729625153.402278 6803184 random_forest.cc:812] Training of tree  267/300 (tree index:265) done accuracy:0.783333 logloss:0.518197\n",
      "I0000 00:00:1729625153.402428 6803179 random_forest.cc:812] Training of tree  277/300 (tree index:277) done accuracy:0.783333 logloss:0.518806\n",
      "I0000 00:00:1729625153.402547 6803180 random_forest.cc:812] Training of tree  287/300 (tree index:286) done accuracy:0.783333 logloss:0.516995\n",
      "I0000 00:00:1729625153.402682 6803178 random_forest.cc:812] Training of tree  297/300 (tree index:297) done accuracy:0.783333 logloss:0.516748\n",
      "I0000 00:00:1729625153.402753 6803181 random_forest.cc:812] Training of tree  300/300 (tree index:295) done accuracy:0.783333 logloss:0.516345\n",
      "I0000 00:00:1729625153.402835 6803169 random_forest.cc:892] Final OOB metrics: accuracy:0.783333 logloss:0.516345\n",
      "I0000 00:00:1729625153.403226 6803169 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_9gw86s6 with prefix 4e5f8907b2e04a71\n",
      "I0000 00:00:1729625153.405328 6803169 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625153.405945 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.783333  CI95[W][0.712318 0.843521]\n",
      "LogLoss: : 0.516345\n",
      "ErrorRate: : 0.216667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  14\n",
      "2  12  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:53.411687: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp_9gw86s6/model/ with prefix 4e5f8907b2e04a71\n",
      "I0000 00:00:1729625153.416542 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 3744 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:53.416561: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.187329. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017346\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgio0cfun as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625153.741093 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625153.741103 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625153.741107 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625153.741172 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625153.741178 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625153.741221 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.741231 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.741236 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.741242 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625153.741271 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625153.741289 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625153.741439 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625153.741471 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo8i4aknz/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625153.741515 6803239 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625153.741621 6803239 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625153.742238 6803248 random_forest.cc:812] Training of tree  1/300 (tree index:2) done accuracy:0.756098 logloss:8.79113\n",
      "I0000 00:00:1729625153.742389 6803248 random_forest.cc:812] Training of tree  14/300 (tree index:13) done accuracy:0.661017 logloss:4.3293\n",
      "I0000 00:00:1729625153.742553 6803248 random_forest.cc:812] Training of tree  24/300 (tree index:23) done accuracy:0.766667 logloss:2.24765\n",
      "I0000 00:00:1729625153.742693 6803255 random_forest.cc:812] Training of tree  34/300 (tree index:25) done accuracy:0.733333 logloss:1.40691\n",
      "I0000 00:00:1729625153.742816 6803253 random_forest.cc:812] Training of tree  44/300 (tree index:43) done accuracy:0.733333 logloss:1.41102\n",
      "I0000 00:00:1729625153.742955 6803252 random_forest.cc:812] Training of tree  56/300 (tree index:55) done accuracy:0.708333 logloss:1.13498\n",
      "I0000 00:00:1729625153.743107 6803251 random_forest.cc:812] Training of tree  66/300 (tree index:64) done accuracy:0.708333 logloss:0.834499\n",
      "I0000 00:00:1729625153.743248 6803254 random_forest.cc:812] Training of tree  76/300 (tree index:75) done accuracy:0.716667 logloss:0.844616\n",
      "I0000 00:00:1729625153.743386 6803248 random_forest.cc:812] Training of tree  86/300 (tree index:85) done accuracy:0.7 logloss:0.853633\n",
      "I0000 00:00:1729625153.743499 6803253 random_forest.cc:812] Training of tree  96/300 (tree index:97) done accuracy:0.7 logloss:0.582346\n",
      "I0000 00:00:1729625153.743634 6803252 random_forest.cc:812] Training of tree  106/300 (tree index:106) done accuracy:0.691667 logloss:0.585639\n",
      "I0000 00:00:1729625153.743759 6803254 random_forest.cc:812] Training of tree  116/300 (tree index:115) done accuracy:0.708333 logloss:0.589909\n",
      "I0000 00:00:1729625153.743873 6803255 random_forest.cc:812] Training of tree  126/300 (tree index:125) done accuracy:0.7 logloss:0.584956\n",
      "I0000 00:00:1729625153.743989 6803250 random_forest.cc:812] Training of tree  136/300 (tree index:134) done accuracy:0.7 logloss:0.584284\n",
      "I0000 00:00:1729625153.744104 6803252 random_forest.cc:812] Training of tree  146/300 (tree index:147) done accuracy:0.708333 logloss:0.581515\n",
      "I0000 00:00:1729625153.744208 6803253 random_forest.cc:812] Training of tree  156/300 (tree index:156) done accuracy:0.725 logloss:0.580883\n",
      "I0000 00:00:1729625153.744351 6803248 random_forest.cc:812] Training of tree  166/300 (tree index:167) done accuracy:0.725 logloss:0.578194\n",
      "I0000 00:00:1729625153.744470 6803254 random_forest.cc:812] Training of tree  176/300 (tree index:175) done accuracy:0.725 logloss:0.571147\n",
      "I0000 00:00:1729625153.744632 6803248 random_forest.cc:812] Training of tree  186/300 (tree index:186) done accuracy:0.725 logloss:0.569563\n",
      "I0000 00:00:1729625153.744736 6803255 random_forest.cc:812] Training of tree  196/300 (tree index:193) done accuracy:0.716667 logloss:0.570046\n",
      "I0000 00:00:1729625153.744861 6803249 random_forest.cc:812] Training of tree  206/300 (tree index:206) done accuracy:0.716667 logloss:0.572946\n",
      "I0000 00:00:1729625153.744998 6803249 random_forest.cc:812] Training of tree  216/300 (tree index:217) done accuracy:0.725 logloss:0.578262\n",
      "I0000 00:00:1729625153.745136 6803252 random_forest.cc:812] Training of tree  226/300 (tree index:227) done accuracy:0.733333 logloss:0.578582\n",
      "I0000 00:00:1729625153.745251 6803253 random_forest.cc:812] Training of tree  236/300 (tree index:237) done accuracy:0.716667 logloss:0.576429\n",
      "I0000 00:00:1729625153.745361 6803250 random_forest.cc:812] Training of tree  246/300 (tree index:246) done accuracy:0.733333 logloss:0.573584\n",
      "I0000 00:00:1729625153.745489 6803249 random_forest.cc:812] Training of tree  256/300 (tree index:255) done accuracy:0.741667 logloss:0.572462\n",
      "I0000 00:00:1729625153.745613 6803250 random_forest.cc:812] Training of tree  266/300 (tree index:265) done accuracy:0.725 logloss:0.575915\n",
      "I0000 00:00:1729625153.745775 6803249 random_forest.cc:812] Training of tree  276/300 (tree index:275) done accuracy:0.733333 logloss:0.575572\n",
      "I0000 00:00:1729625153.745900 6803252 random_forest.cc:812] Training of tree  286/300 (tree index:284) done accuracy:0.741667 logloss:0.5755\n",
      "I0000 00:00:1729625153.746066 6803249 random_forest.cc:812] Training of tree  299/300 (tree index:299) done accuracy:0.75 logloss:0.574927\n",
      "I0000 00:00:1729625153.746119 6803255 random_forest.cc:812] Training of tree  300/300 (tree index:294) done accuracy:0.741667 logloss:0.575682\n",
      "I0000 00:00:1729625153.746230 6803239 random_forest.cc:892] Final OOB metrics: accuracy:0.741667 logloss:0.575682\n",
      "I0000 00:00:1729625153.746503 6803239 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo8i4aknz with prefix 4b0bf8a0027a4249\n",
      "I0000 00:00:1729625153.748151 6803239 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625153.748755 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.741667  CI95[W][0.667671 0.806467]\n",
      "LogLoss: : 0.575682\n",
      "ErrorRate: : 0.258333\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  17\n",
      "2  14  48\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:53.753563: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpo8i4aknz/model/ with prefix 4b0bf8a0027a4249\n",
      "I0000 00:00:1729625153.756711 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2456 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:53.756726: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145682. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018734\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmprsie3s4b as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625154.033821 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625154.033831 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625154.033836 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625154.033897 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625154.033901 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625154.033946 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.033955 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.033961 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.033965 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.033992 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625154.034009 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625154.034144 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625154.034165 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgio0cfun/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625154.034221 6803310 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625154.034319 6803310 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625154.034917 6803326 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.767442 logloss:8.38224\n",
      "I0000 00:00:1729625154.035074 6803320 random_forest.cc:812] Training of tree  13/300 (tree index:13) done accuracy:0.644068 logloss:5.82293\n",
      "I0000 00:00:1729625154.035294 6803322 random_forest.cc:812] Training of tree  25/300 (tree index:23) done accuracy:0.675 logloss:1.75894\n",
      "I0000 00:00:1729625154.035462 6803324 random_forest.cc:812] Training of tree  36/300 (tree index:34) done accuracy:0.7 logloss:0.891485\n",
      "I0000 00:00:1729625154.035621 6803320 random_forest.cc:812] Training of tree  46/300 (tree index:46) done accuracy:0.708333 logloss:0.622943\n",
      "I0000 00:00:1729625154.035772 6803323 random_forest.cc:812] Training of tree  57/300 (tree index:55) done accuracy:0.7 logloss:0.621721\n",
      "I0000 00:00:1729625154.035911 6803322 random_forest.cc:812] Training of tree  68/300 (tree index:69) done accuracy:0.716667 logloss:0.619561\n",
      "I0000 00:00:1729625154.036065 6803321 random_forest.cc:812] Training of tree  79/300 (tree index:80) done accuracy:0.725 logloss:0.609093\n",
      "I0000 00:00:1729625154.036196 6803320 random_forest.cc:812] Training of tree  89/300 (tree index:90) done accuracy:0.741667 logloss:0.603235\n",
      "I0000 00:00:1729625154.036338 6803319 random_forest.cc:812] Training of tree  99/300 (tree index:100) done accuracy:0.741667 logloss:0.591298\n",
      "I0000 00:00:1729625154.036472 6803325 random_forest.cc:812] Training of tree  109/300 (tree index:108) done accuracy:0.725 logloss:0.59367\n",
      "I0000 00:00:1729625154.036615 6803324 random_forest.cc:812] Training of tree  119/300 (tree index:120) done accuracy:0.733333 logloss:0.593086\n",
      "I0000 00:00:1729625154.036722 6803322 random_forest.cc:812] Training of tree  129/300 (tree index:128) done accuracy:0.741667 logloss:0.590008\n",
      "I0000 00:00:1729625154.036878 6803325 random_forest.cc:812] Training of tree  139/300 (tree index:140) done accuracy:0.75 logloss:0.596868\n",
      "I0000 00:00:1729625154.037016 6803323 random_forest.cc:812] Training of tree  150/300 (tree index:151) done accuracy:0.741667 logloss:0.601567\n",
      "I0000 00:00:1729625154.037153 6803325 random_forest.cc:812] Training of tree  160/300 (tree index:160) done accuracy:0.75 logloss:0.59951\n",
      "I0000 00:00:1729625154.037309 6803326 random_forest.cc:812] Training of tree  172/300 (tree index:172) done accuracy:0.758333 logloss:0.601544\n",
      "I0000 00:00:1729625154.037440 6803319 random_forest.cc:812] Training of tree  182/300 (tree index:181) done accuracy:0.758333 logloss:0.598359\n",
      "I0000 00:00:1729625154.037602 6803322 random_forest.cc:812] Training of tree  192/300 (tree index:195) done accuracy:0.766667 logloss:0.602036\n",
      "I0000 00:00:1729625154.037730 6803325 random_forest.cc:812] Training of tree  202/300 (tree index:202) done accuracy:0.775 logloss:0.599481\n",
      "I0000 00:00:1729625154.037872 6803325 random_forest.cc:812] Training of tree  212/300 (tree index:211) done accuracy:0.766667 logloss:0.600393\n",
      "I0000 00:00:1729625154.037986 6803319 random_forest.cc:812] Training of tree  222/300 (tree index:223) done accuracy:0.766667 logloss:0.599126\n",
      "I0000 00:00:1729625154.038090 6803324 random_forest.cc:812] Training of tree  232/300 (tree index:232) done accuracy:0.766667 logloss:0.596469\n",
      "I0000 00:00:1729625154.038220 6803320 random_forest.cc:812] Training of tree  242/300 (tree index:241) done accuracy:0.766667 logloss:0.593354\n",
      "I0000 00:00:1729625154.038355 6803320 random_forest.cc:812] Training of tree  252/300 (tree index:253) done accuracy:0.766667 logloss:0.592227\n",
      "I0000 00:00:1729625154.038508 6803322 random_forest.cc:812] Training of tree  262/300 (tree index:264) done accuracy:0.783333 logloss:0.588545\n",
      "I0000 00:00:1729625154.038629 6803323 random_forest.cc:812] Training of tree  272/300 (tree index:271) done accuracy:0.775 logloss:0.586677\n",
      "I0000 00:00:1729625154.038777 6803320 random_forest.cc:812] Training of tree  282/300 (tree index:283) done accuracy:0.783333 logloss:0.586787\n",
      "I0000 00:00:1729625154.038890 6803325 random_forest.cc:812] Training of tree  292/300 (tree index:293) done accuracy:0.783333 logloss:0.583967\n",
      "I0000 00:00:1729625154.038992 6803324 random_forest.cc:812] Training of tree  300/300 (tree index:281) done accuracy:0.775 logloss:0.582626\n",
      "I0000 00:00:1729625154.039108 6803310 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.582626\n",
      "I0000 00:00:1729625154.039409 6803310 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgio0cfun with prefix 3d62b20b9dbf4e59\n",
      "I0000 00:00:1729625154.041356 6803310 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625154.042135 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.582626\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  17\n",
      "2  10  57\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:54.047329: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpgio0cfun/model/ with prefix 3d62b20b9dbf4e59\n",
      "I0000 00:00:1729625154.050447 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2434 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:54.050462: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.144204. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.018808\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp8psnna4c as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625154.326052 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625154.326061 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625154.326069 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625154.326131 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625154.326137 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625154.326192 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.326205 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.326236 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.326249 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.326282 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625154.326301 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625154.326434 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625154.326462 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmprsie3s4b/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625154.326508 6803380 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625154.326666 6803380 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625154.327153 6803393 random_forest.cc:812] Training of tree  1/300 (tree index:4) done accuracy:0.645833 logloss:12.7655\n",
      "I0000 00:00:1729625154.327306 6803392 random_forest.cc:812] Training of tree  11/300 (tree index:0) done accuracy:0.663866 logloss:3.41313\n",
      "I0000 00:00:1729625154.327462 6803393 random_forest.cc:812] Training of tree  22/300 (tree index:21) done accuracy:0.666667 logloss:0.884933\n",
      "I0000 00:00:1729625154.327596 6803390 random_forest.cc:812] Training of tree  33/300 (tree index:32) done accuracy:0.7 logloss:0.589826\n",
      "I0000 00:00:1729625154.327757 6803390 random_forest.cc:812] Training of tree  43/300 (tree index:43) done accuracy:0.683333 logloss:0.603178\n",
      "I0000 00:00:1729625154.327904 6803393 random_forest.cc:812] Training of tree  53/300 (tree index:52) done accuracy:0.691667 logloss:0.604067\n",
      "I0000 00:00:1729625154.328052 6803389 random_forest.cc:812] Training of tree  63/300 (tree index:64) done accuracy:0.725 logloss:0.601506\n",
      "I0000 00:00:1729625154.328157 6803396 random_forest.cc:812] Training of tree  73/300 (tree index:74) done accuracy:0.733333 logloss:0.600263\n",
      "I0000 00:00:1729625154.328282 6803393 random_forest.cc:812] Training of tree  84/300 (tree index:85) done accuracy:0.725 logloss:0.603958\n",
      "I0000 00:00:1729625154.328421 6803391 random_forest.cc:812] Training of tree  94/300 (tree index:94) done accuracy:0.725 logloss:0.587403\n",
      "I0000 00:00:1729625154.328541 6803394 random_forest.cc:812] Training of tree  104/300 (tree index:101) done accuracy:0.725 logloss:0.586666\n",
      "I0000 00:00:1729625154.328657 6803390 random_forest.cc:812] Training of tree  114/300 (tree index:113) done accuracy:0.7 logloss:0.586872\n",
      "I0000 00:00:1729625154.328780 6803395 random_forest.cc:812] Training of tree  124/300 (tree index:106) done accuracy:0.716667 logloss:0.58421\n",
      "I0000 00:00:1729625154.328920 6803391 random_forest.cc:812] Training of tree  134/300 (tree index:133) done accuracy:0.691667 logloss:0.588991\n",
      "I0000 00:00:1729625154.329080 6803396 random_forest.cc:812] Training of tree  145/300 (tree index:138) done accuracy:0.7 logloss:0.590434\n",
      "I0000 00:00:1729625154.329248 6803393 random_forest.cc:812] Training of tree  155/300 (tree index:153) done accuracy:0.708333 logloss:0.592583\n",
      "I0000 00:00:1729625154.329385 6803392 random_forest.cc:812] Training of tree  165/300 (tree index:167) done accuracy:0.708333 logloss:0.588879\n",
      "I0000 00:00:1729625154.329522 6803395 random_forest.cc:812] Training of tree  175/300 (tree index:175) done accuracy:0.741667 logloss:0.586345\n",
      "I0000 00:00:1729625154.329658 6803396 random_forest.cc:812] Training of tree  186/300 (tree index:187) done accuracy:0.725 logloss:0.589033\n",
      "I0000 00:00:1729625154.329788 6803393 random_forest.cc:812] Training of tree  196/300 (tree index:196) done accuracy:0.725 logloss:0.590381\n",
      "I0000 00:00:1729625154.329996 6803395 random_forest.cc:812] Training of tree  206/300 (tree index:203) done accuracy:0.716667 logloss:0.589368\n",
      "I0000 00:00:1729625154.330172 6803390 random_forest.cc:812] Training of tree  216/300 (tree index:216) done accuracy:0.708333 logloss:0.593204\n",
      "I0000 00:00:1729625154.330287 6803394 random_forest.cc:812] Training of tree  226/300 (tree index:225) done accuracy:0.708333 logloss:0.59245\n",
      "I0000 00:00:1729625154.330420 6803389 random_forest.cc:812] Training of tree  236/300 (tree index:236) done accuracy:0.708333 logloss:0.593919\n",
      "I0000 00:00:1729625154.330548 6803391 random_forest.cc:812] Training of tree  246/300 (tree index:248) done accuracy:0.741667 logloss:0.58834\n",
      "I0000 00:00:1729625154.330662 6803395 random_forest.cc:812] Training of tree  256/300 (tree index:256) done accuracy:0.725 logloss:0.5885\n",
      "I0000 00:00:1729625154.330779 6803394 random_forest.cc:812] Training of tree  266/300 (tree index:265) done accuracy:0.725 logloss:0.588038\n",
      "I0000 00:00:1729625154.330896 6803390 random_forest.cc:812] Training of tree  276/300 (tree index:276) done accuracy:0.716667 logloss:0.592127\n",
      "I0000 00:00:1729625154.331018 6803391 random_forest.cc:812] Training of tree  286/300 (tree index:288) done accuracy:0.725 logloss:0.592418\n",
      "I0000 00:00:1729625154.331127 6803389 random_forest.cc:812] Training of tree  296/300 (tree index:296) done accuracy:0.725 logloss:0.59145\n",
      "I0000 00:00:1729625154.331183 6803395 random_forest.cc:812] Training of tree  300/300 (tree index:298) done accuracy:0.725 logloss:0.591725\n",
      "I0000 00:00:1729625154.331253 6803380 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.591725\n",
      "I0000 00:00:1729625154.331581 6803380 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmprsie3s4b with prefix 23ea41f872a24281\n",
      "I0000 00:00:1729625154.333418 6803380 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625154.334071 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.591725\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  34  20\n",
      "2  13  53\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:54.339812: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmprsie3s4b/model/ with prefix 23ea41f872a24281\n",
      "I0000 00:00:1729625154.343042 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2434 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:54.343058: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.183312. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017966\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp651xkhi4 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625154.659062 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625154.659074 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625154.659080 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625154.659151 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625154.659157 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625154.659205 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.659214 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.659219 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.659224 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.659252 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625154.659274 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625154.659411 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625154.659436 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp8psnna4c/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625154.659493 6803447 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625154.659590 6803447 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625154.660156 6803456 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.627907 logloss:13.4116\n",
      "I0000 00:00:1729625154.660279 6803461 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.722689 logloss:3.96193\n",
      "I0000 00:00:1729625154.660399 6803462 random_forest.cc:812] Training of tree  21/300 (tree index:21) done accuracy:0.733333 logloss:1.94335\n",
      "I0000 00:00:1729625154.660517 6803461 random_forest.cc:812] Training of tree  31/300 (tree index:32) done accuracy:0.766667 logloss:1.08104\n",
      "I0000 00:00:1729625154.660641 6803458 random_forest.cc:812] Training of tree  42/300 (tree index:38) done accuracy:0.725 logloss:0.818562\n",
      "I0000 00:00:1729625154.660781 6803461 random_forest.cc:812] Training of tree  52/300 (tree index:50) done accuracy:0.716667 logloss:0.548682\n",
      "I0000 00:00:1729625154.660900 6803460 random_forest.cc:812] Training of tree  62/300 (tree index:59) done accuracy:0.733333 logloss:0.52577\n",
      "I0000 00:00:1729625154.661027 6803458 random_forest.cc:812] Training of tree  72/300 (tree index:73) done accuracy:0.75 logloss:0.516406\n",
      "I0000 00:00:1729625154.661133 6803462 random_forest.cc:812] Training of tree  83/300 (tree index:84) done accuracy:0.75 logloss:0.516807\n",
      "I0000 00:00:1729625154.661253 6803459 random_forest.cc:812] Training of tree  93/300 (tree index:93) done accuracy:0.75 logloss:0.514072\n",
      "I0000 00:00:1729625154.661380 6803458 random_forest.cc:812] Training of tree  103/300 (tree index:104) done accuracy:0.775 logloss:0.508539\n",
      "I0000 00:00:1729625154.661469 6803457 random_forest.cc:812] Training of tree  113/300 (tree index:111) done accuracy:0.775 logloss:0.504472\n",
      "I0000 00:00:1729625154.661598 6803461 random_forest.cc:812] Training of tree  123/300 (tree index:124) done accuracy:0.8 logloss:0.505888\n",
      "I0000 00:00:1729625154.661701 6803457 random_forest.cc:812] Training of tree  133/300 (tree index:133) done accuracy:0.791667 logloss:0.508131\n",
      "I0000 00:00:1729625154.661823 6803458 random_forest.cc:812] Training of tree  143/300 (tree index:145) done accuracy:0.808333 logloss:0.514422\n",
      "I0000 00:00:1729625154.661947 6803463 random_forest.cc:812] Training of tree  153/300 (tree index:152) done accuracy:0.8 logloss:0.512678\n",
      "I0000 00:00:1729625154.662060 6803457 random_forest.cc:812] Training of tree  163/300 (tree index:163) done accuracy:0.8 logloss:0.513824\n",
      "I0000 00:00:1729625154.662161 6803456 random_forest.cc:812] Training of tree  173/300 (tree index:173) done accuracy:0.791667 logloss:0.51337\n",
      "I0000 00:00:1729625154.662286 6803457 random_forest.cc:812] Training of tree  183/300 (tree index:183) done accuracy:0.8 logloss:0.510624\n",
      "I0000 00:00:1729625154.662408 6803462 random_forest.cc:812] Training of tree  193/300 (tree index:194) done accuracy:0.8 logloss:0.51035\n",
      "I0000 00:00:1729625154.662505 6803460 random_forest.cc:812] Training of tree  203/300 (tree index:203) done accuracy:0.8 logloss:0.50737\n",
      "I0000 00:00:1729625154.662628 6803462 random_forest.cc:812] Training of tree  213/300 (tree index:213) done accuracy:0.8 logloss:0.508433\n",
      "I0000 00:00:1729625154.662749 6803456 random_forest.cc:812] Training of tree  223/300 (tree index:223) done accuracy:0.8 logloss:0.51183\n",
      "I0000 00:00:1729625154.662902 6803459 random_forest.cc:812] Training of tree  234/300 (tree index:234) done accuracy:0.808333 logloss:0.508746\n",
      "I0000 00:00:1729625154.663060 6803461 random_forest.cc:812] Training of tree  244/300 (tree index:242) done accuracy:0.791667 logloss:0.510556\n",
      "I0000 00:00:1729625154.663204 6803457 random_forest.cc:812] Training of tree  254/300 (tree index:253) done accuracy:0.8 logloss:0.509196\n",
      "I0000 00:00:1729625154.663367 6803457 random_forest.cc:812] Training of tree  264/300 (tree index:264) done accuracy:0.791667 logloss:0.511462\n",
      "I0000 00:00:1729625154.663501 6803457 random_forest.cc:812] Training of tree  274/300 (tree index:275) done accuracy:0.8 logloss:0.511208\n",
      "I0000 00:00:1729625154.663637 6803456 random_forest.cc:812] Training of tree  284/300 (tree index:286) done accuracy:0.8 logloss:0.510249\n",
      "I0000 00:00:1729625154.663801 6803460 random_forest.cc:812] Training of tree  294/300 (tree index:287) done accuracy:0.8 logloss:0.513009\n",
      "I0000 00:00:1729625154.663852 6803459 random_forest.cc:812] Training of tree  300/300 (tree index:297) done accuracy:0.8 logloss:0.513095\n",
      "I0000 00:00:1729625154.663940 6803447 random_forest.cc:892] Final OOB metrics: accuracy:0.8 logloss:0.513095\n",
      "I0000 00:00:1729625154.664203 6803447 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp8psnna4c with prefix ed1235184a7647ee\n",
      "I0000 00:00:1729625154.666005 6803447 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625154.666595 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.8  CI95[W][0.730419 0.858091]\n",
      "LogLoss: : 0.513095\n",
      "ErrorRate: : 0.2\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  41  15\n",
      "2   9  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:54.671727: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp8psnna4c/model/ with prefix ed1235184a7647ee\n",
      "I0000 00:00:1729625154.674784 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2394 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:54.674799: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.143756. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017954\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "Testing parameters: {'num_trees': 300, 'max_depth': -1, 'min_examples': 20, 'bootstrap_size_ratio': 0.8}\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyfvxvf_v as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625154.949823 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625154.949836 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625154.949840 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625154.949906 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625154.949911 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625154.949955 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.949965 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.949970 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.949976 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625154.950002 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625154.950019 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625154.950172 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625154.950195 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp651xkhi4/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625154.950251 6803515 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625154.950354 6803515 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625154.950959 6803525 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.5 logloss:18.0218\n",
      "I0000 00:00:1729625154.951061 6803528 random_forest.cc:812] Training of tree  11/300 (tree index:11) done accuracy:0.641026 logloss:6.14784\n",
      "I0000 00:00:1729625154.951217 6803528 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.7 logloss:1.45009\n",
      "I0000 00:00:1729625154.951359 6803529 random_forest.cc:812] Training of tree  31/300 (tree index:21) done accuracy:0.691667 logloss:0.8802\n",
      "I0000 00:00:1729625154.951525 6803528 random_forest.cc:812] Training of tree  43/300 (tree index:42) done accuracy:0.733333 logloss:0.861197\n",
      "I0000 00:00:1729625154.951682 6803525 random_forest.cc:812] Training of tree  53/300 (tree index:53) done accuracy:0.758333 logloss:0.8488\n",
      "I0000 00:00:1729625154.951844 6803527 random_forest.cc:812] Training of tree  63/300 (tree index:62) done accuracy:0.758333 logloss:0.838668\n",
      "I0000 00:00:1729625154.952000 6803528 random_forest.cc:812] Training of tree  73/300 (tree index:74) done accuracy:0.75 logloss:0.843392\n",
      "I0000 00:00:1729625154.952151 6803531 random_forest.cc:812] Training of tree  83/300 (tree index:76) done accuracy:0.741667 logloss:0.838644\n",
      "I0000 00:00:1729625154.952263 6803524 random_forest.cc:812] Training of tree  93/300 (tree index:92) done accuracy:0.733333 logloss:0.834192\n",
      "I0000 00:00:1729625154.952468 6803524 random_forest.cc:812] Training of tree  103/300 (tree index:103) done accuracy:0.725 logloss:0.836261\n",
      "I0000 00:00:1729625154.952601 6803530 random_forest.cc:812] Training of tree  113/300 (tree index:115) done accuracy:0.75 logloss:0.831097\n",
      "I0000 00:00:1729625154.952723 6803531 random_forest.cc:812] Training of tree  123/300 (tree index:121) done accuracy:0.758333 logloss:0.828668\n",
      "I0000 00:00:1729625154.952823 6803530 random_forest.cc:812] Training of tree  133/300 (tree index:134) done accuracy:0.775 logloss:0.55866\n",
      "I0000 00:00:1729625154.952975 6803529 random_forest.cc:812] Training of tree  145/300 (tree index:144) done accuracy:0.758333 logloss:0.564428\n",
      "I0000 00:00:1729625154.953154 6803531 random_forest.cc:812] Training of tree  155/300 (tree index:159) done accuracy:0.758333 logloss:0.567348\n",
      "I0000 00:00:1729625154.953281 6803524 random_forest.cc:812] Training of tree  166/300 (tree index:165) done accuracy:0.758333 logloss:0.569437\n",
      "I0000 00:00:1729625154.953499 6803525 random_forest.cc:812] Training of tree  178/300 (tree index:178) done accuracy:0.758333 logloss:0.560787\n",
      "I0000 00:00:1729625154.953651 6803529 random_forest.cc:812] Training of tree  188/300 (tree index:188) done accuracy:0.758333 logloss:0.558681\n",
      "I0000 00:00:1729625154.953786 6803527 random_forest.cc:812] Training of tree  198/300 (tree index:197) done accuracy:0.758333 logloss:0.553259\n",
      "I0000 00:00:1729625154.953950 6803529 random_forest.cc:812] Training of tree  208/300 (tree index:209) done accuracy:0.766667 logloss:0.548775\n",
      "I0000 00:00:1729625154.954068 6803531 random_forest.cc:812] Training of tree  218/300 (tree index:217) done accuracy:0.758333 logloss:0.551224\n",
      "I0000 00:00:1729625154.954219 6803531 random_forest.cc:812] Training of tree  228/300 (tree index:229) done accuracy:0.758333 logloss:0.551424\n",
      "I0000 00:00:1729625154.954309 6803529 random_forest.cc:812] Training of tree  238/300 (tree index:238) done accuracy:0.758333 logloss:0.552698\n",
      "I0000 00:00:1729625154.954426 6803524 random_forest.cc:812] Training of tree  248/300 (tree index:248) done accuracy:0.75 logloss:0.556396\n",
      "I0000 00:00:1729625154.954581 6803526 random_forest.cc:812] Training of tree  258/300 (tree index:252) done accuracy:0.741667 logloss:0.553665\n",
      "I0000 00:00:1729625154.954701 6803524 random_forest.cc:812] Training of tree  269/300 (tree index:268) done accuracy:0.758333 logloss:0.553737\n",
      "I0000 00:00:1729625154.954861 6803528 random_forest.cc:812] Training of tree  279/300 (tree index:278) done accuracy:0.741667 logloss:0.55232\n",
      "I0000 00:00:1729625154.955094 6803525 random_forest.cc:812] Training of tree  289/300 (tree index:290) done accuracy:0.766667 logloss:0.551393\n",
      "I0000 00:00:1729625154.955266 6803528 random_forest.cc:812] Training of tree  299/300 (tree index:295) done accuracy:0.766667 logloss:0.549171\n",
      "I0000 00:00:1729625154.955286 6803527 random_forest.cc:812] Training of tree  300/300 (tree index:293) done accuracy:0.766667 logloss:0.549098\n",
      "I0000 00:00:1729625154.955374 6803515 random_forest.cc:892] Final OOB metrics: accuracy:0.766667 logloss:0.549098\n",
      "I0000 00:00:1729625154.955689 6803515 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp651xkhi4 with prefix 27202fd1401849dd\n",
      "I0000 00:00:1729625154.957566 6803515 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625154.958199 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.766667  CI95[W][0.694361 0.828801]\n",
      "LogLoss: : 0.549098\n",
      "ErrorRate: : 0.233333\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  37  18\n",
      "2  10  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:54.962958: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmp651xkhi4/model/ with prefix 27202fd1401849dd\n",
      "I0000 00:00:1729625154.966044 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 2424 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:54.966057: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.151426. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016567\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqwza18n4 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625155.250365 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625155.250379 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625155.250383 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625155.250448 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625155.250453 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625155.250496 6784195 data_spec_inference.cc:306] 37 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.250505 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.250510 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.250515 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.250542 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487251 min:0.389262 max:0.660377 sd:0.0382633\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31249 min:2.9007 max:4.53589 sd:0.240879\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28833 min:2.79181 max:4.05102 sd:0.244557\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8055 min:46.5302 max:67.517 sd:4.07594\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.8309 min:47.4946 max:110.076 sd:12.6693\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.8198 min:11.1579 max:65.851 sd:9.38618\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.1657 min:26.7884 max:69.8431 sd:9.19257\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.483089 min:0.404991 max:0.594611 sd:0.0338364\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.29386 min:2.66089 max:4.04401 sd:0.232402\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23864 min:2.60926 max:4.27977 sd:0.298851\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.9774 min:43.4876 max:71.3295 sd:4.98085\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.6417 min:48.344 max:176.338 sd:14.7368\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.695 min:23.8329 max:63.3077 sd:9.21885\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1422 min:24.2678 max:110.462 sd:10.1785\n",
      "\t19: \"day_code\" NUMERICAL mean:3.225 min:0 max:6 sd:1.42281\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:75 (62.5%) most-frequent:\"<OOD>\" 75 (62.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:5 (4.16667%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625155.250560 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625155.250694 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625155.250720 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyfvxvf_v/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625155.250765 6803582 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625155.250869 6803582 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625155.251430 6803596 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.531915 logloss:16.8715\n",
      "I0000 00:00:1729625155.251528 6803593 random_forest.cc:812] Training of tree  11/300 (tree index:3) done accuracy:0.672269 logloss:3.15985\n",
      "I0000 00:00:1729625155.251636 6803591 random_forest.cc:812] Training of tree  21/300 (tree index:22) done accuracy:0.65 logloss:1.4403\n",
      "I0000 00:00:1729625155.251730 6803598 random_forest.cc:812] Training of tree  31/300 (tree index:31) done accuracy:0.7 logloss:0.882795\n",
      "I0000 00:00:1729625155.251855 6803598 random_forest.cc:812] Training of tree  41/300 (tree index:42) done accuracy:0.691667 logloss:0.605973\n",
      "I0000 00:00:1729625155.251980 6803596 random_forest.cc:812] Training of tree  51/300 (tree index:52) done accuracy:0.708333 logloss:0.595493\n",
      "I0000 00:00:1729625155.252094 6803598 random_forest.cc:812] Training of tree  61/300 (tree index:62) done accuracy:0.691667 logloss:0.592371\n",
      "I0000 00:00:1729625155.252202 6803596 random_forest.cc:812] Training of tree  71/300 (tree index:72) done accuracy:0.691667 logloss:0.58632\n",
      "I0000 00:00:1729625155.252344 6803595 random_forest.cc:812] Training of tree  81/300 (tree index:80) done accuracy:0.7 logloss:0.58678\n",
      "I0000 00:00:1729625155.252465 6803593 random_forest.cc:812] Training of tree  92/300 (tree index:92) done accuracy:0.683333 logloss:0.582906\n",
      "I0000 00:00:1729625155.252590 6803593 random_forest.cc:812] Training of tree  102/300 (tree index:103) done accuracy:0.675 logloss:0.587526\n",
      "I0000 00:00:1729625155.252687 6803594 random_forest.cc:812] Training of tree  112/300 (tree index:112) done accuracy:0.7 logloss:0.577263\n",
      "I0000 00:00:1729625155.252788 6803596 random_forest.cc:812] Training of tree  122/300 (tree index:122) done accuracy:0.691667 logloss:0.577875\n",
      "I0000 00:00:1729625155.252894 6803597 random_forest.cc:812] Training of tree  132/300 (tree index:131) done accuracy:0.725 logloss:0.576677\n",
      "I0000 00:00:1729625155.252996 6803595 random_forest.cc:812] Training of tree  142/300 (tree index:140) done accuracy:0.725 logloss:0.574156\n",
      "I0000 00:00:1729625155.253145 6803596 random_forest.cc:812] Training of tree  152/300 (tree index:152) done accuracy:0.708333 logloss:0.578438\n",
      "I0000 00:00:1729625155.253255 6803593 random_forest.cc:812] Training of tree  162/300 (tree index:161) done accuracy:0.716667 logloss:0.577\n",
      "I0000 00:00:1729625155.253383 6803596 random_forest.cc:812] Training of tree  172/300 (tree index:171) done accuracy:0.725 logloss:0.575911\n",
      "I0000 00:00:1729625155.253541 6803598 random_forest.cc:812] Training of tree  182/300 (tree index:182) done accuracy:0.716667 logloss:0.57207\n",
      "I0000 00:00:1729625155.253677 6803593 random_forest.cc:812] Training of tree  194/300 (tree index:193) done accuracy:0.725 logloss:0.571387\n",
      "I0000 00:00:1729625155.253787 6803595 random_forest.cc:812] Training of tree  204/300 (tree index:203) done accuracy:0.708333 logloss:0.575278\n",
      "I0000 00:00:1729625155.253882 6803597 random_forest.cc:812] Training of tree  214/300 (tree index:213) done accuracy:0.7 logloss:0.577346\n",
      "I0000 00:00:1729625155.254026 6803594 random_forest.cc:812] Training of tree  224/300 (tree index:224) done accuracy:0.716667 logloss:0.57702\n",
      "I0000 00:00:1729625155.254149 6803595 random_forest.cc:812] Training of tree  234/300 (tree index:233) done accuracy:0.733333 logloss:0.572559\n",
      "I0000 00:00:1729625155.254252 6803594 random_forest.cc:812] Training of tree  245/300 (tree index:243) done accuracy:0.716667 logloss:0.573622\n",
      "I0000 00:00:1729625155.254395 6803593 random_forest.cc:812] Training of tree  255/300 (tree index:245) done accuracy:0.725 logloss:0.574824\n",
      "I0000 00:00:1729625155.254496 6803592 random_forest.cc:812] Training of tree  265/300 (tree index:264) done accuracy:0.725 logloss:0.5758\n",
      "I0000 00:00:1729625155.254589 6803597 random_forest.cc:812] Training of tree  275/300 (tree index:275) done accuracy:0.725 logloss:0.575392\n",
      "I0000 00:00:1729625155.254694 6803591 random_forest.cc:812] Training of tree  285/300 (tree index:284) done accuracy:0.716667 logloss:0.573513\n",
      "I0000 00:00:1729625155.254775 6803597 random_forest.cc:812] Training of tree  295/300 (tree index:295) done accuracy:0.725 logloss:0.573817\n",
      "I0000 00:00:1729625155.254887 6803598 random_forest.cc:812] Training of tree  300/300 (tree index:294) done accuracy:0.725 logloss:0.573882\n",
      "I0000 00:00:1729625155.254957 6803582 random_forest.cc:892] Final OOB metrics: accuracy:0.725 logloss:0.573882\n",
      "I0000 00:00:1729625155.255227 6803582 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyfvxvf_v with prefix 744dfa2825644ca1\n",
      "I0000 00:00:1729625155.256815 6803582 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625155.257477 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.725  CI95[W][0.65003 0.791421]\n",
      "LogLoss: : 0.573882\n",
      "ErrorRate: : 0.275\n",
      "\n",
      "Default Accuracy: : 0.516667\n",
      "Default LogLoss: : 0.692592\n",
      "Default ErrorRate: : 0.483333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  19\n",
      "2  14  48\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:55.262662: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpyfvxvf_v/model/ with prefix 744dfa2825644ca1\n",
      "I0000 00:00:1729625155.265264 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1944 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:55.265281: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.186336. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016657\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpctr3kmdc as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625155.584144 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625155.584154 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625155.584159 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625155.584221 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625155.584226 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625155.584272 6784195 data_spec_inference.cc:306] 42 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.584282 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.584287 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.584292 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.584322 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.489553 min:0.419052 max:0.660377 sd:0.0343448\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.30286 min:2.90472 max:4.53589 sd:0.230337\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2939 min:2.78712 max:4.01048 sd:0.237489\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.8983 min:46.452 max:66.8413 sd:3.95814\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9616 min:47.0412 max:110.076 sd:11.6709\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.3655 min:11.1579 max:66.7931 sd:9.46476\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.5324 min:26.7884 max:68.8521 sd:8.31938\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.484261 min:0.295246 max:0.594611 sd:0.037043\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30454 min:2.11636 max:4.04401 sd:0.258189\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.24882 min:2.19476 max:4.27977 sd:0.316143\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.147 min:36.5793 max:71.3295 sd:5.26905\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:72.457 min:40.946 max:176.338 sd:17.2357\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.9431 min:22.8253 max:63.3077 sd:9.68537\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.1749 min:19.5123 max:110.462 sd:11.691\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.35951\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:85 (70.8333%) most-frequent:\"<OOD>\" 85 (70.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"Australia\" 27 (22.5%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 22 (18.3333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:6 (5%) most-frequent:\"Australia\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625155.584350 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625155.584504 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625155.584525 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqwza18n4/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625155.584577 6803655 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625155.584674 6803655 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625155.585225 6803665 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.433962 logloss:20.4021\n",
      "I0000 00:00:1729625155.585363 6803669 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.596639 logloss:3.8459\n",
      "I0000 00:00:1729625155.585482 6803670 random_forest.cc:812] Training of tree  21/300 (tree index:15) done accuracy:0.65 logloss:1.50461\n",
      "I0000 00:00:1729625155.585627 6803664 random_forest.cc:812] Training of tree  32/300 (tree index:31) done accuracy:0.683333 logloss:1.17982\n",
      "I0000 00:00:1729625155.585760 6803665 random_forest.cc:812] Training of tree  42/300 (tree index:42) done accuracy:0.683333 logloss:0.900438\n",
      "I0000 00:00:1729625155.585855 6803671 random_forest.cc:812] Training of tree  52/300 (tree index:51) done accuracy:0.691667 logloss:0.62695\n",
      "I0000 00:00:1729625155.585956 6803665 random_forest.cc:812] Training of tree  62/300 (tree index:62) done accuracy:0.733333 logloss:0.603171\n",
      "I0000 00:00:1729625155.586088 6803667 random_forest.cc:812] Training of tree  72/300 (tree index:73) done accuracy:0.708333 logloss:0.604414\n",
      "I0000 00:00:1729625155.586165 6803666 random_forest.cc:812] Training of tree  82/300 (tree index:80) done accuracy:0.691667 logloss:0.598921\n",
      "I0000 00:00:1729625155.586262 6803664 random_forest.cc:812] Training of tree  92/300 (tree index:93) done accuracy:0.716667 logloss:0.608096\n",
      "I0000 00:00:1729625155.586379 6803664 random_forest.cc:812] Training of tree  104/300 (tree index:105) done accuracy:0.733333 logloss:0.609754\n",
      "I0000 00:00:1729625155.586537 6803665 random_forest.cc:812] Training of tree  114/300 (tree index:111) done accuracy:0.741667 logloss:0.60965\n",
      "I0000 00:00:1729625155.586683 6803669 random_forest.cc:812] Training of tree  124/300 (tree index:124) done accuracy:0.733333 logloss:0.60924\n",
      "I0000 00:00:1729625155.586826 6803670 random_forest.cc:812] Training of tree  134/300 (tree index:135) done accuracy:0.733333 logloss:0.609401\n",
      "I0000 00:00:1729625155.586975 6803671 random_forest.cc:812] Training of tree  145/300 (tree index:143) done accuracy:0.733333 logloss:0.605008\n",
      "I0000 00:00:1729625155.587088 6803669 random_forest.cc:812] Training of tree  155/300 (tree index:155) done accuracy:0.75 logloss:0.605533\n",
      "I0000 00:00:1729625155.587251 6803666 random_forest.cc:812] Training of tree  165/300 (tree index:165) done accuracy:0.733333 logloss:0.606728\n",
      "I0000 00:00:1729625155.587359 6803664 random_forest.cc:812] Training of tree  175/300 (tree index:174) done accuracy:0.733333 logloss:0.605109\n",
      "I0000 00:00:1729625155.587473 6803668 random_forest.cc:812] Training of tree  185/300 (tree index:189) done accuracy:0.741667 logloss:0.601937\n",
      "I0000 00:00:1729625155.587596 6803665 random_forest.cc:812] Training of tree  196/300 (tree index:196) done accuracy:0.741667 logloss:0.599505\n",
      "I0000 00:00:1729625155.587738 6803670 random_forest.cc:812] Training of tree  206/300 (tree index:203) done accuracy:0.741667 logloss:0.605849\n",
      "I0000 00:00:1729625155.587817 6803671 random_forest.cc:812] Training of tree  216/300 (tree index:215) done accuracy:0.758333 logloss:0.601986\n",
      "I0000 00:00:1729625155.587947 6803667 random_forest.cc:812] Training of tree  226/300 (tree index:225) done accuracy:0.758333 logloss:0.601661\n",
      "I0000 00:00:1729625155.588063 6803665 random_forest.cc:812] Training of tree  236/300 (tree index:235) done accuracy:0.758333 logloss:0.598606\n",
      "I0000 00:00:1729625155.588160 6803670 random_forest.cc:812] Training of tree  246/300 (tree index:247) done accuracy:0.766667 logloss:0.598282\n",
      "I0000 00:00:1729625155.588248 6803665 random_forest.cc:812] Training of tree  256/300 (tree index:254) done accuracy:0.758333 logloss:0.600123\n",
      "I0000 00:00:1729625155.588353 6803670 random_forest.cc:812] Training of tree  266/300 (tree index:266) done accuracy:0.766667 logloss:0.600223\n",
      "I0000 00:00:1729625155.588504 6803664 random_forest.cc:812] Training of tree  277/300 (tree index:268) done accuracy:0.758333 logloss:0.598027\n",
      "I0000 00:00:1729625155.588646 6803669 random_forest.cc:812] Training of tree  288/300 (tree index:289) done accuracy:0.758333 logloss:0.597352\n",
      "I0000 00:00:1729625155.588770 6803668 random_forest.cc:812] Training of tree  299/300 (tree index:298) done accuracy:0.758333 logloss:0.595518\n",
      "I0000 00:00:1729625155.588792 6803666 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.758333 logloss:0.595589\n",
      "I0000 00:00:1729625155.588967 6803655 random_forest.cc:892] Final OOB metrics: accuracy:0.758333 logloss:0.595589\n",
      "I0000 00:00:1729625155.589194 6803655 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqwza18n4 with prefix 425578073f5c459c\n",
      "I0000 00:00:1729625155.590806 6803655 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625155.591440 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.758333  CI95[W][0.685433 0.821389]\n",
      "LogLoss: : 0.595589\n",
      "ErrorRate: : 0.241667\n",
      "\n",
      "Default Accuracy: : 0.558333\n",
      "Default LogLoss: : 0.686326\n",
      "Default ErrorRate: : 0.441667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  17\n",
      "2  12  55\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:55.596619: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpqwza18n4/model/ with prefix 425578073f5c459c\n",
      "I0000 00:00:1729625155.599145 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1954 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:55.599162: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.145470. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017398\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvpd70gn0 as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625155.874321 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625155.874334 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625155.874338 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625155.874409 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625155.874414 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625155.874468 6784195 data_spec_inference.cc:306] 36 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.874489 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.874496 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.874501 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625155.874545 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.485615 min:0.389262 max:0.625129 sd:0.0349563\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.28972 min:2.9007 max:3.7543 sd:0.193249\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.2954 min:2.78712 max:4.05102 sd:0.225396\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9234 min:46.452 max:67.517 sd:3.75661\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.6445 min:47.0412 max:107.229 sd:11.5768\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.705 min:24.1687 max:66.7931 sd:8.38773\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.1111 min:26.7884 max:69.8431 sd:8.09166\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.480392 min:0.295246 max:0.594611 sd:0.0374296\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.2985 min:2.11636 max:4.04401 sd:0.266382\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.25867 min:2.19476 max:3.92544 sd:0.302783\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:54.3112 min:36.5793 max:65.424 sd:5.04637\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.4352 min:40.946 max:142.799 sd:14.3516\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:36.4495 min:22.8253 max:62.5145 sd:9.321\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5427 min:19.5123 max:88.712 sd:9.92143\n",
      "\t19: \"day_code\" NUMERICAL mean:3.20833 min:0 max:6 sd:1.34719\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:9 num-oods:73 (60.8333%) most-frequent:\"<OOD>\" 73 (60.8333%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:9 num-oods:7 (5.83333%) most-frequent:\"Pakistan\" 21 (17.5%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625155.874565 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625155.874714 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625155.874737 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpctr3kmdc/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625155.874799 6803724 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625155.874898 6803724 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625155.875400 6803736 random_forest.cc:812] Training of tree  1/300 (tree index:3) done accuracy:0.45283 logloss:19.722\n",
      "I0000 00:00:1729625155.875498 6803739 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.59292 logloss:7.69388\n",
      "I0000 00:00:1729625155.875667 6803737 random_forest.cc:812] Training of tree  21/300 (tree index:19) done accuracy:0.6 logloss:0.941215\n",
      "I0000 00:00:1729625155.875828 6803738 random_forest.cc:812] Training of tree  31/300 (tree index:30) done accuracy:0.708333 logloss:0.581844\n",
      "I0000 00:00:1729625155.875915 6803736 random_forest.cc:812] Training of tree  41/300 (tree index:41) done accuracy:0.675 logloss:0.609249\n",
      "I0000 00:00:1729625155.876008 6803733 random_forest.cc:812] Training of tree  52/300 (tree index:52) done accuracy:0.675 logloss:0.61221\n",
      "I0000 00:00:1729625155.876124 6803740 random_forest.cc:812] Training of tree  62/300 (tree index:61) done accuracy:0.675 logloss:0.610142\n",
      "I0000 00:00:1729625155.876282 6803733 random_forest.cc:812] Training of tree  72/300 (tree index:71) done accuracy:0.7 logloss:0.611834\n",
      "I0000 00:00:1729625155.876416 6803734 random_forest.cc:812] Training of tree  82/300 (tree index:81) done accuracy:0.708333 logloss:0.606234\n",
      "I0000 00:00:1729625155.876514 6803738 random_forest.cc:812] Training of tree  92/300 (tree index:87) done accuracy:0.708333 logloss:0.606923\n",
      "I0000 00:00:1729625155.876599 6803737 random_forest.cc:812] Training of tree  102/300 (tree index:102) done accuracy:0.7 logloss:0.606844\n",
      "I0000 00:00:1729625155.876698 6803733 random_forest.cc:812] Training of tree  112/300 (tree index:103) done accuracy:0.708333 logloss:0.612985\n",
      "I0000 00:00:1729625155.876801 6803735 random_forest.cc:812] Training of tree  122/300 (tree index:123) done accuracy:0.708333 logloss:0.61343\n",
      "I0000 00:00:1729625155.876901 6803739 random_forest.cc:812] Training of tree  132/300 (tree index:132) done accuracy:0.7 logloss:0.611621\n",
      "I0000 00:00:1729625155.877000 6803736 random_forest.cc:812] Training of tree  142/300 (tree index:141) done accuracy:0.716667 logloss:0.612108\n",
      "I0000 00:00:1729625155.877143 6803733 random_forest.cc:812] Training of tree  154/300 (tree index:154) done accuracy:0.708333 logloss:0.610362\n",
      "I0000 00:00:1729625155.877264 6803738 random_forest.cc:812] Training of tree  164/300 (tree index:163) done accuracy:0.7 logloss:0.609319\n",
      "I0000 00:00:1729625155.877394 6803738 random_forest.cc:812] Training of tree  174/300 (tree index:175) done accuracy:0.691667 logloss:0.614856\n",
      "I0000 00:00:1729625155.877521 6803734 random_forest.cc:812] Training of tree  184/300 (tree index:176) done accuracy:0.691667 logloss:0.610973\n",
      "I0000 00:00:1729625155.877643 6803740 random_forest.cc:812] Training of tree  194/300 (tree index:193) done accuracy:0.683333 logloss:0.611281\n",
      "I0000 00:00:1729625155.877746 6803736 random_forest.cc:812] Training of tree  204/300 (tree index:203) done accuracy:0.675 logloss:0.615684\n",
      "I0000 00:00:1729625155.877869 6803740 random_forest.cc:812] Training of tree  215/300 (tree index:214) done accuracy:0.691667 logloss:0.611384\n",
      "I0000 00:00:1729625155.878000 6803735 random_forest.cc:812] Training of tree  225/300 (tree index:225) done accuracy:0.691667 logloss:0.610001\n",
      "I0000 00:00:1729625155.878117 6803737 random_forest.cc:812] Training of tree  235/300 (tree index:234) done accuracy:0.7 logloss:0.604083\n",
      "I0000 00:00:1729625155.878247 6803737 random_forest.cc:812] Training of tree  245/300 (tree index:244) done accuracy:0.691667 logloss:0.605485\n",
      "I0000 00:00:1729625155.878384 6803734 random_forest.cc:812] Training of tree  255/300 (tree index:257) done accuracy:0.691667 logloss:0.605179\n",
      "I0000 00:00:1729625155.878472 6803737 random_forest.cc:812] Training of tree  265/300 (tree index:263) done accuracy:0.691667 logloss:0.60746\n",
      "I0000 00:00:1729625155.878661 6803733 random_forest.cc:812] Training of tree  276/300 (tree index:274) done accuracy:0.7 logloss:0.605414\n",
      "I0000 00:00:1729625155.878809 6803736 random_forest.cc:812] Training of tree  286/300 (tree index:290) done accuracy:0.691667 logloss:0.605966\n",
      "I0000 00:00:1729625155.878903 6803738 random_forest.cc:812] Training of tree  296/300 (tree index:297) done accuracy:0.7 logloss:0.603866\n",
      "I0000 00:00:1729625155.878969 6803738 random_forest.cc:812] Training of tree  300/300 (tree index:299) done accuracy:0.7 logloss:0.6046\n",
      "I0000 00:00:1729625155.879076 6803724 random_forest.cc:892] Final OOB metrics: accuracy:0.7 logloss:0.6046\n",
      "I0000 00:00:1729625155.879290 6803724 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpctr3kmdc with prefix 541793a0ac8c4b36\n",
      "I0000 00:00:1729625155.880965 6803724 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625155.881688 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.7  CI95[W][0.623778 0.768636]\n",
      "LogLoss: : 0.6046\n",
      "ErrorRate: : 0.3\n",
      "\n",
      "Default Accuracy: : 0.55\n",
      "Default LogLoss: : 0.688139\n",
      "Default ErrorRate: : 0.45\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  32  22\n",
      "2  14  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:55.887593: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpctr3kmdc/model/ with prefix 541793a0ac8c4b36\n",
      "I0000 00:00:1729625155.890118 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1928 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:55.890134: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.146558. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.017358\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpatniwpvc as temporary training directory\n",
      "Warning: Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625156.167934 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625156.167947 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625156.167954 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625156.168018 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625156.168032 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625156.168089 6784195 data_spec_inference.cc:306] 38 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.168102 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.168109 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.168114 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.168144 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.486178 min:0.389262 max:0.660377 sd:0.0344684\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.31417 min:2.9007 max:4.53589 sd:0.23641\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.29949 min:2.78712 max:4.05102 sd:0.251627\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.9915 min:46.452 max:67.517 sd:4.19378\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:69.9059 min:47.0412 max:110.076 sd:12.1338\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.5975 min:11.1579 max:66.7931 sd:9.12519\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:39.569 min:26.7884 max:69.8431 sd:8.89218\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.481272 min:0.295246 max:0.586524 sd:0.037533\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.28668 min:2.11636 max:3.95622 sd:0.246843\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.2323 min:2.19476 max:4.27977 sd:0.322514\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8717 min:36.5793 max:71.3295 sd:5.37523\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:71.5988 min:40.946 max:176.338 sd:17.3462\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.3834 min:22.8253 max:63.3077 sd:9.19881\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:40.5687 min:19.5123 max:110.462 sd:11.6284\n",
      "\t19: \"day_code\" NUMERICAL mean:3.3 min:0 max:6 sd:1.37598\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:8 num-oods:81 (67.5%) most-frequent:\"<OOD>\" 81 (67.5%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:6 (5%) most-frequent:\"England\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:8 num-oods:11 (9.16667%) most-frequent:\"West Indies\" 24 (20%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:9 num-oods:4 (3.33333%) most-frequent:\"drawn\" 23 (19.1667%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625156.168166 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625156.168321 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625156.168348 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvpd70gn0/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625156.168397 6803791 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625156.168492 6803791 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625156.169108 6803807 random_forest.cc:812] Training of tree  1/300 (tree index:0) done accuracy:0.754717 logloss:8.8409\n",
      "I0000 00:00:1729625156.169232 6803804 random_forest.cc:812] Training of tree  11/300 (tree index:12) done accuracy:0.621849 logloss:2.92051\n",
      "I0000 00:00:1729625156.169338 6803807 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.683333 logloss:1.45449\n",
      "I0000 00:00:1729625156.169446 6803805 random_forest.cc:812] Training of tree  31/300 (tree index:31) done accuracy:0.691667 logloss:1.15711\n",
      "I0000 00:00:1729625156.169576 6803806 random_forest.cc:812] Training of tree  41/300 (tree index:40) done accuracy:0.75 logloss:0.570648\n",
      "I0000 00:00:1729625156.169698 6803804 random_forest.cc:812] Training of tree  52/300 (tree index:51) done accuracy:0.741667 logloss:0.582021\n",
      "I0000 00:00:1729625156.169901 6803804 random_forest.cc:812] Training of tree  62/300 (tree index:62) done accuracy:0.725 logloss:0.569897\n",
      "I0000 00:00:1729625156.170060 6803803 random_forest.cc:812] Training of tree  73/300 (tree index:72) done accuracy:0.725 logloss:0.57838\n",
      "I0000 00:00:1729625156.170226 6803806 random_forest.cc:812] Training of tree  83/300 (tree index:85) done accuracy:0.733333 logloss:0.564461\n",
      "I0000 00:00:1729625156.170342 6803800 random_forest.cc:812] Training of tree  93/300 (tree index:93) done accuracy:0.741667 logloss:0.557119\n",
      "I0000 00:00:1729625156.170485 6803806 random_forest.cc:812] Training of tree  103/300 (tree index:102) done accuracy:0.733333 logloss:0.558947\n",
      "I0000 00:00:1729625156.170577 6803804 random_forest.cc:812] Training of tree  113/300 (tree index:112) done accuracy:0.741667 logloss:0.553958\n",
      "I0000 00:00:1729625156.170665 6803800 random_forest.cc:812] Training of tree  123/300 (tree index:121) done accuracy:0.741667 logloss:0.559491\n",
      "I0000 00:00:1729625156.170782 6803805 random_forest.cc:812] Training of tree  133/300 (tree index:133) done accuracy:0.733333 logloss:0.549179\n",
      "I0000 00:00:1729625156.170893 6803807 random_forest.cc:812] Training of tree  143/300 (tree index:143) done accuracy:0.741667 logloss:0.548789\n",
      "I0000 00:00:1729625156.170995 6803800 random_forest.cc:812] Training of tree  153/300 (tree index:142) done accuracy:0.741667 logloss:0.545489\n",
      "I0000 00:00:1729625156.171120 6803803 random_forest.cc:812] Training of tree  163/300 (tree index:162) done accuracy:0.75 logloss:0.547193\n",
      "I0000 00:00:1729625156.171208 6803804 random_forest.cc:812] Training of tree  173/300 (tree index:172) done accuracy:0.741667 logloss:0.548292\n",
      "I0000 00:00:1729625156.171341 6803805 random_forest.cc:812] Training of tree  183/300 (tree index:182) done accuracy:0.741667 logloss:0.546549\n",
      "I0000 00:00:1729625156.171461 6803806 random_forest.cc:812] Training of tree  193/300 (tree index:192) done accuracy:0.75 logloss:0.545484\n",
      "I0000 00:00:1729625156.171661 6803805 random_forest.cc:812] Training of tree  205/300 (tree index:202) done accuracy:0.741667 logloss:0.541807\n",
      "I0000 00:00:1729625156.171809 6803802 random_forest.cc:812] Training of tree  215/300 (tree index:215) done accuracy:0.75 logloss:0.539904\n",
      "I0000 00:00:1729625156.171907 6803800 random_forest.cc:812] Training of tree  225/300 (tree index:224) done accuracy:0.75 logloss:0.537156\n",
      "I0000 00:00:1729625156.172083 6803807 random_forest.cc:812] Training of tree  235/300 (tree index:235) done accuracy:0.758333 logloss:0.533794\n",
      "I0000 00:00:1729625156.172160 6803804 random_forest.cc:812] Training of tree  245/300 (tree index:245) done accuracy:0.758333 logloss:0.534974\n",
      "I0000 00:00:1729625156.172278 6803800 random_forest.cc:812] Training of tree  255/300 (tree index:255) done accuracy:0.766667 logloss:0.534131\n",
      "I0000 00:00:1729625156.172359 6803805 random_forest.cc:812] Training of tree  265/300 (tree index:265) done accuracy:0.766667 logloss:0.533011\n",
      "I0000 00:00:1729625156.172459 6803800 random_forest.cc:812] Training of tree  275/300 (tree index:274) done accuracy:0.75 logloss:0.532389\n",
      "I0000 00:00:1729625156.172579 6803800 random_forest.cc:812] Training of tree  285/300 (tree index:286) done accuracy:0.75 logloss:0.530752\n",
      "I0000 00:00:1729625156.172660 6803806 random_forest.cc:812] Training of tree  295/300 (tree index:295) done accuracy:0.775 logloss:0.529406\n",
      "I0000 00:00:1729625156.172733 6803804 random_forest.cc:812] Training of tree  300/300 (tree index:291) done accuracy:0.775 logloss:0.528174\n",
      "I0000 00:00:1729625156.172869 6803791 random_forest.cc:892] Final OOB metrics: accuracy:0.775 logloss:0.528174\n",
      "I0000 00:00:1729625156.173115 6803791 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvpd70gn0 with prefix 04de0ae95130407b\n",
      "I0000 00:00:1729625156.174720 6803791 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625156.175404 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.775  CI95[W][0.703323 0.836179]\n",
      "LogLoss: : 0.528174\n",
      "ErrorRate: : 0.225\n",
      "\n",
      "Default Accuracy: : 0.533333\n",
      "Default LogLoss: : 0.690923\n",
      "Default ErrorRate: : 0.466667\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  39  17\n",
      "2  10  54\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:56.181095: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpvpd70gn0/model/ with prefix 04de0ae95130407b\n",
      "I0000 00:00:1729625156.183655 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1950 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:56.183693: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n",
      "WARNING:absl:Model constructor argument verboes=0 not supported. See https://www.tensorflow.org/decision_forests/migration for an explanation about the specificities of TF-DF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.183287. Found 120 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.016410\n",
      "Compiling model...\n",
      "Model compiled.\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625156.499638 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625156.499650 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625156.499654 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625156.499718 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625156.499723 6784195 kernel.cc:395] Number of examples: 120\n",
      "I0000 00:00:1729625156.499768 6784195 data_spec_inference.cc:306] 40 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (6 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.499781 6784195 data_spec_inference.cc:306] 3 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.499787 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.499794 6784195 data_spec_inference.cc:306] 4 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (7 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.499822 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 120\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487598 min:0.389262 max:0.660377 sd:0.0361886\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.32413 min:2.9007 max:4.53589 sd:0.236289\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.30215 min:2.78712 max:4.05102 sd:0.245934\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:55.0359 min:46.452 max:67.517 sd:4.09889\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL mean:70.602 min:47.0412 max:110.076 sd:12.6966\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL mean:37.6714 min:11.1579 max:66.7931 sd:9.1677\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL mean:40.0938 min:27.7148 max:69.8431 sd:9.21275\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.48225 min:0.295246 max:0.594611 sd:0.0380072\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.30821 min:2.11636 max:4.04401 sd:0.262708\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.23249 min:2.19476 max:4.27977 sd:0.332729\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.8748 min:36.5793 max:71.3295 sd:5.54549\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL mean:73.4092 min:40.946 max:176.338 sd:17.4381\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL mean:35.1607 min:22.8253 max:63.3077 sd:9.56235\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL mean:41.9177 min:19.5123 max:110.462 sd:12.0139\n",
      "\t19: \"day_code\" NUMERICAL mean:3.25833 min:0 max:6 sd:1.38742\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:7 num-oods:89 (74.1667%) most-frequent:\"<OOD>\" 89 (74.1667%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (4.16667%) most-frequent:\"Australia\" 26 (21.6667%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (3.33333%) most-frequent:\"West Indies\" 25 (20.8333%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:8 num-oods:7 (5.83333%) most-frequent:\"Australia\" 22 (18.3333%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625156.499838 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625156.499989 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: -1\n",
      "    min_examples: 20\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625156.500012 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpatniwpvc/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625156.500068 6803864 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625156.500160 6803864 random_forest.cc:428] Training random forest on 120 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625156.500713 6803873 random_forest.cc:812] Training of tree  1/300 (tree index:1) done accuracy:0.531915 logloss:16.8715\n",
      "I0000 00:00:1729625156.500808 6803876 random_forest.cc:812] Training of tree  11/300 (tree index:10) done accuracy:0.630252 logloss:6.10132\n",
      "I0000 00:00:1729625156.500930 6803874 random_forest.cc:812] Training of tree  21/300 (tree index:20) done accuracy:0.691667 logloss:1.1655\n",
      "I0000 00:00:1729625156.501034 6803873 random_forest.cc:812] Training of tree  31/300 (tree index:31) done accuracy:0.725 logloss:1.14042\n",
      "I0000 00:00:1729625156.501124 6803880 random_forest.cc:812] Training of tree  41/300 (tree index:41) done accuracy:0.683333 logloss:0.869225\n",
      "I0000 00:00:1729625156.501210 6803873 random_forest.cc:812] Training of tree  51/300 (tree index:50) done accuracy:0.675 logloss:0.879647\n",
      "I0000 00:00:1729625156.501331 6803877 random_forest.cc:812] Training of tree  61/300 (tree index:60) done accuracy:0.675 logloss:0.587445\n",
      "I0000 00:00:1729625156.501474 6803880 random_forest.cc:812] Training of tree  74/300 (tree index:73) done accuracy:0.725 logloss:0.580798\n",
      "I0000 00:00:1729625156.501667 6803875 random_forest.cc:812] Training of tree  84/300 (tree index:83) done accuracy:0.708333 logloss:0.57991\n",
      "I0000 00:00:1729625156.501776 6803873 random_forest.cc:812] Training of tree  94/300 (tree index:93) done accuracy:0.708333 logloss:0.582746\n",
      "I0000 00:00:1729625156.501886 6803880 random_forest.cc:812] Training of tree  104/300 (tree index:105) done accuracy:0.691667 logloss:0.584235\n",
      "I0000 00:00:1729625156.501972 6803880 random_forest.cc:812] Training of tree  114/300 (tree index:111) done accuracy:0.716667 logloss:0.579007\n",
      "I0000 00:00:1729625156.502090 6803874 random_forest.cc:812] Training of tree  124/300 (tree index:118) done accuracy:0.7 logloss:0.580299\n",
      "I0000 00:00:1729625156.502188 6803879 random_forest.cc:812] Training of tree  135/300 (tree index:134) done accuracy:0.716667 logloss:0.577876\n",
      "I0000 00:00:1729625156.502329 6803879 random_forest.cc:812] Training of tree  145/300 (tree index:146) done accuracy:0.725 logloss:0.575012\n",
      "I0000 00:00:1729625156.502479 6803880 random_forest.cc:812] Training of tree  155/300 (tree index:154) done accuracy:0.725 logloss:0.577573\n",
      "I0000 00:00:1729625156.502603 6803878 random_forest.cc:812] Training of tree  165/300 (tree index:163) done accuracy:0.716667 logloss:0.573609\n",
      "I0000 00:00:1729625156.502727 6803873 random_forest.cc:812] Training of tree  175/300 (tree index:172) done accuracy:0.716667 logloss:0.578348\n",
      "I0000 00:00:1729625156.502862 6803877 random_forest.cc:812] Training of tree  185/300 (tree index:184) done accuracy:0.708333 logloss:0.577821\n",
      "I0000 00:00:1729625156.503022 6803879 random_forest.cc:812] Training of tree  196/300 (tree index:193) done accuracy:0.708333 logloss:0.574203\n",
      "I0000 00:00:1729625156.503124 6803874 random_forest.cc:812] Training of tree  206/300 (tree index:205) done accuracy:0.708333 logloss:0.573608\n",
      "I0000 00:00:1729625156.503242 6803879 random_forest.cc:812] Training of tree  216/300 (tree index:216) done accuracy:0.725 logloss:0.573009\n",
      "I0000 00:00:1729625156.503388 6803880 random_forest.cc:812] Training of tree  227/300 (tree index:227) done accuracy:0.725 logloss:0.571885\n",
      "I0000 00:00:1729625156.503538 6803879 random_forest.cc:812] Training of tree  237/300 (tree index:239) done accuracy:0.725 logloss:0.569117\n",
      "I0000 00:00:1729625156.503641 6803875 random_forest.cc:812] Training of tree  247/300 (tree index:247) done accuracy:0.725 logloss:0.570008\n",
      "I0000 00:00:1729625156.503765 6803877 random_forest.cc:812] Training of tree  257/300 (tree index:249) done accuracy:0.708333 logloss:0.56976\n",
      "I0000 00:00:1729625156.503893 6803874 random_forest.cc:812] Training of tree  267/300 (tree index:267) done accuracy:0.725 logloss:0.569952\n",
      "I0000 00:00:1729625156.504016 6803874 random_forest.cc:812] Training of tree  277/300 (tree index:278) done accuracy:0.725 logloss:0.567155\n",
      "I0000 00:00:1729625156.504110 6803876 random_forest.cc:812] Training of tree  287/300 (tree index:287) done accuracy:0.733333 logloss:0.567871\n",
      "I0000 00:00:1729625156.504250 6803877 random_forest.cc:812] Training of tree  297/300 (tree index:297) done accuracy:0.733333 logloss:0.564161\n",
      "I0000 00:00:1729625156.504326 6803880 random_forest.cc:812] Training of tree  300/300 (tree index:293) done accuracy:0.733333 logloss:0.562626\n",
      "I0000 00:00:1729625156.504381 6803864 random_forest.cc:892] Final OOB metrics: accuracy:0.733333 logloss:0.562626\n",
      "I0000 00:00:1729625156.504603 6803864 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpatniwpvc with prefix 745524bfda134278\n",
      "I0000 00:00:1729625156.506223 6803864 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625156.507340 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 120\n",
      "Number of predictions (with weights): 120\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.733333  CI95[W][0.658836 0.798959]\n",
      "LogLoss: : 0.562626\n",
      "ErrorRate: : 0.266667\n",
      "\n",
      "Default Accuracy: : 0.541667\n",
      "Default LogLoss: : 0.689671\n",
      "Default ErrorRate: : 0.458333\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  36  19\n",
      "2  13  52\n",
      "Total: 120\n",
      "\n",
      "\n",
      "2024-10-22 20:25:56.511896: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpatniwpvc/model/ with prefix 745524bfda134278\n",
      "I0000 00:00:1729625156.514415 6784195 decision_forest.cc:761] Model loaded with 300 root(s), 1930 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:56.514432: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    }
   ],
   "source": [
    "best_params, tuning_results = tune_hyperparameters(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters (optimized for precision):\n",
      "num_trees               200.000000\n",
      "max_depth                20.000000\n",
      "min_examples              5.000000\n",
      "bootstrap_size_ratio      0.800000\n",
      "mean_precision            0.805817\n",
      "std_precision             0.077383\n",
      "mean_avg_precision        0.897798\n",
      "std_avg_precision         0.064319\n",
      "Name: 19, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Parameters (optimized for precision):\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzmjvf14n as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.168366. Found 238 examples.\n",
      "Training model...\n",
      "Model trained in 0:00:00.030043\n",
      "Compiling model...\n",
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729625156.850862 6784195 kernel.cc:774] Start Yggdrasil model training\n",
      "I0000 00:00:1729625156.850872 6784195 kernel.cc:775] Collect training examples\n",
      "I0000 00:00:1729625156.850877 6784195 kernel.cc:787] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1729625156.850941 6784195 kernel.cc:394] Number of batches: 1\n",
      "I0000 00:00:1729625156.850946 6784195 kernel.cc:395] Number of examples: 238\n",
      "I0000 00:00:1729625156.851020 6784195 data_spec_inference.cc:306] 43 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ground (26 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.851037 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_A (9 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.851043 6784195 data_spec_inference.cc:306] 1 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Team_B (10 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.851049 6784195 data_spec_inference.cc:306] 2 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Winner (10 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1729625156.851090 6784195 kernel.cc:794] Training dataset:\n",
      "Number of records: 238\n",
      "Number of columns: 20\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 15 (75%)\n",
      "\tCATEGORICAL: 5 (25%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 15 (75%)\n",
      "\t2: \"Team_A_BP_rolling\" NUMERICAL mean:0.487076 min:0.389262 max:0.660377 sd:0.0331707\n",
      "\t3: \"Team_A_ER_rolling\" NUMERICAL mean:3.26094 min:2.63125 max:4.53589 sd:0.229439\n",
      "\t4: \"Team_A_RR_rolling\" NUMERICAL mean:3.28914 min:2.57162 max:4.05102 sd:0.227356\n",
      "\t5: \"Team_A_SR_rolling\" NUMERICAL mean:54.819 min:42.8603 max:67.517 sd:3.78927\n",
      "\t6: \"Team_A_balls_per_wicket_rolling\" NUMERICAL num-nas:11 (4.62185%) mean:67.8225 min:44.2373 max:166.5 sd:13.6478\n",
      "\t7: \"Team_A_batting_average_rolling\" NUMERICAL num-nas:23 (9.66387%) mean:37.6842 min:11.1579 max:66.7931 sd:8.51428\n",
      "\t8: \"Team_A_bowling_average_rolling\" NUMERICAL num-nas:11 (4.62185%) mean:37.8822 min:21.885 max:96 sd:9.43531\n",
      "\t10: \"Team_B_BP_rolling\" NUMERICAL mean:0.482142 min:0.295246 max:0.594611 sd:0.0373709\n",
      "\t11: \"Team_B_ER_rolling\" NUMERICAL mean:3.23217 min:2.11636 max:4.04401 sd:0.265046\n",
      "\t12: \"Team_B_RR_rolling\" NUMERICAL mean:3.21072 min:2.19476 max:4.27977 sd:0.297291\n",
      "\t13: \"Team_B_SR_rolling\" NUMERICAL mean:53.512 min:36.5793 max:71.3295 sd:4.95486\n",
      "\t14: \"Team_B_balls_per_wicket_rolling\" NUMERICAL num-nas:35 (14.7059%) mean:69.2812 min:40.946 max:176.338 sd:16.1446\n",
      "\t15: \"Team_B_batting_average_rolling\" NUMERICAL num-nas:27 (11.3445%) mean:35.0849 min:19.712 max:63.3077 sd:8.67718\n",
      "\t16: \"Team_B_bowling_average_rolling\" NUMERICAL num-nas:35 (14.7059%) mean:38.943 min:19.5123 max:110.462 sd:11.1408\n",
      "\t19: \"day_code\" NUMERICAL mean:3.31933 min:0 max:6 sd:1.29597\n",
      "\n",
      "CATEGORICAL: 5 (25%)\n",
      "\t0: \"Ground\" CATEGORICAL has-dict vocab-size:27 num-oods:83 (34.8739%) most-frequent:\"<OOD>\" 83 (34.8739%)\n",
      "\t1: \"Team_A\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (1.68067%) most-frequent:\"England\" 52 (21.8487%)\n",
      "\t9: \"Team_B\" CATEGORICAL has-dict vocab-size:11 num-oods:3 (1.2605%) most-frequent:\"Sri Lanka\" 40 (16.8067%)\n",
      "\t17: \"Winner\" CATEGORICAL has-dict vocab-size:11 num-oods:3 (1.2605%) most-frequent:\"England\" 34 (14.2857%)\n",
      "\t18: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1729625156.851115 6784195 kernel.cc:810] Configure learner\n",
      "I0000 00:00:1729625156.851251 6784195 kernel.cc:824] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^Ground$\"\n",
      "features: \"^Team_A$\"\n",
      "features: \"^Team_A_BP_rolling$\"\n",
      "features: \"^Team_A_ER_rolling$\"\n",
      "features: \"^Team_A_RR_rolling$\"\n",
      "features: \"^Team_A_SR_rolling$\"\n",
      "features: \"^Team_A_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_A_batting_average_rolling$\"\n",
      "features: \"^Team_A_bowling_average_rolling$\"\n",
      "features: \"^Team_B$\"\n",
      "features: \"^Team_B_BP_rolling$\"\n",
      "features: \"^Team_B_ER_rolling$\"\n",
      "features: \"^Team_B_RR_rolling$\"\n",
      "features: \"^Team_B_SR_rolling$\"\n",
      "features: \"^Team_B_balls_per_wicket_rolling$\"\n",
      "features: \"^Team_B_batting_average_rolling$\"\n",
      "features: \"^Team_B_bowling_average_rolling$\"\n",
      "features: \"^Winner$\"\n",
      "features: \"^day_code$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 200\n",
      "  decision_tree {\n",
      "    max_depth: 20\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 0.8\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "I0000 00:00:1729625156.851277 6784195 kernel.cc:827] Deployment config:\n",
      "cache_path: \"/var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzmjvf14n/working_cache\"\n",
      "num_threads: 8\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1729625156.851338 6803940 kernel.cc:888] Train model\n",
      "I0000 00:00:1729625156.851430 6803940 random_forest.cc:428] Training random forest on 238 example(s) and 19 feature(s).\n",
      "I0000 00:00:1729625156.852211 6803949 random_forest.cc:812] Training of tree  1/200 (tree index:0) done accuracy:0.633929 logloss:13.1946\n",
      "I0000 00:00:1729625156.852507 6803951 random_forest.cc:812] Training of tree  11/200 (tree index:11) done accuracy:0.697479 logloss:1.49266\n",
      "I0000 00:00:1729625156.852824 6803955 random_forest.cc:812] Training of tree  21/200 (tree index:19) done accuracy:0.773109 logloss:0.607259\n",
      "I0000 00:00:1729625156.853109 6803949 random_forest.cc:812] Training of tree  31/200 (tree index:33) done accuracy:0.777311 logloss:0.468684\n",
      "I0000 00:00:1729625156.853423 6803953 random_forest.cc:812] Training of tree  41/200 (tree index:41) done accuracy:0.806723 logloss:0.459823\n",
      "I0000 00:00:1729625156.853734 6803950 random_forest.cc:812] Training of tree  51/200 (tree index:49) done accuracy:0.773109 logloss:0.469094\n",
      "I0000 00:00:1729625156.854048 6803954 random_forest.cc:812] Training of tree  62/200 (tree index:61) done accuracy:0.802521 logloss:0.456157\n",
      "I0000 00:00:1729625156.854373 6803953 random_forest.cc:812] Training of tree  72/200 (tree index:71) done accuracy:0.819328 logloss:0.446455\n",
      "I0000 00:00:1729625156.854726 6803954 random_forest.cc:812] Training of tree  82/200 (tree index:85) done accuracy:0.823529 logloss:0.442783\n",
      "I0000 00:00:1729625156.855020 6803955 random_forest.cc:812] Training of tree  92/200 (tree index:91) done accuracy:0.819328 logloss:0.442534\n",
      "I0000 00:00:1729625156.855323 6803953 random_forest.cc:812] Training of tree  102/200 (tree index:103) done accuracy:0.831933 logloss:0.43712\n",
      "I0000 00:00:1729625156.855609 6803951 random_forest.cc:812] Training of tree  113/200 (tree index:113) done accuracy:0.836134 logloss:0.436419\n",
      "I0000 00:00:1729625156.855937 6803949 random_forest.cc:812] Training of tree  123/200 (tree index:124) done accuracy:0.831933 logloss:0.436761\n",
      "I0000 00:00:1729625156.856265 6803949 random_forest.cc:812] Training of tree  136/200 (tree index:136) done accuracy:0.836134 logloss:0.432396\n",
      "I0000 00:00:1729625156.856659 6803951 random_forest.cc:812] Training of tree  146/200 (tree index:145) done accuracy:0.823529 logloss:0.433001\n",
      "I0000 00:00:1729625156.856988 6803951 random_forest.cc:812] Training of tree  156/200 (tree index:159) done accuracy:0.827731 logloss:0.431353\n",
      "I0000 00:00:1729625156.857304 6803955 random_forest.cc:812] Training of tree  168/200 (tree index:167) done accuracy:0.831933 logloss:0.430534\n",
      "I0000 00:00:1729625156.857678 6803951 random_forest.cc:812] Training of tree  178/200 (tree index:176) done accuracy:0.823529 logloss:0.433861\n",
      "I0000 00:00:1729625156.857980 6803956 random_forest.cc:812] Training of tree  188/200 (tree index:188) done accuracy:0.823529 logloss:0.434462\n",
      "I0000 00:00:1729625156.858304 6803950 random_forest.cc:812] Training of tree  199/200 (tree index:193) done accuracy:0.827731 logloss:0.435518\n",
      "I0000 00:00:1729625156.858372 6803952 random_forest.cc:812] Training of tree  200/200 (tree index:199) done accuracy:0.823529 logloss:0.435427\n",
      "I0000 00:00:1729625156.858442 6803940 random_forest.cc:892] Final OOB metrics: accuracy:0.823529 logloss:0.435427\n",
      "I0000 00:00:1729625156.859113 6803940 kernel.cc:920] Export model in log directory: /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzmjvf14n with prefix 02e0529efe654d01\n",
      "I0000 00:00:1729625156.862550 6803940 kernel.cc:938] Save model in resources\n",
      "I0000 00:00:1729625156.863266 6784195 abstract_model.cc:833] Model self evaluation:\n",
      "Number of predictions (without weights): 238\n",
      "Number of predictions (with weights): 238\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.823529  CI95[W][0.777819 0.863086]\n",
      "LogLoss: : 0.435427\n",
      "ErrorRate: : 0.176471\n",
      "\n",
      "Default Accuracy: : 0.521008\n",
      "Default LogLoss: : 0.692264\n",
      "Default ErrorRate: : 0.478992\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1    2\n",
      "1  95   19\n",
      "2  23  101\n",
      "Total: 238\n",
      "\n",
      "\n",
      "2024-10-22 20:25:56.870104: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1234] Loading model from path /var/folders/48/k3gz2zq969q95y9yr9kffq580000gn/T/tmpzmjvf14n/model/ with prefix 02e0529efe654d01\n",
      "I0000 00:00:1729625156.878368 6784195 decision_forest.cc:761] Model loaded with 200 root(s), 6124 node(s), and 19 input feature(s).\n",
      "2024-10-22 20:25:56.878385: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1062] Use fast generic engine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x3825a1c10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = tfdf.keras.RandomForestModel(\n",
    "    num_trees=int(best_params['num_trees']),\n",
    "    max_depth=int(best_params['max_depth']),\n",
    "    min_examples=int(best_params['min_examples']),\n",
    "    bootstrap_size_ratio=best_params['bootstrap_size_ratio'],\n",
    "    task=tfdf.keras.Task.CLASSIFICATION\n",
    ")\n",
    "\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "                train_df, label='target', task=tfdf.keras.Task.CLASSIFICATION\n",
    "            )\n",
    "\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "                test_df, label='target', task=tfdf.keras.Task.CLASSIFICATION\n",
    "            )\n",
    "\n",
    "final_model.fit(train_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8205128205128205"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = final_model.predict(test_ds)\n",
    "y_pred_binary = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "precision_score(y_pred_binary, test_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction   0   1\n",
       "actual            \n",
       "0           65   6\n",
       "1           14  64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.DataFrame(dict(actual=test_df['target'], prediction=y_pred_binary.flatten()))\n",
    "pd.crosstab(index=combined['actual'], columns=combined['prediction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
